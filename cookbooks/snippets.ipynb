{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install fastkaggle if not available\n",
    "try: import fastkaggle\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -Uq fastkaggle\n",
    "\n",
    "from fastkaggle import *\n",
    "\n",
    "from fastai.imports import *\n",
    "np.set_printoptions(linewidth=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def report_gpu():\n",
    "    print(torch.cuda.list_gpu_processes())\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(columns=[''])\n",
    "\n",
    "def track_results(experiment_name, result, reset=False):\n",
    "    global results_df\n",
    "    if reset:\n",
    "        results_df = pd.DataFrame(columns=[''])\n",
    "    if hasattr(result, '__dict__') and '__str__' in result.__dict__:\n",
    "        results_df.loc[experiment_name] = result\n",
    "    else:\n",
    "        results_df.loc[experiment_name] = repr(result)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = GradientAccumulation(64)\n",
    "learn = vision_learner(dls, arch, metrics=error_rate, cbs=cbs).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_last_text_batch(dls):\n",
    "    last_batch = None\n",
    "    for batch in dls.train:\n",
    "        last_batch = batch\n",
    "    x, y = last_batch\n",
    "\n",
    "    # Get the vocabulary from the DataLoader\n",
    "    vocab = dls.vocab\n",
    "\n",
    "    # Function to convert indices to text\n",
    "    def indices_to_text(indices):\n",
    "        return ' '.join([vocab[it] for it in indices])\n",
    "\n",
    "    # Convert and print the first input sequence in the batch\n",
    "    print(indices_to_text(x[0]), ' | ', indices_to_text(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 63\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from the data dictionary\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m---> 63\u001b[0m display_learn_model_stats(\u001b[43mlearn\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def display_learn_model_stats(learn):\n",
    "    # Initialize the data dictionary\n",
    "    data = {\n",
    "        'Layer': [],\n",
    "        'Weights': [],\n",
    "        'Conv Size': [],\n",
    "        'Activation Cells': [],\n",
    "        'Multiplications': []\n",
    "    }\n",
    "\n",
    "    # Get initial conv_size from the data loader\n",
    "    conv_size = dls.one_batch()[0].shape[-1]\n",
    "\n",
    "    # Store the previous activation cells, initialized to the input size\n",
    "    prev_activation_cells = conv_size ** 2\n",
    "\n",
    "    # Iterate through the model layers\n",
    "    for i, layer in enumerate(learn.model.children()):\n",
    "        # Check if the layer is a Sequential or Conv2d\n",
    "        if isinstance(layer, nn.Sequential):\n",
    "            conv_layer = layer[0]\n",
    "        elif isinstance(layer, nn.Conv2d):\n",
    "            conv_layer = layer\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if not isinstance(conv_layer, nn.Conv2d):\n",
    "            continue\n",
    "        \n",
    "        layer_name = f'Layer {i+1}'\n",
    "        data['Layer'].append(layer_name)\n",
    "        \n",
    "        # Calculate weights (number of parameters in the convolutional layer)\n",
    "        weights = np.prod(conv_layer.weight.shape) + conv_layer.bias.shape[0]\n",
    "        data['Weights'].append(weights)\n",
    "        \n",
    "        # Update conv_size based on the current layer parameters\n",
    "        kernel_size = conv_layer.kernel_size[0]\n",
    "        stride = conv_layer.stride[0]\n",
    "        padding = conv_layer.padding[0]\n",
    "        \n",
    "        conv_size = (conv_size - kernel_size + 2 * padding) // stride + 1\n",
    "        data['Conv Size'].append(conv_size)\n",
    "        \n",
    "        # Calculate activation cells (number of cells in the feature map)\n",
    "        activation_cells = conv_size ** 2\n",
    "        data['Activation Cells'].append(activation_cells)\n",
    "        \n",
    "        # Calculate multiplications\n",
    "        multiplications = weights * prev_activation_cells\n",
    "        data['Multiplications'].append(multiplications)\n",
    "        \n",
    "        # Update prev_activation_cells for the next iteration\n",
    "        prev_activation_cells = activation_cells\n",
    "\n",
    "    # Create a DataFrame from the data dictionary\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "display_learn_model_stats(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def torch_show_img(tns, title=''):\n",
    "    if tns.ndim == 1:  # If rank 1, reshape to 2D assuming it's a 28x28 image\n",
    "        tns = tns.reshape(28, 28)\n",
    "    show_image(torch.tensor(tns), title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def np_show_img(array, title=''):\n",
    "    if array.ndim == 1:  # If rank 1, reshape to 2D\n",
    "        array = array.reshape(28, 28)\n",
    "    plt.imshow(array, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 3, 784])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape image tensor\n",
    "import torch\n",
    "\n",
    "image_tns = torch.randn((2000, 3, 28, 28))\n",
    "m, c, h, w = image_tns.shape\n",
    "image_tensor = image_tns.view(m, c, h * w)\n",
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
