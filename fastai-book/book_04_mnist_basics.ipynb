{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('/Users/cactus/.fastai/data/mnist_sample/valid'),Path('/Users/cactus/.fastai/data/mnist_sample/labels.csv'),Path('/Users/cactus/.fastai/data/mnist_sample/train')]"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.data.external import untar_data, URLs\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/Users/cactus/.fastai/data/mnist_sample/train/7'),Path('/Users/cactus/.fastai/data/mnist_sample/train/3')]"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('/Users/cactus/.fastai/data/mnist_sample/train/3/10.png'),Path('/Users/cactus/.fastai/data/mnist_sample/train/3/10000.png'),Path('/Users/cactus/.fastai/data/mnist_sample/train/3/10011.png'),Path('/Users/cactus/.fastai/data/mnist_sample/train/3/10031.png'),Path('/Users/cactus/.fastai/data/mnist_sample/train/3/10034.png'),Path('/Users/cactus/.fastai/data/mnist_sample/train/3/10042.png'),Path('/Users/cactus/.fastai/data/mnist_sample/train/3/10052.png'),Path('/Users/cactus/.fastai/data/mnist_sample/train/3/1007.png'),Path('/Users/cactus/.fastai/data/mnist_sample/train/3/10074.png'),Path('/Users/cactus/.fastai/data/mnist_sample/train/3/10091.png')...]"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APCdP02+1a8W006znu7l+VigjLsQOpwO1dlb/CjVnkS3vNb8O6dqDkKtheaiFn3Hou1QcE8YBPcVg+LfCGqeCtYXS9WEPnvEJlML7lKEkA547qawatafqd/pN2LvTb24s7lQQJbeQowB6jI5r1D4Y6b4OvdXtdf8S+K45NY85phY3W6MeaCdrSTNw3IDcd8ZzyKx/i5pXiiLxMNZ8RC1kjvx/os1nJvh2KOFU8HgEHkc5zXntWdP0681a/hsbC3kubqY7Y4oxlmPXiu68OfBzxPq1yJNVtW0XTI/mnu73CbF74UkEn64HvVn4r+LdI1GDR/C3h2QzaTosXli5JJ858BeM9QAOvck9sV5nU1rdXFjdR3VpPLb3ETbo5YnKOh9QRyDV7UfE2v6vbi31PXNSvYA24RXN3JIufXDEjNZdFf/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9UlEQVR4AWNgGGSAEe4e2Upda8b/mwSvnloAF4MyDJY9+Pv31ZG/QPASTS72y8+/u/W4OFi4DiFLsoCV8XEyvCy9BGT++cfAsBlNJ7OICD9YSPvB369eaJJw7s+/X+vgHBQGX+r9vz9qUIRgHO5l74FO3S0H46PQAj9+gTzy4mo+E4o4lKOdlHQBJL9bDJssAwOncTlQ1ge7JAMD4/a/f7uhkhjm///PwHAXl87Qn3//quCQtLn29+9abuySSd///n3EiVVOa9ofYKSYostpFWvZFM//8Pfvr/WS6HIMu0GeB4KjYRhSDAzpYKkXzohUg0URtYQA/HZrR+ekLi0AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 934,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_path = threes[1]\n",
    "im3 = Image.open(im3_path)\n",
    "im3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  29],\n",
       "       [  0,   0,   0,  48, 166, 224],\n",
       "       [  0,  93, 244, 249, 253, 187],\n",
       "       [  0, 107, 253, 253, 230,  48],\n",
       "       [  0,   3,  20,  20,  15,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 935,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  29],\n",
       "        [  0,   0,   0,  48, 166, 224],\n",
       "        [  0,  93, 244, 249, 253, 187],\n",
       "        [  0, 107, 253, 253, 230,  48],\n",
       "        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dda8b_row0_col0, #T_dda8b_row0_col1, #T_dda8b_row0_col2, #T_dda8b_row0_col3, #T_dda8b_row0_col4, #T_dda8b_row0_col5, #T_dda8b_row0_col6, #T_dda8b_row0_col7, #T_dda8b_row0_col8, #T_dda8b_row0_col9, #T_dda8b_row0_col10, #T_dda8b_row0_col11, #T_dda8b_row0_col12, #T_dda8b_row0_col13, #T_dda8b_row0_col14, #T_dda8b_row0_col15, #T_dda8b_row0_col16, #T_dda8b_row0_col17, #T_dda8b_row0_col18, #T_dda8b_row0_col19, #T_dda8b_row0_col20, #T_dda8b_row0_col21, #T_dda8b_row0_col22, #T_dda8b_row0_col23, #T_dda8b_row0_col24, #T_dda8b_row0_col25, #T_dda8b_row0_col26, #T_dda8b_row0_col27, #T_dda8b_row1_col0, #T_dda8b_row1_col1, #T_dda8b_row1_col2, #T_dda8b_row1_col3, #T_dda8b_row1_col4, #T_dda8b_row1_col5, #T_dda8b_row1_col6, #T_dda8b_row1_col7, #T_dda8b_row1_col8, #T_dda8b_row1_col9, #T_dda8b_row1_col10, #T_dda8b_row1_col11, #T_dda8b_row1_col12, #T_dda8b_row1_col13, #T_dda8b_row1_col14, #T_dda8b_row1_col15, #T_dda8b_row1_col16, #T_dda8b_row1_col17, #T_dda8b_row1_col18, #T_dda8b_row1_col19, #T_dda8b_row1_col20, #T_dda8b_row1_col21, #T_dda8b_row1_col22, #T_dda8b_row1_col23, #T_dda8b_row1_col24, #T_dda8b_row1_col25, #T_dda8b_row1_col26, #T_dda8b_row1_col27, #T_dda8b_row2_col0, #T_dda8b_row2_col1, #T_dda8b_row2_col2, #T_dda8b_row2_col3, #T_dda8b_row2_col4, #T_dda8b_row2_col5, #T_dda8b_row2_col6, #T_dda8b_row2_col7, #T_dda8b_row2_col8, #T_dda8b_row2_col9, #T_dda8b_row2_col10, #T_dda8b_row2_col11, #T_dda8b_row2_col12, #T_dda8b_row2_col13, #T_dda8b_row2_col14, #T_dda8b_row2_col15, #T_dda8b_row2_col16, #T_dda8b_row2_col17, #T_dda8b_row2_col18, #T_dda8b_row2_col19, #T_dda8b_row2_col20, #T_dda8b_row2_col21, #T_dda8b_row2_col22, #T_dda8b_row2_col23, #T_dda8b_row2_col24, #T_dda8b_row2_col25, #T_dda8b_row2_col26, #T_dda8b_row2_col27, #T_dda8b_row3_col0, #T_dda8b_row3_col1, #T_dda8b_row3_col2, #T_dda8b_row3_col3, #T_dda8b_row3_col4, #T_dda8b_row3_col5, #T_dda8b_row3_col6, #T_dda8b_row3_col7, #T_dda8b_row3_col8, #T_dda8b_row3_col9, #T_dda8b_row3_col10, #T_dda8b_row3_col11, #T_dda8b_row3_col12, #T_dda8b_row3_col13, #T_dda8b_row3_col14, #T_dda8b_row3_col15, #T_dda8b_row3_col16, #T_dda8b_row3_col17, #T_dda8b_row3_col18, #T_dda8b_row3_col19, #T_dda8b_row3_col20, #T_dda8b_row3_col21, #T_dda8b_row3_col22, #T_dda8b_row3_col23, #T_dda8b_row3_col24, #T_dda8b_row3_col25, #T_dda8b_row3_col26, #T_dda8b_row3_col27, #T_dda8b_row4_col0, #T_dda8b_row4_col1, #T_dda8b_row4_col2, #T_dda8b_row4_col3, #T_dda8b_row4_col4, #T_dda8b_row4_col5, #T_dda8b_row4_col6, #T_dda8b_row4_col7, #T_dda8b_row4_col8, #T_dda8b_row4_col9, #T_dda8b_row4_col10, #T_dda8b_row4_col11, #T_dda8b_row4_col12, #T_dda8b_row4_col13, #T_dda8b_row4_col14, #T_dda8b_row4_col15, #T_dda8b_row4_col16, #T_dda8b_row4_col17, #T_dda8b_row4_col18, #T_dda8b_row4_col19, #T_dda8b_row4_col20, #T_dda8b_row4_col21, #T_dda8b_row4_col22, #T_dda8b_row4_col23, #T_dda8b_row4_col24, #T_dda8b_row4_col25, #T_dda8b_row4_col26, #T_dda8b_row4_col27, #T_dda8b_row5_col0, #T_dda8b_row5_col1, #T_dda8b_row5_col2, #T_dda8b_row5_col3, #T_dda8b_row5_col4, #T_dda8b_row5_col5, #T_dda8b_row5_col6, #T_dda8b_row5_col7, #T_dda8b_row5_col8, #T_dda8b_row5_col19, #T_dda8b_row5_col20, #T_dda8b_row5_col21, #T_dda8b_row5_col22, #T_dda8b_row5_col23, #T_dda8b_row5_col24, #T_dda8b_row5_col25, #T_dda8b_row5_col26, #T_dda8b_row5_col27, #T_dda8b_row6_col0, #T_dda8b_row6_col1, #T_dda8b_row6_col2, #T_dda8b_row6_col3, #T_dda8b_row6_col4, #T_dda8b_row6_col5, #T_dda8b_row6_col6, #T_dda8b_row6_col19, #T_dda8b_row6_col20, #T_dda8b_row6_col21, #T_dda8b_row6_col22, #T_dda8b_row6_col23, #T_dda8b_row6_col24, #T_dda8b_row6_col25, #T_dda8b_row6_col26, #T_dda8b_row6_col27, #T_dda8b_row7_col0, #T_dda8b_row7_col1, #T_dda8b_row7_col2, #T_dda8b_row7_col3, #T_dda8b_row7_col4, #T_dda8b_row7_col19, #T_dda8b_row7_col20, #T_dda8b_row7_col21, #T_dda8b_row7_col22, #T_dda8b_row7_col23, #T_dda8b_row7_col24, #T_dda8b_row7_col25, #T_dda8b_row7_col26, #T_dda8b_row7_col27, #T_dda8b_row8_col0, #T_dda8b_row8_col1, #T_dda8b_row8_col2, #T_dda8b_row8_col3, #T_dda8b_row8_col4, #T_dda8b_row8_col10, #T_dda8b_row8_col11, #T_dda8b_row8_col12, #T_dda8b_row8_col13, #T_dda8b_row8_col14, #T_dda8b_row8_col19, #T_dda8b_row8_col20, #T_dda8b_row8_col21, #T_dda8b_row8_col22, #T_dda8b_row8_col23, #T_dda8b_row8_col24, #T_dda8b_row8_col25, #T_dda8b_row8_col26, #T_dda8b_row8_col27, #T_dda8b_row9_col0, #T_dda8b_row9_col1, #T_dda8b_row9_col2, #T_dda8b_row9_col3, #T_dda8b_row9_col4, #T_dda8b_row9_col9, #T_dda8b_row9_col10, #T_dda8b_row9_col11, #T_dda8b_row9_col12, #T_dda8b_row9_col13, #T_dda8b_row9_col19, #T_dda8b_row9_col20, #T_dda8b_row9_col21, #T_dda8b_row9_col22, #T_dda8b_row9_col23, #T_dda8b_row9_col24, #T_dda8b_row9_col25, #T_dda8b_row9_col26, #T_dda8b_row9_col27, #T_dda8b_row10_col0, #T_dda8b_row10_col1, #T_dda8b_row10_col2, #T_dda8b_row10_col3, #T_dda8b_row10_col4, #T_dda8b_row10_col5, #T_dda8b_row10_col6, #T_dda8b_row10_col7, #T_dda8b_row10_col8, #T_dda8b_row10_col9, #T_dda8b_row10_col10, #T_dda8b_row10_col11, #T_dda8b_row10_col12, #T_dda8b_row10_col13, #T_dda8b_row10_col18, #T_dda8b_row10_col19, #T_dda8b_row10_col20, #T_dda8b_row10_col21, #T_dda8b_row10_col22, #T_dda8b_row10_col23, #T_dda8b_row10_col24, #T_dda8b_row10_col25, #T_dda8b_row10_col26, #T_dda8b_row10_col27, #T_dda8b_row11_col0, #T_dda8b_row11_col1, #T_dda8b_row11_col2, #T_dda8b_row11_col3, #T_dda8b_row11_col4, #T_dda8b_row11_col5, #T_dda8b_row11_col6, #T_dda8b_row11_col7, #T_dda8b_row11_col8, #T_dda8b_row11_col9, #T_dda8b_row11_col10, #T_dda8b_row11_col17, #T_dda8b_row11_col18, #T_dda8b_row11_col19, #T_dda8b_row11_col20, #T_dda8b_row11_col21, #T_dda8b_row11_col22, #T_dda8b_row11_col23, #T_dda8b_row11_col24, #T_dda8b_row11_col25, #T_dda8b_row11_col26, #T_dda8b_row11_col27, #T_dda8b_row12_col0, #T_dda8b_row12_col1, #T_dda8b_row12_col2, #T_dda8b_row12_col3, #T_dda8b_row12_col4, #T_dda8b_row12_col5, #T_dda8b_row12_col6, #T_dda8b_row12_col7, #T_dda8b_row12_col8, #T_dda8b_row12_col17, #T_dda8b_row12_col18, #T_dda8b_row12_col19, #T_dda8b_row12_col20, #T_dda8b_row12_col21, #T_dda8b_row12_col22, #T_dda8b_row12_col23, #T_dda8b_row12_col24, #T_dda8b_row12_col25, #T_dda8b_row12_col26, #T_dda8b_row12_col27, #T_dda8b_row13_col0, #T_dda8b_row13_col1, #T_dda8b_row13_col2, #T_dda8b_row13_col3, #T_dda8b_row13_col4, #T_dda8b_row13_col5, #T_dda8b_row13_col6, #T_dda8b_row13_col7, #T_dda8b_row13_col8, #T_dda8b_row13_col20, #T_dda8b_row13_col21, #T_dda8b_row13_col22, #T_dda8b_row13_col23, #T_dda8b_row13_col24, #T_dda8b_row13_col25, #T_dda8b_row13_col26, #T_dda8b_row13_col27, #T_dda8b_row14_col0, #T_dda8b_row14_col1, #T_dda8b_row14_col2, #T_dda8b_row14_col3, #T_dda8b_row14_col4, #T_dda8b_row14_col5, #T_dda8b_row14_col6, #T_dda8b_row14_col7, #T_dda8b_row14_col8, #T_dda8b_row14_col9, #T_dda8b_row14_col10, #T_dda8b_row14_col21, #T_dda8b_row14_col22, #T_dda8b_row14_col23, #T_dda8b_row14_col24, #T_dda8b_row14_col25, #T_dda8b_row14_col26, #T_dda8b_row14_col27, #T_dda8b_row15_col0, #T_dda8b_row15_col1, #T_dda8b_row15_col2, #T_dda8b_row15_col3, #T_dda8b_row15_col4, #T_dda8b_row15_col5, #T_dda8b_row15_col6, #T_dda8b_row15_col7, #T_dda8b_row15_col8, #T_dda8b_row15_col9, #T_dda8b_row15_col10, #T_dda8b_row15_col11, #T_dda8b_row15_col12, #T_dda8b_row15_col13, #T_dda8b_row15_col21, #T_dda8b_row15_col22, #T_dda8b_row15_col23, #T_dda8b_row15_col24, #T_dda8b_row15_col25, #T_dda8b_row15_col26, #T_dda8b_row15_col27, #T_dda8b_row16_col0, #T_dda8b_row16_col1, #T_dda8b_row16_col2, #T_dda8b_row16_col3, #T_dda8b_row16_col4, #T_dda8b_row16_col5, #T_dda8b_row16_col6, #T_dda8b_row16_col7, #T_dda8b_row16_col8, #T_dda8b_row16_col9, #T_dda8b_row16_col10, #T_dda8b_row16_col11, #T_dda8b_row16_col12, #T_dda8b_row16_col13, #T_dda8b_row16_col14, #T_dda8b_row16_col15, #T_dda8b_row16_col16, #T_dda8b_row16_col21, #T_dda8b_row16_col22, #T_dda8b_row16_col23, #T_dda8b_row16_col24, #T_dda8b_row16_col25, #T_dda8b_row16_col26, #T_dda8b_row16_col27, #T_dda8b_row17_col0, #T_dda8b_row17_col1, #T_dda8b_row17_col2, #T_dda8b_row17_col3, #T_dda8b_row17_col4, #T_dda8b_row17_col5, #T_dda8b_row17_col6, #T_dda8b_row17_col7, #T_dda8b_row17_col8, #T_dda8b_row17_col9, #T_dda8b_row17_col10, #T_dda8b_row17_col11, #T_dda8b_row17_col12, #T_dda8b_row17_col13, #T_dda8b_row17_col14, #T_dda8b_row17_col15, #T_dda8b_row17_col16, #T_dda8b_row17_col21, #T_dda8b_row17_col22, #T_dda8b_row17_col23, #T_dda8b_row17_col24, #T_dda8b_row17_col25, #T_dda8b_row17_col26, #T_dda8b_row17_col27, #T_dda8b_row18_col0, #T_dda8b_row18_col1, #T_dda8b_row18_col2, #T_dda8b_row18_col3, #T_dda8b_row18_col4, #T_dda8b_row18_col5, #T_dda8b_row18_col6, #T_dda8b_row18_col7, #T_dda8b_row18_col8, #T_dda8b_row18_col9, #T_dda8b_row18_col10, #T_dda8b_row18_col11, #T_dda8b_row18_col12, #T_dda8b_row18_col13, #T_dda8b_row18_col14, #T_dda8b_row18_col15, #T_dda8b_row18_col21, #T_dda8b_row18_col22, #T_dda8b_row18_col23, #T_dda8b_row18_col24, #T_dda8b_row18_col25, #T_dda8b_row18_col26, #T_dda8b_row18_col27, #T_dda8b_row19_col0, #T_dda8b_row19_col1, #T_dda8b_row19_col2, #T_dda8b_row19_col3, #T_dda8b_row19_col4, #T_dda8b_row19_col5, #T_dda8b_row19_col6, #T_dda8b_row19_col7, #T_dda8b_row19_col8, #T_dda8b_row19_col9, #T_dda8b_row19_col10, #T_dda8b_row19_col11, #T_dda8b_row19_col12, #T_dda8b_row19_col13, #T_dda8b_row19_col14, #T_dda8b_row19_col21, #T_dda8b_row19_col22, #T_dda8b_row19_col23, #T_dda8b_row19_col24, #T_dda8b_row19_col25, #T_dda8b_row19_col26, #T_dda8b_row19_col27, #T_dda8b_row20_col0, #T_dda8b_row20_col1, #T_dda8b_row20_col2, #T_dda8b_row20_col3, #T_dda8b_row20_col4, #T_dda8b_row20_col5, #T_dda8b_row20_col6, #T_dda8b_row20_col7, #T_dda8b_row20_col8, #T_dda8b_row20_col9, #T_dda8b_row20_col10, #T_dda8b_row20_col11, #T_dda8b_row20_col12, #T_dda8b_row20_col13, #T_dda8b_row20_col20, #T_dda8b_row20_col21, #T_dda8b_row20_col22, #T_dda8b_row20_col23, #T_dda8b_row20_col24, #T_dda8b_row20_col25, #T_dda8b_row20_col26, #T_dda8b_row20_col27, #T_dda8b_row21_col0, #T_dda8b_row21_col1, #T_dda8b_row21_col2, #T_dda8b_row21_col3, #T_dda8b_row21_col4, #T_dda8b_row21_col5, #T_dda8b_row21_col6, #T_dda8b_row21_col7, #T_dda8b_row21_col8, #T_dda8b_row21_col9, #T_dda8b_row21_col10, #T_dda8b_row21_col11, #T_dda8b_row21_col19, #T_dda8b_row21_col20, #T_dda8b_row21_col21, #T_dda8b_row21_col22, #T_dda8b_row21_col23, #T_dda8b_row21_col24, #T_dda8b_row21_col25, #T_dda8b_row21_col26, #T_dda8b_row21_col27, #T_dda8b_row22_col0, #T_dda8b_row22_col1, #T_dda8b_row22_col2, #T_dda8b_row22_col3, #T_dda8b_row22_col4, #T_dda8b_row22_col5, #T_dda8b_row22_col18, #T_dda8b_row22_col19, #T_dda8b_row22_col20, #T_dda8b_row22_col21, #T_dda8b_row22_col22, #T_dda8b_row22_col23, #T_dda8b_row22_col24, #T_dda8b_row22_col25, #T_dda8b_row22_col26, #T_dda8b_row22_col27, #T_dda8b_row23_col0, #T_dda8b_row23_col1, #T_dda8b_row23_col2, #T_dda8b_row23_col3, #T_dda8b_row23_col4, #T_dda8b_row23_col5, #T_dda8b_row23_col16, #T_dda8b_row23_col17, #T_dda8b_row23_col18, #T_dda8b_row23_col19, #T_dda8b_row23_col20, #T_dda8b_row23_col21, #T_dda8b_row23_col22, #T_dda8b_row23_col23, #T_dda8b_row23_col24, #T_dda8b_row23_col25, #T_dda8b_row23_col26, #T_dda8b_row23_col27, #T_dda8b_row24_col0, #T_dda8b_row24_col1, #T_dda8b_row24_col2, #T_dda8b_row24_col3, #T_dda8b_row24_col4, #T_dda8b_row24_col5, #T_dda8b_row24_col14, #T_dda8b_row24_col15, #T_dda8b_row24_col16, #T_dda8b_row24_col17, #T_dda8b_row24_col18, #T_dda8b_row24_col19, #T_dda8b_row24_col20, #T_dda8b_row24_col21, #T_dda8b_row24_col22, #T_dda8b_row24_col23, #T_dda8b_row24_col24, #T_dda8b_row24_col25, #T_dda8b_row24_col26, #T_dda8b_row24_col27, #T_dda8b_row25_col0, #T_dda8b_row25_col1, #T_dda8b_row25_col2, #T_dda8b_row25_col3, #T_dda8b_row25_col4, #T_dda8b_row25_col5, #T_dda8b_row25_col6, #T_dda8b_row25_col7, #T_dda8b_row25_col8, #T_dda8b_row25_col9, #T_dda8b_row25_col10, #T_dda8b_row25_col11, #T_dda8b_row25_col12, #T_dda8b_row25_col13, #T_dda8b_row25_col14, #T_dda8b_row25_col15, #T_dda8b_row25_col16, #T_dda8b_row25_col17, #T_dda8b_row25_col18, #T_dda8b_row25_col19, #T_dda8b_row25_col20, #T_dda8b_row25_col21, #T_dda8b_row25_col22, #T_dda8b_row25_col23, #T_dda8b_row25_col24, #T_dda8b_row25_col25, #T_dda8b_row25_col26, #T_dda8b_row25_col27, #T_dda8b_row26_col0, #T_dda8b_row26_col1, #T_dda8b_row26_col2, #T_dda8b_row26_col3, #T_dda8b_row26_col4, #T_dda8b_row26_col5, #T_dda8b_row26_col6, #T_dda8b_row26_col7, #T_dda8b_row26_col8, #T_dda8b_row26_col9, #T_dda8b_row26_col10, #T_dda8b_row26_col11, #T_dda8b_row26_col12, #T_dda8b_row26_col13, #T_dda8b_row26_col14, #T_dda8b_row26_col15, #T_dda8b_row26_col16, #T_dda8b_row26_col17, #T_dda8b_row26_col18, #T_dda8b_row26_col19, #T_dda8b_row26_col20, #T_dda8b_row26_col21, #T_dda8b_row26_col22, #T_dda8b_row26_col23, #T_dda8b_row26_col24, #T_dda8b_row26_col25, #T_dda8b_row26_col26, #T_dda8b_row26_col27, #T_dda8b_row27_col0, #T_dda8b_row27_col1, #T_dda8b_row27_col2, #T_dda8b_row27_col3, #T_dda8b_row27_col4, #T_dda8b_row27_col5, #T_dda8b_row27_col6, #T_dda8b_row27_col7, #T_dda8b_row27_col8, #T_dda8b_row27_col9, #T_dda8b_row27_col10, #T_dda8b_row27_col11, #T_dda8b_row27_col12, #T_dda8b_row27_col13, #T_dda8b_row27_col14, #T_dda8b_row27_col15, #T_dda8b_row27_col16, #T_dda8b_row27_col17, #T_dda8b_row27_col18, #T_dda8b_row27_col19, #T_dda8b_row27_col20, #T_dda8b_row27_col21, #T_dda8b_row27_col22, #T_dda8b_row27_col23, #T_dda8b_row27_col24, #T_dda8b_row27_col25, #T_dda8b_row27_col26, #T_dda8b_row27_col27 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row5_col9, #T_dda8b_row12_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f1f1f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row5_col10, #T_dda8b_row5_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #7c7c7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row5_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4a4a4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row5_col12, #T_dda8b_row5_col13, #T_dda8b_row5_col14, #T_dda8b_row6_col10, #T_dda8b_row6_col11, #T_dda8b_row6_col15, #T_dda8b_row6_col16, #T_dda8b_row6_col17, #T_dda8b_row7_col8, #T_dda8b_row7_col16, #T_dda8b_row7_col17, #T_dda8b_row8_col5, #T_dda8b_row8_col6, #T_dda8b_row8_col7, #T_dda8b_row8_col16, #T_dda8b_row8_col17, #T_dda8b_row9_col16, #T_dda8b_row10_col15, #T_dda8b_row13_col15, #T_dda8b_row14_col15, #T_dda8b_row14_col16, #T_dda8b_row14_col17, #T_dda8b_row14_col18, #T_dda8b_row15_col17, #T_dda8b_row15_col18, #T_dda8b_row15_col19, #T_dda8b_row16_col18, #T_dda8b_row16_col19, #T_dda8b_row16_col20, #T_dda8b_row17_col18, #T_dda8b_row17_col19, #T_dda8b_row18_col18, #T_dda8b_row18_col19, #T_dda8b_row19_col17, #T_dda8b_row19_col18, #T_dda8b_row20_col16, #T_dda8b_row20_col17, #T_dda8b_row21_col15, #T_dda8b_row21_col16, #T_dda8b_row23_col7, #T_dda8b_row23_col8, #T_dda8b_row23_col9, #T_dda8b_row23_col10, #T_dda8b_row23_col11, #T_dda8b_row24_col7, #T_dda8b_row24_col8, #T_dda8b_row24_col9, #T_dda8b_row24_col10, #T_dda8b_row24_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row5_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #606060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row5_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4d4d4d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row5_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bbbbbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row6_col7, #T_dda8b_row8_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e4e4e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row6_col8, #T_dda8b_row12_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #6b6b6b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row6_col9, #T_dda8b_row9_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #222222;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row6_col12, #T_dda8b_row6_col18, #T_dda8b_row7_col18, #T_dda8b_row21_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #171717;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row6_col13, #T_dda8b_row7_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4b4b4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row6_col14, #T_dda8b_row11_col14, #T_dda8b_row12_col12, #T_dda8b_row12_col14, #T_dda8b_row13_col12, #T_dda8b_row13_col14, #T_dda8b_row22_col14, #T_dda8b_row23_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #010101;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row7_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #272727;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row7_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #0a0a0a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row7_col7, #T_dda8b_row18_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #050505;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row7_col9, #T_dda8b_row12_col15, #T_dda8b_row14_col19, #T_dda8b_row23_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #545454;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row7_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e6e6e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row7_col11, #T_dda8b_row7_col14, #T_dda8b_row12_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fafafa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row7_col12, #T_dda8b_row15_col14, #T_dda8b_row20_col19 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fbfbfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row7_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fdfdfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row8_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1b1b1b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row8_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4e4e4e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row8_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #767676;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row9_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fcfcfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row9_col6, #T_dda8b_row9_col7, #T_dda8b_row19_col20 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f6f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row9_col8, #T_dda8b_row11_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f8f8f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row9_col14, #T_dda8b_row14_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e8e8e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row9_col17, #T_dda8b_row10_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #090909;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row9_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d0d0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row10_col14, #T_dda8b_row11_col15, #T_dda8b_row13_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #060606;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row10_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #979797;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row11_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #b6b6b6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row11_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #252525;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row11_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #999999;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row12_col11, #T_dda8b_row22_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #101010;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row12_col13, #T_dda8b_row13_col13, #T_dda8b_row21_col14, #T_dda8b_row22_col13, #T_dda8b_row23_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #020202;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row13_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f7f7f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row13_col11, #T_dda8b_row22_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #030303;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row13_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #181818;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row13_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #303030;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row13_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #a9a9a9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row13_col19 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fefefe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row14_col12, #T_dda8b_row14_col13, #T_dda8b_row20_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bababa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row14_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #393939;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row14_col20 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #eaeaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row15_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e2e2e2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row15_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #9f9f9f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row15_col20 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #898989;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row16_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #585858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row17_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #5a5a5a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row17_col20 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #525252;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row18_col16, #T_dda8b_row23_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #c5c5c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row18_col20 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d7d7d7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row19_col15, #T_dda8b_row22_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #dcdcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row19_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #2f2f2f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row19_col19 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #636363;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row20_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #070707;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row20_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1f1f1f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row21_col12, #T_dda8b_row22_col6, #T_dda8b_row22_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e9e9e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row21_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #7d7d7d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row21_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e1e1e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row22_col7, #T_dda8b_row22_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #a4a4a4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row22_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #727272;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row22_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #616161;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row22_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f3f3f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row23_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #484848;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row24_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #b3b3b3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_dda8b_row24_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1a1a1a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_dda8b_row24_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d6d6d6;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dda8b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dda8b_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_dda8b_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_dda8b_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_dda8b_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_dda8b_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_dda8b_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "      <th id=\"T_dda8b_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
       "      <th id=\"T_dda8b_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
       "      <th id=\"T_dda8b_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
       "      <th id=\"T_dda8b_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
       "      <th id=\"T_dda8b_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
       "      <th id=\"T_dda8b_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
       "      <th id=\"T_dda8b_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
       "      <th id=\"T_dda8b_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
       "      <th id=\"T_dda8b_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n",
       "      <th id=\"T_dda8b_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n",
       "      <th id=\"T_dda8b_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n",
       "      <th id=\"T_dda8b_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n",
       "      <th id=\"T_dda8b_level0_col18\" class=\"col_heading level0 col18\" >18</th>\n",
       "      <th id=\"T_dda8b_level0_col19\" class=\"col_heading level0 col19\" >19</th>\n",
       "      <th id=\"T_dda8b_level0_col20\" class=\"col_heading level0 col20\" >20</th>\n",
       "      <th id=\"T_dda8b_level0_col21\" class=\"col_heading level0 col21\" >21</th>\n",
       "      <th id=\"T_dda8b_level0_col22\" class=\"col_heading level0 col22\" >22</th>\n",
       "      <th id=\"T_dda8b_level0_col23\" class=\"col_heading level0 col23\" >23</th>\n",
       "      <th id=\"T_dda8b_level0_col24\" class=\"col_heading level0 col24\" >24</th>\n",
       "      <th id=\"T_dda8b_level0_col25\" class=\"col_heading level0 col25\" >25</th>\n",
       "      <th id=\"T_dda8b_level0_col26\" class=\"col_heading level0 col26\" >26</th>\n",
       "      <th id=\"T_dda8b_level0_col27\" class=\"col_heading level0 col27\" >27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_dda8b_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col9\" class=\"data row0 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col12\" class=\"data row0 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col13\" class=\"data row0 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col14\" class=\"data row0 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col15\" class=\"data row0 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col17\" class=\"data row0 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col18\" class=\"data row0 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col19\" class=\"data row0 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col20\" class=\"data row0 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col21\" class=\"data row0 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col22\" class=\"data row0 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col23\" class=\"data row0 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col24\" class=\"data row0 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col25\" class=\"data row0 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col26\" class=\"data row0 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row0_col27\" class=\"data row0 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_dda8b_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col6\" class=\"data row1 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col7\" class=\"data row1 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col8\" class=\"data row1 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col9\" class=\"data row1 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col10\" class=\"data row1 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col11\" class=\"data row1 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col12\" class=\"data row1 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col13\" class=\"data row1 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col14\" class=\"data row1 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col15\" class=\"data row1 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col16\" class=\"data row1 col16\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col17\" class=\"data row1 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col18\" class=\"data row1 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col19\" class=\"data row1 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col20\" class=\"data row1 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col21\" class=\"data row1 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col22\" class=\"data row1 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col23\" class=\"data row1 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col24\" class=\"data row1 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col25\" class=\"data row1 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col26\" class=\"data row1 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row1_col27\" class=\"data row1 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_dda8b_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col3\" class=\"data row2 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col7\" class=\"data row2 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col8\" class=\"data row2 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col9\" class=\"data row2 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col10\" class=\"data row2 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col11\" class=\"data row2 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col12\" class=\"data row2 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col13\" class=\"data row2 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col14\" class=\"data row2 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col15\" class=\"data row2 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col16\" class=\"data row2 col16\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col17\" class=\"data row2 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col18\" class=\"data row2 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col19\" class=\"data row2 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col20\" class=\"data row2 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col21\" class=\"data row2 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col22\" class=\"data row2 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col23\" class=\"data row2 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col24\" class=\"data row2 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col25\" class=\"data row2 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col26\" class=\"data row2 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row2_col27\" class=\"data row2 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_dda8b_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col6\" class=\"data row3 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col7\" class=\"data row3 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col8\" class=\"data row3 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col9\" class=\"data row3 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col10\" class=\"data row3 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col11\" class=\"data row3 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col12\" class=\"data row3 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col13\" class=\"data row3 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col14\" class=\"data row3 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col15\" class=\"data row3 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col16\" class=\"data row3 col16\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col17\" class=\"data row3 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col18\" class=\"data row3 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col19\" class=\"data row3 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col20\" class=\"data row3 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col21\" class=\"data row3 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col22\" class=\"data row3 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col23\" class=\"data row3 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col24\" class=\"data row3 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col25\" class=\"data row3 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col26\" class=\"data row3 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row3_col27\" class=\"data row3 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_dda8b_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col3\" class=\"data row4 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col7\" class=\"data row4 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col8\" class=\"data row4 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col9\" class=\"data row4 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col11\" class=\"data row4 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col12\" class=\"data row4 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col13\" class=\"data row4 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col14\" class=\"data row4 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col15\" class=\"data row4 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col16\" class=\"data row4 col16\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col17\" class=\"data row4 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col18\" class=\"data row4 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col19\" class=\"data row4 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col20\" class=\"data row4 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col21\" class=\"data row4 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col22\" class=\"data row4 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col23\" class=\"data row4 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col24\" class=\"data row4 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col25\" class=\"data row4 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col26\" class=\"data row4 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row4_col27\" class=\"data row4 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_dda8b_row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col1\" class=\"data row5 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col3\" class=\"data row5 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col4\" class=\"data row5 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col6\" class=\"data row5 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col7\" class=\"data row5 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col9\" class=\"data row5 col9\" >29</td>\n",
       "      <td id=\"T_dda8b_row5_col10\" class=\"data row5 col10\" >150</td>\n",
       "      <td id=\"T_dda8b_row5_col11\" class=\"data row5 col11\" >195</td>\n",
       "      <td id=\"T_dda8b_row5_col12\" class=\"data row5 col12\" >254</td>\n",
       "      <td id=\"T_dda8b_row5_col13\" class=\"data row5 col13\" >255</td>\n",
       "      <td id=\"T_dda8b_row5_col14\" class=\"data row5 col14\" >254</td>\n",
       "      <td id=\"T_dda8b_row5_col15\" class=\"data row5 col15\" >176</td>\n",
       "      <td id=\"T_dda8b_row5_col16\" class=\"data row5 col16\" >193</td>\n",
       "      <td id=\"T_dda8b_row5_col17\" class=\"data row5 col17\" >150</td>\n",
       "      <td id=\"T_dda8b_row5_col18\" class=\"data row5 col18\" >96</td>\n",
       "      <td id=\"T_dda8b_row5_col19\" class=\"data row5 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col20\" class=\"data row5 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col21\" class=\"data row5 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col22\" class=\"data row5 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col23\" class=\"data row5 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col24\" class=\"data row5 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col25\" class=\"data row5 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col26\" class=\"data row5 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row5_col27\" class=\"data row5 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_dda8b_row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col7\" class=\"data row6 col7\" >48</td>\n",
       "      <td id=\"T_dda8b_row6_col8\" class=\"data row6 col8\" >166</td>\n",
       "      <td id=\"T_dda8b_row6_col9\" class=\"data row6 col9\" >224</td>\n",
       "      <td id=\"T_dda8b_row6_col10\" class=\"data row6 col10\" >253</td>\n",
       "      <td id=\"T_dda8b_row6_col11\" class=\"data row6 col11\" >253</td>\n",
       "      <td id=\"T_dda8b_row6_col12\" class=\"data row6 col12\" >234</td>\n",
       "      <td id=\"T_dda8b_row6_col13\" class=\"data row6 col13\" >196</td>\n",
       "      <td id=\"T_dda8b_row6_col14\" class=\"data row6 col14\" >253</td>\n",
       "      <td id=\"T_dda8b_row6_col15\" class=\"data row6 col15\" >253</td>\n",
       "      <td id=\"T_dda8b_row6_col16\" class=\"data row6 col16\" >253</td>\n",
       "      <td id=\"T_dda8b_row6_col17\" class=\"data row6 col17\" >253</td>\n",
       "      <td id=\"T_dda8b_row6_col18\" class=\"data row6 col18\" >233</td>\n",
       "      <td id=\"T_dda8b_row6_col19\" class=\"data row6 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col20\" class=\"data row6 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col21\" class=\"data row6 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col22\" class=\"data row6 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col23\" class=\"data row6 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col24\" class=\"data row6 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col25\" class=\"data row6 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col26\" class=\"data row6 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row6_col27\" class=\"data row6 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_dda8b_row7_col0\" class=\"data row7 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col4\" class=\"data row7 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col5\" class=\"data row7 col5\" >93</td>\n",
       "      <td id=\"T_dda8b_row7_col6\" class=\"data row7 col6\" >244</td>\n",
       "      <td id=\"T_dda8b_row7_col7\" class=\"data row7 col7\" >249</td>\n",
       "      <td id=\"T_dda8b_row7_col8\" class=\"data row7 col8\" >253</td>\n",
       "      <td id=\"T_dda8b_row7_col9\" class=\"data row7 col9\" >187</td>\n",
       "      <td id=\"T_dda8b_row7_col10\" class=\"data row7 col10\" >46</td>\n",
       "      <td id=\"T_dda8b_row7_col11\" class=\"data row7 col11\" >10</td>\n",
       "      <td id=\"T_dda8b_row7_col12\" class=\"data row7 col12\" >8</td>\n",
       "      <td id=\"T_dda8b_row7_col13\" class=\"data row7 col13\" >4</td>\n",
       "      <td id=\"T_dda8b_row7_col14\" class=\"data row7 col14\" >10</td>\n",
       "      <td id=\"T_dda8b_row7_col15\" class=\"data row7 col15\" >194</td>\n",
       "      <td id=\"T_dda8b_row7_col16\" class=\"data row7 col16\" >253</td>\n",
       "      <td id=\"T_dda8b_row7_col17\" class=\"data row7 col17\" >253</td>\n",
       "      <td id=\"T_dda8b_row7_col18\" class=\"data row7 col18\" >233</td>\n",
       "      <td id=\"T_dda8b_row7_col19\" class=\"data row7 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col20\" class=\"data row7 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col21\" class=\"data row7 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col22\" class=\"data row7 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col23\" class=\"data row7 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col24\" class=\"data row7 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col25\" class=\"data row7 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col26\" class=\"data row7 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row7_col27\" class=\"data row7 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_dda8b_row8_col0\" class=\"data row8 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col4\" class=\"data row8 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col5\" class=\"data row8 col5\" >107</td>\n",
       "      <td id=\"T_dda8b_row8_col6\" class=\"data row8 col6\" >253</td>\n",
       "      <td id=\"T_dda8b_row8_col7\" class=\"data row8 col7\" >253</td>\n",
       "      <td id=\"T_dda8b_row8_col8\" class=\"data row8 col8\" >230</td>\n",
       "      <td id=\"T_dda8b_row8_col9\" class=\"data row8 col9\" >48</td>\n",
       "      <td id=\"T_dda8b_row8_col10\" class=\"data row8 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col11\" class=\"data row8 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col12\" class=\"data row8 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col13\" class=\"data row8 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col14\" class=\"data row8 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col15\" class=\"data row8 col15\" >192</td>\n",
       "      <td id=\"T_dda8b_row8_col16\" class=\"data row8 col16\" >253</td>\n",
       "      <td id=\"T_dda8b_row8_col17\" class=\"data row8 col17\" >253</td>\n",
       "      <td id=\"T_dda8b_row8_col18\" class=\"data row8 col18\" >156</td>\n",
       "      <td id=\"T_dda8b_row8_col19\" class=\"data row8 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col20\" class=\"data row8 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col21\" class=\"data row8 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col22\" class=\"data row8 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col23\" class=\"data row8 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col24\" class=\"data row8 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col25\" class=\"data row8 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col26\" class=\"data row8 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row8_col27\" class=\"data row8 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_dda8b_row9_col0\" class=\"data row9 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col5\" class=\"data row9 col5\" >3</td>\n",
       "      <td id=\"T_dda8b_row9_col6\" class=\"data row9 col6\" >20</td>\n",
       "      <td id=\"T_dda8b_row9_col7\" class=\"data row9 col7\" >20</td>\n",
       "      <td id=\"T_dda8b_row9_col8\" class=\"data row9 col8\" >15</td>\n",
       "      <td id=\"T_dda8b_row9_col9\" class=\"data row9 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col10\" class=\"data row9 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col11\" class=\"data row9 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col12\" class=\"data row9 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col13\" class=\"data row9 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col14\" class=\"data row9 col14\" >43</td>\n",
       "      <td id=\"T_dda8b_row9_col15\" class=\"data row9 col15\" >224</td>\n",
       "      <td id=\"T_dda8b_row9_col16\" class=\"data row9 col16\" >253</td>\n",
       "      <td id=\"T_dda8b_row9_col17\" class=\"data row9 col17\" >245</td>\n",
       "      <td id=\"T_dda8b_row9_col18\" class=\"data row9 col18\" >74</td>\n",
       "      <td id=\"T_dda8b_row9_col19\" class=\"data row9 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col20\" class=\"data row9 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col21\" class=\"data row9 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col22\" class=\"data row9 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col23\" class=\"data row9 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col24\" class=\"data row9 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col25\" class=\"data row9 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col26\" class=\"data row9 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row9_col27\" class=\"data row9 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_dda8b_row10_col0\" class=\"data row10 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col3\" class=\"data row10 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col4\" class=\"data row10 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col6\" class=\"data row10 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col7\" class=\"data row10 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col8\" class=\"data row10 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col9\" class=\"data row10 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col10\" class=\"data row10 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col11\" class=\"data row10 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col12\" class=\"data row10 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col13\" class=\"data row10 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col14\" class=\"data row10 col14\" >249</td>\n",
       "      <td id=\"T_dda8b_row10_col15\" class=\"data row10 col15\" >253</td>\n",
       "      <td id=\"T_dda8b_row10_col16\" class=\"data row10 col16\" >245</td>\n",
       "      <td id=\"T_dda8b_row10_col17\" class=\"data row10 col17\" >126</td>\n",
       "      <td id=\"T_dda8b_row10_col18\" class=\"data row10 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col19\" class=\"data row10 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col20\" class=\"data row10 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col21\" class=\"data row10 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col22\" class=\"data row10 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col23\" class=\"data row10 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col24\" class=\"data row10 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col25\" class=\"data row10 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col26\" class=\"data row10 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row10_col27\" class=\"data row10 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_dda8b_row11_col0\" class=\"data row11 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col1\" class=\"data row11 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col2\" class=\"data row11 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col3\" class=\"data row11 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col4\" class=\"data row11 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col5\" class=\"data row11 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col6\" class=\"data row11 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col7\" class=\"data row11 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col8\" class=\"data row11 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col9\" class=\"data row11 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col10\" class=\"data row11 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col11\" class=\"data row11 col11\" >14</td>\n",
       "      <td id=\"T_dda8b_row11_col12\" class=\"data row11 col12\" >101</td>\n",
       "      <td id=\"T_dda8b_row11_col13\" class=\"data row11 col13\" >223</td>\n",
       "      <td id=\"T_dda8b_row11_col14\" class=\"data row11 col14\" >253</td>\n",
       "      <td id=\"T_dda8b_row11_col15\" class=\"data row11 col15\" >248</td>\n",
       "      <td id=\"T_dda8b_row11_col16\" class=\"data row11 col16\" >124</td>\n",
       "      <td id=\"T_dda8b_row11_col17\" class=\"data row11 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col18\" class=\"data row11 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col19\" class=\"data row11 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col20\" class=\"data row11 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col21\" class=\"data row11 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col22\" class=\"data row11 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col23\" class=\"data row11 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col24\" class=\"data row11 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col25\" class=\"data row11 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col26\" class=\"data row11 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row11_col27\" class=\"data row11 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_dda8b_row12_col0\" class=\"data row12 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col1\" class=\"data row12 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col2\" class=\"data row12 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col3\" class=\"data row12 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col4\" class=\"data row12 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col5\" class=\"data row12 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col6\" class=\"data row12 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col7\" class=\"data row12 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col8\" class=\"data row12 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col9\" class=\"data row12 col9\" >11</td>\n",
       "      <td id=\"T_dda8b_row12_col10\" class=\"data row12 col10\" >166</td>\n",
       "      <td id=\"T_dda8b_row12_col11\" class=\"data row12 col11\" >239</td>\n",
       "      <td id=\"T_dda8b_row12_col12\" class=\"data row12 col12\" >253</td>\n",
       "      <td id=\"T_dda8b_row12_col13\" class=\"data row12 col13\" >253</td>\n",
       "      <td id=\"T_dda8b_row12_col14\" class=\"data row12 col14\" >253</td>\n",
       "      <td id=\"T_dda8b_row12_col15\" class=\"data row12 col15\" >187</td>\n",
       "      <td id=\"T_dda8b_row12_col16\" class=\"data row12 col16\" >30</td>\n",
       "      <td id=\"T_dda8b_row12_col17\" class=\"data row12 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col18\" class=\"data row12 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col19\" class=\"data row12 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col20\" class=\"data row12 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col21\" class=\"data row12 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col22\" class=\"data row12 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col23\" class=\"data row12 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col24\" class=\"data row12 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col25\" class=\"data row12 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col26\" class=\"data row12 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row12_col27\" class=\"data row12 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_dda8b_row13_col0\" class=\"data row13 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col1\" class=\"data row13 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col2\" class=\"data row13 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col3\" class=\"data row13 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col4\" class=\"data row13 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col5\" class=\"data row13 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col6\" class=\"data row13 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col7\" class=\"data row13 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col8\" class=\"data row13 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col9\" class=\"data row13 col9\" >16</td>\n",
       "      <td id=\"T_dda8b_row13_col10\" class=\"data row13 col10\" >248</td>\n",
       "      <td id=\"T_dda8b_row13_col11\" class=\"data row13 col11\" >250</td>\n",
       "      <td id=\"T_dda8b_row13_col12\" class=\"data row13 col12\" >253</td>\n",
       "      <td id=\"T_dda8b_row13_col13\" class=\"data row13 col13\" >253</td>\n",
       "      <td id=\"T_dda8b_row13_col14\" class=\"data row13 col14\" >253</td>\n",
       "      <td id=\"T_dda8b_row13_col15\" class=\"data row13 col15\" >253</td>\n",
       "      <td id=\"T_dda8b_row13_col16\" class=\"data row13 col16\" >232</td>\n",
       "      <td id=\"T_dda8b_row13_col17\" class=\"data row13 col17\" >213</td>\n",
       "      <td id=\"T_dda8b_row13_col18\" class=\"data row13 col18\" >111</td>\n",
       "      <td id=\"T_dda8b_row13_col19\" class=\"data row13 col19\" >2</td>\n",
       "      <td id=\"T_dda8b_row13_col20\" class=\"data row13 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col21\" class=\"data row13 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col22\" class=\"data row13 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col23\" class=\"data row13 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col24\" class=\"data row13 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col25\" class=\"data row13 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col26\" class=\"data row13 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row13_col27\" class=\"data row13 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_dda8b_row14_col0\" class=\"data row14 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col1\" class=\"data row14 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col2\" class=\"data row14 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col3\" class=\"data row14 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col4\" class=\"data row14 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col5\" class=\"data row14 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col6\" class=\"data row14 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col7\" class=\"data row14 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col8\" class=\"data row14 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col9\" class=\"data row14 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col10\" class=\"data row14 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col11\" class=\"data row14 col11\" >43</td>\n",
       "      <td id=\"T_dda8b_row14_col12\" class=\"data row14 col12\" >98</td>\n",
       "      <td id=\"T_dda8b_row14_col13\" class=\"data row14 col13\" >98</td>\n",
       "      <td id=\"T_dda8b_row14_col14\" class=\"data row14 col14\" >208</td>\n",
       "      <td id=\"T_dda8b_row14_col15\" class=\"data row14 col15\" >253</td>\n",
       "      <td id=\"T_dda8b_row14_col16\" class=\"data row14 col16\" >253</td>\n",
       "      <td id=\"T_dda8b_row14_col17\" class=\"data row14 col17\" >253</td>\n",
       "      <td id=\"T_dda8b_row14_col18\" class=\"data row14 col18\" >253</td>\n",
       "      <td id=\"T_dda8b_row14_col19\" class=\"data row14 col19\" >187</td>\n",
       "      <td id=\"T_dda8b_row14_col20\" class=\"data row14 col20\" >22</td>\n",
       "      <td id=\"T_dda8b_row14_col21\" class=\"data row14 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col22\" class=\"data row14 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col23\" class=\"data row14 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col24\" class=\"data row14 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col25\" class=\"data row14 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col26\" class=\"data row14 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row14_col27\" class=\"data row14 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_dda8b_row15_col0\" class=\"data row15 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col1\" class=\"data row15 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col2\" class=\"data row15 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col3\" class=\"data row15 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col4\" class=\"data row15 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col5\" class=\"data row15 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col6\" class=\"data row15 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col7\" class=\"data row15 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col8\" class=\"data row15 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col9\" class=\"data row15 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col10\" class=\"data row15 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col11\" class=\"data row15 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col12\" class=\"data row15 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col13\" class=\"data row15 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col14\" class=\"data row15 col14\" >9</td>\n",
       "      <td id=\"T_dda8b_row15_col15\" class=\"data row15 col15\" >51</td>\n",
       "      <td id=\"T_dda8b_row15_col16\" class=\"data row15 col16\" >119</td>\n",
       "      <td id=\"T_dda8b_row15_col17\" class=\"data row15 col17\" >253</td>\n",
       "      <td id=\"T_dda8b_row15_col18\" class=\"data row15 col18\" >253</td>\n",
       "      <td id=\"T_dda8b_row15_col19\" class=\"data row15 col19\" >253</td>\n",
       "      <td id=\"T_dda8b_row15_col20\" class=\"data row15 col20\" >76</td>\n",
       "      <td id=\"T_dda8b_row15_col21\" class=\"data row15 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col22\" class=\"data row15 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col23\" class=\"data row15 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col24\" class=\"data row15 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col25\" class=\"data row15 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col26\" class=\"data row15 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row15_col27\" class=\"data row15 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_dda8b_row16_col0\" class=\"data row16 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col1\" class=\"data row16 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col2\" class=\"data row16 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col3\" class=\"data row16 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col4\" class=\"data row16 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col5\" class=\"data row16 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col6\" class=\"data row16 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col7\" class=\"data row16 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col8\" class=\"data row16 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col9\" class=\"data row16 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col10\" class=\"data row16 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col11\" class=\"data row16 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col12\" class=\"data row16 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col13\" class=\"data row16 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col14\" class=\"data row16 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col15\" class=\"data row16 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col16\" class=\"data row16 col16\" >1</td>\n",
       "      <td id=\"T_dda8b_row16_col17\" class=\"data row16 col17\" >183</td>\n",
       "      <td id=\"T_dda8b_row16_col18\" class=\"data row16 col18\" >253</td>\n",
       "      <td id=\"T_dda8b_row16_col19\" class=\"data row16 col19\" >253</td>\n",
       "      <td id=\"T_dda8b_row16_col20\" class=\"data row16 col20\" >139</td>\n",
       "      <td id=\"T_dda8b_row16_col21\" class=\"data row16 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col22\" class=\"data row16 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col23\" class=\"data row16 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col24\" class=\"data row16 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col25\" class=\"data row16 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col26\" class=\"data row16 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row16_col27\" class=\"data row16 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_dda8b_row17_col0\" class=\"data row17 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col1\" class=\"data row17 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col2\" class=\"data row17 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col3\" class=\"data row17 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col4\" class=\"data row17 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col5\" class=\"data row17 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col6\" class=\"data row17 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col7\" class=\"data row17 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col8\" class=\"data row17 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col9\" class=\"data row17 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col10\" class=\"data row17 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col11\" class=\"data row17 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col12\" class=\"data row17 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col13\" class=\"data row17 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col14\" class=\"data row17 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col15\" class=\"data row17 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col16\" class=\"data row17 col16\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col17\" class=\"data row17 col17\" >182</td>\n",
       "      <td id=\"T_dda8b_row17_col18\" class=\"data row17 col18\" >253</td>\n",
       "      <td id=\"T_dda8b_row17_col19\" class=\"data row17 col19\" >253</td>\n",
       "      <td id=\"T_dda8b_row17_col20\" class=\"data row17 col20\" >104</td>\n",
       "      <td id=\"T_dda8b_row17_col21\" class=\"data row17 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col22\" class=\"data row17 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col23\" class=\"data row17 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col24\" class=\"data row17 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col25\" class=\"data row17 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col26\" class=\"data row17 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row17_col27\" class=\"data row17 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_dda8b_row18_col0\" class=\"data row18 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col1\" class=\"data row18 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col2\" class=\"data row18 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col3\" class=\"data row18 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col4\" class=\"data row18 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col5\" class=\"data row18 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col6\" class=\"data row18 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col7\" class=\"data row18 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col8\" class=\"data row18 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col9\" class=\"data row18 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col10\" class=\"data row18 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col11\" class=\"data row18 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col12\" class=\"data row18 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col13\" class=\"data row18 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col14\" class=\"data row18 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col15\" class=\"data row18 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col16\" class=\"data row18 col16\" >85</td>\n",
       "      <td id=\"T_dda8b_row18_col17\" class=\"data row18 col17\" >249</td>\n",
       "      <td id=\"T_dda8b_row18_col18\" class=\"data row18 col18\" >253</td>\n",
       "      <td id=\"T_dda8b_row18_col19\" class=\"data row18 col19\" >253</td>\n",
       "      <td id=\"T_dda8b_row18_col20\" class=\"data row18 col20\" >36</td>\n",
       "      <td id=\"T_dda8b_row18_col21\" class=\"data row18 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col22\" class=\"data row18 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col23\" class=\"data row18 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col24\" class=\"data row18 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col25\" class=\"data row18 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col26\" class=\"data row18 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row18_col27\" class=\"data row18 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_dda8b_row19_col0\" class=\"data row19 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col1\" class=\"data row19 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col2\" class=\"data row19 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col3\" class=\"data row19 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col4\" class=\"data row19 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col5\" class=\"data row19 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col6\" class=\"data row19 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col7\" class=\"data row19 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col8\" class=\"data row19 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col9\" class=\"data row19 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col10\" class=\"data row19 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col11\" class=\"data row19 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col12\" class=\"data row19 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col13\" class=\"data row19 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col14\" class=\"data row19 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col15\" class=\"data row19 col15\" >60</td>\n",
       "      <td id=\"T_dda8b_row19_col16\" class=\"data row19 col16\" >214</td>\n",
       "      <td id=\"T_dda8b_row19_col17\" class=\"data row19 col17\" >253</td>\n",
       "      <td id=\"T_dda8b_row19_col18\" class=\"data row19 col18\" >253</td>\n",
       "      <td id=\"T_dda8b_row19_col19\" class=\"data row19 col19\" >173</td>\n",
       "      <td id=\"T_dda8b_row19_col20\" class=\"data row19 col20\" >11</td>\n",
       "      <td id=\"T_dda8b_row19_col21\" class=\"data row19 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col22\" class=\"data row19 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col23\" class=\"data row19 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col24\" class=\"data row19 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col25\" class=\"data row19 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col26\" class=\"data row19 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row19_col27\" class=\"data row19 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_dda8b_row20_col0\" class=\"data row20 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col1\" class=\"data row20 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col2\" class=\"data row20 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col3\" class=\"data row20 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col4\" class=\"data row20 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col5\" class=\"data row20 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col6\" class=\"data row20 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col7\" class=\"data row20 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col8\" class=\"data row20 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col9\" class=\"data row20 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col10\" class=\"data row20 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col11\" class=\"data row20 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col12\" class=\"data row20 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col13\" class=\"data row20 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col14\" class=\"data row20 col14\" >98</td>\n",
       "      <td id=\"T_dda8b_row20_col15\" class=\"data row20 col15\" >247</td>\n",
       "      <td id=\"T_dda8b_row20_col16\" class=\"data row20 col16\" >253</td>\n",
       "      <td id=\"T_dda8b_row20_col17\" class=\"data row20 col17\" >253</td>\n",
       "      <td id=\"T_dda8b_row20_col18\" class=\"data row20 col18\" >226</td>\n",
       "      <td id=\"T_dda8b_row20_col19\" class=\"data row20 col19\" >9</td>\n",
       "      <td id=\"T_dda8b_row20_col20\" class=\"data row20 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col21\" class=\"data row20 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col22\" class=\"data row20 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col23\" class=\"data row20 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col24\" class=\"data row20 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col25\" class=\"data row20 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col26\" class=\"data row20 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row20_col27\" class=\"data row20 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_dda8b_row21_col0\" class=\"data row21 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col1\" class=\"data row21 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col2\" class=\"data row21 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col3\" class=\"data row21 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col4\" class=\"data row21 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col5\" class=\"data row21 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col6\" class=\"data row21 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col7\" class=\"data row21 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col8\" class=\"data row21 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col9\" class=\"data row21 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col10\" class=\"data row21 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col11\" class=\"data row21 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col12\" class=\"data row21 col12\" >42</td>\n",
       "      <td id=\"T_dda8b_row21_col13\" class=\"data row21 col13\" >150</td>\n",
       "      <td id=\"T_dda8b_row21_col14\" class=\"data row21 col14\" >252</td>\n",
       "      <td id=\"T_dda8b_row21_col15\" class=\"data row21 col15\" >253</td>\n",
       "      <td id=\"T_dda8b_row21_col16\" class=\"data row21 col16\" >253</td>\n",
       "      <td id=\"T_dda8b_row21_col17\" class=\"data row21 col17\" >233</td>\n",
       "      <td id=\"T_dda8b_row21_col18\" class=\"data row21 col18\" >53</td>\n",
       "      <td id=\"T_dda8b_row21_col19\" class=\"data row21 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col20\" class=\"data row21 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col21\" class=\"data row21 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col22\" class=\"data row21 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col23\" class=\"data row21 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col24\" class=\"data row21 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col25\" class=\"data row21 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col26\" class=\"data row21 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row21_col27\" class=\"data row21 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_dda8b_row22_col0\" class=\"data row22 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col1\" class=\"data row22 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col2\" class=\"data row22 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col3\" class=\"data row22 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col4\" class=\"data row22 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col5\" class=\"data row22 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col6\" class=\"data row22 col6\" >42</td>\n",
       "      <td id=\"T_dda8b_row22_col7\" class=\"data row22 col7\" >115</td>\n",
       "      <td id=\"T_dda8b_row22_col8\" class=\"data row22 col8\" >42</td>\n",
       "      <td id=\"T_dda8b_row22_col9\" class=\"data row22 col9\" >60</td>\n",
       "      <td id=\"T_dda8b_row22_col10\" class=\"data row22 col10\" >115</td>\n",
       "      <td id=\"T_dda8b_row22_col11\" class=\"data row22 col11\" >159</td>\n",
       "      <td id=\"T_dda8b_row22_col12\" class=\"data row22 col12\" >240</td>\n",
       "      <td id=\"T_dda8b_row22_col13\" class=\"data row22 col13\" >253</td>\n",
       "      <td id=\"T_dda8b_row22_col14\" class=\"data row22 col14\" >253</td>\n",
       "      <td id=\"T_dda8b_row22_col15\" class=\"data row22 col15\" >250</td>\n",
       "      <td id=\"T_dda8b_row22_col16\" class=\"data row22 col16\" >175</td>\n",
       "      <td id=\"T_dda8b_row22_col17\" class=\"data row22 col17\" >25</td>\n",
       "      <td id=\"T_dda8b_row22_col18\" class=\"data row22 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col19\" class=\"data row22 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col20\" class=\"data row22 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col21\" class=\"data row22 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col22\" class=\"data row22 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col23\" class=\"data row22 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col24\" class=\"data row22 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col25\" class=\"data row22 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col26\" class=\"data row22 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row22_col27\" class=\"data row22 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_dda8b_row23_col0\" class=\"data row23 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col1\" class=\"data row23 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col2\" class=\"data row23 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col3\" class=\"data row23 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col4\" class=\"data row23 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col5\" class=\"data row23 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col6\" class=\"data row23 col6\" >187</td>\n",
       "      <td id=\"T_dda8b_row23_col7\" class=\"data row23 col7\" >253</td>\n",
       "      <td id=\"T_dda8b_row23_col8\" class=\"data row23 col8\" >253</td>\n",
       "      <td id=\"T_dda8b_row23_col9\" class=\"data row23 col9\" >253</td>\n",
       "      <td id=\"T_dda8b_row23_col10\" class=\"data row23 col10\" >253</td>\n",
       "      <td id=\"T_dda8b_row23_col11\" class=\"data row23 col11\" >253</td>\n",
       "      <td id=\"T_dda8b_row23_col12\" class=\"data row23 col12\" >253</td>\n",
       "      <td id=\"T_dda8b_row23_col13\" class=\"data row23 col13\" >253</td>\n",
       "      <td id=\"T_dda8b_row23_col14\" class=\"data row23 col14\" >197</td>\n",
       "      <td id=\"T_dda8b_row23_col15\" class=\"data row23 col15\" >86</td>\n",
       "      <td id=\"T_dda8b_row23_col16\" class=\"data row23 col16\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col17\" class=\"data row23 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col18\" class=\"data row23 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col19\" class=\"data row23 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col20\" class=\"data row23 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col21\" class=\"data row23 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col22\" class=\"data row23 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col23\" class=\"data row23 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col24\" class=\"data row23 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col25\" class=\"data row23 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col26\" class=\"data row23 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row23_col27\" class=\"data row23 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_dda8b_row24_col0\" class=\"data row24 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col1\" class=\"data row24 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col2\" class=\"data row24 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col3\" class=\"data row24 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col4\" class=\"data row24 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col5\" class=\"data row24 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col6\" class=\"data row24 col6\" >103</td>\n",
       "      <td id=\"T_dda8b_row24_col7\" class=\"data row24 col7\" >253</td>\n",
       "      <td id=\"T_dda8b_row24_col8\" class=\"data row24 col8\" >253</td>\n",
       "      <td id=\"T_dda8b_row24_col9\" class=\"data row24 col9\" >253</td>\n",
       "      <td id=\"T_dda8b_row24_col10\" class=\"data row24 col10\" >253</td>\n",
       "      <td id=\"T_dda8b_row24_col11\" class=\"data row24 col11\" >253</td>\n",
       "      <td id=\"T_dda8b_row24_col12\" class=\"data row24 col12\" >232</td>\n",
       "      <td id=\"T_dda8b_row24_col13\" class=\"data row24 col13\" >67</td>\n",
       "      <td id=\"T_dda8b_row24_col14\" class=\"data row24 col14\" >1</td>\n",
       "      <td id=\"T_dda8b_row24_col15\" class=\"data row24 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col16\" class=\"data row24 col16\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col17\" class=\"data row24 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col18\" class=\"data row24 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col19\" class=\"data row24 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col20\" class=\"data row24 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col21\" class=\"data row24 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col22\" class=\"data row24 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col23\" class=\"data row24 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col24\" class=\"data row24 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col25\" class=\"data row24 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col26\" class=\"data row24 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row24_col27\" class=\"data row24 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_dda8b_row25_col0\" class=\"data row25 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col1\" class=\"data row25 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col2\" class=\"data row25 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col3\" class=\"data row25 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col4\" class=\"data row25 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col5\" class=\"data row25 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col6\" class=\"data row25 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col7\" class=\"data row25 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col8\" class=\"data row25 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col9\" class=\"data row25 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col10\" class=\"data row25 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col11\" class=\"data row25 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col12\" class=\"data row25 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col13\" class=\"data row25 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col14\" class=\"data row25 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col15\" class=\"data row25 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col16\" class=\"data row25 col16\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col17\" class=\"data row25 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col18\" class=\"data row25 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col19\" class=\"data row25 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col20\" class=\"data row25 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col21\" class=\"data row25 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col22\" class=\"data row25 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col23\" class=\"data row25 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col24\" class=\"data row25 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col25\" class=\"data row25 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col26\" class=\"data row25 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row25_col27\" class=\"data row25 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_dda8b_row26_col0\" class=\"data row26 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col1\" class=\"data row26 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col2\" class=\"data row26 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col3\" class=\"data row26 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col4\" class=\"data row26 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col5\" class=\"data row26 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col6\" class=\"data row26 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col7\" class=\"data row26 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col8\" class=\"data row26 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col9\" class=\"data row26 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col10\" class=\"data row26 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col11\" class=\"data row26 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col12\" class=\"data row26 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col13\" class=\"data row26 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col14\" class=\"data row26 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col15\" class=\"data row26 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col16\" class=\"data row26 col16\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col17\" class=\"data row26 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col18\" class=\"data row26 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col19\" class=\"data row26 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col20\" class=\"data row26 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col21\" class=\"data row26 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col22\" class=\"data row26 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col23\" class=\"data row26 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col24\" class=\"data row26 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col25\" class=\"data row26 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col26\" class=\"data row26 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row26_col27\" class=\"data row26 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dda8b_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_dda8b_row27_col0\" class=\"data row27 col0\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col1\" class=\"data row27 col1\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col2\" class=\"data row27 col2\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col3\" class=\"data row27 col3\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col4\" class=\"data row27 col4\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col5\" class=\"data row27 col5\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col6\" class=\"data row27 col6\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col7\" class=\"data row27 col7\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col8\" class=\"data row27 col8\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col9\" class=\"data row27 col9\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col10\" class=\"data row27 col10\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col11\" class=\"data row27 col11\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col12\" class=\"data row27 col12\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col13\" class=\"data row27 col13\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col14\" class=\"data row27 col14\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col15\" class=\"data row27 col15\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col16\" class=\"data row27 col16\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col17\" class=\"data row27 col17\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col18\" class=\"data row27 col18\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col19\" class=\"data row27 col19\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col20\" class=\"data row27 col20\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col21\" class=\"data row27 col21\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col22\" class=\"data row27 col22\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col23\" class=\"data row27 col23\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col24\" class=\"data row27 col24\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col25\" class=\"data row27 col25\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col26\" class=\"data row27 col26\" >0</td>\n",
       "      <td id=\"T_dda8b_row27_col27\" class=\"data row27 col27\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x31b4d1d90>"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_t = tensor(im3)\n",
    "df = pd.DataFrame(im3_t)\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "len(three_tensors),len(seven_tensors)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [1, 1, 1]])"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tensor([0, 1, 2])\n",
    "b = tensor([1, 1, 1])\n",
    "torch.stack([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([6131, 28, 28]))"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_threes.ndim, stacked_threes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the ideal 3\n",
    "mean3 = stacked_threes.mean(0)\n",
    "show_image(mean3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean7 = stacked_sevens.mean(0)\n",
    "show_image(mean7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a sample \n",
    "a_3 = stacked_threes[1]\n",
    "show_image(a_3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you calculate how different are the two arrays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1114), tensor(0.2021))"
      ]
     },
     "execution_count": 944,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just mean3 - a_3 is no good\n",
    "# because some values would become negative and some would be 0 so cancel out\n",
    "\n",
    "# data scientists often use\n",
    "# the mean absolute difference (L1 Norm)\n",
    "dist_3_abs = (a_3 - mean3).abs().mean()\n",
    "\n",
    "# or the Root Mean Squared Error RMSE (L2 Norm)\n",
    "dist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()\n",
    "dist_3_abs,dist_3_sqr\n",
    "\n",
    "# when to use which?\n",
    "# L2 norm MSE:  penalize bigger mistakes more heavily and tolerate small mistakes\n",
    "# can you think of a use case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 945,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAXg0lEQVR4nO2cS48r2ZHffxHnZCYfVXXrvrrV6pZmWgMLGE0LsI1ZGfDGgL+AAX8HfxB/G68MLw1vvbQXs/GMR5Y0rVa3+r7rQTIzzznhRZxMskp3RoJVvF1tVAC8JIu8STIi4x+vf6SYmfEg36nod/0FHuTBCPdCHoxwD+TBCPdAHoxwD+TBCPdAHoxwD+TBCPdAHoxwDyT+sW/8t/rvj/k9/r+U/1r+0x/1vgdPuAfyYIR7IA9GuAfyYIR7IA9GuAfyYIR7IA9GuAfyR9cJH0xEbj3Xeie/97c/KFZuPbX3v/YdDxfvjxHk/UoWlf1zFeS2kfSWQcpeuWYH7y2GBGblW6n/z8r+s78jY3xYI7xH0bOSJwWrQghIqEqKcf+6qr8usj+W3lQ04MrMGcywg8fkjGU3guSM5ezvr/dWbO8hH9AgxzfCpCzRPaSE4AoPAWmqkmNE2sbf3zZY14AqZRGxoH5rFVPBVChxbwgTEAPMkGxIAR0LUgwZM9onf61P6DC6gvsBG/2xDaMbot6sGAhukA9gjA8PR6JICCDi9zG6MWJ05QeFrp2VX5aREpUShdIqFqAEwYJggitrOnQ2xEAyhKEgGXQIhKhIMVTdo8gFMat6Lu4VTHo3RMs+fogc3RDHM4LI/uwXdXgJAVSRrnWlx4gtWgjBz3RVULCuobQBi8K4ipROyI0wnCilBQ50IpOuEizfFJrLjAX3FAtg0T0HcGWmCj2rBXa6RsaEbHZISu4Z/bD3iDHVTzmuRxzHCJMBJmxXdahpWn++XGBtg3WRfNJR2lBhxH9oaZXcKhaF4SSQO2Fcwe65kBeGJEEHkArfUiBu4eRro/v6krJs2H20IncKVtCokFyRMowQAunpCeNJQxgL8W2DDAnZDRC2kBIM4xxjLE//HEfu3ghykM3APpBOBqlnPepBuHSB3KrDSNoboTR+NpcGcuNndIlQIqhN4OFi6rf5TC/Nwd8dukCxELDG4a80gdL59whtrIE7IqqYBkSSe9AHgKW7NUINlDMENTXYhoAsFtC1/no/wvUWHp8xnEWHmUbI3aHifv/w3Wv/jObSWL7JSDaGU2U4ETRBXijDDx9RWmWsx0xLYfvUDyalQ/Mp4HEFgdC7YsM2EpqAloKMyWPElFVZcUc4kiHuzggHWdCU/UiMewjqWspq4T/seoO9u0DWS8a1snuqjGsYz8xxXAzEkCzEjRB6CDtYvDLirrB8MdL96iWMifHPnnP92RJTSAsltw0WhNS5IdNSGM7cuKX1m2SI10Lc+nE1B2LjHtP02b9/LjAOntKG4B5xq/i7K7lzOJLDfL+JyHqJxUB+dkr/uEOK0Z4uCFfnjM/X7M6V8cSVgwBT7SQCVpUXQVrIHYCS1oHm/ARSYTxrGVd+AoTe0LSHJwt+w9EIC+awxf64GivsTQE8CBTdxzUxjp2k3jEcaS2saib05Jzdjx8zngZe/jySv7hCxOivW+iXEAxdbgmhML7pWH4VCaPn/eAKHE+M8dRz//6JQIF3Y0Poz8EgrYy8NMJOOP9bYf3NQFoFhpNIWngcwYACOsoc/C1CVkBgXLqVNBmli6iI1y+1YBQRN4ToUQL0cbKjGoRtvWDzUUP/SEh/dcV//Bf/mbX2fDU+4U1ac5kX/MP2MZvU8j/zjwj/J9JceaFkIpQWhjMo6wwKORY/QUMhB0MqbAWB4aKj/CISL3pMF6Aen6fYIgZkamXnXlEaoPjn5CyekTUBK4bF4CeSmWd3Kjd7T3coRy3WLOxz9RgLZ7pjpT1numUMgWxKU/PMMirNldFeGakTSmtgQhigbEJVnIJACUbRWtWqgYLsvJBLpx3jSSAtPND7/wPM8T/uHIqGUyGv7EaxN8vt/tSR5Q4Dcy3MdB+gLShpKaQlrBcDz8MlK0mUqCx0JFD4tT6hmCCbyOlvMt2bgc0nHZvnimZo3wrN1UE6Wqvk6b40UKKhScgtXH3WMq6F/imkpVfQExStvzLO//eWvAi8/suOzXp/rBvHnX6SCPYBDHLctoUKJXgAjCHTSKGVQiOJhYw0kimmFFNkENrLgfBuR3jcOo4bhB7o6/EMxMwVo66w0kJpahAPMK6FtPKiLi88UMsomBpxZzTfXhJXHaH3dHlufRzo2qbE4APJ3RuhmLeTcya823L2ZcfwJvCm+5h/9+Y/oFooOVCyYKMi1wEdhdNfK2TDmoCOhe6dYvp+DJ4ynxsfG2A8Efpzx/gyvW5eUUuphd+TNXkRKdGDtGTQBJpq8y+bp6eleAe21gXHigdwl0awghWtPXvDcka+fcX6csM6KOf/o4EmgggWD/pEU/VcpSwicZNZje/50RN0RC/EAMI2EzeJtIq8+nnH7nnZG0k8x3UlQ1rA9uOFp6PRIUqT9510BB0MHTMyZiTVVnfO+xnF96VOwPwsIoR9ixiwYcSGwWPHokNDbV8vFhADtuzIpwsIguRCuHXmmeA5PLVuqsMcrT0nMT/7S2v7/2DiZ/ooSK0f0sIDuLc5Ji/Bj1EMqjdQ9k27Y6/1HSUmmNlc8hvsZwddB+CVdKg1hZm3lvuRIOLKDT4rMJH5cYnq2ZYKpVHS0tvbV59G+kcLSgPjI1eWJCH0rvjurbD6pqAJ+kfC5Y91xv+488ZfszXi1oi7jPYjjLWBNyb3hiNWy3DXRpggSQzD+/XUQkdCgNaDIWHf2phdfUxIznO1bUG9mdZEiIqaeR4v4j2hhZA74eJz4CdXfojLDtmqtzuuPL1d/a5w/nfXkAov//qMzacFDLqXSnsBYWfETSFuMrp15cvobe0Zjo5oADhWdmTFU1QzxMwNYYbUvwNQvIUgcDAX1j3/Yx5fMqeJMhaHn+oFpfHXMfF5chJ0cOWHwTMrE2E8a5Fi5E4wLUgRh6AalCUbmgtSb+QKRdN4dP5d971Yq8qevUELFMXwmCAhYFXZEoIH41pL+OzB5qG9xYAtbo43ZczENxsYE6V7wngipJUH0/HrJVJg+U4JW1d+984Ig7F7LPz2X3fk1jA1tFd0hLiB9sqI20KzSYTrEd0MsOuxlD2G1aGOz56/D9nRLZnGhGRc2ZMxqldQYUfMjWDazPBFDFgbK/77hC2MGbncYNcb9JNz8gLS0oNu98YDcHsBYWuEAbqLjA7G9ScN6acbVqueixcnNC8joRfizgi91w66TcguIf3o07WUZhiyI8cDuPOYsPcGRKsh6vPiqajV2e4sohC0xoI66Fl3DI87ShDSSsmtEHcNy6iEzchw3iDFIWeCFUnQXhjtVaFEYXceKA3056CheAPuRjZ0M7OSqSYw29c6H0iOkKIeGAJmfs8ET/6k7ANzjD5vaBqs9Vpi+/GSix9Hb+Cde6dUB6F9tyb0VYG9B9XQews79sbqtzviyyt2f/6YF/+8YfzBSOgyiyZTikKWOV3VsRZoyRkZjMmncjljNRYcs0A7lA/LtjgMzBPGqqevnrJ6ippWynjm84P+ccFOEoxKaYLj+bWweG3+eGs02+JZzpsNvHiN/vAR6VHh+cfvSFkZcyBnRYq3wmdvyNysCabvdOgFH4D2cqTsyPbZzW1ogv28IQSkaTwGNBFbON+oPxV2Tw1rDNSQXUB6n7Lp4EE19H4ma2Ye/qTzFSF8TO6UxdeBl+kpwEyDOfmtcvJVmblJpREkeftaxgC1fe1FW3b4LMr3k20B7zXELFKnb8Gnb5MByqolLyO7Z4J8ukGA/KYjXCqhF9p3ewhqNlZTS1eoBaF/1mEfdVgQHv2icPZLKv3Fz/xHv9jS/N1XSNOw++kP2HzceE+pi0gqDkexqiRnLyK1HJNoAXyXXNTDFLXSYixoJXZBiP7Lcw2mOuH4uM/tpTB3WxHInVCCIAaxNzBvc5fG64KwS7DdzVhvOg38ZZ+tTZX6Icf1SBO1ST6YEQ45p06DqY/rDy5tYDyJlFYJPWxfrPwLXipx68N+by145xNxJTq2WyWKOWHAW9779naJ7pHj6oTmJz8DgWHt3VZTweIEkwITMW3mrmaEvCcX32u2xf+DSA3EPsoMpFUgt67w7oX3onXwMz9sHYLirnj9UAf4U6qZgxPE+vNpqOR388Bf4fpTKAugQHshhK037kxlHmNa23jlnBI2jP4di9WO7Peli/o++af2CeqZJTZ1MkGSob3MSp7gpkTIzUQIZv5/mFJah6EpUGvy+9xBairTItZgnyG35vPlRmbi8GyIypOdThLnrx5PPcejQc6PdX9/a7/AzJCUQQTtE/E6oGOdFUgNqg3zdG73RD0IT4w73FPCaPMUbvWNtyJW3w6ETeLiJ2te/6xyWAEZ/NjptDCeG5oiYZPgdy+R1Yry+MRjQ8owdEg5ZGsfJ1M6ricc0uFvi5UbUzgZM6EvlVdaG3TRSCtxpUcYK0PvcBwpCTR76rp8WejeFdq3I83/+g3lzRvWq5/z5i+XlDh5mbhHLDNhmUmvA9KP5FevCRqw8AhrKnswBizh6bTo0TKl43NR4b1eALghcvG/p4JWSAg7pZkCqnlG5GQtmT1gNkKesicP2BYgLwPNR08IJyv6ZfR4UiHMasyliEO8QF53xKdPkNM11igWdV8zTF1graSwI+DSUWiQcsC4mEaXcjvtA9fGOEIpCBDM0KiEPpMvAwQhN0pptGZDciPg+oGZqe8mbqj+PLJ5/nh+//Jbb5vvngn948rASELpA6aw/WTBkh85/LU1IdhGQlPVM8cHjpKu3j0D7/Dx4dk/GUAO/lZsP4VL6oOd5K2FkAoEQWOtJdgre5o5WD1Dpx2EtKwk4E4YHjkFprk2ureO4ePpZEFPYS3X+LAQ0mkz013EmCd6HDDIpdRG4B0Tg+/GCAcQJLUXNCs6VNpDLYT8sczd01kqG3r6gZLD3EuaZsvzyBPcEDNpQNxQFiitc2HSsmY5Ze81N+KJ4TPoEdrLQvt6R15E0jrOK1kWdIajY1Jg7tQTpmHNtA6F6n4B8ACa3hs3DlgNcug10/sn0ZueZdF7PhYCkjrKIiA5kJY+yZ/ihInM5OBDglcYhO5lj375LfrsMenkzGNPU49rNm8Y3fvJ2s09430L4B9V/mGsmGT6kfk9mHvDEFOpLPNJLYCmgiX1ntJohPoZJcieqX14QteWh4808/uVfMsDROXOM6Q/3QiHAXlajZo2MoN6C2AKynrTALNM48PDVvJtusmBgmaIUIUiM95YrS3iLnP6qxEx4/rTJe/+IpA7yItbShanyPTPFyzyD8ir9qa3vAeCjjFjuKOYcNATOtzIVIVpLVb3AfbGj5sgKJd5qQ+46Q23RowGdXGjIOqbmVbMW88qhKuR8MtvsMtL2rMv2D5X8llCBkV7r6wnVZYWNs8ipus5dky7cFMsmKnx8xe4p8WaHHxhX66QPZaKVKr5gRGmDMPUs6QJ/8HP7jlA56qcsN8fm7Kumr1Mx3YYKt4CWS+RoL48eJtOWQTtwQZBe+ep5lZmEtis8fcxLo4gf5oRDtdkte4nT3tqdVBD11aKfICoFTJ0zlCkznSlmPf0zfa9/drWkJmGaPPnWqzZ07L1xXMzdDOgb68pZ0su/uUnDGtl90yAggyKjIJkpz52r5T2cvpsGFdKGGyeU0iupLRcfp8Oecdyt8Xa1JqeFiyaSGkjhIk1UfmnFTZmI5i3oyXVJe8xI6lmI6Pe4AEB7l0xYKqURUNZRm/6vb2GtxdwsuTys8D2I2/aYaCDG0DMGRqLV8b6m5G8UPpHgbzYNwudKFzpnFN8mgjCR5DjrEtNZb6qn/3B8/nSuieU5oDkBXsWRHIo0RSQsdSWRfbJDtVgePC1JjiE5eINOCA/O8U+OqN/2pEX7L0t10xsInsl6hZQ8Co5HHyHbLUFckAEm2DwSPSXOwzMtUKeMTpgTSB37gF5EcgLN05uax9nbgVwA49nqvrcE7p5BlpwCqQUWP12S/jyJXay4sW/es7l51OWZPNxdageMPgNnJfaPwpogrixmX0RdxkdCrqrfNSUsJR8i/N7NU+YAmb1gOkyB9MsILdCbmCaEeyNIAdGoD4W9JYRpmPNS4DX10jXMjwS+h8OkJRwpejoLZC5yTc6V8nUiWOlm6gz1HkGewpM7e7aBEtHlOOxLQ7w03cKmK83kRZQ2rrF0x60E6q40mrMOOiShp0bJ+4KywtfJk+rhvLF56STxmfT7yKSxRWbZA9Bsyf4JG3qpvjYFOLO5xBhl/wSCxMbby7kytHokHdjhGknYWrITXn7zPP1AXxufUiTVr7HZtGJXb5vbPO07FCmYBl6YfHSR5LtNax+9Q7GxNXPnvH2LzpvUQssXujMKdrj/GQEZ2r4BpAbKG6N7rI4M/tqRK92TgTb7mBwZrZNGdKR5M6p8b9X/YKngbZ3eaaRLXv8LhGIhon5kB5/n4m/yeTAYwzvuI7Jt/eXOKG7Yv6h4vc5f/274YuEyatuZ+N5faE1NZaUsVIVb8ebLU9yp6xsywUJ2X8IoENCh4hkRV+PtO/80gW5XkBkXAvXn6hPz4LNrIi4kRl6mms/ewG/3AJujOGzc6e7N0J7wZ55YU6LXLxxVt5wpmyfat1xcwtOV4XRy0LsjfbtSNgldDMg294JwX2/p0QeXlHsCPKnGcFHVD57za54svqPABgTOmRMC7obkd04e4kUIz07JTcnDOcOV1a37xevjOWrQtgVFt9uCG+uKScLdj88Ja2UEuD6By0T7aW9sDnIm0JzZax/syW826J/ds7muc47zYigo9Fd+LWR4i4T322R3Yj0A7bd+obOlBVNaen3ioE3wVEtdCQVrxU6Z9jBNCEThvOGtBZSzemny6jNl9SJQmkj2jVOlQ8+9HcCgEOUzNDiwdzUGRclKrLwhpxmsDRlR56Oht58pj0ULw5vEYK/f6xsq+nc9LwfDujuCouGt1+c8/afKbkz0lnBlg7aoj2IYUOYV51K6xcR0RGaZ4Fmu6QEyK3MFw2ZoKu9NJqte5YONhPBrj9dUJoFpkK8Npor5y011xlJRvtuQK8GZBiR660vOY4DtuvnixfOwfhe946AiXNqxZypBpASYor1Q73QlLL5SOGLS56st/zVk2/46fp3vBxP+NvLj7kcOl5fr7i8WFIGpddIbr3HM64rnf2ATT15hBSwKwi74oXWdUL7xHDesftRZDwVmisfb4bRaC8yzcWApIJebGf8t+3Wt3Jy/mAQdCh35Am2z/MrjcVgDtKMibgxLi59ezM+y3zWvuYk7OhL5G27ZBlHvtHCmAPbZce4jN7t3OreCKPTW+K1xw0dvWaYhv3TTYqvQknxs7+9PDDSdvT2yDDCONb0s8zd0g+1k3Aod7tMnnFQH6istdp9TIn1t5ntL1t2zyLd54l/s/w1G4OfL75kUzpe5RN+MzxhVxpejWvejktSCVyljm1q6FPkzWbJOAby35zy9G+u0LfXpOen9E+7elEpBSI6Fk6/9JRK++ywk7Nf4267c2X3vZ/9ZvX+1mrU9/K6qIcbOiaQa4o+gIgSrzLNRSQvBBXjWVgyWqaRK67LhifhivNwza60vG1XvM5riinv0pK+RC7Ski+bczZjy4twSnh5Qfn6d4Tln0M1gtVLdepY0KvRA+4wOuyU4rjfV8yvXvBdKn+So+ysTS49x4hhoPv2mvNFoH+l/JflX/PfPv8pZsI4BqwIpShlVNdB8tWmuQNamXOhF3SE878vsOtBFb3asXgxXVuvXhKhFD/rs8OhDSOUPKeelHJvDADH2lmrk3Azma8vqn//D6y/7FjHyNP/vsaWHh9M6lbnH1LAwVKf7HrP50PA3rwjXFz6e6ZOZzHKVO1Oc4Cq7H3hVW4e+zuU43JR5yF9pmy3sN3681evf4+lZ3CTKHabNHZ42MPHw7D/nMPBy4Gy36v4w+/3HcuH2084GE3OQRw8kOdKJZnee5uT9I+RimGvbLih5Pt6mf73yYdfErmthAm6PlyBeu/kn9jeeJAPJQ9GuAfyYIR7IA9GuAcidmx62YP8QXnwhHsgD0a4B/JghHsgD0a4B/JghHsgD0a4B/JghHsgD0a4B/JghHsg/xd55uv2Yj3EXQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image((a_3 - mean3).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 and L2 are already available in pytorch\n",
    "F.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors gymanstics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns = tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5])"
      ]
     },
     "execution_count": 949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6])"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns[1,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you guess the shapes of those things? What do these vectors represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want ratio, so we divide by the max value possible which is the max value of a pixel (255)\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float() / valid_3_tens.max()\n",
    "\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float() / valid_3_tens.max()\n",
    "valid_3_tens.shape,valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_distance(a,b): return (a-b).abs().mean((-1, -2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([28, 28]), torch.Size([28, 28]), tensor(0.1114))"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets compare a_3 to the ideal_3\n",
    "a_3.shape, mean3.shape, mnist_distance(a_3, mean3)\n",
    "# it works! we are just comparing an image to an image 2d to 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1074)\n",
      "tensor(0.1114)\n",
      "tensor(0.1100)\n",
      "tensor(0.1154)\n",
      "tensor(0.1300)\n",
      "tensor(0.1700)\n",
      "tensor(0.1158)\n",
      "tensor(0.1414)\n",
      "tensor(0.1265)\n",
      "tensor(0.1356)\n",
      "tensor(0.1100)\n",
      "tensor(0.1162)\n",
      "tensor(0.1286)\n",
      "tensor(0.1511)\n",
      "tensor(0.1210)\n",
      "tensor(0.1146)\n",
      "tensor(0.1133)\n",
      "tensor(0.1137)\n",
      "tensor(0.1470)\n",
      "tensor(0.1194)\n",
      "tensor(0.1414)\n",
      "tensor(0.1199)\n",
      "tensor(0.1811)\n",
      "tensor(0.1151)\n",
      "tensor(0.1648)\n",
      "tensor(0.1447)\n",
      "tensor(0.1098)\n",
      "tensor(0.1445)\n",
      "tensor(0.1154)\n",
      "tensor(0.1108)\n",
      "tensor(0.1126)\n",
      "tensor(0.1258)\n",
      "tensor(0.1077)\n",
      "tensor(0.1224)\n",
      "tensor(0.1331)\n",
      "tensor(0.1401)\n",
      "tensor(0.1423)\n",
      "tensor(0.1396)\n",
      "tensor(0.1472)\n",
      "tensor(0.1343)\n",
      "tensor(0.1264)\n",
      "tensor(0.1630)\n",
      "tensor(0.1210)\n",
      "tensor(0.1291)\n",
      "tensor(0.1304)\n",
      "tensor(0.1117)\n",
      "tensor(0.1270)\n",
      "tensor(0.1808)\n",
      "tensor(0.1280)\n",
      "tensor(0.1207)\n",
      "tensor(0.1300)\n",
      "tensor(0.1202)\n",
      "tensor(0.1570)\n",
      "tensor(0.1702)\n",
      "tensor(0.1255)\n",
      "tensor(0.1280)\n",
      "tensor(0.1242)\n",
      "tensor(0.1337)\n",
      "tensor(0.1172)\n",
      "tensor(0.1351)\n",
      "tensor(0.1175)\n",
      "tensor(0.1273)\n",
      "tensor(0.1199)\n",
      "tensor(0.1261)\n",
      "tensor(0.1585)\n",
      "tensor(0.1287)\n",
      "tensor(0.1265)\n",
      "tensor(0.1523)\n",
      "tensor(0.1385)\n",
      "tensor(0.1573)\n",
      "tensor(0.1309)\n",
      "tensor(0.1235)\n",
      "tensor(0.1110)\n",
      "tensor(0.1072)\n",
      "tensor(0.1211)\n",
      "tensor(0.1348)\n",
      "tensor(0.1223)\n",
      "tensor(0.1332)\n",
      "tensor(0.1088)\n",
      "tensor(0.1346)\n",
      "tensor(0.1561)\n",
      "tensor(0.1420)\n",
      "tensor(0.1232)\n",
      "tensor(0.1280)\n",
      "tensor(0.1087)\n",
      "tensor(0.1398)\n",
      "tensor(0.1131)\n",
      "tensor(0.1361)\n",
      "tensor(0.1325)\n",
      "tensor(0.1188)\n",
      "tensor(0.1160)\n",
      "tensor(0.1269)\n",
      "tensor(0.1102)\n",
      "tensor(0.1200)\n",
      "tensor(0.1297)\n",
      "tensor(0.1187)\n",
      "tensor(0.1276)\n",
      "tensor(0.1480)\n",
      "tensor(0.1383)\n",
      "tensor(0.1202)\n",
      "tensor(0.1440)\n",
      "tensor(0.1240)\n",
      "tensor(0.1053)\n",
      "tensor(0.1156)\n",
      "tensor(0.1130)\n",
      "tensor(0.1126)\n",
      "tensor(0.1307)\n",
      "tensor(0.1825)\n",
      "tensor(0.1770)\n",
      "tensor(0.1119)\n",
      "tensor(0.1109)\n",
      "tensor(0.1144)\n",
      "tensor(0.1280)\n",
      "tensor(0.1212)\n",
      "tensor(0.1270)\n",
      "tensor(0.1296)\n",
      "tensor(0.1057)\n",
      "tensor(0.1402)\n",
      "tensor(0.1368)\n",
      "tensor(0.1259)\n",
      "tensor(0.1429)\n",
      "tensor(0.1139)\n",
      "tensor(0.1262)\n",
      "tensor(0.1578)\n",
      "tensor(0.1512)\n",
      "tensor(0.1259)\n",
      "tensor(0.1177)\n",
      "tensor(0.1832)\n",
      "tensor(0.1514)\n",
      "tensor(0.1416)\n",
      "tensor(0.1401)\n",
      "tensor(0.1469)\n",
      "tensor(0.1223)\n",
      "tensor(0.1281)\n",
      "tensor(0.1156)\n",
      "tensor(0.1553)\n",
      "tensor(0.1205)\n",
      "tensor(0.1147)\n",
      "tensor(0.1710)\n",
      "tensor(0.1188)\n",
      "tensor(0.1178)\n",
      "tensor(0.1108)\n",
      "tensor(0.1611)\n",
      "tensor(0.1229)\n",
      "tensor(0.1770)\n",
      "tensor(0.1140)\n",
      "tensor(0.1262)\n",
      "tensor(0.1336)\n",
      "tensor(0.1288)\n",
      "tensor(0.1205)\n",
      "tensor(0.1071)\n",
      "tensor(0.1317)\n",
      "tensor(0.1149)\n",
      "tensor(0.1048)\n",
      "tensor(0.1783)\n",
      "tensor(0.1193)\n",
      "tensor(0.1122)\n",
      "tensor(0.1352)\n",
      "tensor(0.1133)\n",
      "tensor(0.1198)\n",
      "tensor(0.1173)\n",
      "tensor(0.1497)\n",
      "tensor(0.1211)\n",
      "tensor(0.1127)\n",
      "tensor(0.1189)\n",
      "tensor(0.1191)\n",
      "tensor(0.1235)\n",
      "tensor(0.1121)\n",
      "tensor(0.1148)\n",
      "tensor(0.1215)\n",
      "tensor(0.1285)\n",
      "tensor(0.1125)\n",
      "tensor(0.1226)\n",
      "tensor(0.1151)\n",
      "tensor(0.1472)\n",
      "tensor(0.1181)\n",
      "tensor(0.1176)\n",
      "tensor(0.1773)\n",
      "tensor(0.1476)\n",
      "tensor(0.1717)\n",
      "tensor(0.1615)\n",
      "tensor(0.1174)\n",
      "tensor(0.1733)\n",
      "tensor(0.1508)\n",
      "tensor(0.1353)\n",
      "tensor(0.1207)\n",
      "tensor(0.1730)\n",
      "tensor(0.1602)\n",
      "tensor(0.1463)\n",
      "tensor(0.1406)\n",
      "tensor(0.1110)\n",
      "tensor(0.1448)\n",
      "tensor(0.1577)\n",
      "tensor(0.1141)\n",
      "tensor(0.1223)\n",
      "tensor(0.1186)\n",
      "tensor(0.1567)\n",
      "tensor(0.1226)\n",
      "tensor(0.1356)\n",
      "tensor(0.1270)\n",
      "tensor(0.1311)\n",
      "tensor(0.1500)\n",
      "tensor(0.1368)\n",
      "tensor(0.1311)\n",
      "tensor(0.1509)\n",
      "tensor(0.1368)\n",
      "tensor(0.1745)\n",
      "tensor(0.1261)\n",
      "tensor(0.1332)\n",
      "tensor(0.1113)\n",
      "tensor(0.1429)\n",
      "tensor(0.1258)\n",
      "tensor(0.1512)\n",
      "tensor(0.1395)\n",
      "tensor(0.1264)\n",
      "tensor(0.1531)\n",
      "tensor(0.1541)\n",
      "tensor(0.1310)\n",
      "tensor(0.1534)\n",
      "tensor(0.1262)\n",
      "tensor(0.1618)\n",
      "tensor(0.1336)\n",
      "tensor(0.1274)\n",
      "tensor(0.1384)\n",
      "tensor(0.1154)\n",
      "tensor(0.1729)\n",
      "tensor(0.1612)\n",
      "tensor(0.1259)\n",
      "tensor(0.1499)\n",
      "tensor(0.1145)\n",
      "tensor(0.1309)\n",
      "tensor(0.1123)\n",
      "tensor(0.1432)\n",
      "tensor(0.1682)\n",
      "tensor(0.1159)\n",
      "tensor(0.1394)\n",
      "tensor(0.1858)\n",
      "tensor(0.1252)\n",
      "tensor(0.1440)\n",
      "tensor(0.1033)\n",
      "tensor(0.1739)\n",
      "tensor(0.1622)\n",
      "tensor(0.1442)\n",
      "tensor(0.1671)\n",
      "tensor(0.1207)\n",
      "tensor(0.1149)\n",
      "tensor(0.1159)\n",
      "tensor(0.1232)\n",
      "tensor(0.1185)\n",
      "tensor(0.1456)\n",
      "tensor(0.1308)\n",
      "tensor(0.1144)\n",
      "tensor(0.1188)\n",
      "tensor(0.1218)\n",
      "tensor(0.1443)\n",
      "tensor(0.1439)\n",
      "tensor(0.1244)\n",
      "tensor(0.1304)\n",
      "tensor(0.1472)\n",
      "tensor(0.1063)\n",
      "tensor(0.1253)\n",
      "tensor(0.1322)\n",
      "tensor(0.1554)\n",
      "tensor(0.1208)\n",
      "tensor(0.1489)\n",
      "tensor(0.1253)\n",
      "tensor(0.1149)\n",
      "tensor(0.1327)\n",
      "tensor(0.1233)\n",
      "tensor(0.1655)\n",
      "tensor(0.1232)\n",
      "tensor(0.1587)\n",
      "tensor(0.1215)\n",
      "tensor(0.1548)\n",
      "tensor(0.1845)\n",
      "tensor(0.1308)\n",
      "tensor(0.1600)\n",
      "tensor(0.1444)\n",
      "tensor(0.1435)\n",
      "tensor(0.1211)\n",
      "tensor(0.1462)\n",
      "tensor(0.1084)\n",
      "tensor(0.1451)\n",
      "tensor(0.1282)\n",
      "tensor(0.1344)\n",
      "tensor(0.1302)\n",
      "tensor(0.1260)\n",
      "tensor(0.1149)\n",
      "tensor(0.1218)\n",
      "tensor(0.1257)\n",
      "tensor(0.1218)\n",
      "tensor(0.1432)\n",
      "tensor(0.1475)\n",
      "tensor(0.1283)\n",
      "tensor(0.1160)\n",
      "tensor(0.1330)\n",
      "tensor(0.1409)\n",
      "tensor(0.1733)\n",
      "tensor(0.1305)\n",
      "tensor(0.1269)\n",
      "tensor(0.1445)\n",
      "tensor(0.1600)\n",
      "tensor(0.1503)\n",
      "tensor(0.1297)\n",
      "tensor(0.1455)\n",
      "tensor(0.1614)\n",
      "tensor(0.1152)\n",
      "tensor(0.1559)\n",
      "tensor(0.1486)\n",
      "tensor(0.1320)\n",
      "tensor(0.1084)\n",
      "tensor(0.1483)\n",
      "tensor(0.1421)\n",
      "tensor(0.1079)\n",
      "tensor(0.1222)\n",
      "tensor(0.1230)\n",
      "tensor(0.1092)\n",
      "tensor(0.1418)\n",
      "tensor(0.1351)\n",
      "tensor(0.1107)\n",
      "tensor(0.1531)\n",
      "tensor(0.1117)\n",
      "tensor(0.1463)\n",
      "tensor(0.1035)\n",
      "tensor(0.1193)\n",
      "tensor(0.1481)\n",
      "tensor(0.1517)\n",
      "tensor(0.1329)\n",
      "tensor(0.1292)\n",
      "tensor(0.1517)\n",
      "tensor(0.1844)\n",
      "tensor(0.1440)\n",
      "tensor(0.1558)\n",
      "tensor(0.1225)\n",
      "tensor(0.1182)\n",
      "tensor(0.1530)\n",
      "tensor(0.1186)\n",
      "tensor(0.1784)\n",
      "tensor(0.1440)\n",
      "tensor(0.2138)\n",
      "tensor(0.1056)\n",
      "tensor(0.1452)\n",
      "tensor(0.1497)\n",
      "tensor(0.1195)\n",
      "tensor(0.1709)\n",
      "tensor(0.1077)\n",
      "tensor(0.1057)\n",
      "tensor(0.1438)\n",
      "tensor(0.1751)\n",
      "tensor(0.1902)\n",
      "tensor(0.1797)\n",
      "tensor(0.1257)\n",
      "tensor(0.1677)\n",
      "tensor(0.1437)\n",
      "tensor(0.1424)\n",
      "tensor(0.1104)\n",
      "tensor(0.1166)\n",
      "tensor(0.1854)\n",
      "tensor(0.1309)\n",
      "tensor(0.1443)\n",
      "tensor(0.1094)\n",
      "tensor(0.1100)\n",
      "tensor(0.1183)\n",
      "tensor(0.1480)\n",
      "tensor(0.1350)\n",
      "tensor(0.1508)\n",
      "tensor(0.1566)\n",
      "tensor(0.1504)\n",
      "tensor(0.1175)\n",
      "tensor(0.1126)\n",
      "tensor(0.1580)\n",
      "tensor(0.1801)\n",
      "tensor(0.1191)\n",
      "tensor(0.1378)\n",
      "tensor(0.1282)\n",
      "tensor(0.1156)\n",
      "tensor(0.1553)\n",
      "tensor(0.1263)\n",
      "tensor(0.1574)\n",
      "tensor(0.1433)\n",
      "tensor(0.1382)\n",
      "tensor(0.1331)\n",
      "tensor(0.1037)\n",
      "tensor(0.1389)\n",
      "tensor(0.1489)\n",
      "tensor(0.1296)\n",
      "tensor(0.1348)\n",
      "tensor(0.1456)\n",
      "tensor(0.1274)\n",
      "tensor(0.1242)\n",
      "tensor(0.1302)\n",
      "tensor(0.1330)\n",
      "tensor(0.1324)\n",
      "tensor(0.1140)\n",
      "tensor(0.1312)\n",
      "tensor(0.1207)\n",
      "tensor(0.1600)\n",
      "tensor(0.1306)\n",
      "tensor(0.1090)\n",
      "tensor(0.1182)\n",
      "tensor(0.1267)\n",
      "tensor(0.1321)\n",
      "tensor(0.1336)\n",
      "tensor(0.1231)\n",
      "tensor(0.1211)\n",
      "tensor(0.1377)\n",
      "tensor(0.1321)\n",
      "tensor(0.1555)\n",
      "tensor(0.1281)\n",
      "tensor(0.1665)\n",
      "tensor(0.1599)\n",
      "tensor(0.1228)\n",
      "tensor(0.1638)\n",
      "tensor(0.1041)\n",
      "tensor(0.1391)\n",
      "tensor(0.1188)\n",
      "tensor(0.1430)\n",
      "tensor(0.1126)\n",
      "tensor(0.1778)\n",
      "tensor(0.1429)\n",
      "tensor(0.1145)\n",
      "tensor(0.1392)\n",
      "tensor(0.1495)\n",
      "tensor(0.1349)\n",
      "tensor(0.1240)\n",
      "tensor(0.1206)\n",
      "tensor(0.1541)\n",
      "tensor(0.1196)\n",
      "tensor(0.1921)\n",
      "tensor(0.1028)\n",
      "tensor(0.1393)\n",
      "tensor(0.1207)\n",
      "tensor(0.1179)\n",
      "tensor(0.1306)\n",
      "tensor(0.1488)\n",
      "tensor(0.1226)\n",
      "tensor(0.1070)\n",
      "tensor(0.1122)\n",
      "tensor(0.1454)\n",
      "tensor(0.1458)\n",
      "tensor(0.1219)\n",
      "tensor(0.1182)\n",
      "tensor(0.1234)\n",
      "tensor(0.1223)\n",
      "tensor(0.1191)\n",
      "tensor(0.1253)\n",
      "tensor(0.1226)\n",
      "tensor(0.1346)\n",
      "tensor(0.1590)\n",
      "tensor(0.1720)\n",
      "tensor(0.1249)\n",
      "tensor(0.1367)\n",
      "tensor(0.1179)\n",
      "tensor(0.1193)\n",
      "tensor(0.1430)\n",
      "tensor(0.1157)\n",
      "tensor(0.1394)\n",
      "tensor(0.1478)\n",
      "tensor(0.1428)\n",
      "tensor(0.1266)\n",
      "tensor(0.1299)\n",
      "tensor(0.1321)\n",
      "tensor(0.1358)\n",
      "tensor(0.1936)\n",
      "tensor(0.1269)\n",
      "tensor(0.1798)\n",
      "tensor(0.1250)\n",
      "tensor(0.1121)\n",
      "tensor(0.1309)\n",
      "tensor(0.1230)\n",
      "tensor(0.1203)\n",
      "tensor(0.1406)\n",
      "tensor(0.1322)\n",
      "tensor(0.1563)\n",
      "tensor(0.1210)\n",
      "tensor(0.1303)\n",
      "tensor(0.1218)\n",
      "tensor(0.1157)\n",
      "tensor(0.1474)\n",
      "tensor(0.1090)\n",
      "tensor(0.1414)\n",
      "tensor(0.1143)\n",
      "tensor(0.1313)\n",
      "tensor(0.1512)\n",
      "tensor(0.1213)\n",
      "tensor(0.1577)\n",
      "tensor(0.1400)\n",
      "tensor(0.1394)\n",
      "tensor(0.1292)\n",
      "tensor(0.1331)\n",
      "tensor(0.1433)\n",
      "tensor(0.1455)\n",
      "tensor(0.1541)\n",
      "tensor(0.1330)\n",
      "tensor(0.1245)\n",
      "tensor(0.1779)\n",
      "tensor(0.1557)\n",
      "tensor(0.1268)\n",
      "tensor(0.1352)\n",
      "tensor(0.1307)\n",
      "tensor(0.1466)\n",
      "tensor(0.1193)\n",
      "tensor(0.1626)\n",
      "tensor(0.1254)\n",
      "tensor(0.1336)\n",
      "tensor(0.1131)\n",
      "tensor(0.1554)\n",
      "tensor(0.1972)\n",
      "tensor(0.1279)\n",
      "tensor(0.1485)\n",
      "tensor(0.1611)\n",
      "tensor(0.1345)\n",
      "tensor(0.1153)\n",
      "tensor(0.1336)\n",
      "tensor(0.1072)\n",
      "tensor(0.1152)\n",
      "tensor(0.1068)\n",
      "tensor(0.1459)\n",
      "tensor(0.1222)\n",
      "tensor(0.1412)\n",
      "tensor(0.1194)\n",
      "tensor(0.1221)\n",
      "tensor(0.1409)\n",
      "tensor(0.1552)\n",
      "tensor(0.1184)\n",
      "tensor(0.1082)\n",
      "tensor(0.1247)\n",
      "tensor(0.1159)\n",
      "tensor(0.1256)\n",
      "tensor(0.1265)\n",
      "tensor(0.1354)\n",
      "tensor(0.1185)\n",
      "tensor(0.1036)\n",
      "tensor(0.1174)\n",
      "tensor(0.1288)\n",
      "tensor(0.1641)\n",
      "tensor(0.1123)\n",
      "tensor(0.1834)\n",
      "tensor(0.1251)\n",
      "tensor(0.1864)\n",
      "tensor(0.1174)\n",
      "tensor(0.1334)\n",
      "tensor(0.1413)\n",
      "tensor(0.1554)\n",
      "tensor(0.1720)\n",
      "tensor(0.1235)\n",
      "tensor(0.1147)\n",
      "tensor(0.1110)\n",
      "tensor(0.1111)\n",
      "tensor(0.1080)\n",
      "tensor(0.1249)\n",
      "tensor(0.1641)\n",
      "tensor(0.1745)\n",
      "tensor(0.1082)\n",
      "tensor(0.1495)\n",
      "tensor(0.1015)\n",
      "tensor(0.1628)\n",
      "tensor(0.1259)\n",
      "tensor(0.1618)\n",
      "tensor(0.1755)\n",
      "tensor(0.1703)\n",
      "tensor(0.1569)\n",
      "tensor(0.1447)\n",
      "tensor(0.1126)\n",
      "tensor(0.1253)\n",
      "tensor(0.1519)\n",
      "tensor(0.1564)\n",
      "tensor(0.1298)\n",
      "tensor(0.1425)\n",
      "tensor(0.1250)\n",
      "tensor(0.1472)\n",
      "tensor(0.1327)\n",
      "tensor(0.1544)\n",
      "tensor(0.1195)\n",
      "tensor(0.1122)\n",
      "tensor(0.1054)\n",
      "tensor(0.1305)\n",
      "tensor(0.1234)\n",
      "tensor(0.1311)\n",
      "tensor(0.1554)\n",
      "tensor(0.1249)\n",
      "tensor(0.1343)\n",
      "tensor(0.1188)\n",
      "tensor(0.1082)\n",
      "tensor(0.1163)\n",
      "tensor(0.1206)\n",
      "tensor(0.1191)\n",
      "tensor(0.1575)\n",
      "tensor(0.1299)\n",
      "tensor(0.1340)\n",
      "tensor(0.1227)\n",
      "tensor(0.1296)\n",
      "tensor(0.1209)\n",
      "tensor(0.1171)\n",
      "tensor(0.1249)\n",
      "tensor(0.1384)\n",
      "tensor(0.1066)\n",
      "tensor(0.1227)\n",
      "tensor(0.1271)\n",
      "tensor(0.1363)\n",
      "tensor(0.1514)\n",
      "tensor(0.1273)\n",
      "tensor(0.1481)\n",
      "tensor(0.1102)\n",
      "tensor(0.1259)\n",
      "tensor(0.1471)\n",
      "tensor(0.1514)\n",
      "tensor(0.1419)\n",
      "tensor(0.1554)\n",
      "tensor(0.1073)\n",
      "tensor(0.1423)\n",
      "tensor(0.1241)\n",
      "tensor(0.1014)\n",
      "tensor(0.1101)\n",
      "tensor(0.1267)\n",
      "tensor(0.1174)\n",
      "tensor(0.1427)\n",
      "tensor(0.1209)\n",
      "tensor(0.1128)\n",
      "tensor(0.1136)\n",
      "tensor(0.1213)\n",
      "tensor(0.1322)\n",
      "tensor(0.1351)\n",
      "tensor(0.1177)\n",
      "tensor(0.1178)\n",
      "tensor(0.1451)\n",
      "tensor(0.1330)\n",
      "tensor(0.1402)\n",
      "tensor(0.1276)\n",
      "tensor(0.1163)\n",
      "tensor(0.1178)\n",
      "tensor(0.1108)\n",
      "tensor(0.1545)\n",
      "tensor(0.1169)\n",
      "tensor(0.1045)\n",
      "tensor(0.1033)\n",
      "tensor(0.1381)\n",
      "tensor(0.1469)\n",
      "tensor(0.1198)\n",
      "tensor(0.1251)\n",
      "tensor(0.1076)\n",
      "tensor(0.1569)\n",
      "tensor(0.1062)\n",
      "tensor(0.1240)\n",
      "tensor(0.1014)\n",
      "tensor(0.1090)\n",
      "tensor(0.1230)\n",
      "tensor(0.1345)\n",
      "tensor(0.1140)\n",
      "tensor(0.1179)\n",
      "tensor(0.1517)\n",
      "tensor(0.1168)\n",
      "tensor(0.1561)\n",
      "tensor(0.1020)\n",
      "tensor(0.1063)\n",
      "tensor(0.1206)\n",
      "tensor(0.1542)\n",
      "tensor(0.1327)\n",
      "tensor(0.1105)\n",
      "tensor(0.1377)\n",
      "tensor(0.1362)\n",
      "tensor(0.1613)\n",
      "tensor(0.1609)\n",
      "tensor(0.1634)\n",
      "tensor(0.1516)\n",
      "tensor(0.1093)\n",
      "tensor(0.1231)\n",
      "tensor(0.1272)\n",
      "tensor(0.1620)\n",
      "tensor(0.1571)\n",
      "tensor(0.1216)\n",
      "tensor(0.1410)\n",
      "tensor(0.1465)\n",
      "tensor(0.1127)\n",
      "tensor(0.1446)\n",
      "tensor(0.1117)\n",
      "tensor(0.1169)\n",
      "tensor(0.1397)\n",
      "tensor(0.1151)\n",
      "tensor(0.1686)\n",
      "tensor(0.1021)\n",
      "tensor(0.1419)\n",
      "tensor(0.1209)\n",
      "tensor(0.1105)\n",
      "tensor(0.1232)\n",
      "tensor(0.1133)\n",
      "tensor(0.1171)\n",
      "tensor(0.1160)\n",
      "tensor(0.1076)\n",
      "tensor(0.1232)\n",
      "tensor(0.1189)\n",
      "tensor(0.1165)\n",
      "tensor(0.1300)\n",
      "tensor(0.1364)\n",
      "tensor(0.1167)\n",
      "tensor(0.1162)\n",
      "tensor(0.1194)\n",
      "tensor(0.1290)\n",
      "tensor(0.1156)\n",
      "tensor(0.1277)\n",
      "tensor(0.1138)\n",
      "tensor(0.1194)\n",
      "tensor(0.1160)\n",
      "tensor(0.1269)\n",
      "tensor(0.1242)\n",
      "tensor(0.1273)\n",
      "tensor(0.1404)\n",
      "tensor(0.1146)\n",
      "tensor(0.1224)\n",
      "tensor(0.1291)\n",
      "tensor(0.1313)\n",
      "tensor(0.1530)\n",
      "tensor(0.1529)\n",
      "tensor(0.1221)\n",
      "tensor(0.1248)\n",
      "tensor(0.1520)\n",
      "tensor(0.1220)\n",
      "tensor(0.1845)\n",
      "tensor(0.1274)\n",
      "tensor(0.1389)\n",
      "tensor(0.1336)\n",
      "tensor(0.1653)\n",
      "tensor(0.1193)\n",
      "tensor(0.1517)\n",
      "tensor(0.1201)\n",
      "tensor(0.1136)\n",
      "tensor(0.1099)\n",
      "tensor(0.1120)\n",
      "tensor(0.1366)\n",
      "tensor(0.1079)\n",
      "tensor(0.1355)\n",
      "tensor(0.1270)\n",
      "tensor(0.1095)\n",
      "tensor(0.1280)\n",
      "tensor(0.1090)\n",
      "tensor(0.1151)\n",
      "tensor(0.1111)\n",
      "tensor(0.1306)\n",
      "tensor(0.1500)\n",
      "tensor(0.1665)\n",
      "tensor(0.1147)\n",
      "tensor(0.1081)\n",
      "tensor(0.1257)\n",
      "tensor(0.1208)\n",
      "tensor(0.1286)\n",
      "tensor(0.1321)\n",
      "tensor(0.1418)\n",
      "tensor(0.1145)\n",
      "tensor(0.1375)\n",
      "tensor(0.1422)\n",
      "tensor(0.1361)\n",
      "tensor(0.1118)\n",
      "tensor(0.1199)\n",
      "tensor(0.1154)\n",
      "tensor(0.1433)\n",
      "tensor(0.1149)\n",
      "tensor(0.1225)\n",
      "tensor(0.1212)\n",
      "tensor(0.1509)\n",
      "tensor(0.1157)\n",
      "tensor(0.1320)\n",
      "tensor(0.1247)\n",
      "tensor(0.1246)\n",
      "tensor(0.1484)\n",
      "tensor(0.1057)\n",
      "tensor(0.1469)\n",
      "tensor(0.1332)\n",
      "tensor(0.1127)\n",
      "tensor(0.1306)\n",
      "tensor(0.1284)\n",
      "tensor(0.1176)\n",
      "tensor(0.1277)\n",
      "tensor(0.2388)\n",
      "tensor(0.1447)\n",
      "tensor(0.1103)\n",
      "tensor(0.1182)\n",
      "tensor(0.1129)\n",
      "tensor(0.1467)\n",
      "tensor(0.1260)\n",
      "tensor(0.1135)\n",
      "tensor(0.1146)\n",
      "tensor(0.1367)\n",
      "tensor(0.1089)\n",
      "tensor(0.1692)\n",
      "tensor(0.1092)\n",
      "tensor(0.1714)\n",
      "tensor(0.1070)\n",
      "tensor(0.1428)\n",
      "tensor(0.1096)\n",
      "tensor(0.1106)\n",
      "tensor(0.1188)\n",
      "tensor(0.1190)\n",
      "tensor(0.1145)\n",
      "tensor(0.1255)\n",
      "tensor(0.1080)\n",
      "tensor(0.1400)\n",
      "tensor(0.1305)\n",
      "tensor(0.1097)\n",
      "tensor(0.1284)\n",
      "tensor(0.1312)\n",
      "tensor(0.1664)\n",
      "tensor(0.1558)\n",
      "tensor(0.1076)\n",
      "tensor(0.1209)\n",
      "tensor(0.1467)\n",
      "tensor(0.1231)\n",
      "tensor(0.1392)\n",
      "tensor(0.1134)\n",
      "tensor(0.1527)\n",
      "tensor(0.1595)\n",
      "tensor(0.1047)\n",
      "tensor(0.1083)\n",
      "tensor(0.1236)\n",
      "tensor(0.1281)\n",
      "tensor(0.1410)\n",
      "tensor(0.1234)\n",
      "tensor(0.1289)\n",
      "tensor(0.1557)\n",
      "tensor(0.1396)\n",
      "tensor(0.1366)\n",
      "tensor(0.1426)\n",
      "tensor(0.1310)\n",
      "tensor(0.1256)\n",
      "tensor(0.1064)\n",
      "tensor(0.1348)\n",
      "tensor(0.1140)\n",
      "tensor(0.1263)\n",
      "tensor(0.1564)\n",
      "tensor(0.1574)\n",
      "tensor(0.1104)\n",
      "tensor(0.1408)\n",
      "tensor(0.1134)\n",
      "tensor(0.1411)\n",
      "tensor(0.1318)\n",
      "tensor(0.1202)\n",
      "tensor(0.1310)\n",
      "tensor(0.1350)\n",
      "tensor(0.1287)\n",
      "tensor(0.1344)\n",
      "tensor(0.1317)\n",
      "tensor(0.1349)\n",
      "tensor(0.1370)\n",
      "tensor(0.1382)\n",
      "tensor(0.1300)\n",
      "tensor(0.1452)\n",
      "tensor(0.1081)\n",
      "tensor(0.1981)\n",
      "tensor(0.1476)\n",
      "tensor(0.1233)\n",
      "tensor(0.1122)\n",
      "tensor(0.1281)\n",
      "tensor(0.1379)\n",
      "tensor(0.1506)\n",
      "tensor(0.1239)\n",
      "tensor(0.1367)\n",
      "tensor(0.1437)\n",
      "tensor(0.1610)\n",
      "tensor(0.1181)\n",
      "tensor(0.1218)\n",
      "tensor(0.1453)\n",
      "tensor(0.1357)\n",
      "tensor(0.1143)\n",
      "tensor(0.1190)\n",
      "tensor(0.1144)\n",
      "tensor(0.1223)\n",
      "tensor(0.1409)\n",
      "tensor(0.1345)\n",
      "tensor(0.1458)\n",
      "tensor(0.1485)\n",
      "tensor(0.1656)\n",
      "tensor(0.1570)\n",
      "tensor(0.1147)\n",
      "tensor(0.1399)\n",
      "tensor(0.1240)\n",
      "tensor(0.1167)\n",
      "tensor(0.1474)\n",
      "tensor(0.1241)\n",
      "tensor(0.1287)\n",
      "tensor(0.1760)\n",
      "tensor(0.1198)\n",
      "tensor(0.1718)\n",
      "tensor(0.1679)\n",
      "tensor(0.1098)\n",
      "tensor(0.1667)\n",
      "tensor(0.1352)\n",
      "tensor(0.1244)\n",
      "tensor(0.1298)\n",
      "tensor(0.1143)\n",
      "tensor(0.1472)\n",
      "tensor(0.1617)\n",
      "tensor(0.1442)\n",
      "tensor(0.1742)\n",
      "tensor(0.1320)\n",
      "tensor(0.1145)\n",
      "tensor(0.1386)\n",
      "tensor(0.1102)\n",
      "tensor(0.1496)\n",
      "tensor(0.1440)\n",
      "tensor(0.1377)\n",
      "tensor(0.1612)\n",
      "tensor(0.1290)\n",
      "tensor(0.1208)\n",
      "tensor(0.1710)\n",
      "tensor(0.1668)\n",
      "tensor(0.1440)\n",
      "tensor(0.1301)\n",
      "tensor(0.1152)\n",
      "tensor(0.1120)\n",
      "tensor(0.1121)\n",
      "tensor(0.1043)\n",
      "tensor(0.1142)\n",
      "tensor(0.1221)\n",
      "tensor(0.1687)\n",
      "tensor(0.1140)\n",
      "tensor(0.1446)\n",
      "tensor(0.1177)\n",
      "tensor(0.1212)\n",
      "tensor(0.1032)\n",
      "tensor(0.1403)\n",
      "tensor(0.1384)\n",
      "tensor(0.1270)\n",
      "tensor(0.1116)\n",
      "tensor(0.1395)\n",
      "tensor(0.1257)\n",
      "tensor(0.1411)\n",
      "tensor(0.1209)\n",
      "tensor(0.1437)\n",
      "tensor(0.1491)\n",
      "tensor(0.1229)\n",
      "tensor(0.1240)\n",
      "tensor(0.1179)\n",
      "tensor(0.1249)\n",
      "tensor(0.1430)\n",
      "tensor(0.1271)\n",
      "tensor(0.1377)\n",
      "tensor(0.1481)\n",
      "tensor(0.1216)\n",
      "tensor(0.1210)\n",
      "tensor(0.1257)\n",
      "tensor(0.1540)\n",
      "tensor(0.1145)\n",
      "tensor(0.1369)\n",
      "tensor(0.1286)\n",
      "tensor(0.1228)\n",
      "tensor(0.1203)\n",
      "tensor(0.1637)\n",
      "tensor(0.1138)\n",
      "tensor(0.1407)\n",
      "tensor(0.1350)\n",
      "tensor(0.1539)\n",
      "tensor(0.1152)\n",
      "tensor(0.1088)\n",
      "tensor(0.1209)\n",
      "tensor(0.1682)\n",
      "tensor(0.1474)\n",
      "tensor(0.1048)\n",
      "tensor(0.1177)\n",
      "tensor(0.1084)\n",
      "tensor(0.1127)\n",
      "tensor(0.1215)\n",
      "tensor(0.1172)\n",
      "tensor(0.1445)\n",
      "tensor(0.1305)\n",
      "tensor(0.1157)\n",
      "tensor(0.1267)\n",
      "tensor(0.1249)\n",
      "tensor(0.1096)\n",
      "tensor(0.1552)\n",
      "tensor(0.1126)\n",
      "tensor(0.1433)\n",
      "tensor(0.1177)\n",
      "tensor(0.1081)\n",
      "tensor(0.1239)\n",
      "tensor(0.1147)\n",
      "tensor(0.1129)\n",
      "tensor(0.1226)\n",
      "tensor(0.1250)\n",
      "tensor(0.1154)\n",
      "tensor(0.1079)\n",
      "tensor(0.1194)\n",
      "tensor(0.1266)\n",
      "tensor(0.1473)\n",
      "tensor(0.1454)\n",
      "tensor(0.1358)\n",
      "tensor(0.1452)\n",
      "tensor(0.1221)\n",
      "tensor(0.1161)\n",
      "tensor(0.1251)\n",
      "tensor(0.1301)\n",
      "tensor(0.1374)\n",
      "tensor(0.1271)\n",
      "tensor(0.1199)\n",
      "tensor(0.1527)\n",
      "tensor(0.1147)\n",
      "tensor(0.1375)\n",
      "tensor(0.1129)\n",
      "tensor(0.1329)\n",
      "tensor(0.1423)\n",
      "tensor(0.1110)\n",
      "tensor(0.1194)\n",
      "tensor(0.1505)\n",
      "tensor(0.1069)\n",
      "tensor(0.1101)\n",
      "tensor(0.1164)\n",
      "tensor(0.1608)\n",
      "tensor(0.1158)\n",
      "tensor(0.1191)\n",
      "tensor(0.1284)\n",
      "tensor(0.1425)\n",
      "tensor(0.1587)\n",
      "tensor(0.1216)\n",
      "tensor(0.1452)\n",
      "tensor(0.1552)\n",
      "tensor(0.1314)\n",
      "tensor(0.1973)\n",
      "tensor(0.1078)\n",
      "tensor(0.1208)\n",
      "tensor(0.1341)\n",
      "tensor(0.1106)\n",
      "tensor(0.1210)\n",
      "tensor(0.1090)\n",
      "tensor(0.1213)\n",
      "tensor(0.1182)\n",
      "tensor(0.1408)\n",
      "tensor(0.1259)\n",
      "tensor(0.1237)\n",
      "tensor(0.1236)\n",
      "tensor(0.1212)\n",
      "tensor(0.1319)\n",
      "tensor(0.1498)\n",
      "tensor(0.1147)\n",
      "tensor(0.1294)\n",
      "tensor(0.1078)\n",
      "tensor(0.1373)\n",
      "tensor(0.1050)\n",
      "tensor(0.1147)\n",
      "tensor(0.1353)\n",
      "tensor(0.1237)\n",
      "tensor(0.1435)\n",
      "tensor(0.1163)\n",
      "tensor(0.1164)\n",
      "tensor(0.1220)\n",
      "tensor(0.1184)\n",
      "tensor(0.1073)\n",
      "tensor(0.1066)\n",
      "tensor(0.1083)\n",
      "tensor(0.1246)\n",
      "tensor(0.1367)\n",
      "tensor(0.1294)\n",
      "tensor(0.1087)\n",
      "tensor(0.1307)\n",
      "tensor(0.1168)\n",
      "tensor(0.1102)\n",
      "tensor(0.1356)\n",
      "tensor(0.1234)\n",
      "tensor(0.1122)\n",
      "tensor(0.1418)\n",
      "tensor(0.1206)\n",
      "tensor(0.1330)\n",
      "tensor(0.1232)\n",
      "tensor(0.1497)\n",
      "tensor(0.1224)\n",
      "tensor(0.1509)\n",
      "tensor(0.1370)\n",
      "tensor(0.1419)\n",
      "tensor(0.1164)\n",
      "tensor(0.1680)\n",
      "tensor(0.1375)\n",
      "tensor(0.1455)\n",
      "tensor(0.1757)\n",
      "tensor(0.1256)\n",
      "tensor(0.1194)\n",
      "tensor(0.1663)\n",
      "tensor(0.1185)\n",
      "tensor(0.1407)\n",
      "tensor(0.1308)\n",
      "tensor(0.1441)\n",
      "tensor(0.1232)\n",
      "tensor(0.1402)\n",
      "tensor(0.1516)\n",
      "tensor(0.1368)\n",
      "tensor(0.1376)\n",
      "tensor(0.1315)\n",
      "tensor(0.1187)\n",
      "tensor(0.1539)\n",
      "tensor(0.1545)\n",
      "tensor(0.1605)\n",
      "tensor(0.1409)\n",
      "tensor(0.1382)\n",
      "tensor(0.1685)\n",
      "tensor(0.1227)\n",
      "tensor(0.1666)\n",
      "tensor(0.1558)\n",
      "tensor(0.1502)\n",
      "tensor(0.1280)\n",
      "tensor(0.1869)\n",
      "tensor(0.1220)\n",
      "tensor(0.1497)\n",
      "tensor(0.1175)\n",
      "tensor(0.1292)\n",
      "tensor(0.1180)\n",
      "tensor(0.1225)\n",
      "tensor(0.1236)\n",
      "tensor(0.1268)\n",
      "tensor(0.1594)\n",
      "tensor(0.1259)\n",
      "tensor(0.1555)\n",
      "tensor(0.1292)\n",
      "tensor(0.1115)\n",
      "tensor(0.1264)\n",
      "tensor(0.1353)\n",
      "tensor(0.1539)\n",
      "tensor(0.1237)\n",
      "tensor(0.1166)\n",
      "tensor(0.1331)\n",
      "tensor(0.1254)\n",
      "tensor(0.1250)\n",
      "tensor(0.1356)\n",
      "tensor(0.1358)\n",
      "tensor(0.1658)\n",
      "tensor(0.1343)\n",
      "tensor(0.1437)\n",
      "tensor(0.1255)\n",
      "tensor(0.1166)\n",
      "tensor(0.1466)\n",
      "tensor(0.1233)\n",
      "tensor(0.1626)\n",
      "tensor(0.1194)\n",
      "tensor(0.1326)\n",
      "tensor(0.1296)\n",
      "tensor(0.1475)\n",
      "tensor(0.1308)\n",
      "tensor(0.1095)\n",
      "tensor(0.1486)\n",
      "tensor(0.1180)\n",
      "tensor(0.1566)\n",
      "tensor(0.1180)\n",
      "tensor(0.1529)\n",
      "tensor(0.1680)\n",
      "tensor(0.1176)\n",
      "tensor(0.1162)\n",
      "tensor(0.1415)\n",
      "tensor(0.1251)\n",
      "tensor(0.1193)\n",
      "tensor(0.1592)\n",
      "tensor(0.1504)\n",
      "tensor(0.1380)\n",
      "tensor(0.1695)\n",
      "tensor(0.1182)\n",
      "tensor(0.1365)\n",
      "tensor(0.1529)\n",
      "tensor(0.1695)\n",
      "tensor(0.1259)\n",
      "tensor(0.1474)\n",
      "tensor(0.1441)\n",
      "tensor(0.1406)\n",
      "tensor(0.1272)\n",
      "tensor(0.1631)\n",
      "tensor(0.1680)\n",
      "tensor(0.2027)\n",
      "tensor(0.1368)\n",
      "tensor(0.1381)\n",
      "tensor(0.1299)\n",
      "tensor(0.1149)\n",
      "tensor(0.1177)\n",
      "tensor(0.1065)\n",
      "tensor(0.1359)\n",
      "tensor(0.1219)\n",
      "tensor(0.1385)\n",
      "tensor(0.1384)\n",
      "tensor(0.1189)\n",
      "tensor(0.1293)\n",
      "tensor(0.1260)\n",
      "tensor(0.1086)\n",
      "tensor(0.1217)\n",
      "tensor(0.1479)\n",
      "tensor(0.1202)\n",
      "tensor(0.1278)\n",
      "tensor(0.1064)\n",
      "tensor(0.1188)\n",
      "tensor(0.1161)\n",
      "tensor(0.1357)\n",
      "tensor(0.1078)\n",
      "tensor(0.1156)\n",
      "tensor(0.1301)\n",
      "tensor(0.1459)\n",
      "tensor(0.1210)\n",
      "tensor(0.1225)\n",
      "tensor(0.1140)\n",
      "tensor(0.1182)\n",
      "tensor(0.1299)\n",
      "tensor(0.1345)\n",
      "tensor(0.1436)\n",
      "tensor(0.1068)\n",
      "tensor(0.1142)\n",
      "tensor(0.1173)\n",
      "tensor(0.1239)\n",
      "tensor(0.1082)\n",
      "tensor(0.1396)\n",
      "tensor(0.1146)\n",
      "tensor(0.1498)\n",
      "tensor(0.1261)\n",
      "tensor(0.1211)\n",
      "tensor(0.1205)\n",
      "tensor(0.1079)\n",
      "tensor(0.1473)\n",
      "tensor(0.1065)\n",
      "tensor(0.1386)\n",
      "tensor(0.1240)\n",
      "tensor(0.1159)\n",
      "tensor(0.1679)\n",
      "tensor(0.1408)\n",
      "tensor(0.1178)\n",
      "tensor(0.1492)\n",
      "tensor(0.1214)\n",
      "tensor(0.1216)\n",
      "tensor(0.1166)\n",
      "tensor(0.1160)\n",
      "tensor(0.1534)\n",
      "tensor(0.1249)\n",
      "tensor(0.1399)\n",
      "tensor(0.1194)\n",
      "tensor(0.1284)\n",
      "tensor(0.1231)\n",
      "tensor(0.1211)\n",
      "tensor(0.1342)\n",
      "tensor(0.1189)\n",
      "tensor(0.1152)\n",
      "tensor(0.1400)\n",
      "tensor(0.1213)\n",
      "tensor(0.1356)\n",
      "tensor(0.1315)\n",
      "tensor(0.1250)\n",
      "tensor(0.1140)\n",
      "tensor(0.1575)\n",
      "tensor(0.1095)\n",
      "tensor(0.1179)\n",
      "tensor(0.1206)\n",
      "tensor(0.1209)\n",
      "tensor(0.1148)\n",
      "tensor(0.1269)\n",
      "tensor(0.1549)\n",
      "tensor(0.1402)\n",
      "tensor(0.1306)\n",
      "tensor(0.1134)\n",
      "tensor(0.1337)\n",
      "tensor(0.1129)\n",
      "tensor(0.1032)\n",
      "tensor(0.1197)\n",
      "tensor(0.1342)\n",
      "tensor(0.1135)\n",
      "tensor(0.1349)\n",
      "tensor(0.1727)\n",
      "tensor(0.1248)\n",
      "tensor(0.1932)\n",
      "tensor(0.1132)\n",
      "tensor(0.1190)\n",
      "tensor(0.1167)\n",
      "tensor(0.1108)\n",
      "tensor(0.1783)\n",
      "tensor(0.1572)\n",
      "tensor(0.1208)\n",
      "tensor(0.1404)\n",
      "tensor(0.1656)\n",
      "tensor(0.1462)\n",
      "tensor(0.1595)\n",
      "tensor(0.1379)\n",
      "tensor(0.1151)\n",
      "tensor(0.1258)\n",
      "tensor(0.1522)\n",
      "tensor(0.1711)\n",
      "tensor(0.1877)\n",
      "tensor(0.1637)\n",
      "tensor(0.1513)\n",
      "tensor(0.1017)\n",
      "tensor(0.1389)\n",
      "tensor(0.1079)\n",
      "tensor(0.1371)\n",
      "tensor(0.1421)\n",
      "tensor(0.1182)\n",
      "tensor(0.1235)\n",
      "tensor(0.1071)\n",
      "tensor(0.1163)\n",
      "tensor(0.1042)\n",
      "tensor(0.1316)\n",
      "tensor(0.1166)\n",
      "tensor(0.1538)\n",
      "tensor(0.1392)\n",
      "tensor(0.1312)\n",
      "tensor(0.1246)\n",
      "tensor(0.1168)\n",
      "tensor(0.1149)\n",
      "tensor(0.1209)\n",
      "tensor(0.1791)\n",
      "tensor(0.1215)\n",
      "tensor(0.1180)\n",
      "tensor(0.1489)\n",
      "tensor(0.1284)\n",
      "tensor(0.1151)\n",
      "tensor(0.1249)\n",
      "tensor(0.1267)\n",
      "tensor(0.1221)\n",
      "tensor(0.1481)\n",
      "tensor(0.1104)\n",
      "tensor(0.1222)\n",
      "tensor(0.1297)\n",
      "tensor(0.1313)\n",
      "tensor(0.1396)\n",
      "tensor(0.1233)\n",
      "tensor(0.1332)\n",
      "tensor(0.1189)\n",
      "tensor(0.1232)\n",
      "tensor(0.1096)\n",
      "tensor(0.1610)\n",
      "tensor(0.1157)\n",
      "tensor(0.1608)\n",
      "tensor(0.1591)\n",
      "tensor(0.1360)\n",
      "tensor(0.1347)\n",
      "tensor(0.1379)\n",
      "tensor(0.1235)\n",
      "tensor(0.1491)\n",
      "tensor(0.1242)\n",
      "tensor(0.1723)\n",
      "tensor(0.1497)\n",
      "tensor(0.1560)\n",
      "tensor(0.1642)\n",
      "tensor(0.1555)\n",
      "tensor(0.1399)\n",
      "tensor(0.1512)\n",
      "tensor(0.1056)\n",
      "tensor(0.1426)\n",
      "tensor(0.1225)\n",
      "tensor(0.1165)\n",
      "tensor(0.1682)\n",
      "tensor(0.1224)\n",
      "tensor(0.1272)\n",
      "tensor(0.1177)\n",
      "tensor(0.1637)\n",
      "tensor(0.1192)\n",
      "tensor(0.1671)\n",
      "tensor(0.1348)\n",
      "tensor(0.1802)\n",
      "tensor(0.1249)\n",
      "tensor(0.1111)\n",
      "tensor(0.1097)\n",
      "tensor(0.1093)\n",
      "tensor(0.1150)\n",
      "tensor(0.1226)\n",
      "tensor(0.1101)\n",
      "tensor(0.1207)\n",
      "tensor(0.1091)\n",
      "tensor(0.1403)\n",
      "tensor(0.1035)\n",
      "tensor(0.1121)\n",
      "tensor(0.1067)\n",
      "tensor(0.1127)\n",
      "tensor(0.1065)\n",
      "tensor(0.1202)\n",
      "tensor(0.0989)\n",
      "tensor(0.1142)\n",
      "tensor(0.1276)\n",
      "tensor(0.1134)\n",
      "tensor(0.1094)\n",
      "tensor(0.1071)\n",
      "tensor(0.1602)\n",
      "tensor(0.1199)\n",
      "tensor(0.1307)\n",
      "tensor(0.1062)\n",
      "tensor(0.1414)\n",
      "tensor(0.1266)\n",
      "tensor(0.1139)\n",
      "tensor(0.1238)\n",
      "tensor(0.1169)\n",
      "tensor(0.1240)\n",
      "tensor(0.1269)\n",
      "tensor(0.1225)\n",
      "tensor(0.1281)\n",
      "tensor(0.1097)\n",
      "tensor(0.1088)\n",
      "tensor(0.1257)\n",
      "tensor(0.1190)\n",
      "tensor(0.1304)\n",
      "tensor(0.1097)\n",
      "tensor(0.1317)\n",
      "tensor(0.1237)\n",
      "tensor(0.1549)\n",
      "tensor(0.1430)\n",
      "tensor(0.1346)\n",
      "tensor(0.1724)\n",
      "tensor(0.1228)\n",
      "tensor(0.1470)\n",
      "tensor(0.1181)\n",
      "tensor(0.1137)\n",
      "tensor(0.1189)\n",
      "tensor(0.1138)\n",
      "tensor(0.1238)\n",
      "tensor(0.1198)\n",
      "tensor(0.1189)\n",
      "tensor(0.1559)\n",
      "tensor(0.1132)\n",
      "tensor(0.1374)\n",
      "tensor(0.1144)\n",
      "tensor(0.1086)\n",
      "tensor(0.1132)\n",
      "tensor(0.1068)\n",
      "tensor(0.1495)\n",
      "tensor(0.1085)\n",
      "tensor(0.1228)\n",
      "tensor(0.1326)\n",
      "tensor(0.1339)\n",
      "tensor(0.1363)\n",
      "tensor(0.1225)\n",
      "tensor(0.1530)\n",
      "tensor(0.1503)\n",
      "tensor(0.1373)\n",
      "tensor(0.1469)\n",
      "tensor(0.1177)\n",
      "tensor(0.1109)\n",
      "tensor(0.1421)\n",
      "tensor(0.1446)\n",
      "tensor(0.1578)\n",
      "tensor(0.1121)\n",
      "tensor(0.1130)\n",
      "tensor(0.1405)\n",
      "tensor(0.1297)\n",
      "tensor(0.1762)\n",
      "tensor(0.1127)\n",
      "tensor(0.1354)\n",
      "tensor(0.1486)\n",
      "tensor(0.1351)\n",
      "tensor(0.1208)\n",
      "tensor(0.1167)\n",
      "tensor(0.1330)\n",
      "tensor(0.1533)\n",
      "tensor(0.1144)\n",
      "tensor(0.1318)\n",
      "tensor(0.1318)\n",
      "tensor(0.1511)\n",
      "tensor(0.1441)\n",
      "tensor(0.1517)\n",
      "tensor(0.1104)\n",
      "tensor(0.1188)\n",
      "tensor(0.1074)\n",
      "tensor(0.1122)\n",
      "tensor(0.1324)\n",
      "tensor(0.1295)\n",
      "tensor(0.1377)\n",
      "tensor(0.1578)\n",
      "tensor(0.1103)\n",
      "tensor(0.1423)\n",
      "tensor(0.1528)\n",
      "tensor(0.1429)\n",
      "tensor(0.1237)\n",
      "tensor(0.1221)\n",
      "tensor(0.1369)\n",
      "tensor(0.1078)\n",
      "tensor(0.1087)\n",
      "tensor(0.1157)\n",
      "tensor(0.1347)\n",
      "tensor(0.1270)\n",
      "tensor(0.1181)\n",
      "tensor(0.1667)\n",
      "tensor(0.1218)\n",
      "tensor(0.1278)\n",
      "tensor(0.1446)\n",
      "tensor(0.1299)\n",
      "tensor(0.1230)\n",
      "tensor(0.1216)\n",
      "tensor(0.1247)\n",
      "tensor(0.1251)\n",
      "tensor(0.1313)\n",
      "tensor(0.1249)\n",
      "tensor(0.1271)\n",
      "tensor(0.1546)\n",
      "tensor(0.1012)\n",
      "tensor(0.1385)\n",
      "tensor(0.2055)\n",
      "tensor(0.1423)\n",
      "tensor(0.1170)\n",
      "tensor(0.1201)\n",
      "tensor(0.1595)\n",
      "tensor(0.1485)\n",
      "tensor(0.1080)\n",
      "tensor(0.1317)\n",
      "tensor(0.1812)\n",
      "tensor(0.1529)\n",
      "tensor(0.1288)\n",
      "tensor(0.1181)\n",
      "tensor(0.1064)\n",
      "tensor(0.1359)\n",
      "tensor(0.1180)\n",
      "tensor(0.1747)\n",
      "tensor(0.1178)\n",
      "tensor(0.1413)\n",
      "tensor(0.1147)\n",
      "tensor(0.1520)\n",
      "tensor(0.1362)\n",
      "tensor(0.1539)\n",
      "tensor(0.1202)\n",
      "tensor(0.1306)\n",
      "tensor(0.1543)\n",
      "tensor(0.1429)\n",
      "tensor(0.1383)\n",
      "tensor(0.1062)\n",
      "tensor(0.1348)\n",
      "tensor(0.1045)\n",
      "tensor(0.1335)\n",
      "tensor(0.1199)\n",
      "tensor(0.1706)\n",
      "tensor(0.1147)\n",
      "tensor(0.1388)\n",
      "tensor(0.1132)\n",
      "tensor(0.1167)\n",
      "tensor(0.1135)\n",
      "tensor(0.1479)\n",
      "tensor(0.1397)\n",
      "tensor(0.1247)\n",
      "tensor(0.1033)\n",
      "tensor(0.1297)\n",
      "tensor(0.1580)\n",
      "tensor(0.1153)\n",
      "tensor(0.1278)\n",
      "tensor(0.1138)\n",
      "tensor(0.1250)\n",
      "tensor(0.1113)\n",
      "tensor(0.1132)\n",
      "tensor(0.1163)\n",
      "tensor(0.1349)\n",
      "tensor(0.1269)\n",
      "tensor(0.1299)\n",
      "tensor(0.1331)\n",
      "tensor(0.1368)\n",
      "tensor(0.1559)\n",
      "tensor(0.1170)\n",
      "tensor(0.1118)\n",
      "tensor(0.1220)\n",
      "tensor(0.1244)\n",
      "tensor(0.1326)\n",
      "tensor(0.1148)\n",
      "tensor(0.1446)\n",
      "tensor(0.1241)\n",
      "tensor(0.1129)\n",
      "tensor(0.1354)\n",
      "tensor(0.1262)\n",
      "tensor(0.1139)\n",
      "tensor(0.1166)\n",
      "tensor(0.1422)\n",
      "tensor(0.1659)\n",
      "tensor(0.1239)\n",
      "tensor(0.1191)\n",
      "tensor(0.1241)\n",
      "tensor(0.1563)\n",
      "tensor(0.1473)\n",
      "tensor(0.1203)\n",
      "tensor(0.1365)\n",
      "tensor(0.1362)\n",
      "tensor(0.1299)\n",
      "tensor(0.1287)\n",
      "tensor(0.1610)\n",
      "tensor(0.1276)\n",
      "tensor(0.1568)\n",
      "tensor(0.1294)\n",
      "tensor(0.1533)\n",
      "tensor(0.1323)\n",
      "tensor(0.1164)\n",
      "tensor(0.1223)\n",
      "tensor(0.1203)\n",
      "tensor(0.1175)\n",
      "tensor(0.1206)\n",
      "tensor(0.1362)\n",
      "tensor(0.1683)\n",
      "tensor(0.1143)\n",
      "tensor(0.1330)\n",
      "tensor(0.1102)\n",
      "tensor(0.1335)\n",
      "tensor(0.1318)\n",
      "tensor(0.1112)\n",
      "tensor(0.1124)\n",
      "tensor(0.1447)\n",
      "tensor(0.1546)\n",
      "tensor(0.1698)\n",
      "tensor(0.1463)\n",
      "tensor(0.1339)\n",
      "tensor(0.1195)\n",
      "tensor(0.1396)\n",
      "tensor(0.1236)\n",
      "tensor(0.1555)\n",
      "tensor(0.1335)\n",
      "tensor(0.1396)\n",
      "tensor(0.1114)\n",
      "tensor(0.1557)\n",
      "tensor(0.1427)\n",
      "tensor(0.1226)\n",
      "tensor(0.1373)\n",
      "tensor(0.1803)\n",
      "tensor(0.1412)\n",
      "tensor(0.1266)\n",
      "tensor(0.1544)\n",
      "tensor(0.1731)\n",
      "tensor(0.1423)\n",
      "tensor(0.1221)\n",
      "tensor(0.1453)\n",
      "tensor(0.1405)\n",
      "tensor(0.1221)\n",
      "tensor(0.1275)\n",
      "tensor(0.1448)\n",
      "tensor(0.1227)\n",
      "tensor(0.1237)\n",
      "tensor(0.1301)\n",
      "tensor(0.1326)\n",
      "tensor(0.1066)\n",
      "tensor(0.1400)\n",
      "tensor(0.1214)\n",
      "tensor(0.1465)\n",
      "tensor(0.1389)\n",
      "tensor(0.1304)\n",
      "tensor(0.1109)\n",
      "tensor(0.1212)\n",
      "tensor(0.1225)\n",
      "tensor(0.1323)\n",
      "tensor(0.1137)\n",
      "tensor(0.1274)\n",
      "tensor(0.1098)\n",
      "tensor(0.1590)\n",
      "tensor(0.1129)\n",
      "tensor(0.1335)\n",
      "tensor(0.1256)\n",
      "tensor(0.1064)\n",
      "tensor(0.1300)\n",
      "tensor(0.1201)\n",
      "tensor(0.1164)\n",
      "tensor(0.1121)\n",
      "tensor(0.1269)\n",
      "tensor(0.1668)\n",
      "tensor(0.1456)\n",
      "tensor(0.1438)\n",
      "tensor(0.1277)\n",
      "tensor(0.1100)\n",
      "tensor(0.1388)\n",
      "tensor(0.1482)\n",
      "tensor(0.1213)\n",
      "tensor(0.1514)\n",
      "tensor(0.1336)\n",
      "tensor(0.1241)\n",
      "tensor(0.1154)\n",
      "tensor(0.1303)\n",
      "tensor(0.1148)\n",
      "tensor(0.1339)\n",
      "tensor(0.1131)\n",
      "tensor(0.1399)\n",
      "tensor(0.1189)\n",
      "tensor(0.1208)\n",
      "tensor(0.1275)\n",
      "tensor(0.1291)\n",
      "tensor(0.1224)\n",
      "tensor(0.1362)\n",
      "tensor(0.1282)\n",
      "tensor(0.1310)\n",
      "tensor(0.1295)\n",
      "tensor(0.1500)\n",
      "tensor(0.1197)\n",
      "tensor(0.1527)\n",
      "tensor(0.1354)\n",
      "tensor(0.1300)\n",
      "tensor(0.1471)\n",
      "tensor(0.1608)\n",
      "tensor(0.1404)\n",
      "tensor(0.1693)\n",
      "tensor(0.1273)\n",
      "tensor(0.1470)\n",
      "tensor(0.1292)\n",
      "tensor(0.1227)\n",
      "tensor(0.1504)\n",
      "tensor(0.1718)\n",
      "tensor(0.1146)\n",
      "tensor(0.1539)\n",
      "tensor(0.1256)\n",
      "tensor(0.1274)\n",
      "tensor(0.1441)\n",
      "tensor(0.1464)\n",
      "tensor(0.1627)\n",
      "tensor(0.1444)\n",
      "tensor(0.1480)\n",
      "tensor(0.1119)\n",
      "tensor(0.1580)\n",
      "tensor(0.1255)\n",
      "tensor(0.1201)\n",
      "tensor(0.1151)\n",
      "tensor(0.1131)\n",
      "tensor(0.1136)\n",
      "tensor(0.1248)\n",
      "tensor(0.1426)\n",
      "tensor(0.1499)\n",
      "tensor(0.1313)\n",
      "tensor(0.1497)\n",
      "tensor(0.1597)\n",
      "tensor(0.1475)\n",
      "tensor(0.1292)\n",
      "tensor(0.1169)\n",
      "tensor(0.1274)\n",
      "tensor(0.1205)\n",
      "tensor(0.1332)\n",
      "tensor(0.1265)\n",
      "tensor(0.1256)\n",
      "tensor(0.1176)\n",
      "tensor(0.1171)\n",
      "tensor(0.1376)\n",
      "tensor(0.1403)\n",
      "tensor(0.1163)\n",
      "tensor(0.1256)\n",
      "tensor(0.1180)\n",
      "tensor(0.1452)\n",
      "tensor(0.1467)\n",
      "tensor(0.1246)\n",
      "tensor(0.1221)\n",
      "tensor(0.1517)\n",
      "tensor(0.1387)\n",
      "tensor(0.1238)\n",
      "tensor(0.1347)\n",
      "tensor(0.1481)\n",
      "tensor(0.1300)\n",
      "tensor(0.1271)\n",
      "tensor(0.1148)\n",
      "tensor(0.1104)\n",
      "tensor(0.1568)\n",
      "tensor(0.1278)\n",
      "tensor(0.1159)\n",
      "tensor(0.1120)\n",
      "tensor(0.1582)\n",
      "tensor(0.1232)\n",
      "tensor(0.1114)\n",
      "tensor(0.1335)\n",
      "tensor(0.1241)\n",
      "tensor(0.1882)\n",
      "tensor(0.1442)\n",
      "tensor(0.1356)\n",
      "tensor(0.1167)\n",
      "tensor(0.1524)\n",
      "tensor(0.1382)\n",
      "tensor(0.1254)\n",
      "tensor(0.1532)\n",
      "tensor(0.1332)\n",
      "tensor(0.1208)\n",
      "tensor(0.1418)\n",
      "tensor(0.1123)\n",
      "tensor(0.1153)\n",
      "tensor(0.1096)\n",
      "tensor(0.1599)\n",
      "tensor(0.1296)\n",
      "tensor(0.1249)\n",
      "tensor(0.1476)\n",
      "tensor(0.1499)\n",
      "tensor(0.1282)\n",
      "tensor(0.1036)\n",
      "tensor(0.1371)\n",
      "tensor(0.1150)\n",
      "tensor(0.1213)\n",
      "tensor(0.1219)\n",
      "tensor(0.1176)\n",
      "tensor(0.1215)\n",
      "tensor(0.1223)\n",
      "tensor(0.1426)\n",
      "tensor(0.1646)\n",
      "tensor(0.1130)\n",
      "tensor(0.1570)\n",
      "tensor(0.1708)\n",
      "tensor(0.1163)\n",
      "tensor(0.1534)\n",
      "tensor(0.1160)\n",
      "tensor(0.1504)\n",
      "tensor(0.1164)\n",
      "tensor(0.1306)\n",
      "tensor(0.1349)\n",
      "tensor(0.1062)\n",
      "tensor(0.1233)\n",
      "tensor(0.1318)\n",
      "tensor(0.1423)\n",
      "tensor(0.1117)\n",
      "tensor(0.1272)\n",
      "tensor(0.1160)\n",
      "tensor(0.1435)\n",
      "tensor(0.1281)\n",
      "tensor(0.1181)\n",
      "tensor(0.1569)\n",
      "tensor(0.1385)\n",
      "tensor(0.1365)\n",
      "tensor(0.1205)\n",
      "tensor(0.1405)\n",
      "tensor(0.1214)\n",
      "tensor(0.1460)\n",
      "tensor(0.1198)\n",
      "tensor(0.1330)\n",
      "tensor(0.1235)\n",
      "tensor(0.1404)\n",
      "tensor(0.1450)\n",
      "tensor(0.1106)\n",
      "tensor(0.1078)\n",
      "tensor(0.1365)\n",
      "tensor(0.1060)\n",
      "tensor(0.1175)\n",
      "tensor(0.1307)\n",
      "tensor(0.1187)\n",
      "tensor(0.1190)\n",
      "tensor(0.1212)\n",
      "tensor(0.1183)\n",
      "tensor(0.1186)\n",
      "tensor(0.1342)\n",
      "tensor(0.1368)\n",
      "tensor(0.1529)\n",
      "tensor(0.1270)\n",
      "tensor(0.1224)\n",
      "tensor(0.1689)\n",
      "tensor(0.1225)\n",
      "tensor(0.1219)\n",
      "tensor(0.1188)\n",
      "tensor(0.1275)\n",
      "tensor(0.1287)\n",
      "tensor(0.1136)\n",
      "tensor(0.1219)\n",
      "tensor(0.1101)\n",
      "tensor(0.1473)\n",
      "tensor(0.1371)\n",
      "tensor(0.1268)\n",
      "tensor(0.1312)\n",
      "tensor(0.1335)\n",
      "tensor(0.1060)\n",
      "tensor(0.1305)\n",
      "tensor(0.1283)\n",
      "tensor(0.1165)\n",
      "tensor(0.1262)\n",
      "tensor(0.1229)\n",
      "tensor(0.1065)\n",
      "tensor(0.1112)\n",
      "tensor(0.1350)\n",
      "tensor(0.1330)\n",
      "tensor(0.1318)\n",
      "tensor(0.1356)\n",
      "tensor(0.1561)\n",
      "tensor(0.1365)\n",
      "tensor(0.1289)\n",
      "tensor(0.1675)\n",
      "tensor(0.1242)\n",
      "tensor(0.1184)\n",
      "tensor(0.1231)\n",
      "tensor(0.1258)\n",
      "tensor(0.1748)\n",
      "tensor(0.1107)\n",
      "tensor(0.1294)\n",
      "tensor(0.1323)\n",
      "tensor(0.1332)\n",
      "tensor(0.1320)\n",
      "tensor(0.1117)\n",
      "tensor(0.1352)\n",
      "tensor(0.1247)\n",
      "tensor(0.1431)\n",
      "tensor(0.1038)\n",
      "tensor(0.1133)\n",
      "tensor(0.1161)\n",
      "tensor(0.1268)\n",
      "tensor(0.1228)\n",
      "tensor(0.1072)\n",
      "tensor(0.1207)\n",
      "tensor(0.1563)\n",
      "tensor(0.1096)\n",
      "tensor(0.1086)\n",
      "tensor(0.1053)\n",
      "tensor(0.1261)\n",
      "tensor(0.1296)\n",
      "tensor(0.1411)\n",
      "tensor(0.1098)\n",
      "tensor(0.1192)\n",
      "tensor(0.1210)\n",
      "tensor(0.1317)\n",
      "tensor(0.1214)\n",
      "tensor(0.1211)\n",
      "tensor(0.1114)\n",
      "tensor(0.1058)\n",
      "tensor(0.1844)\n",
      "tensor(0.1109)\n",
      "tensor(0.1128)\n",
      "tensor(0.1069)\n",
      "tensor(0.1242)\n",
      "tensor(0.1102)\n",
      "tensor(0.1201)\n",
      "tensor(0.1444)\n",
      "tensor(0.1312)\n",
      "tensor(0.1284)\n",
      "tensor(0.1496)\n",
      "tensor(0.1359)\n",
      "tensor(0.1124)\n",
      "tensor(0.1118)\n",
      "tensor(0.1210)\n",
      "tensor(0.1343)\n",
      "tensor(0.1207)\n",
      "tensor(0.1829)\n",
      "tensor(0.1002)\n",
      "tensor(0.1768)\n",
      "tensor(0.1365)\n",
      "tensor(0.1269)\n",
      "tensor(0.1058)\n",
      "tensor(0.1222)\n",
      "tensor(0.1078)\n",
      "tensor(0.1313)\n",
      "tensor(0.1138)\n",
      "tensor(0.1275)\n",
      "tensor(0.1437)\n",
      "tensor(0.1320)\n",
      "tensor(0.1276)\n",
      "tensor(0.1787)\n",
      "tensor(0.1032)\n",
      "tensor(0.1324)\n",
      "tensor(0.1271)\n",
      "tensor(0.1323)\n",
      "tensor(0.1192)\n",
      "tensor(0.1216)\n",
      "tensor(0.1295)\n",
      "tensor(0.1312)\n",
      "tensor(0.1237)\n",
      "tensor(0.1247)\n",
      "tensor(0.1105)\n",
      "tensor(0.1311)\n",
      "tensor(0.1097)\n",
      "tensor(0.1193)\n",
      "tensor(0.1184)\n",
      "tensor(0.1087)\n",
      "tensor(0.1250)\n",
      "tensor(0.1133)\n",
      "tensor(0.1236)\n",
      "tensor(0.1286)\n",
      "tensor(0.1463)\n",
      "tensor(0.1315)\n",
      "tensor(0.1123)\n",
      "tensor(0.1222)\n",
      "tensor(0.1244)\n",
      "tensor(0.1436)\n",
      "tensor(0.1177)\n",
      "tensor(0.1210)\n",
      "tensor(0.1466)\n",
      "tensor(0.1302)\n",
      "tensor(0.1137)\n",
      "tensor(0.1472)\n",
      "tensor(0.1294)\n",
      "tensor(0.1354)\n",
      "tensor(0.1384)\n",
      "tensor(0.1466)\n",
      "tensor(0.1457)\n",
      "tensor(0.1371)\n",
      "tensor(0.1339)\n",
      "tensor(0.1417)\n",
      "tensor(0.1300)\n",
      "tensor(0.1235)\n",
      "tensor(0.1381)\n",
      "tensor(0.1225)\n",
      "tensor(0.1433)\n",
      "tensor(0.1052)\n",
      "tensor(0.1296)\n",
      "tensor(0.1181)\n",
      "tensor(0.1528)\n",
      "tensor(0.1186)\n",
      "tensor(0.1513)\n",
      "tensor(0.1474)\n",
      "tensor(0.1251)\n",
      "tensor(0.1157)\n",
      "tensor(0.1394)\n",
      "tensor(0.1258)\n",
      "tensor(0.1072)\n",
      "tensor(0.1240)\n",
      "tensor(0.1493)\n",
      "tensor(0.1516)\n",
      "tensor(0.1428)\n",
      "tensor(0.1145)\n",
      "tensor(0.1185)\n",
      "tensor(0.1283)\n",
      "tensor(0.1370)\n",
      "tensor(0.1299)\n",
      "tensor(0.1352)\n",
      "tensor(0.1364)\n",
      "tensor(0.1149)\n",
      "tensor(0.1106)\n",
      "tensor(0.1310)\n",
      "tensor(0.1569)\n",
      "tensor(0.1227)\n",
      "tensor(0.1348)\n",
      "tensor(0.1186)\n",
      "tensor(0.1618)\n",
      "tensor(0.1391)\n",
      "tensor(0.1294)\n",
      "tensor(0.1173)\n",
      "tensor(0.1627)\n",
      "tensor(0.1304)\n",
      "tensor(0.1470)\n",
      "tensor(0.1155)\n",
      "tensor(0.1381)\n",
      "tensor(0.1545)\n",
      "tensor(0.1157)\n",
      "tensor(0.1431)\n",
      "tensor(0.1174)\n",
      "tensor(0.1682)\n",
      "tensor(0.1559)\n",
      "tensor(0.1779)\n",
      "tensor(0.1421)\n",
      "tensor(0.1482)\n",
      "tensor(0.1268)\n",
      "tensor(0.1033)\n",
      "tensor(0.1225)\n",
      "tensor(0.1147)\n",
      "tensor(0.1231)\n",
      "tensor(0.1334)\n",
      "tensor(0.1337)\n",
      "tensor(0.1512)\n",
      "tensor(0.1053)\n",
      "tensor(0.1582)\n",
      "tensor(0.1100)\n",
      "tensor(0.1363)\n",
      "tensor(0.1207)\n",
      "tensor(0.1201)\n",
      "tensor(0.1158)\n",
      "tensor(0.1156)\n",
      "tensor(0.1284)\n",
      "tensor(0.1272)\n",
      "tensor(0.1411)\n",
      "tensor(0.1196)\n",
      "tensor(0.1487)\n",
      "tensor(0.1658)\n",
      "tensor(0.1269)\n",
      "tensor(0.1158)\n",
      "tensor(0.1570)\n",
      "tensor(0.1216)\n",
      "tensor(0.1166)\n",
      "tensor(0.1252)\n",
      "tensor(0.1103)\n",
      "tensor(0.1103)\n",
      "tensor(0.1116)\n",
      "tensor(0.1576)\n",
      "tensor(0.1203)\n",
      "tensor(0.1271)\n",
      "tensor(0.1207)\n",
      "tensor(0.1479)\n",
      "tensor(0.1516)\n",
      "tensor(0.1274)\n",
      "tensor(0.1588)\n",
      "tensor(0.1163)\n",
      "tensor(0.1224)\n",
      "tensor(0.1322)\n",
      "tensor(0.1318)\n",
      "tensor(0.1369)\n",
      "tensor(0.1047)\n",
      "tensor(0.1184)\n",
      "tensor(0.1299)\n",
      "tensor(0.1439)\n",
      "tensor(0.1192)\n",
      "tensor(0.1395)\n",
      "tensor(0.1114)\n",
      "tensor(0.1257)\n",
      "tensor(0.1222)\n",
      "tensor(0.1124)\n",
      "tensor(0.1218)\n",
      "tensor(0.1580)\n",
      "tensor(0.1341)\n",
      "tensor(0.1347)\n",
      "tensor(0.1291)\n",
      "tensor(0.1248)\n",
      "tensor(0.1020)\n",
      "tensor(0.1752)\n",
      "tensor(0.1174)\n",
      "tensor(0.1265)\n",
      "tensor(0.1218)\n",
      "tensor(0.1222)\n",
      "tensor(0.1217)\n",
      "tensor(0.1124)\n",
      "tensor(0.1651)\n",
      "tensor(0.1035)\n",
      "tensor(0.1194)\n",
      "tensor(0.1055)\n",
      "tensor(0.1193)\n",
      "tensor(0.1400)\n",
      "tensor(0.1288)\n",
      "tensor(0.1176)\n",
      "tensor(0.1224)\n",
      "tensor(0.1168)\n",
      "tensor(0.1577)\n",
      "tensor(0.1196)\n",
      "tensor(0.1089)\n",
      "tensor(0.1297)\n",
      "tensor(0.1174)\n",
      "tensor(0.1639)\n",
      "tensor(0.1286)\n",
      "tensor(0.1235)\n",
      "tensor(0.1647)\n",
      "tensor(0.1038)\n",
      "tensor(0.1230)\n",
      "tensor(0.1136)\n",
      "tensor(0.1386)\n",
      "tensor(0.1499)\n",
      "tensor(0.1073)\n",
      "tensor(0.1215)\n",
      "tensor(0.1406)\n",
      "tensor(0.1159)\n",
      "tensor(0.1274)\n",
      "tensor(0.1062)\n",
      "tensor(0.1109)\n",
      "tensor(0.1150)\n",
      "tensor(0.1485)\n",
      "tensor(0.1137)\n",
      "tensor(0.1719)\n",
      "tensor(0.1842)\n",
      "tensor(0.1476)\n",
      "tensor(0.1368)\n",
      "tensor(0.1855)\n",
      "tensor(0.1468)\n",
      "tensor(0.1073)\n",
      "tensor(0.1306)\n",
      "tensor(0.1286)\n",
      "tensor(0.1213)\n",
      "tensor(0.1320)\n",
      "tensor(0.1187)\n",
      "tensor(0.1399)\n",
      "tensor(0.1343)\n",
      "tensor(0.1265)\n",
      "tensor(0.1516)\n",
      "tensor(0.1380)\n",
      "tensor(0.1259)\n",
      "tensor(0.1190)\n",
      "tensor(0.1594)\n",
      "tensor(0.1412)\n",
      "tensor(0.1541)\n",
      "tensor(0.1486)\n",
      "tensor(0.1171)\n",
      "tensor(0.1562)\n",
      "tensor(0.1104)\n",
      "tensor(0.1877)\n",
      "tensor(0.1666)\n",
      "tensor(0.1274)\n",
      "tensor(0.1599)\n",
      "tensor(0.1365)\n",
      "tensor(0.1433)\n",
      "tensor(0.1314)\n",
      "tensor(0.1372)\n",
      "tensor(0.1168)\n",
      "tensor(0.1476)\n",
      "tensor(0.1071)\n",
      "tensor(0.1592)\n",
      "tensor(0.1438)\n",
      "tensor(0.1398)\n",
      "tensor(0.1476)\n",
      "tensor(0.1552)\n",
      "tensor(0.1396)\n",
      "tensor(0.1488)\n",
      "tensor(0.1228)\n",
      "tensor(0.1511)\n",
      "tensor(0.1134)\n",
      "tensor(0.1309)\n",
      "tensor(0.1307)\n",
      "tensor(0.1164)\n",
      "tensor(0.1387)\n",
      "tensor(0.1366)\n",
      "tensor(0.1523)\n",
      "tensor(0.1275)\n",
      "tensor(0.1510)\n",
      "tensor(0.1120)\n",
      "tensor(0.1381)\n",
      "tensor(0.1199)\n",
      "tensor(0.1531)\n",
      "tensor(0.1684)\n",
      "tensor(0.1658)\n",
      "tensor(0.1162)\n",
      "tensor(0.1423)\n",
      "tensor(0.1402)\n",
      "tensor(0.1536)\n",
      "tensor(0.1277)\n",
      "tensor(0.1103)\n",
      "tensor(0.1224)\n",
      "tensor(0.1455)\n",
      "tensor(0.1671)\n",
      "tensor(0.1522)\n",
      "tensor(0.1131)\n",
      "tensor(0.1565)\n",
      "tensor(0.1321)\n",
      "tensor(0.1197)\n",
      "tensor(0.1196)\n",
      "tensor(0.1559)\n",
      "tensor(0.1035)\n",
      "tensor(0.1266)\n",
      "tensor(0.1485)\n",
      "tensor(0.1085)\n",
      "tensor(0.1400)\n",
      "tensor(0.1351)\n",
      "tensor(0.1230)\n",
      "tensor(0.1516)\n",
      "tensor(0.1344)\n",
      "tensor(0.1413)\n",
      "tensor(0.1396)\n",
      "tensor(0.1330)\n",
      "tensor(0.1565)\n",
      "tensor(0.1806)\n",
      "tensor(0.1517)\n",
      "tensor(0.1187)\n",
      "tensor(0.1147)\n",
      "tensor(0.1239)\n",
      "tensor(0.1430)\n",
      "tensor(0.1520)\n",
      "tensor(0.1567)\n",
      "tensor(0.1477)\n",
      "tensor(0.1229)\n",
      "tensor(0.1283)\n",
      "tensor(0.1456)\n",
      "tensor(0.1386)\n",
      "tensor(0.1341)\n",
      "tensor(0.1330)\n",
      "tensor(0.1320)\n",
      "tensor(0.1145)\n",
      "tensor(0.1655)\n",
      "tensor(0.2006)\n",
      "tensor(0.1111)\n",
      "tensor(0.1240)\n",
      "tensor(0.1070)\n",
      "tensor(0.1464)\n",
      "tensor(0.1286)\n",
      "tensor(0.1282)\n",
      "tensor(0.1599)\n",
      "tensor(0.1314)\n",
      "tensor(0.1613)\n",
      "tensor(0.1202)\n",
      "tensor(0.1315)\n",
      "tensor(0.1308)\n",
      "tensor(0.1201)\n",
      "tensor(0.1317)\n",
      "tensor(0.1237)\n",
      "tensor(0.1313)\n",
      "tensor(0.1252)\n",
      "tensor(0.1138)\n",
      "tensor(0.1260)\n",
      "tensor(0.1204)\n",
      "tensor(0.1360)\n",
      "tensor(0.1041)\n",
      "tensor(0.1595)\n",
      "tensor(0.1242)\n",
      "tensor(0.1078)\n",
      "tensor(0.1293)\n",
      "tensor(0.1231)\n",
      "tensor(0.1320)\n",
      "tensor(0.1293)\n",
      "tensor(0.1321)\n",
      "tensor(0.1221)\n",
      "tensor(0.1350)\n",
      "tensor(0.1347)\n",
      "tensor(0.1479)\n",
      "tensor(0.1221)\n",
      "tensor(0.1331)\n",
      "tensor(0.1241)\n",
      "tensor(0.1229)\n",
      "tensor(0.1190)\n",
      "tensor(0.1232)\n",
      "tensor(0.1316)\n",
      "tensor(0.1455)\n",
      "tensor(0.1326)\n",
      "tensor(0.1299)\n",
      "tensor(0.1228)\n",
      "tensor(0.1125)\n",
      "tensor(0.1290)\n",
      "tensor(0.1549)\n",
      "tensor(0.1160)\n",
      "tensor(0.1208)\n",
      "tensor(0.1173)\n",
      "tensor(0.1095)\n",
      "tensor(0.1301)\n",
      "tensor(0.1487)\n",
      "tensor(0.1766)\n",
      "tensor(0.1453)\n",
      "tensor(0.1131)\n",
      "tensor(0.1025)\n",
      "tensor(0.1791)\n",
      "tensor(0.1206)\n",
      "tensor(0.1496)\n",
      "tensor(0.1304)\n",
      "tensor(0.1265)\n",
      "tensor(0.1193)\n",
      "tensor(0.1223)\n",
      "tensor(0.1345)\n",
      "tensor(0.1205)\n",
      "tensor(0.1526)\n",
      "tensor(0.1143)\n",
      "tensor(0.1273)\n",
      "tensor(0.1637)\n",
      "tensor(0.1529)\n",
      "tensor(0.1124)\n",
      "tensor(0.1220)\n",
      "tensor(0.1635)\n",
      "tensor(0.1480)\n",
      "tensor(0.1362)\n",
      "tensor(0.1516)\n",
      "tensor(0.1230)\n",
      "tensor(0.1387)\n",
      "tensor(0.1219)\n",
      "tensor(0.1358)\n",
      "tensor(0.1427)\n",
      "tensor(0.1262)\n",
      "tensor(0.1256)\n",
      "tensor(0.1116)\n",
      "tensor(0.1092)\n",
      "tensor(0.1242)\n",
      "tensor(0.1261)\n",
      "tensor(0.1068)\n",
      "tensor(0.1439)\n",
      "tensor(0.1093)\n",
      "tensor(0.1087)\n",
      "tensor(0.1229)\n",
      "tensor(0.1282)\n",
      "tensor(0.1233)\n",
      "tensor(0.1346)\n",
      "tensor(0.1520)\n",
      "tensor(0.1219)\n",
      "tensor(0.1178)\n",
      "tensor(0.1096)\n",
      "tensor(0.1136)\n",
      "tensor(0.1291)\n",
      "tensor(0.1374)\n",
      "tensor(0.1365)\n",
      "tensor(0.1518)\n",
      "tensor(0.1315)\n",
      "tensor(0.1523)\n",
      "tensor(0.1253)\n",
      "tensor(0.1391)\n",
      "tensor(0.1320)\n",
      "tensor(0.1511)\n",
      "tensor(0.1301)\n",
      "tensor(0.1152)\n",
      "tensor(0.1100)\n",
      "tensor(0.1192)\n",
      "tensor(0.1137)\n",
      "tensor(0.1517)\n",
      "tensor(0.1529)\n",
      "tensor(0.1513)\n",
      "tensor(0.1140)\n",
      "tensor(0.1165)\n",
      "tensor(0.1084)\n",
      "tensor(0.1486)\n",
      "tensor(0.1074)\n",
      "tensor(0.1264)\n",
      "tensor(0.1231)\n",
      "tensor(0.1282)\n",
      "tensor(0.1128)\n",
      "tensor(0.1154)\n",
      "tensor(0.1298)\n",
      "tensor(0.1110)\n",
      "tensor(0.1175)\n",
      "tensor(0.1162)\n",
      "tensor(0.1156)\n",
      "tensor(0.1710)\n",
      "tensor(0.1060)\n",
      "tensor(0.1612)\n",
      "tensor(0.1280)\n",
      "tensor(0.1245)\n",
      "tensor(0.1413)\n",
      "tensor(0.1450)\n",
      "tensor(0.1175)\n",
      "tensor(0.1208)\n",
      "tensor(0.1089)\n",
      "tensor(0.1190)\n",
      "tensor(0.1094)\n",
      "tensor(0.1110)\n",
      "tensor(0.1327)\n",
      "tensor(0.1189)\n",
      "tensor(0.1661)\n",
      "tensor(0.1273)\n",
      "tensor(0.1212)\n",
      "tensor(0.1714)\n",
      "tensor(0.1333)\n",
      "tensor(0.1468)\n",
      "tensor(0.1297)\n",
      "tensor(0.1189)\n",
      "tensor(0.1064)\n",
      "tensor(0.1157)\n",
      "tensor(0.1395)\n",
      "tensor(0.1466)\n",
      "tensor(0.1132)\n",
      "tensor(0.1295)\n",
      "tensor(0.1543)\n",
      "tensor(0.1310)\n",
      "tensor(0.1227)\n",
      "tensor(0.1355)\n",
      "tensor(0.1391)\n",
      "tensor(0.1155)\n",
      "tensor(0.1330)\n",
      "tensor(0.1575)\n",
      "tensor(0.1237)\n",
      "tensor(0.1224)\n",
      "tensor(0.1204)\n",
      "tensor(0.1261)\n",
      "tensor(0.1137)\n",
      "tensor(0.1350)\n",
      "tensor(0.1294)\n",
      "tensor(0.1362)\n",
      "tensor(0.1554)\n",
      "tensor(0.1092)\n",
      "tensor(0.1246)\n",
      "tensor(0.1184)\n",
      "tensor(0.1281)\n",
      "tensor(0.1123)\n",
      "tensor(0.1090)\n",
      "tensor(0.1201)\n",
      "tensor(0.1337)\n",
      "tensor(0.1425)\n",
      "tensor(0.1190)\n",
      "tensor(0.1540)\n",
      "tensor(0.1332)\n",
      "tensor(0.1560)\n",
      "tensor(0.1685)\n",
      "tensor(0.1486)\n",
      "tensor(0.1255)\n",
      "tensor(0.1448)\n",
      "tensor(0.1311)\n",
      "tensor(0.1493)\n",
      "tensor(0.1397)\n",
      "tensor(0.1161)\n",
      "tensor(0.1249)\n",
      "tensor(0.1325)\n",
      "tensor(0.1120)\n",
      "tensor(0.1312)\n",
      "tensor(0.1224)\n",
      "tensor(0.1407)\n",
      "tensor(0.1365)\n",
      "tensor(0.1176)\n",
      "tensor(0.1189)\n",
      "tensor(0.1366)\n",
      "tensor(0.1029)\n",
      "tensor(0.1167)\n",
      "tensor(0.1131)\n",
      "tensor(0.1176)\n",
      "tensor(0.1549)\n",
      "tensor(0.1408)\n",
      "tensor(0.1271)\n",
      "tensor(0.1134)\n",
      "tensor(0.1096)\n",
      "tensor(0.1202)\n",
      "tensor(0.1280)\n",
      "tensor(0.1485)\n",
      "tensor(0.1205)\n",
      "tensor(0.1051)\n",
      "tensor(0.1066)\n",
      "tensor(0.1317)\n",
      "tensor(0.1144)\n",
      "tensor(0.1213)\n",
      "tensor(0.1619)\n",
      "tensor(0.1524)\n",
      "tensor(0.1134)\n",
      "tensor(0.1112)\n",
      "tensor(0.1463)\n",
      "tensor(0.1203)\n",
      "tensor(0.1432)\n",
      "tensor(0.1158)\n",
      "tensor(0.1161)\n",
      "tensor(0.1187)\n",
      "tensor(0.1169)\n",
      "tensor(0.1320)\n",
      "tensor(0.1082)\n",
      "tensor(0.1627)\n",
      "tensor(0.1520)\n",
      "tensor(0.1231)\n",
      "tensor(0.1227)\n",
      "tensor(0.1258)\n",
      "tensor(0.1209)\n",
      "tensor(0.1232)\n",
      "tensor(0.1162)\n",
      "tensor(0.1104)\n",
      "tensor(0.1168)\n",
      "tensor(0.1385)\n",
      "tensor(0.1323)\n",
      "tensor(0.1187)\n",
      "tensor(0.1440)\n",
      "tensor(0.1461)\n",
      "tensor(0.1213)\n",
      "tensor(0.1259)\n",
      "tensor(0.1217)\n",
      "tensor(0.1150)\n",
      "tensor(0.1346)\n",
      "tensor(0.1190)\n",
      "tensor(0.1931)\n",
      "tensor(0.1531)\n",
      "tensor(0.1600)\n",
      "tensor(0.1301)\n",
      "tensor(0.1394)\n",
      "tensor(0.1347)\n",
      "tensor(0.1682)\n",
      "tensor(0.1076)\n",
      "tensor(0.1247)\n",
      "tensor(0.1168)\n",
      "tensor(0.1359)\n",
      "tensor(0.1287)\n",
      "tensor(0.1097)\n",
      "tensor(0.1304)\n",
      "tensor(0.1184)\n",
      "tensor(0.1527)\n",
      "tensor(0.1080)\n",
      "tensor(0.1300)\n",
      "tensor(0.1535)\n",
      "tensor(0.1126)\n",
      "tensor(0.1594)\n",
      "tensor(0.1621)\n",
      "tensor(0.1083)\n",
      "tensor(0.1576)\n",
      "tensor(0.1683)\n",
      "tensor(0.1064)\n",
      "tensor(0.1570)\n",
      "tensor(0.1588)\n",
      "tensor(0.1350)\n",
      "tensor(0.1564)\n",
      "tensor(0.1306)\n",
      "tensor(0.1283)\n",
      "tensor(0.1402)\n",
      "tensor(0.1415)\n",
      "tensor(0.1609)\n",
      "tensor(0.1440)\n",
      "tensor(0.1045)\n",
      "tensor(0.1453)\n",
      "tensor(0.1179)\n",
      "tensor(0.1706)\n",
      "tensor(0.1168)\n",
      "tensor(0.1334)\n",
      "tensor(0.1811)\n",
      "tensor(0.1473)\n",
      "tensor(0.1153)\n",
      "tensor(0.1281)\n",
      "tensor(0.1394)\n",
      "tensor(0.1156)\n",
      "tensor(0.1572)\n",
      "tensor(0.1663)\n",
      "tensor(0.1073)\n",
      "tensor(0.1129)\n",
      "tensor(0.1519)\n",
      "tensor(0.1383)\n",
      "tensor(0.1130)\n",
      "tensor(0.1490)\n",
      "tensor(0.1226)\n",
      "tensor(0.1531)\n",
      "tensor(0.1130)\n",
      "tensor(0.1545)\n",
      "tensor(0.1562)\n",
      "tensor(0.1309)\n",
      "tensor(0.1377)\n",
      "tensor(0.1471)\n",
      "tensor(0.1307)\n",
      "tensor(0.1167)\n",
      "tensor(0.1185)\n",
      "tensor(0.1479)\n",
      "tensor(0.1384)\n",
      "tensor(0.1453)\n",
      "tensor(0.1112)\n",
      "tensor(0.1114)\n",
      "tensor(0.1249)\n",
      "tensor(0.1233)\n",
      "tensor(0.1057)\n",
      "tensor(0.1227)\n",
      "tensor(0.1071)\n",
      "tensor(0.1190)\n",
      "tensor(0.1019)\n",
      "tensor(0.1350)\n",
      "tensor(0.1168)\n",
      "tensor(0.1476)\n",
      "tensor(0.1079)\n",
      "tensor(0.1139)\n",
      "tensor(0.1417)\n",
      "tensor(0.1077)\n",
      "tensor(0.1332)\n",
      "tensor(0.1108)\n",
      "tensor(0.1206)\n",
      "tensor(0.1145)\n",
      "tensor(0.1424)\n",
      "tensor(0.1121)\n",
      "tensor(0.1563)\n",
      "tensor(0.1088)\n",
      "tensor(0.1117)\n",
      "tensor(0.1298)\n",
      "tensor(0.1097)\n",
      "tensor(0.1091)\n",
      "tensor(0.1424)\n",
      "tensor(0.1277)\n",
      "tensor(0.1081)\n",
      "tensor(0.1075)\n",
      "tensor(0.1187)\n",
      "tensor(0.1133)\n",
      "tensor(0.1116)\n",
      "tensor(0.1033)\n",
      "tensor(0.1153)\n",
      "tensor(0.1214)\n",
      "tensor(0.1140)\n",
      "tensor(0.1260)\n",
      "tensor(0.1477)\n",
      "tensor(0.1508)\n",
      "tensor(0.1168)\n",
      "tensor(0.1114)\n",
      "tensor(0.1255)\n",
      "tensor(0.1155)\n",
      "tensor(0.1091)\n",
      "tensor(0.1033)\n",
      "tensor(0.1296)\n",
      "tensor(0.1697)\n",
      "tensor(0.1509)\n",
      "tensor(0.1146)\n",
      "tensor(0.1582)\n",
      "tensor(0.1609)\n",
      "tensor(0.1421)\n",
      "tensor(0.1080)\n",
      "tensor(0.1484)\n",
      "tensor(0.1091)\n",
      "tensor(0.1049)\n",
      "tensor(0.1340)\n",
      "tensor(0.1663)\n",
      "tensor(0.1322)\n",
      "tensor(0.1186)\n",
      "tensor(0.1793)\n",
      "tensor(0.1678)\n",
      "tensor(0.1162)\n",
      "tensor(0.1512)\n",
      "tensor(0.1378)\n",
      "tensor(0.1173)\n",
      "tensor(0.1114)\n",
      "tensor(0.1181)\n",
      "tensor(0.1256)\n",
      "tensor(0.1249)\n",
      "tensor(0.1241)\n",
      "tensor(0.1170)\n",
      "tensor(0.1091)\n",
      "tensor(0.1490)\n",
      "tensor(0.1029)\n",
      "tensor(0.1266)\n",
      "tensor(0.1133)\n",
      "tensor(0.1462)\n",
      "tensor(0.1230)\n",
      "tensor(0.1165)\n",
      "tensor(0.1358)\n",
      "tensor(0.1668)\n",
      "tensor(0.1417)\n",
      "tensor(0.1229)\n",
      "tensor(0.1458)\n",
      "tensor(0.1630)\n",
      "tensor(0.1357)\n",
      "tensor(0.1432)\n",
      "tensor(0.1368)\n",
      "tensor(0.1049)\n",
      "tensor(0.1360)\n",
      "tensor(0.1321)\n",
      "tensor(0.1110)\n",
      "tensor(0.1278)\n",
      "tensor(0.1125)\n",
      "tensor(0.1411)\n",
      "tensor(0.1174)\n",
      "tensor(0.1163)\n",
      "tensor(0.1251)\n",
      "tensor(0.1436)\n",
      "tensor(0.1393)\n",
      "tensor(0.1280)\n",
      "tensor(0.1084)\n",
      "tensor(0.1186)\n",
      "tensor(0.1343)\n",
      "tensor(0.1171)\n",
      "tensor(0.1276)\n",
      "tensor(0.1619)\n",
      "tensor(0.1166)\n",
      "tensor(0.1185)\n",
      "tensor(0.1166)\n",
      "tensor(0.1274)\n",
      "tensor(0.1104)\n",
      "tensor(0.1445)\n",
      "tensor(0.1144)\n",
      "tensor(0.1369)\n",
      "tensor(0.1248)\n",
      "tensor(0.1121)\n",
      "tensor(0.1484)\n",
      "tensor(0.1308)\n",
      "tensor(0.1301)\n",
      "tensor(0.1305)\n",
      "tensor(0.1291)\n",
      "tensor(0.1358)\n",
      "tensor(0.1189)\n",
      "tensor(0.1457)\n",
      "tensor(0.1253)\n",
      "tensor(0.1406)\n",
      "tensor(0.1241)\n",
      "tensor(0.1199)\n",
      "tensor(0.1085)\n",
      "tensor(0.1224)\n",
      "tensor(0.1125)\n",
      "tensor(0.1497)\n",
      "tensor(0.1162)\n",
      "tensor(0.1251)\n",
      "tensor(0.1174)\n",
      "tensor(0.1195)\n",
      "tensor(0.1433)\n",
      "tensor(0.1139)\n",
      "tensor(0.1166)\n",
      "tensor(0.1174)\n",
      "tensor(0.1213)\n",
      "tensor(0.1057)\n",
      "tensor(0.1256)\n",
      "tensor(0.1097)\n",
      "tensor(0.1159)\n",
      "tensor(0.1389)\n",
      "tensor(0.1144)\n",
      "tensor(0.1274)\n",
      "tensor(0.1270)\n",
      "tensor(0.1358)\n",
      "tensor(0.1162)\n",
      "tensor(0.1075)\n",
      "tensor(0.1190)\n",
      "tensor(0.1163)\n",
      "tensor(0.1250)\n",
      "tensor(0.1468)\n",
      "tensor(0.1591)\n",
      "tensor(0.1184)\n",
      "tensor(0.1304)\n",
      "tensor(0.1316)\n",
      "tensor(0.1361)\n",
      "tensor(0.1417)\n",
      "tensor(0.1155)\n",
      "tensor(0.1350)\n",
      "tensor(0.1350)\n",
      "tensor(0.1149)\n",
      "tensor(0.1420)\n",
      "tensor(0.1135)\n",
      "tensor(0.1231)\n",
      "tensor(0.1390)\n",
      "tensor(0.1236)\n",
      "tensor(0.1252)\n",
      "tensor(0.1440)\n",
      "tensor(0.1473)\n",
      "tensor(0.1598)\n",
      "tensor(0.1200)\n",
      "tensor(0.1200)\n",
      "tensor(0.1326)\n",
      "tensor(0.1202)\n",
      "tensor(0.1262)\n",
      "tensor(0.1334)\n",
      "tensor(0.1153)\n",
      "tensor(0.1134)\n",
      "tensor(0.1316)\n",
      "tensor(0.1161)\n",
      "tensor(0.1347)\n",
      "tensor(0.1185)\n",
      "tensor(0.1119)\n",
      "tensor(0.1315)\n",
      "tensor(0.1643)\n",
      "tensor(0.1148)\n",
      "tensor(0.1377)\n",
      "tensor(0.1444)\n",
      "tensor(0.1265)\n",
      "tensor(0.1148)\n",
      "tensor(0.1459)\n",
      "tensor(0.1318)\n",
      "tensor(0.1235)\n",
      "tensor(0.1140)\n",
      "tensor(0.1187)\n",
      "tensor(0.1127)\n",
      "tensor(0.1074)\n",
      "tensor(0.1389)\n",
      "tensor(0.1565)\n",
      "tensor(0.1369)\n",
      "tensor(0.1114)\n",
      "tensor(0.1132)\n",
      "tensor(0.1076)\n",
      "tensor(0.1261)\n",
      "tensor(0.1524)\n",
      "tensor(0.1349)\n",
      "tensor(0.1683)\n",
      "tensor(0.1770)\n",
      "tensor(0.1424)\n",
      "tensor(0.1194)\n",
      "tensor(0.1296)\n",
      "tensor(0.1237)\n",
      "tensor(0.1361)\n",
      "tensor(0.1091)\n",
      "tensor(0.1636)\n",
      "tensor(0.1106)\n",
      "tensor(0.1276)\n",
      "tensor(0.1263)\n",
      "tensor(0.1836)\n",
      "tensor(0.1388)\n",
      "tensor(0.1488)\n",
      "tensor(0.1167)\n",
      "tensor(0.1219)\n",
      "tensor(0.1129)\n",
      "tensor(0.1516)\n",
      "tensor(0.1126)\n",
      "tensor(0.1142)\n",
      "tensor(0.1255)\n",
      "tensor(0.1446)\n",
      "tensor(0.1530)\n",
      "tensor(0.1414)\n",
      "tensor(0.1176)\n",
      "tensor(0.1446)\n",
      "tensor(0.1649)\n",
      "tensor(0.1385)\n",
      "tensor(0.1554)\n",
      "tensor(0.1316)\n",
      "tensor(0.1192)\n",
      "tensor(0.1167)\n",
      "tensor(0.1085)\n",
      "tensor(0.1212)\n",
      "tensor(0.1672)\n",
      "tensor(0.1426)\n",
      "tensor(0.1334)\n",
      "tensor(0.1477)\n",
      "tensor(0.1310)\n",
      "tensor(0.1067)\n",
      "tensor(0.1530)\n",
      "tensor(0.1210)\n",
      "tensor(0.1301)\n",
      "tensor(0.1295)\n",
      "tensor(0.1466)\n",
      "tensor(0.1696)\n",
      "tensor(0.1419)\n",
      "tensor(0.1361)\n",
      "tensor(0.1511)\n",
      "tensor(0.1175)\n",
      "tensor(0.1376)\n",
      "tensor(0.1186)\n",
      "tensor(0.1175)\n",
      "tensor(0.1348)\n",
      "tensor(0.1256)\n",
      "tensor(0.1265)\n",
      "tensor(0.1556)\n",
      "tensor(0.1262)\n",
      "tensor(0.1301)\n",
      "tensor(0.1243)\n",
      "tensor(0.1432)\n",
      "tensor(0.1262)\n",
      "tensor(0.1221)\n",
      "tensor(0.1223)\n",
      "tensor(0.1175)\n",
      "tensor(0.1290)\n",
      "tensor(0.1429)\n",
      "tensor(0.1296)\n",
      "tensor(0.1318)\n",
      "tensor(0.1240)\n",
      "tensor(0.1155)\n",
      "tensor(0.1369)\n",
      "tensor(0.1573)\n",
      "tensor(0.1271)\n",
      "tensor(0.1254)\n",
      "tensor(0.1532)\n",
      "tensor(0.1032)\n",
      "tensor(0.1242)\n",
      "tensor(0.1158)\n",
      "tensor(0.1136)\n",
      "tensor(0.1306)\n",
      "tensor(0.1450)\n",
      "tensor(0.1216)\n",
      "tensor(0.1225)\n",
      "tensor(0.1123)\n",
      "tensor(0.1432)\n",
      "tensor(0.1297)\n",
      "tensor(0.1391)\n",
      "tensor(0.1168)\n",
      "tensor(0.1240)\n",
      "tensor(0.1282)\n",
      "tensor(0.1158)\n",
      "tensor(0.1331)\n",
      "tensor(0.1161)\n",
      "tensor(0.1077)\n",
      "tensor(0.1556)\n",
      "tensor(0.1279)\n",
      "tensor(0.1156)\n",
      "tensor(0.1317)\n",
      "tensor(0.1231)\n",
      "tensor(0.1470)\n",
      "tensor(0.1024)\n",
      "tensor(0.1330)\n",
      "tensor(0.1398)\n",
      "tensor(0.1224)\n",
      "tensor(0.1432)\n",
      "tensor(0.1375)\n",
      "tensor(0.1606)\n",
      "tensor(0.1379)\n",
      "tensor(0.1753)\n",
      "tensor(0.1521)\n",
      "tensor(0.1513)\n",
      "tensor(0.1271)\n",
      "tensor(0.1375)\n",
      "tensor(0.1320)\n",
      "tensor(0.1371)\n",
      "tensor(0.1189)\n",
      "tensor(0.1485)\n",
      "tensor(0.1563)\n",
      "tensor(0.1311)\n",
      "tensor(0.1389)\n",
      "tensor(0.1228)\n",
      "tensor(0.1241)\n",
      "tensor(0.1402)\n",
      "tensor(0.1343)\n",
      "tensor(0.1277)\n",
      "tensor(0.1240)\n",
      "tensor(0.1316)\n",
      "tensor(0.1264)\n",
      "tensor(0.1453)\n",
      "tensor(0.1111)\n",
      "tensor(0.1182)\n",
      "tensor(0.1301)\n",
      "tensor(0.1334)\n",
      "tensor(0.1166)\n",
      "tensor(0.1345)\n",
      "tensor(0.1093)\n",
      "tensor(0.1133)\n",
      "tensor(0.1529)\n",
      "tensor(0.1131)\n",
      "tensor(0.1145)\n",
      "tensor(0.1372)\n",
      "tensor(0.1443)\n",
      "tensor(0.1215)\n",
      "tensor(0.1400)\n",
      "tensor(0.1145)\n",
      "tensor(0.1533)\n",
      "tensor(0.1425)\n",
      "tensor(0.1196)\n",
      "tensor(0.1292)\n",
      "tensor(0.1262)\n",
      "tensor(0.1145)\n",
      "tensor(0.1242)\n",
      "tensor(0.1258)\n",
      "tensor(0.1344)\n",
      "tensor(0.1084)\n",
      "tensor(0.1158)\n",
      "tensor(0.1467)\n",
      "tensor(0.1273)\n",
      "tensor(0.1702)\n",
      "tensor(0.1238)\n",
      "tensor(0.1210)\n",
      "tensor(0.1321)\n",
      "tensor(0.1179)\n",
      "tensor(0.1342)\n",
      "tensor(0.1167)\n",
      "tensor(0.1140)\n",
      "tensor(0.1683)\n",
      "tensor(0.1486)\n",
      "tensor(0.1649)\n",
      "tensor(0.1228)\n",
      "tensor(0.1411)\n",
      "tensor(0.1204)\n",
      "tensor(0.1576)\n",
      "tensor(0.1283)\n",
      "tensor(0.1125)\n",
      "tensor(0.1201)\n",
      "tensor(0.1105)\n",
      "tensor(0.1145)\n",
      "tensor(0.1575)\n",
      "tensor(0.1196)\n",
      "tensor(0.1420)\n",
      "tensor(0.1401)\n",
      "tensor(0.1140)\n",
      "tensor(0.1107)\n",
      "tensor(0.1095)\n",
      "tensor(0.1329)\n",
      "tensor(0.1114)\n",
      "tensor(0.1331)\n",
      "tensor(0.1259)\n",
      "tensor(0.1120)\n",
      "tensor(0.1400)\n",
      "tensor(0.1189)\n",
      "tensor(0.1089)\n",
      "tensor(0.1258)\n",
      "tensor(0.1139)\n",
      "tensor(0.1585)\n",
      "tensor(0.1260)\n",
      "tensor(0.1221)\n",
      "tensor(0.1279)\n",
      "tensor(0.1314)\n",
      "tensor(0.1310)\n",
      "tensor(0.1249)\n",
      "tensor(0.1231)\n",
      "tensor(0.1647)\n",
      "tensor(0.1104)\n",
      "tensor(0.1542)\n",
      "tensor(0.1300)\n",
      "tensor(0.1904)\n",
      "tensor(0.1457)\n",
      "tensor(0.1647)\n",
      "tensor(0.1178)\n",
      "tensor(0.1637)\n",
      "tensor(0.1492)\n",
      "tensor(0.1473)\n",
      "tensor(0.1338)\n",
      "tensor(0.1174)\n",
      "tensor(0.1438)\n",
      "tensor(0.1253)\n",
      "tensor(0.1302)\n",
      "tensor(0.1333)\n",
      "tensor(0.1533)\n",
      "tensor(0.1664)\n",
      "tensor(0.1697)\n",
      "tensor(0.1152)\n",
      "tensor(0.1470)\n",
      "tensor(0.1418)\n",
      "tensor(0.1624)\n",
      "tensor(0.1638)\n",
      "tensor(0.1784)\n",
      "tensor(0.1260)\n",
      "tensor(0.1522)\n",
      "tensor(0.1226)\n",
      "tensor(0.1101)\n",
      "tensor(0.1508)\n",
      "tensor(0.1681)\n",
      "tensor(0.1748)\n",
      "tensor(0.1606)\n",
      "tensor(0.1420)\n",
      "tensor(0.1064)\n",
      "tensor(0.1570)\n",
      "tensor(0.1209)\n",
      "tensor(0.1274)\n",
      "tensor(0.1141)\n",
      "tensor(0.1525)\n",
      "tensor(0.1530)\n",
      "tensor(0.1123)\n",
      "tensor(0.1136)\n",
      "tensor(0.1400)\n",
      "tensor(0.1442)\n",
      "tensor(0.1135)\n",
      "tensor(0.1246)\n",
      "tensor(0.1269)\n",
      "tensor(0.1183)\n",
      "tensor(0.1483)\n",
      "tensor(0.1310)\n",
      "tensor(0.1535)\n",
      "tensor(0.1156)\n",
      "tensor(0.1461)\n",
      "tensor(0.1264)\n",
      "tensor(0.1358)\n",
      "tensor(0.1159)\n",
      "tensor(0.1554)\n",
      "tensor(0.1130)\n",
      "tensor(0.1227)\n",
      "tensor(0.1395)\n",
      "tensor(0.1275)\n",
      "tensor(0.1513)\n",
      "tensor(0.1174)\n",
      "tensor(0.1073)\n",
      "tensor(0.1352)\n",
      "tensor(0.1434)\n",
      "tensor(0.1321)\n",
      "tensor(0.1556)\n",
      "tensor(0.1363)\n",
      "tensor(0.1177)\n",
      "tensor(0.1232)\n",
      "tensor(0.1236)\n",
      "tensor(0.1553)\n",
      "tensor(0.1227)\n",
      "tensor(0.1457)\n",
      "tensor(0.1201)\n",
      "tensor(0.1204)\n",
      "tensor(0.1086)\n",
      "tensor(0.1320)\n",
      "tensor(0.1181)\n",
      "tensor(0.1423)\n",
      "tensor(0.1105)\n",
      "tensor(0.1254)\n",
      "tensor(0.1423)\n",
      "tensor(0.1223)\n",
      "tensor(0.1407)\n",
      "tensor(0.1311)\n",
      "tensor(0.1302)\n",
      "tensor(0.1052)\n",
      "tensor(0.1118)\n",
      "tensor(0.1080)\n",
      "tensor(0.1106)\n",
      "tensor(0.1078)\n",
      "tensor(0.1152)\n",
      "tensor(0.1282)\n",
      "tensor(0.1344)\n",
      "tensor(0.1229)\n",
      "tensor(0.1322)\n",
      "tensor(0.1323)\n",
      "tensor(0.1423)\n",
      "tensor(0.1530)\n",
      "tensor(0.1139)\n",
      "tensor(0.1299)\n",
      "tensor(0.1187)\n",
      "tensor(0.1323)\n",
      "tensor(0.1437)\n",
      "tensor(0.1223)\n",
      "tensor(0.1038)\n",
      "tensor(0.1240)\n",
      "tensor(0.1338)\n",
      "tensor(0.1223)\n",
      "tensor(0.1784)\n",
      "tensor(0.1152)\n",
      "tensor(0.1285)\n",
      "tensor(0.1402)\n",
      "tensor(0.1405)\n",
      "tensor(0.1305)\n",
      "tensor(0.1303)\n",
      "tensor(0.1212)\n",
      "tensor(0.1366)\n",
      "tensor(0.1352)\n",
      "tensor(0.1240)\n",
      "tensor(0.1356)\n",
      "tensor(0.1893)\n",
      "tensor(0.1230)\n",
      "tensor(0.1094)\n",
      "tensor(0.1828)\n",
      "tensor(0.1408)\n",
      "tensor(0.1688)\n",
      "tensor(0.1130)\n",
      "tensor(0.1257)\n",
      "tensor(0.1184)\n",
      "tensor(0.1406)\n",
      "tensor(0.1582)\n",
      "tensor(0.1280)\n",
      "tensor(0.1154)\n",
      "tensor(0.1797)\n",
      "tensor(0.1328)\n",
      "tensor(0.1891)\n",
      "tensor(0.1654)\n",
      "tensor(0.1405)\n",
      "tensor(0.1148)\n",
      "tensor(0.1366)\n",
      "tensor(0.1737)\n",
      "tensor(0.1511)\n",
      "tensor(0.1177)\n",
      "tensor(0.1449)\n",
      "tensor(0.1304)\n",
      "tensor(0.1091)\n",
      "tensor(0.1183)\n",
      "tensor(0.1274)\n",
      "tensor(0.1169)\n",
      "tensor(0.1339)\n",
      "tensor(0.1265)\n",
      "tensor(0.1235)\n",
      "tensor(0.1390)\n",
      "tensor(0.1316)\n",
      "tensor(0.1094)\n",
      "tensor(0.1398)\n",
      "tensor(0.1162)\n",
      "tensor(0.1376)\n",
      "tensor(0.1112)\n",
      "tensor(0.1545)\n",
      "tensor(0.1124)\n",
      "tensor(0.1171)\n",
      "tensor(0.1244)\n",
      "tensor(0.1493)\n",
      "tensor(0.1226)\n",
      "tensor(0.1300)\n",
      "tensor(0.1234)\n",
      "tensor(0.1430)\n",
      "tensor(0.1448)\n",
      "tensor(0.1266)\n",
      "tensor(0.1426)\n",
      "tensor(0.1272)\n",
      "tensor(0.1123)\n",
      "tensor(0.1106)\n",
      "tensor(0.1050)\n",
      "tensor(0.1148)\n",
      "tensor(0.1603)\n",
      "tensor(0.1111)\n",
      "tensor(0.1199)\n",
      "tensor(0.1499)\n",
      "tensor(0.1386)\n",
      "tensor(0.1261)\n",
      "tensor(0.1273)\n",
      "tensor(0.1587)\n",
      "tensor(0.1195)\n",
      "tensor(0.1509)\n",
      "tensor(0.1284)\n",
      "tensor(0.1309)\n",
      "tensor(0.1251)\n",
      "tensor(0.1389)\n",
      "tensor(0.1283)\n",
      "tensor(0.1201)\n",
      "tensor(0.1358)\n",
      "tensor(0.1356)\n",
      "tensor(0.1140)\n",
      "tensor(0.1280)\n",
      "tensor(0.1333)\n",
      "tensor(0.1237)\n",
      "tensor(0.1248)\n",
      "tensor(0.1305)\n",
      "tensor(0.1229)\n",
      "tensor(0.1209)\n",
      "tensor(0.1119)\n",
      "tensor(0.1265)\n",
      "tensor(0.1298)\n",
      "tensor(0.1343)\n",
      "tensor(0.1177)\n",
      "tensor(0.1098)\n",
      "tensor(0.1322)\n",
      "tensor(0.1253)\n",
      "tensor(0.1435)\n",
      "tensor(0.1358)\n",
      "tensor(0.1098)\n",
      "tensor(0.1188)\n",
      "tensor(0.1260)\n",
      "tensor(0.1373)\n",
      "tensor(0.1316)\n",
      "tensor(0.1184)\n",
      "tensor(0.1245)\n",
      "tensor(0.1162)\n",
      "tensor(0.1377)\n",
      "tensor(0.1218)\n",
      "tensor(0.1220)\n",
      "tensor(0.1086)\n",
      "tensor(0.1341)\n",
      "tensor(0.1194)\n",
      "tensor(0.1583)\n",
      "tensor(0.1427)\n",
      "tensor(0.1337)\n",
      "tensor(0.1351)\n",
      "tensor(0.1350)\n",
      "tensor(0.1160)\n",
      "tensor(0.1326)\n",
      "tensor(0.1450)\n",
      "tensor(0.1297)\n",
      "tensor(0.1694)\n",
      "tensor(0.1576)\n",
      "tensor(0.1299)\n",
      "tensor(0.1341)\n",
      "tensor(0.1223)\n",
      "tensor(0.1260)\n",
      "tensor(0.1399)\n",
      "tensor(0.1387)\n",
      "tensor(0.1291)\n",
      "tensor(0.1049)\n",
      "tensor(0.1645)\n",
      "tensor(0.1389)\n",
      "tensor(0.1311)\n",
      "tensor(0.1361)\n",
      "tensor(0.1508)\n",
      "tensor(0.1073)\n",
      "tensor(0.1138)\n",
      "tensor(0.1121)\n",
      "tensor(0.1566)\n",
      "tensor(0.1186)\n",
      "tensor(0.1260)\n",
      "tensor(0.1136)\n",
      "tensor(0.1283)\n",
      "tensor(0.1394)\n",
      "tensor(0.1441)\n",
      "tensor(0.0998)\n",
      "tensor(0.1181)\n",
      "tensor(0.1255)\n",
      "tensor(0.1398)\n",
      "tensor(0.1374)\n",
      "tensor(0.1578)\n",
      "tensor(0.1192)\n",
      "tensor(0.1441)\n",
      "tensor(0.1084)\n",
      "tensor(0.1659)\n",
      "tensor(0.1330)\n",
      "tensor(0.1455)\n",
      "tensor(0.1314)\n",
      "tensor(0.1360)\n",
      "tensor(0.1361)\n",
      "tensor(0.1387)\n",
      "tensor(0.1257)\n",
      "tensor(0.1190)\n",
      "tensor(0.1167)\n",
      "tensor(0.1267)\n",
      "tensor(0.1141)\n",
      "tensor(0.1112)\n",
      "tensor(0.1115)\n",
      "tensor(0.1395)\n",
      "tensor(0.1479)\n",
      "tensor(0.1199)\n",
      "tensor(0.1128)\n",
      "tensor(0.1241)\n",
      "tensor(0.1530)\n",
      "tensor(0.1333)\n",
      "tensor(0.1232)\n",
      "tensor(0.1312)\n",
      "tensor(0.1395)\n",
      "tensor(0.1208)\n",
      "tensor(0.1300)\n",
      "tensor(0.1313)\n",
      "tensor(0.1139)\n",
      "tensor(0.1338)\n",
      "tensor(0.1121)\n",
      "tensor(0.1736)\n",
      "tensor(0.1286)\n",
      "tensor(0.1181)\n",
      "tensor(0.1294)\n",
      "tensor(0.1438)\n",
      "tensor(0.1367)\n",
      "tensor(0.1138)\n",
      "tensor(0.1615)\n",
      "tensor(0.1130)\n",
      "tensor(0.1354)\n",
      "tensor(0.1133)\n",
      "tensor(0.1359)\n",
      "tensor(0.1154)\n",
      "tensor(0.1662)\n",
      "tensor(0.1138)\n",
      "tensor(0.1618)\n",
      "tensor(0.1170)\n",
      "tensor(0.1295)\n",
      "tensor(0.1357)\n",
      "tensor(0.1133)\n",
      "tensor(0.1329)\n",
      "tensor(0.1111)\n",
      "tensor(0.1142)\n",
      "tensor(0.1158)\n",
      "tensor(0.1517)\n",
      "tensor(0.1150)\n",
      "tensor(0.1313)\n",
      "tensor(0.1157)\n",
      "tensor(0.1325)\n",
      "tensor(0.1417)\n",
      "tensor(0.1397)\n",
      "tensor(0.1366)\n",
      "tensor(0.1128)\n",
      "tensor(0.1157)\n",
      "tensor(0.1539)\n",
      "tensor(0.1339)\n",
      "tensor(0.1097)\n",
      "tensor(0.1371)\n",
      "tensor(0.1108)\n",
      "tensor(0.1171)\n",
      "tensor(0.1221)\n",
      "tensor(0.1622)\n",
      "tensor(0.1366)\n",
      "tensor(0.1284)\n",
      "tensor(0.1687)\n",
      "tensor(0.1200)\n",
      "tensor(0.1491)\n",
      "tensor(0.1292)\n",
      "tensor(0.1639)\n",
      "tensor(0.1437)\n",
      "tensor(0.1223)\n",
      "tensor(0.1689)\n",
      "tensor(0.1506)\n",
      "tensor(0.1049)\n",
      "tensor(0.1455)\n",
      "tensor(0.1245)\n",
      "tensor(0.1393)\n",
      "tensor(0.1224)\n",
      "tensor(0.1258)\n",
      "tensor(0.1279)\n",
      "tensor(0.1286)\n",
      "tensor(0.1263)\n",
      "tensor(0.1175)\n",
      "tensor(0.1178)\n",
      "tensor(0.1382)\n",
      "tensor(0.1128)\n",
      "tensor(0.1292)\n",
      "tensor(0.1371)\n",
      "tensor(0.1216)\n",
      "tensor(0.1203)\n",
      "tensor(0.1362)\n",
      "tensor(0.1299)\n",
      "tensor(0.1501)\n",
      "tensor(0.1154)\n",
      "tensor(0.1388)\n",
      "tensor(0.1706)\n",
      "tensor(0.1294)\n",
      "tensor(0.1281)\n",
      "tensor(0.1386)\n",
      "tensor(0.1245)\n",
      "tensor(0.1210)\n",
      "tensor(0.1344)\n",
      "tensor(0.1449)\n",
      "tensor(0.1086)\n",
      "tensor(0.1246)\n",
      "tensor(0.1084)\n",
      "tensor(0.1173)\n",
      "tensor(0.1513)\n",
      "tensor(0.1540)\n",
      "tensor(0.1237)\n",
      "tensor(0.1262)\n",
      "tensor(0.1459)\n",
      "tensor(0.1153)\n",
      "tensor(0.1775)\n",
      "tensor(0.1475)\n",
      "tensor(0.1254)\n",
      "tensor(0.1402)\n",
      "tensor(0.1226)\n",
      "tensor(0.1425)\n",
      "tensor(0.1264)\n",
      "tensor(0.1558)\n",
      "tensor(0.1282)\n",
      "tensor(0.1274)\n",
      "tensor(0.1191)\n",
      "tensor(0.1160)\n",
      "tensor(0.1153)\n",
      "tensor(0.1192)\n",
      "tensor(0.1234)\n",
      "tensor(0.1252)\n",
      "tensor(0.1568)\n",
      "tensor(0.1109)\n",
      "tensor(0.1259)\n",
      "tensor(0.1376)\n",
      "tensor(0.1161)\n",
      "tensor(0.1196)\n",
      "tensor(0.1097)\n",
      "tensor(0.1249)\n",
      "tensor(0.1442)\n",
      "tensor(0.1440)\n",
      "tensor(0.1196)\n",
      "tensor(0.1308)\n",
      "tensor(0.1390)\n",
      "tensor(0.1169)\n",
      "tensor(0.1369)\n",
      "tensor(0.1359)\n",
      "tensor(0.1187)\n",
      "tensor(0.1305)\n",
      "tensor(0.1066)\n",
      "tensor(0.1414)\n",
      "tensor(0.1302)\n",
      "tensor(0.1135)\n",
      "tensor(0.1464)\n",
      "tensor(0.1417)\n",
      "tensor(0.1166)\n",
      "tensor(0.1411)\n",
      "tensor(0.1408)\n",
      "tensor(0.1240)\n",
      "tensor(0.1182)\n",
      "tensor(0.1286)\n",
      "tensor(0.1332)\n",
      "tensor(0.1250)\n",
      "tensor(0.1301)\n",
      "tensor(0.1286)\n",
      "tensor(0.1078)\n",
      "tensor(0.1263)\n",
      "tensor(0.1594)\n",
      "tensor(0.1145)\n",
      "tensor(0.1387)\n",
      "tensor(0.1207)\n",
      "tensor(0.1144)\n",
      "tensor(0.1659)\n",
      "tensor(0.1479)\n",
      "tensor(0.1488)\n",
      "tensor(0.1186)\n",
      "tensor(0.1744)\n",
      "tensor(0.1248)\n",
      "tensor(0.1597)\n",
      "tensor(0.1677)\n",
      "tensor(0.1104)\n",
      "tensor(0.1298)\n",
      "tensor(0.1260)\n",
      "tensor(0.1178)\n",
      "tensor(0.1442)\n",
      "tensor(0.1176)\n",
      "tensor(0.1361)\n",
      "tensor(0.1405)\n",
      "tensor(0.1129)\n",
      "tensor(0.1394)\n",
      "tensor(0.1295)\n",
      "tensor(0.1114)\n",
      "tensor(0.1168)\n",
      "tensor(0.1560)\n",
      "tensor(0.1358)\n",
      "tensor(0.1164)\n",
      "tensor(0.1184)\n",
      "tensor(0.1198)\n",
      "tensor(0.1239)\n",
      "tensor(0.1545)\n",
      "tensor(0.1200)\n",
      "tensor(0.1125)\n",
      "tensor(0.1362)\n",
      "tensor(0.1197)\n",
      "tensor(0.1124)\n",
      "tensor(0.1405)\n",
      "tensor(0.1462)\n",
      "tensor(0.1194)\n",
      "tensor(0.1572)\n",
      "tensor(0.1317)\n",
      "tensor(0.1391)\n",
      "tensor(0.1251)\n",
      "tensor(0.1093)\n",
      "tensor(0.1555)\n",
      "tensor(0.1161)\n",
      "tensor(0.1068)\n",
      "tensor(0.1137)\n",
      "tensor(0.1390)\n",
      "tensor(0.1035)\n",
      "tensor(0.1256)\n",
      "tensor(0.1323)\n",
      "tensor(0.1063)\n",
      "tensor(0.1629)\n",
      "tensor(0.1237)\n",
      "tensor(0.1404)\n",
      "tensor(0.1272)\n",
      "tensor(0.1224)\n",
      "tensor(0.1446)\n",
      "tensor(0.1277)\n",
      "tensor(0.1298)\n",
      "tensor(0.1141)\n",
      "tensor(0.1147)\n",
      "tensor(0.1168)\n",
      "tensor(0.1081)\n",
      "tensor(0.1073)\n",
      "tensor(0.1189)\n",
      "tensor(0.1190)\n",
      "tensor(0.1217)\n",
      "tensor(0.1143)\n",
      "tensor(0.1305)\n",
      "tensor(0.1379)\n",
      "tensor(0.1230)\n",
      "tensor(0.1280)\n",
      "tensor(0.1349)\n",
      "tensor(0.1266)\n",
      "tensor(0.1549)\n",
      "tensor(0.1209)\n",
      "tensor(0.1100)\n",
      "tensor(0.1032)\n",
      "tensor(0.1148)\n",
      "tensor(0.1331)\n",
      "tensor(0.1398)\n",
      "tensor(0.1591)\n",
      "tensor(0.1351)\n",
      "tensor(0.1601)\n",
      "tensor(0.1375)\n",
      "tensor(0.1699)\n",
      "tensor(0.1091)\n",
      "tensor(0.1213)\n",
      "tensor(0.1130)\n",
      "tensor(0.1341)\n",
      "tensor(0.1699)\n",
      "tensor(0.1350)\n",
      "tensor(0.1617)\n",
      "tensor(0.1458)\n",
      "tensor(0.1439)\n",
      "tensor(0.1286)\n",
      "tensor(0.1400)\n",
      "tensor(0.1315)\n",
      "tensor(0.1265)\n",
      "tensor(0.1162)\n",
      "tensor(0.1460)\n",
      "tensor(0.1472)\n",
      "tensor(0.1341)\n",
      "tensor(0.1320)\n",
      "tensor(0.1446)\n",
      "tensor(0.1320)\n",
      "tensor(0.1319)\n",
      "tensor(0.1130)\n",
      "tensor(0.1101)\n",
      "tensor(0.2154)\n",
      "tensor(0.1594)\n",
      "tensor(0.1270)\n",
      "tensor(0.1689)\n",
      "tensor(0.1269)\n",
      "tensor(0.1651)\n",
      "tensor(0.1421)\n",
      "tensor(0.1441)\n",
      "tensor(0.1819)\n",
      "tensor(0.1135)\n",
      "tensor(0.1169)\n",
      "tensor(0.1215)\n",
      "tensor(0.1601)\n",
      "tensor(0.1483)\n",
      "tensor(0.1479)\n",
      "tensor(0.1295)\n",
      "tensor(0.1081)\n",
      "tensor(0.1336)\n",
      "tensor(0.1460)\n",
      "tensor(0.1396)\n",
      "tensor(0.1059)\n",
      "tensor(0.1566)\n",
      "tensor(0.1123)\n",
      "tensor(0.1125)\n",
      "tensor(0.1306)\n",
      "tensor(0.1130)\n",
      "tensor(0.1196)\n",
      "tensor(0.1368)\n",
      "tensor(0.1647)\n",
      "tensor(0.1197)\n",
      "tensor(0.1223)\n",
      "tensor(0.1111)\n",
      "tensor(0.1084)\n",
      "tensor(0.1137)\n",
      "tensor(0.1185)\n",
      "tensor(0.1562)\n",
      "tensor(0.1264)\n",
      "tensor(0.1379)\n",
      "tensor(0.1150)\n",
      "tensor(0.1648)\n",
      "tensor(0.1362)\n",
      "tensor(0.1613)\n",
      "tensor(0.1241)\n",
      "tensor(0.1345)\n",
      "tensor(0.1575)\n",
      "tensor(0.1158)\n",
      "tensor(0.1283)\n",
      "tensor(0.1252)\n",
      "tensor(0.1583)\n",
      "tensor(0.1291)\n",
      "tensor(0.1223)\n",
      "tensor(0.1566)\n",
      "tensor(0.1433)\n",
      "tensor(0.1636)\n",
      "tensor(0.1422)\n",
      "tensor(0.1212)\n",
      "tensor(0.1064)\n",
      "tensor(0.1242)\n",
      "tensor(0.1315)\n",
      "tensor(0.1261)\n",
      "tensor(0.1089)\n",
      "tensor(0.1176)\n",
      "tensor(0.1025)\n",
      "tensor(0.1478)\n",
      "tensor(0.1260)\n",
      "tensor(0.1175)\n",
      "tensor(0.1269)\n",
      "tensor(0.1232)\n",
      "tensor(0.1623)\n",
      "tensor(0.1321)\n",
      "tensor(0.1254)\n",
      "tensor(0.1483)\n",
      "tensor(0.1208)\n",
      "tensor(0.1635)\n",
      "tensor(0.1420)\n",
      "tensor(0.1161)\n",
      "tensor(0.1436)\n",
      "tensor(0.1246)\n",
      "tensor(0.1194)\n",
      "tensor(0.1792)\n",
      "tensor(0.1583)\n",
      "tensor(0.1641)\n",
      "tensor(0.1317)\n",
      "tensor(0.1455)\n",
      "tensor(0.1509)\n",
      "tensor(0.1391)\n",
      "tensor(0.1345)\n",
      "tensor(0.1570)\n",
      "tensor(0.1148)\n",
      "tensor(0.1611)\n",
      "tensor(0.1469)\n",
      "tensor(0.1863)\n",
      "tensor(0.1611)\n",
      "tensor(0.1479)\n",
      "tensor(0.1150)\n",
      "tensor(0.1499)\n",
      "tensor(0.1283)\n",
      "tensor(0.1167)\n",
      "tensor(0.1612)\n",
      "tensor(0.1264)\n",
      "tensor(0.1544)\n",
      "tensor(0.1215)\n",
      "tensor(0.1265)\n",
      "tensor(0.1374)\n",
      "tensor(0.1113)\n",
      "tensor(0.1321)\n",
      "tensor(0.1382)\n",
      "tensor(0.1210)\n",
      "tensor(0.1240)\n",
      "tensor(0.1484)\n",
      "tensor(0.1231)\n",
      "tensor(0.1240)\n",
      "tensor(0.1439)\n",
      "tensor(0.1161)\n",
      "tensor(0.1614)\n",
      "tensor(0.1518)\n",
      "tensor(0.1186)\n",
      "tensor(0.1395)\n",
      "tensor(0.1160)\n",
      "tensor(0.1083)\n",
      "tensor(0.1424)\n",
      "tensor(0.1513)\n",
      "tensor(0.1124)\n",
      "tensor(0.1387)\n",
      "tensor(0.1841)\n",
      "tensor(0.1537)\n",
      "tensor(0.1248)\n",
      "tensor(0.1362)\n",
      "tensor(0.1005)\n",
      "tensor(0.1649)\n",
      "tensor(0.1181)\n",
      "tensor(0.1120)\n",
      "tensor(0.1432)\n",
      "tensor(0.1086)\n",
      "tensor(0.1788)\n",
      "tensor(0.1589)\n",
      "tensor(0.1697)\n",
      "tensor(0.1675)\n",
      "tensor(0.1753)\n",
      "tensor(0.1267)\n",
      "tensor(0.1230)\n",
      "tensor(0.1327)\n",
      "tensor(0.1125)\n",
      "tensor(0.1484)\n",
      "tensor(0.1331)\n",
      "tensor(0.1370)\n",
      "tensor(0.1328)\n",
      "tensor(0.1183)\n",
      "tensor(0.1104)\n",
      "tensor(0.1363)\n",
      "tensor(0.1154)\n",
      "tensor(0.1307)\n",
      "tensor(0.1215)\n",
      "tensor(0.1320)\n",
      "tensor(0.1559)\n",
      "tensor(0.1329)\n",
      "tensor(0.1141)\n",
      "tensor(0.1622)\n",
      "tensor(0.1552)\n",
      "tensor(0.1135)\n",
      "tensor(0.1336)\n",
      "tensor(0.1504)\n",
      "tensor(0.1152)\n",
      "tensor(0.1542)\n",
      "tensor(0.1259)\n",
      "tensor(0.1285)\n",
      "tensor(0.1333)\n",
      "tensor(0.1174)\n",
      "tensor(0.1145)\n",
      "tensor(0.1237)\n",
      "tensor(0.1270)\n",
      "tensor(0.1278)\n",
      "tensor(0.1274)\n",
      "tensor(0.1561)\n",
      "tensor(0.1506)\n",
      "tensor(0.1452)\n",
      "tensor(0.1468)\n",
      "tensor(0.1686)\n",
      "tensor(0.1153)\n",
      "tensor(0.1500)\n",
      "tensor(0.1232)\n",
      "tensor(0.1234)\n",
      "tensor(0.1312)\n",
      "tensor(0.1332)\n",
      "tensor(0.1133)\n",
      "tensor(0.1102)\n",
      "tensor(0.1333)\n",
      "tensor(0.1700)\n",
      "tensor(0.1134)\n",
      "tensor(0.1103)\n",
      "tensor(0.1157)\n",
      "tensor(0.1126)\n",
      "tensor(0.1205)\n",
      "tensor(0.1117)\n",
      "tensor(0.1203)\n",
      "tensor(0.1099)\n",
      "tensor(0.1214)\n",
      "tensor(0.1208)\n",
      "tensor(0.1124)\n",
      "tensor(0.1930)\n",
      "tensor(0.1141)\n",
      "tensor(0.1663)\n",
      "tensor(0.1607)\n",
      "tensor(0.1158)\n",
      "tensor(0.1301)\n",
      "tensor(0.1196)\n",
      "tensor(0.1285)\n",
      "tensor(0.1399)\n",
      "tensor(0.1130)\n",
      "tensor(0.1112)\n",
      "tensor(0.1119)\n",
      "tensor(0.1324)\n",
      "tensor(0.1169)\n",
      "tensor(0.1186)\n",
      "tensor(0.1290)\n",
      "tensor(0.1420)\n",
      "tensor(0.1501)\n",
      "tensor(0.1261)\n",
      "tensor(0.1306)\n",
      "tensor(0.1172)\n",
      "tensor(0.1327)\n",
      "tensor(0.1635)\n",
      "tensor(0.1543)\n",
      "tensor(0.1174)\n",
      "tensor(0.1313)\n",
      "tensor(0.1086)\n",
      "tensor(0.1328)\n",
      "tensor(0.1393)\n",
      "tensor(0.1271)\n",
      "tensor(0.1306)\n",
      "tensor(0.1316)\n",
      "tensor(0.1320)\n",
      "tensor(0.1216)\n",
      "tensor(0.1492)\n",
      "tensor(0.1376)\n",
      "tensor(0.1156)\n",
      "tensor(0.1172)\n",
      "tensor(0.1197)\n",
      "tensor(0.1241)\n",
      "tensor(0.1839)\n",
      "tensor(0.1146)\n",
      "tensor(0.1410)\n",
      "tensor(0.1411)\n",
      "tensor(0.1196)\n",
      "tensor(0.1353)\n",
      "tensor(0.1274)\n",
      "tensor(0.1187)\n",
      "tensor(0.1375)\n",
      "tensor(0.1247)\n",
      "tensor(0.1199)\n",
      "tensor(0.1146)\n",
      "tensor(0.1256)\n",
      "tensor(0.1123)\n",
      "tensor(0.1207)\n",
      "tensor(0.1532)\n",
      "tensor(0.1569)\n",
      "tensor(0.1183)\n",
      "tensor(0.1289)\n",
      "tensor(0.1264)\n",
      "tensor(0.1505)\n",
      "tensor(0.1236)\n",
      "tensor(0.1278)\n",
      "tensor(0.1135)\n",
      "tensor(0.1233)\n",
      "tensor(0.1280)\n",
      "tensor(0.1054)\n",
      "tensor(0.1122)\n",
      "tensor(0.1340)\n",
      "tensor(0.1111)\n",
      "tensor(0.1160)\n",
      "tensor(0.1492)\n",
      "tensor(0.1614)\n",
      "tensor(0.1408)\n",
      "tensor(0.1452)\n",
      "tensor(0.1722)\n",
      "tensor(0.1579)\n",
      "tensor(0.1484)\n",
      "tensor(0.1621)\n",
      "tensor(0.1078)\n",
      "tensor(0.1172)\n",
      "tensor(0.1163)\n",
      "tensor(0.1127)\n",
      "tensor(0.1328)\n",
      "tensor(0.1365)\n",
      "tensor(0.1307)\n",
      "tensor(0.1472)\n",
      "tensor(0.1314)\n",
      "tensor(0.1107)\n",
      "tensor(0.1211)\n",
      "tensor(0.1701)\n",
      "tensor(0.1171)\n",
      "tensor(0.1189)\n",
      "tensor(0.1269)\n",
      "tensor(0.1182)\n",
      "tensor(0.1229)\n",
      "tensor(0.1295)\n",
      "tensor(0.1241)\n",
      "tensor(0.1476)\n",
      "tensor(0.1228)\n",
      "tensor(0.1417)\n",
      "tensor(0.1416)\n",
      "tensor(0.1193)\n",
      "tensor(0.1751)\n",
      "tensor(0.1181)\n",
      "tensor(0.1086)\n",
      "tensor(0.1230)\n",
      "tensor(0.1417)\n",
      "tensor(0.1162)\n",
      "tensor(0.1601)\n",
      "tensor(0.1170)\n",
      "tensor(0.1388)\n",
      "tensor(0.1463)\n",
      "tensor(0.1404)\n",
      "tensor(0.1403)\n",
      "tensor(0.1346)\n",
      "tensor(0.1206)\n",
      "tensor(0.1319)\n",
      "tensor(0.1406)\n",
      "tensor(0.1248)\n",
      "tensor(0.1355)\n",
      "tensor(0.1305)\n",
      "tensor(0.1327)\n",
      "tensor(0.1322)\n",
      "tensor(0.1035)\n",
      "tensor(0.1247)\n",
      "tensor(0.1404)\n",
      "tensor(0.1372)\n",
      "tensor(0.1362)\n",
      "tensor(0.1191)\n",
      "tensor(0.1403)\n",
      "tensor(0.1222)\n",
      "tensor(0.1666)\n",
      "tensor(0.1388)\n",
      "tensor(0.1102)\n",
      "tensor(0.1219)\n",
      "tensor(0.1348)\n",
      "tensor(0.1448)\n",
      "tensor(0.1213)\n",
      "tensor(0.1743)\n",
      "tensor(0.1503)\n",
      "tensor(0.1382)\n",
      "tensor(0.1511)\n",
      "tensor(0.1154)\n",
      "tensor(0.1623)\n",
      "tensor(0.1160)\n",
      "tensor(0.1306)\n",
      "tensor(0.1120)\n",
      "tensor(0.1278)\n",
      "tensor(0.1222)\n",
      "tensor(0.1283)\n",
      "tensor(0.1076)\n",
      "tensor(0.1471)\n",
      "tensor(0.1139)\n",
      "tensor(0.1171)\n",
      "tensor(0.1070)\n",
      "tensor(0.1094)\n",
      "tensor(0.1466)\n",
      "tensor(0.1619)\n",
      "tensor(0.1659)\n",
      "tensor(0.1154)\n",
      "tensor(0.1081)\n",
      "tensor(0.1069)\n",
      "tensor(0.1144)\n",
      "tensor(0.1240)\n",
      "tensor(0.1434)\n",
      "tensor(0.1293)\n",
      "tensor(0.1230)\n",
      "tensor(0.1364)\n",
      "tensor(0.1207)\n",
      "tensor(0.1137)\n",
      "tensor(0.1305)\n",
      "tensor(0.1340)\n",
      "tensor(0.1241)\n",
      "tensor(0.1553)\n",
      "tensor(0.1147)\n",
      "tensor(0.1301)\n",
      "tensor(0.1274)\n",
      "tensor(0.1183)\n",
      "tensor(0.1082)\n",
      "tensor(0.1333)\n",
      "tensor(0.1149)\n",
      "tensor(0.1234)\n",
      "tensor(0.1262)\n",
      "tensor(0.1737)\n",
      "tensor(0.1264)\n",
      "tensor(0.1369)\n",
      "tensor(0.1308)\n",
      "tensor(0.1053)\n",
      "tensor(0.1813)\n",
      "tensor(0.1166)\n",
      "tensor(0.1428)\n",
      "tensor(0.1397)\n",
      "tensor(0.1545)\n",
      "tensor(0.1063)\n",
      "tensor(0.1745)\n",
      "tensor(0.1507)\n",
      "tensor(0.1208)\n",
      "tensor(0.1420)\n",
      "tensor(0.1482)\n",
      "tensor(0.1324)\n",
      "tensor(0.1295)\n",
      "tensor(0.1357)\n",
      "tensor(0.1149)\n",
      "tensor(0.1036)\n",
      "tensor(0.1409)\n",
      "tensor(0.1607)\n",
      "tensor(0.1566)\n",
      "tensor(0.1359)\n",
      "tensor(0.1491)\n",
      "tensor(0.1215)\n",
      "tensor(0.1434)\n",
      "tensor(0.1133)\n",
      "tensor(0.1557)\n",
      "tensor(0.1070)\n",
      "tensor(0.1303)\n",
      "tensor(0.1343)\n",
      "tensor(0.1330)\n",
      "tensor(0.1481)\n",
      "tensor(0.1574)\n",
      "tensor(0.1396)\n",
      "tensor(0.1174)\n",
      "tensor(0.1164)\n",
      "tensor(0.1103)\n",
      "tensor(0.1504)\n",
      "tensor(0.1292)\n",
      "tensor(0.1453)\n",
      "tensor(0.1309)\n",
      "tensor(0.1486)\n",
      "tensor(0.1375)\n",
      "tensor(0.1136)\n",
      "tensor(0.1363)\n",
      "tensor(0.1271)\n",
      "tensor(0.1099)\n",
      "tensor(0.1114)\n",
      "tensor(0.1569)\n",
      "tensor(0.1173)\n",
      "tensor(0.1072)\n",
      "tensor(0.1251)\n",
      "tensor(0.1406)\n",
      "tensor(0.1247)\n",
      "tensor(0.1246)\n",
      "tensor(0.1235)\n",
      "tensor(0.1424)\n",
      "tensor(0.1193)\n",
      "tensor(0.1324)\n",
      "tensor(0.1249)\n",
      "tensor(0.1126)\n",
      "tensor(0.1550)\n",
      "tensor(0.1013)\n",
      "tensor(0.1641)\n",
      "tensor(0.1429)\n",
      "tensor(0.1343)\n",
      "tensor(0.1264)\n",
      "tensor(0.1301)\n",
      "tensor(0.1590)\n",
      "tensor(0.1129)\n",
      "tensor(0.1120)\n",
      "tensor(0.1372)\n",
      "tensor(0.1137)\n",
      "tensor(0.1387)\n",
      "tensor(0.1194)\n",
      "tensor(0.1222)\n",
      "tensor(0.1054)\n",
      "tensor(0.1102)\n",
      "tensor(0.1182)\n",
      "tensor(0.1479)\n",
      "tensor(0.1505)\n",
      "tensor(0.1409)\n",
      "tensor(0.1643)\n",
      "tensor(0.1198)\n",
      "tensor(0.1386)\n",
      "tensor(0.1269)\n",
      "tensor(0.1399)\n",
      "tensor(0.1524)\n",
      "tensor(0.1103)\n",
      "tensor(0.1236)\n",
      "tensor(0.1276)\n",
      "tensor(0.1318)\n",
      "tensor(0.1376)\n",
      "tensor(0.1210)\n",
      "tensor(0.1125)\n",
      "tensor(0.1163)\n",
      "tensor(0.1640)\n",
      "tensor(0.1567)\n",
      "tensor(0.1404)\n",
      "tensor(0.1391)\n",
      "tensor(0.1137)\n",
      "tensor(0.1806)\n",
      "tensor(0.1208)\n",
      "tensor(0.1321)\n",
      "tensor(0.1408)\n",
      "tensor(0.1267)\n",
      "tensor(0.1241)\n",
      "tensor(0.1179)\n",
      "tensor(0.1178)\n",
      "tensor(0.1175)\n",
      "tensor(0.1173)\n",
      "tensor(0.1168)\n",
      "tensor(0.1753)\n",
      "tensor(0.1056)\n",
      "tensor(0.1596)\n",
      "tensor(0.1177)\n",
      "tensor(0.1191)\n",
      "tensor(0.1222)\n",
      "tensor(0.1483)\n",
      "tensor(0.1223)\n",
      "tensor(0.1192)\n",
      "tensor(0.1282)\n",
      "tensor(0.1176)\n",
      "tensor(0.1336)\n",
      "tensor(0.1118)\n",
      "tensor(0.1230)\n",
      "tensor(0.1365)\n",
      "tensor(0.1261)\n",
      "tensor(0.1278)\n",
      "tensor(0.1756)\n",
      "tensor(0.1155)\n",
      "tensor(0.1160)\n",
      "tensor(0.1307)\n",
      "tensor(0.1220)\n",
      "tensor(0.1088)\n",
      "tensor(0.1264)\n",
      "tensor(0.1378)\n",
      "tensor(0.1317)\n",
      "tensor(0.1108)\n",
      "tensor(0.1328)\n",
      "tensor(0.1231)\n",
      "tensor(0.1510)\n",
      "tensor(0.1436)\n",
      "tensor(0.1288)\n",
      "tensor(0.1308)\n",
      "tensor(0.1435)\n",
      "tensor(0.1593)\n",
      "tensor(0.1063)\n",
      "tensor(0.1178)\n",
      "tensor(0.1287)\n",
      "tensor(0.1343)\n",
      "tensor(0.1406)\n",
      "tensor(0.1800)\n",
      "tensor(0.1114)\n",
      "tensor(0.1508)\n",
      "tensor(0.1196)\n",
      "tensor(0.1076)\n",
      "tensor(0.1252)\n",
      "tensor(0.1282)\n",
      "tensor(0.1392)\n",
      "tensor(0.1208)\n",
      "tensor(0.1210)\n",
      "tensor(0.1574)\n",
      "tensor(0.1410)\n",
      "tensor(0.1226)\n",
      "tensor(0.1226)\n",
      "tensor(0.1260)\n",
      "tensor(0.1219)\n",
      "tensor(0.1384)\n",
      "tensor(0.1570)\n",
      "tensor(0.1506)\n",
      "tensor(0.1815)\n",
      "tensor(0.1227)\n",
      "tensor(0.1292)\n",
      "tensor(0.1304)\n",
      "tensor(0.1754)\n",
      "tensor(0.1203)\n",
      "tensor(0.1283)\n",
      "tensor(0.1228)\n",
      "tensor(0.1625)\n",
      "tensor(0.1137)\n",
      "tensor(0.1359)\n",
      "tensor(0.1350)\n",
      "tensor(0.1389)\n",
      "tensor(0.1301)\n",
      "tensor(0.1356)\n",
      "tensor(0.1627)\n",
      "tensor(0.1195)\n",
      "tensor(0.1322)\n",
      "tensor(0.1430)\n",
      "tensor(0.1423)\n",
      "tensor(0.1143)\n",
      "tensor(0.1425)\n",
      "tensor(0.1279)\n",
      "tensor(0.1285)\n",
      "tensor(0.1197)\n",
      "tensor(0.1142)\n",
      "tensor(0.1383)\n",
      "tensor(0.1242)\n",
      "tensor(0.1095)\n",
      "tensor(0.1182)\n",
      "tensor(0.1402)\n",
      "tensor(0.1357)\n",
      "tensor(0.1339)\n",
      "tensor(0.1519)\n",
      "tensor(0.1591)\n",
      "tensor(0.1053)\n",
      "tensor(0.1075)\n",
      "tensor(0.1809)\n",
      "tensor(0.1132)\n",
      "tensor(0.1265)\n",
      "tensor(0.1069)\n",
      "tensor(0.1114)\n",
      "tensor(0.1394)\n",
      "tensor(0.1139)\n",
      "tensor(0.1196)\n",
      "tensor(0.1055)\n",
      "tensor(0.1205)\n",
      "tensor(0.1373)\n",
      "tensor(0.1623)\n",
      "tensor(0.1112)\n",
      "tensor(0.1703)\n",
      "tensor(0.1476)\n",
      "tensor(0.1305)\n",
      "tensor(0.1396)\n",
      "tensor(0.1340)\n",
      "tensor(0.1276)\n",
      "tensor(0.1052)\n",
      "tensor(0.1186)\n",
      "tensor(0.1261)\n",
      "tensor(0.1353)\n",
      "tensor(0.1565)\n",
      "tensor(0.1297)\n",
      "tensor(0.1321)\n",
      "tensor(0.1480)\n",
      "tensor(0.1054)\n",
      "tensor(0.1175)\n",
      "tensor(0.1407)\n",
      "tensor(0.1645)\n",
      "tensor(0.1277)\n",
      "tensor(0.1447)\n",
      "tensor(0.1331)\n",
      "tensor(0.1360)\n",
      "tensor(0.1258)\n",
      "tensor(0.1275)\n",
      "tensor(0.1212)\n",
      "tensor(0.1177)\n",
      "tensor(0.1353)\n",
      "tensor(0.1478)\n",
      "tensor(0.1239)\n",
      "tensor(0.1564)\n",
      "tensor(0.1896)\n",
      "tensor(0.1705)\n",
      "tensor(0.1127)\n",
      "tensor(0.1302)\n",
      "tensor(0.1205)\n",
      "tensor(0.1288)\n",
      "tensor(0.1194)\n",
      "tensor(0.1183)\n",
      "tensor(0.1103)\n",
      "tensor(0.1319)\n",
      "tensor(0.1084)\n",
      "tensor(0.1428)\n",
      "tensor(0.1157)\n",
      "tensor(0.1679)\n",
      "tensor(0.1338)\n",
      "tensor(0.1267)\n",
      "tensor(0.1080)\n",
      "tensor(0.1672)\n",
      "tensor(0.1163)\n",
      "tensor(0.1068)\n",
      "tensor(0.1164)\n",
      "tensor(0.1400)\n",
      "tensor(0.1253)\n",
      "tensor(0.1125)\n",
      "tensor(0.1157)\n",
      "tensor(0.1173)\n",
      "tensor(0.1059)\n",
      "tensor(0.1285)\n",
      "tensor(0.1409)\n",
      "tensor(0.1226)\n",
      "tensor(0.1410)\n",
      "tensor(0.1177)\n",
      "tensor(0.1383)\n",
      "tensor(0.1503)\n",
      "tensor(0.1307)\n",
      "tensor(0.1342)\n",
      "tensor(0.1478)\n",
      "tensor(0.1135)\n",
      "tensor(0.1396)\n",
      "tensor(0.1198)\n",
      "tensor(0.1142)\n",
      "tensor(0.1206)\n",
      "tensor(0.1322)\n",
      "tensor(0.1324)\n",
      "tensor(0.1377)\n",
      "tensor(0.1339)\n",
      "tensor(0.1476)\n",
      "tensor(0.1172)\n",
      "tensor(0.1446)\n",
      "tensor(0.1169)\n",
      "tensor(0.1190)\n",
      "tensor(0.1418)\n",
      "tensor(0.1544)\n",
      "tensor(0.1415)\n",
      "tensor(0.1238)\n",
      "tensor(0.1520)\n",
      "tensor(0.1670)\n",
      "tensor(0.1455)\n",
      "tensor(0.1591)\n",
      "tensor(0.1238)\n",
      "tensor(0.1649)\n",
      "tensor(0.1177)\n",
      "tensor(0.1867)\n",
      "tensor(0.1088)\n",
      "tensor(0.1504)\n",
      "tensor(0.1719)\n",
      "tensor(0.1904)\n",
      "tensor(0.1844)\n",
      "tensor(0.1381)\n",
      "tensor(0.1071)\n",
      "tensor(0.1893)\n",
      "tensor(0.1507)\n",
      "tensor(0.1182)\n",
      "tensor(0.1397)\n",
      "tensor(0.1325)\n",
      "tensor(0.2059)\n",
      "tensor(0.1542)\n",
      "tensor(0.1078)\n",
      "tensor(0.1614)\n",
      "tensor(0.1292)\n",
      "tensor(0.1163)\n",
      "tensor(0.1792)\n",
      "tensor(0.1360)\n",
      "tensor(0.1823)\n",
      "tensor(0.1447)\n",
      "tensor(0.1675)\n",
      "tensor(0.1517)\n",
      "tensor(0.1046)\n",
      "tensor(0.1279)\n",
      "tensor(0.1489)\n",
      "tensor(0.1111)\n",
      "tensor(0.1260)\n",
      "tensor(0.1393)\n",
      "tensor(0.1136)\n",
      "tensor(0.1163)\n",
      "tensor(0.1339)\n",
      "tensor(0.1455)\n",
      "tensor(0.1080)\n",
      "tensor(0.1480)\n",
      "tensor(0.1816)\n",
      "tensor(0.1454)\n",
      "tensor(0.1784)\n",
      "tensor(0.1278)\n",
      "tensor(0.1453)\n",
      "tensor(0.1264)\n",
      "tensor(0.1430)\n",
      "tensor(0.1130)\n",
      "tensor(0.1361)\n",
      "tensor(0.1296)\n",
      "tensor(0.1822)\n",
      "tensor(0.1234)\n",
      "tensor(0.1262)\n",
      "tensor(0.1326)\n",
      "tensor(0.1534)\n",
      "tensor(0.1305)\n",
      "tensor(0.1556)\n",
      "tensor(0.1251)\n",
      "tensor(0.1112)\n",
      "tensor(0.1051)\n",
      "tensor(0.1097)\n",
      "tensor(0.1206)\n",
      "tensor(0.1346)\n",
      "tensor(0.1511)\n",
      "tensor(0.1392)\n",
      "tensor(0.1196)\n",
      "tensor(0.1142)\n",
      "tensor(0.1350)\n",
      "tensor(0.1239)\n",
      "tensor(0.1048)\n",
      "tensor(0.1362)\n",
      "tensor(0.1409)\n",
      "tensor(0.1323)\n",
      "tensor(0.1231)\n",
      "tensor(0.1659)\n",
      "tensor(0.1058)\n",
      "tensor(0.1417)\n",
      "tensor(0.1404)\n",
      "tensor(0.1213)\n",
      "tensor(0.1394)\n",
      "tensor(0.1423)\n",
      "tensor(0.1142)\n",
      "tensor(0.1235)\n",
      "tensor(0.1498)\n",
      "tensor(0.1614)\n",
      "tensor(0.1348)\n",
      "tensor(0.1871)\n",
      "tensor(0.1506)\n",
      "tensor(0.1442)\n",
      "tensor(0.1092)\n",
      "tensor(0.1113)\n",
      "tensor(0.1386)\n",
      "tensor(0.1045)\n",
      "tensor(0.1402)\n",
      "tensor(0.1567)\n",
      "tensor(0.1263)\n",
      "tensor(0.1414)\n",
      "tensor(0.1261)\n",
      "tensor(0.1254)\n",
      "tensor(0.1574)\n",
      "tensor(0.1247)\n",
      "tensor(0.1151)\n",
      "tensor(0.1475)\n",
      "tensor(0.1226)\n",
      "tensor(0.1454)\n",
      "tensor(0.1324)\n",
      "tensor(0.1192)\n",
      "tensor(0.1125)\n",
      "tensor(0.1340)\n",
      "tensor(0.1470)\n",
      "tensor(0.1483)\n",
      "tensor(0.1351)\n",
      "tensor(0.1130)\n",
      "tensor(0.1512)\n",
      "tensor(0.1544)\n",
      "tensor(0.1193)\n",
      "tensor(0.1531)\n",
      "tensor(0.1381)\n",
      "tensor(0.1175)\n",
      "tensor(0.1475)\n",
      "tensor(0.1251)\n",
      "tensor(0.1190)\n",
      "tensor(0.1403)\n",
      "tensor(0.1393)\n",
      "tensor(0.1092)\n",
      "tensor(0.1107)\n",
      "tensor(0.1284)\n",
      "tensor(0.1358)\n",
      "tensor(0.1452)\n",
      "tensor(0.1167)\n",
      "tensor(0.1184)\n",
      "tensor(0.1312)\n",
      "tensor(0.1277)\n",
      "tensor(0.1372)\n",
      "tensor(0.1334)\n",
      "tensor(0.1205)\n",
      "tensor(0.1166)\n",
      "tensor(0.1184)\n",
      "tensor(0.1200)\n",
      "tensor(0.1189)\n",
      "tensor(0.1417)\n",
      "tensor(0.1112)\n",
      "tensor(0.1582)\n",
      "tensor(0.1333)\n",
      "tensor(0.1251)\n",
      "tensor(0.1082)\n",
      "tensor(0.1089)\n",
      "tensor(0.1152)\n",
      "tensor(0.1269)\n",
      "tensor(0.1547)\n",
      "tensor(0.1317)\n",
      "tensor(0.1285)\n",
      "tensor(0.1316)\n",
      "tensor(0.1137)\n",
      "tensor(0.1331)\n",
      "tensor(0.1072)\n",
      "tensor(0.1152)\n",
      "tensor(0.1002)\n",
      "tensor(0.1265)\n",
      "tensor(0.1269)\n",
      "tensor(0.1180)\n",
      "tensor(0.1229)\n",
      "tensor(0.1147)\n",
      "tensor(0.1115)\n",
      "tensor(0.1542)\n",
      "tensor(0.1142)\n",
      "tensor(0.1230)\n",
      "tensor(0.1340)\n",
      "tensor(0.1378)\n",
      "tensor(0.1396)\n",
      "tensor(0.1335)\n",
      "tensor(0.1242)\n",
      "tensor(0.1144)\n",
      "tensor(0.1352)\n",
      "tensor(0.1536)\n",
      "tensor(0.1546)\n",
      "tensor(0.1483)\n",
      "tensor(0.1782)\n",
      "tensor(0.1152)\n",
      "tensor(0.1323)\n",
      "tensor(0.1575)\n",
      "tensor(0.1149)\n",
      "tensor(0.1271)\n",
      "tensor(0.1797)\n",
      "tensor(0.1614)\n",
      "tensor(0.1714)\n",
      "tensor(0.1127)\n",
      "tensor(0.1209)\n",
      "tensor(0.1426)\n",
      "tensor(0.1648)\n",
      "tensor(0.1408)\n",
      "tensor(0.1558)\n",
      "tensor(0.1251)\n",
      "tensor(0.1150)\n",
      "tensor(0.1271)\n",
      "tensor(0.1534)\n",
      "tensor(0.1203)\n",
      "tensor(0.1394)\n",
      "tensor(0.1303)\n",
      "tensor(0.1532)\n",
      "tensor(0.1267)\n",
      "tensor(0.1078)\n",
      "tensor(0.1334)\n",
      "tensor(0.1355)\n",
      "tensor(0.1507)\n",
      "tensor(0.1297)\n",
      "tensor(0.1452)\n",
      "tensor(0.1206)\n",
      "tensor(0.1224)\n",
      "tensor(0.1476)\n",
      "tensor(0.1290)\n",
      "tensor(0.1160)\n",
      "tensor(0.1284)\n",
      "tensor(0.1138)\n",
      "tensor(0.1476)\n",
      "tensor(0.1215)\n",
      "tensor(0.1114)\n",
      "tensor(0.1391)\n",
      "tensor(0.1377)\n",
      "tensor(0.1344)\n",
      "tensor(0.1492)\n",
      "tensor(0.1246)\n",
      "tensor(0.1178)\n",
      "tensor(0.1095)\n",
      "tensor(0.1542)\n",
      "tensor(0.1479)\n",
      "tensor(0.1316)\n",
      "tensor(0.1196)\n",
      "tensor(0.1394)\n",
      "tensor(0.1514)\n",
      "tensor(0.1227)\n",
      "tensor(0.1229)\n",
      "tensor(0.1247)\n",
      "tensor(0.1224)\n",
      "tensor(0.1144)\n",
      "tensor(0.1130)\n",
      "tensor(0.1586)\n",
      "tensor(0.1438)\n",
      "tensor(0.1603)\n",
      "tensor(0.1175)\n",
      "tensor(0.1565)\n",
      "tensor(0.1124)\n",
      "tensor(0.1203)\n",
      "tensor(0.1152)\n",
      "tensor(0.1160)\n",
      "tensor(0.1625)\n",
      "tensor(0.1245)\n",
      "tensor(0.1018)\n",
      "tensor(0.1168)\n",
      "tensor(0.1556)\n",
      "tensor(0.1194)\n",
      "tensor(0.1289)\n",
      "tensor(0.1357)\n",
      "tensor(0.1076)\n",
      "tensor(0.1275)\n",
      "tensor(0.1110)\n",
      "tensor(0.1094)\n",
      "tensor(0.1438)\n",
      "tensor(0.1179)\n",
      "tensor(0.1310)\n",
      "tensor(0.1614)\n",
      "tensor(0.1806)\n",
      "tensor(0.1225)\n",
      "tensor(0.1434)\n",
      "tensor(0.1089)\n",
      "tensor(0.1389)\n",
      "tensor(0.1474)\n",
      "tensor(0.1533)\n",
      "tensor(0.1625)\n",
      "tensor(0.1229)\n",
      "tensor(0.1334)\n",
      "tensor(0.1213)\n",
      "tensor(0.1360)\n",
      "tensor(0.1646)\n",
      "tensor(0.1639)\n",
      "tensor(0.1174)\n",
      "tensor(0.1224)\n",
      "tensor(0.1581)\n",
      "tensor(0.1459)\n",
      "tensor(0.1144)\n",
      "tensor(0.1163)\n",
      "tensor(0.1625)\n",
      "tensor(0.1402)\n",
      "tensor(0.1161)\n",
      "tensor(0.1240)\n",
      "tensor(0.1379)\n",
      "tensor(0.1632)\n",
      "tensor(0.1091)\n",
      "tensor(0.1544)\n",
      "tensor(0.1140)\n",
      "tensor(0.1198)\n",
      "tensor(0.1254)\n",
      "tensor(0.1165)\n",
      "tensor(0.1442)\n",
      "tensor(0.1159)\n",
      "tensor(0.1123)\n",
      "tensor(0.1136)\n",
      "tensor(0.1302)\n",
      "tensor(0.1385)\n",
      "tensor(0.1265)\n",
      "tensor(0.1071)\n",
      "tensor(0.1204)\n",
      "tensor(0.1129)\n",
      "tensor(0.1155)\n",
      "tensor(0.1341)\n",
      "tensor(0.1101)\n",
      "tensor(0.1385)\n",
      "tensor(0.1189)\n",
      "tensor(0.1184)\n",
      "tensor(0.1269)\n",
      "tensor(0.1259)\n",
      "tensor(0.1437)\n",
      "tensor(0.1434)\n",
      "tensor(0.1074)\n",
      "tensor(0.1385)\n",
      "tensor(0.1168)\n",
      "tensor(0.1230)\n",
      "tensor(0.1116)\n",
      "tensor(0.1099)\n",
      "tensor(0.1159)\n",
      "tensor(0.1468)\n",
      "tensor(0.1236)\n",
      "tensor(0.1086)\n",
      "tensor(0.1607)\n",
      "tensor(0.1284)\n",
      "tensor(0.1147)\n",
      "tensor(0.1644)\n",
      "tensor(0.1166)\n",
      "tensor(0.1296)\n",
      "tensor(0.1402)\n",
      "tensor(0.1731)\n",
      "tensor(0.1095)\n",
      "tensor(0.1050)\n",
      "tensor(0.1133)\n",
      "tensor(0.1861)\n",
      "tensor(0.1237)\n",
      "tensor(0.1071)\n",
      "tensor(0.1344)\n",
      "tensor(0.1233)\n",
      "tensor(0.1619)\n",
      "tensor(0.1331)\n",
      "tensor(0.1094)\n",
      "tensor(0.1329)\n",
      "tensor(0.1572)\n",
      "tensor(0.1518)\n",
      "tensor(0.1355)\n",
      "tensor(0.1120)\n",
      "tensor(0.1861)\n",
      "tensor(0.1182)\n",
      "tensor(0.1364)\n",
      "tensor(0.1264)\n",
      "tensor(0.1321)\n",
      "tensor(0.1328)\n",
      "tensor(0.1303)\n",
      "tensor(0.1227)\n",
      "tensor(0.1183)\n",
      "tensor(0.1172)\n",
      "tensor(0.1277)\n",
      "tensor(0.1074)\n",
      "tensor(0.1520)\n",
      "tensor(0.1180)\n",
      "tensor(0.1262)\n",
      "tensor(0.1503)\n",
      "tensor(0.1142)\n",
      "tensor(0.1270)\n",
      "tensor(0.1223)\n",
      "tensor(0.1349)\n",
      "tensor(0.1185)\n",
      "tensor(0.1115)\n",
      "tensor(0.1247)\n",
      "tensor(0.1418)\n",
      "tensor(0.1052)\n",
      "tensor(0.1245)\n",
      "tensor(0.1375)\n",
      "tensor(0.1239)\n",
      "tensor(0.1169)\n",
      "tensor(0.1143)\n",
      "tensor(0.1078)\n",
      "tensor(0.1152)\n",
      "tensor(0.1187)\n",
      "tensor(0.1080)\n",
      "tensor(0.1422)\n",
      "tensor(0.1404)\n",
      "tensor(0.1490)\n",
      "tensor(0.1122)\n",
      "tensor(0.1069)\n",
      "tensor(0.1697)\n",
      "tensor(0.1103)\n",
      "tensor(0.1270)\n",
      "tensor(0.1234)\n",
      "tensor(0.1224)\n",
      "tensor(0.1232)\n",
      "tensor(0.1408)\n",
      "tensor(0.1240)\n",
      "tensor(0.1250)\n",
      "tensor(0.1279)\n",
      "tensor(0.1229)\n",
      "tensor(0.1167)\n",
      "tensor(0.1214)\n",
      "tensor(0.1276)\n",
      "tensor(0.1207)\n",
      "tensor(0.1440)\n",
      "tensor(0.1216)\n",
      "tensor(0.1198)\n",
      "tensor(0.1166)\n",
      "tensor(0.1437)\n",
      "tensor(0.1128)\n",
      "tensor(0.1278)\n",
      "tensor(0.1380)\n",
      "tensor(0.1226)\n",
      "tensor(0.1207)\n",
      "tensor(0.1212)\n",
      "tensor(0.1500)\n",
      "tensor(0.1148)\n",
      "tensor(0.1212)\n",
      "tensor(0.1275)\n",
      "tensor(0.1250)\n",
      "tensor(0.1205)\n",
      "tensor(0.1279)\n",
      "tensor(0.1463)\n",
      "tensor(0.1449)\n",
      "tensor(0.1464)\n",
      "tensor(0.1195)\n",
      "tensor(0.1432)\n",
      "tensor(0.1438)\n",
      "tensor(0.1489)\n",
      "tensor(0.1199)\n",
      "tensor(0.1291)\n",
      "tensor(0.1265)\n",
      "tensor(0.1443)\n",
      "tensor(0.1257)\n",
      "tensor(0.1166)\n",
      "tensor(0.1146)\n",
      "tensor(0.1698)\n",
      "tensor(0.1576)\n",
      "tensor(0.1485)\n",
      "tensor(0.1133)\n",
      "tensor(0.1225)\n",
      "tensor(0.1515)\n",
      "tensor(0.1544)\n",
      "tensor(0.1236)\n",
      "tensor(0.1149)\n",
      "tensor(0.1225)\n",
      "tensor(0.1349)\n",
      "tensor(0.1282)\n",
      "tensor(0.1238)\n",
      "tensor(0.1572)\n",
      "tensor(0.1164)\n",
      "tensor(0.1373)\n",
      "tensor(0.1306)\n",
      "tensor(0.1126)\n",
      "tensor(0.1132)\n",
      "tensor(0.1279)\n",
      "tensor(0.1265)\n",
      "tensor(0.1009)\n",
      "tensor(0.1074)\n",
      "tensor(0.1509)\n",
      "tensor(0.1419)\n",
      "tensor(0.1591)\n",
      "tensor(0.1177)\n",
      "tensor(0.1252)\n",
      "tensor(0.1191)\n",
      "tensor(0.1344)\n",
      "tensor(0.1355)\n",
      "tensor(0.1365)\n",
      "tensor(0.1133)\n",
      "tensor(0.1033)\n",
      "tensor(0.1311)\n",
      "tensor(0.1192)\n",
      "tensor(0.1559)\n",
      "tensor(0.1385)\n",
      "tensor(0.1266)\n",
      "tensor(0.1335)\n",
      "tensor(0.1375)\n",
      "tensor(0.1333)\n",
      "tensor(0.1122)\n",
      "tensor(0.1245)\n",
      "tensor(0.1372)\n",
      "tensor(0.1221)\n",
      "tensor(0.1506)\n",
      "tensor(0.1500)\n",
      "tensor(0.1463)\n",
      "tensor(0.1335)\n",
      "tensor(0.1243)\n",
      "tensor(0.1352)\n",
      "tensor(0.1125)\n",
      "tensor(0.1236)\n",
      "tensor(0.1127)\n",
      "tensor(0.1222)\n",
      "tensor(0.1208)\n",
      "tensor(0.1234)\n",
      "tensor(0.0998)\n",
      "tensor(0.1167)\n",
      "tensor(0.1174)\n",
      "tensor(0.1095)\n",
      "tensor(0.1193)\n",
      "tensor(0.1204)\n",
      "tensor(0.1295)\n",
      "tensor(0.1112)\n",
      "tensor(0.1016)\n",
      "tensor(0.1304)\n",
      "tensor(0.1031)\n",
      "tensor(0.1293)\n",
      "tensor(0.1306)\n",
      "tensor(0.1442)\n",
      "tensor(0.1159)\n",
      "tensor(0.1180)\n",
      "tensor(0.1145)\n",
      "tensor(0.1365)\n",
      "tensor(0.1313)\n",
      "tensor(0.1281)\n",
      "tensor(0.1207)\n",
      "tensor(0.1134)\n",
      "tensor(0.1339)\n",
      "tensor(0.1222)\n",
      "tensor(0.1051)\n",
      "tensor(0.1379)\n",
      "tensor(0.1558)\n",
      "tensor(0.1045)\n",
      "tensor(0.1437)\n",
      "tensor(0.1335)\n",
      "tensor(0.1333)\n",
      "tensor(0.1426)\n",
      "tensor(0.1220)\n",
      "tensor(0.1464)\n",
      "tensor(0.1475)\n",
      "tensor(0.1379)\n",
      "tensor(0.1091)\n",
      "tensor(0.1633)\n",
      "tensor(0.1255)\n",
      "tensor(0.1443)\n",
      "tensor(0.1136)\n",
      "tensor(0.1220)\n",
      "tensor(0.1265)\n",
      "tensor(0.1174)\n",
      "tensor(0.1152)\n",
      "tensor(0.1199)\n",
      "tensor(0.1467)\n",
      "tensor(0.1234)\n",
      "tensor(0.1142)\n",
      "tensor(0.1438)\n",
      "tensor(0.1323)\n",
      "tensor(0.1415)\n",
      "tensor(0.1582)\n",
      "tensor(0.1058)\n",
      "tensor(0.1055)\n",
      "tensor(0.1145)\n",
      "tensor(0.1326)\n",
      "tensor(0.1419)\n",
      "tensor(0.1329)\n",
      "tensor(0.1342)\n",
      "tensor(0.1184)\n",
      "tensor(0.1086)\n",
      "tensor(0.1318)\n",
      "tensor(0.1101)\n",
      "tensor(0.1381)\n",
      "tensor(0.1379)\n",
      "tensor(0.1453)\n",
      "tensor(0.1140)\n",
      "tensor(0.1589)\n",
      "tensor(0.1231)\n",
      "tensor(0.1500)\n",
      "tensor(0.1825)\n",
      "tensor(0.1254)\n",
      "tensor(0.1118)\n",
      "tensor(0.1176)\n",
      "tensor(0.1154)\n",
      "tensor(0.1135)\n",
      "tensor(0.1034)\n",
      "tensor(0.1102)\n",
      "tensor(0.1222)\n",
      "tensor(0.1481)\n",
      "tensor(0.1202)\n",
      "tensor(0.1445)\n",
      "tensor(0.1301)\n",
      "tensor(0.1390)\n",
      "tensor(0.1196)\n",
      "tensor(0.1449)\n",
      "tensor(0.1262)\n",
      "tensor(0.1096)\n",
      "tensor(0.1290)\n",
      "tensor(0.1334)\n",
      "tensor(0.1141)\n",
      "tensor(0.1519)\n",
      "tensor(0.1111)\n",
      "tensor(0.1231)\n",
      "tensor(0.1205)\n",
      "tensor(0.1810)\n",
      "tensor(0.1330)\n",
      "tensor(0.1809)\n",
      "tensor(0.1441)\n",
      "tensor(0.1577)\n",
      "tensor(0.1341)\n",
      "tensor(0.1631)\n",
      "tensor(0.1294)\n",
      "tensor(0.1771)\n",
      "tensor(0.1425)\n",
      "tensor(0.1142)\n",
      "tensor(0.1071)\n",
      "tensor(0.1123)\n",
      "tensor(0.1219)\n",
      "tensor(0.1286)\n",
      "tensor(0.1257)\n",
      "tensor(0.1179)\n",
      "tensor(0.1205)\n",
      "tensor(0.1289)\n",
      "tensor(0.1491)\n",
      "tensor(0.1234)\n",
      "tensor(0.1272)\n",
      "tensor(0.1168)\n",
      "tensor(0.1297)\n",
      "tensor(0.1377)\n",
      "tensor(0.1245)\n",
      "tensor(0.1359)\n",
      "tensor(0.1414)\n",
      "tensor(0.1298)\n",
      "tensor(0.1122)\n",
      "tensor(0.1409)\n",
      "tensor(0.1369)\n",
      "tensor(0.1168)\n",
      "tensor(0.1361)\n",
      "tensor(0.1505)\n",
      "tensor(0.1092)\n",
      "tensor(0.1367)\n",
      "tensor(0.1633)\n",
      "tensor(0.1214)\n",
      "tensor(0.1376)\n",
      "tensor(0.1135)\n",
      "tensor(0.1189)\n",
      "tensor(0.1227)\n",
      "tensor(0.1133)\n",
      "tensor(0.1356)\n",
      "tensor(0.1567)\n",
      "tensor(0.1321)\n",
      "tensor(0.1764)\n",
      "tensor(0.1770)\n",
      "tensor(0.1417)\n",
      "tensor(0.1291)\n",
      "tensor(0.1204)\n",
      "tensor(0.1202)\n",
      "tensor(0.1203)\n",
      "tensor(0.1361)\n",
      "tensor(0.1358)\n",
      "tensor(0.1385)\n",
      "tensor(0.1215)\n",
      "tensor(0.1148)\n",
      "tensor(0.1290)\n",
      "tensor(0.1344)\n",
      "tensor(0.1289)\n",
      "tensor(0.1462)\n",
      "tensor(0.1259)\n",
      "tensor(0.1274)\n",
      "tensor(0.1313)\n",
      "tensor(0.1222)\n",
      "tensor(0.1585)\n",
      "tensor(0.1194)\n",
      "tensor(0.1317)\n",
      "tensor(0.1585)\n",
      "tensor(0.1264)\n",
      "tensor(0.1731)\n",
      "tensor(0.1032)\n",
      "tensor(0.1206)\n",
      "tensor(0.1500)\n",
      "tensor(0.1302)\n",
      "tensor(0.1531)\n",
      "tensor(0.1367)\n",
      "tensor(0.1178)\n",
      "tensor(0.1101)\n",
      "tensor(0.1220)\n",
      "tensor(0.1094)\n",
      "tensor(0.1042)\n",
      "tensor(0.1273)\n",
      "tensor(0.1425)\n",
      "tensor(0.1606)\n",
      "tensor(0.1138)\n",
      "tensor(0.1298)\n",
      "tensor(0.1277)\n",
      "tensor(0.1312)\n",
      "tensor(0.1098)\n",
      "tensor(0.1455)\n",
      "tensor(0.1166)\n",
      "tensor(0.1241)\n",
      "tensor(0.1206)\n",
      "tensor(0.1518)\n",
      "tensor(0.1440)\n",
      "tensor(0.1627)\n",
      "tensor(0.1106)\n",
      "tensor(0.1335)\n",
      "tensor(0.1581)\n",
      "tensor(0.1329)\n",
      "tensor(0.1264)\n",
      "tensor(0.1123)\n",
      "tensor(0.1078)\n",
      "tensor(0.1279)\n",
      "tensor(0.1274)\n",
      "tensor(0.1186)\n",
      "tensor(0.1248)\n",
      "tensor(0.1237)\n",
      "tensor(0.1644)\n",
      "tensor(0.1350)\n",
      "tensor(0.1158)\n",
      "tensor(0.1306)\n",
      "tensor(0.1542)\n",
      "tensor(0.1220)\n",
      "tensor(0.1389)\n",
      "tensor(0.1190)\n",
      "tensor(0.1358)\n",
      "tensor(0.1100)\n",
      "tensor(0.1127)\n",
      "tensor(0.1190)\n",
      "tensor(0.1328)\n",
      "tensor(0.1292)\n",
      "tensor(0.1338)\n",
      "tensor(0.1493)\n",
      "tensor(0.1299)\n",
      "tensor(0.1461)\n",
      "tensor(0.1211)\n",
      "tensor(0.1342)\n",
      "tensor(0.1051)\n",
      "tensor(0.1445)\n",
      "tensor(0.1211)\n",
      "tensor(0.1426)\n",
      "tensor(0.1380)\n",
      "tensor(0.1272)\n",
      "tensor(0.1643)\n",
      "tensor(0.1161)\n",
      "tensor(0.1069)\n",
      "tensor(0.1174)\n",
      "tensor(0.1285)\n",
      "tensor(0.1527)\n",
      "tensor(0.1555)\n",
      "tensor(0.1377)\n",
      "tensor(0.1058)\n",
      "tensor(0.1181)\n",
      "tensor(0.1287)\n",
      "tensor(0.1292)\n",
      "tensor(0.1326)\n",
      "tensor(0.1321)\n",
      "tensor(0.1244)\n",
      "tensor(0.1175)\n",
      "tensor(0.1295)\n",
      "tensor(0.1497)\n",
      "tensor(0.1290)\n",
      "tensor(0.1201)\n",
      "tensor(0.1181)\n",
      "tensor(0.1236)\n",
      "tensor(0.1145)\n",
      "tensor(0.1227)\n",
      "tensor(0.1191)\n",
      "tensor(0.1516)\n",
      "tensor(0.1604)\n",
      "tensor(0.1316)\n",
      "tensor(0.1249)\n",
      "tensor(0.1051)\n",
      "tensor(0.1087)\n",
      "tensor(0.1092)\n",
      "tensor(0.1114)\n",
      "tensor(0.1234)\n",
      "tensor(0.1112)\n",
      "tensor(0.1127)\n",
      "tensor(0.1193)\n",
      "tensor(0.1496)\n",
      "tensor(0.1149)\n",
      "tensor(0.1298)\n",
      "tensor(0.1082)\n",
      "tensor(0.1165)\n",
      "tensor(0.1417)\n",
      "tensor(0.1271)\n",
      "tensor(0.1033)\n",
      "tensor(0.1214)\n",
      "tensor(0.1347)\n",
      "tensor(0.1155)\n",
      "tensor(0.1141)\n",
      "tensor(0.1220)\n",
      "tensor(0.1049)\n",
      "tensor(0.1320)\n",
      "tensor(0.1064)\n",
      "tensor(0.1237)\n",
      "tensor(0.1074)\n",
      "tensor(0.1154)\n",
      "tensor(0.1299)\n",
      "tensor(0.1145)\n",
      "tensor(0.1178)\n",
      "tensor(0.1071)\n",
      "tensor(0.1892)\n",
      "tensor(0.2056)\n",
      "tensor(0.1563)\n",
      "tensor(0.1208)\n",
      "tensor(0.1194)\n",
      "tensor(0.1150)\n",
      "tensor(0.1315)\n",
      "tensor(0.1529)\n",
      "tensor(0.1257)\n",
      "tensor(0.1349)\n",
      "tensor(0.1263)\n",
      "tensor(0.1107)\n",
      "tensor(0.1137)\n",
      "tensor(0.1842)\n",
      "tensor(0.1864)\n",
      "tensor(0.1407)\n",
      "tensor(0.1506)\n",
      "tensor(0.1152)\n",
      "tensor(0.1183)\n",
      "tensor(0.1565)\n",
      "tensor(0.1214)\n",
      "tensor(0.1401)\n",
      "tensor(0.1864)\n",
      "tensor(0.1399)\n",
      "tensor(0.1534)\n",
      "tensor(0.1257)\n",
      "tensor(0.1279)\n",
      "tensor(0.1271)\n",
      "tensor(0.1105)\n",
      "tensor(0.1448)\n",
      "tensor(0.1266)\n",
      "tensor(0.1452)\n",
      "tensor(0.1173)\n",
      "tensor(0.1250)\n",
      "tensor(0.1064)\n",
      "tensor(0.1217)\n",
      "tensor(0.1397)\n",
      "tensor(0.1042)\n",
      "tensor(0.1170)\n",
      "tensor(0.1397)\n",
      "tensor(0.1249)\n",
      "tensor(0.1214)\n",
      "tensor(0.1102)\n",
      "tensor(0.1091)\n",
      "tensor(0.1134)\n",
      "tensor(0.1323)\n",
      "tensor(0.1355)\n",
      "tensor(0.1150)\n",
      "tensor(0.1142)\n",
      "tensor(0.1139)\n",
      "tensor(0.1206)\n",
      "tensor(0.1555)\n",
      "tensor(0.1243)\n",
      "tensor(0.1220)\n",
      "tensor(0.1060)\n",
      "tensor(0.1210)\n",
      "tensor(0.1285)\n",
      "tensor(0.1213)\n",
      "tensor(0.1290)\n",
      "tensor(0.1648)\n",
      "tensor(0.1182)\n",
      "tensor(0.1557)\n",
      "tensor(0.1075)\n",
      "tensor(0.1205)\n",
      "tensor(0.1193)\n",
      "tensor(0.1268)\n",
      "tensor(0.1542)\n",
      "tensor(0.1477)\n",
      "tensor(0.1411)\n",
      "tensor(0.1690)\n",
      "tensor(0.1132)\n",
      "tensor(0.1413)\n",
      "tensor(0.1314)\n",
      "tensor(0.1363)\n",
      "tensor(0.1217)\n",
      "tensor(0.1184)\n",
      "tensor(0.1404)\n",
      "tensor(0.1165)\n",
      "tensor(0.1116)\n",
      "tensor(0.1256)\n",
      "tensor(0.1385)\n",
      "tensor(0.1069)\n",
      "tensor(0.1130)\n",
      "tensor(0.1232)\n",
      "tensor(0.1614)\n",
      "tensor(0.1527)\n",
      "tensor(0.1407)\n",
      "tensor(0.1540)\n",
      "tensor(0.1502)\n",
      "tensor(0.1424)\n",
      "tensor(0.1534)\n",
      "tensor(0.1382)\n",
      "tensor(0.1193)\n",
      "tensor(0.1160)\n",
      "tensor(0.1280)\n",
      "tensor(0.1127)\n",
      "tensor(0.1073)\n",
      "tensor(0.1067)\n",
      "tensor(0.1055)\n",
      "tensor(0.1178)\n",
      "tensor(0.1437)\n",
      "tensor(0.1366)\n",
      "tensor(0.1114)\n",
      "tensor(0.1469)\n",
      "tensor(0.1326)\n",
      "tensor(0.1257)\n",
      "tensor(0.1062)\n",
      "tensor(0.1119)\n",
      "tensor(0.1178)\n",
      "tensor(0.1158)\n",
      "tensor(0.1373)\n",
      "tensor(0.1446)\n",
      "tensor(0.1113)\n",
      "tensor(0.1074)\n",
      "tensor(0.1169)\n",
      "tensor(0.1059)\n",
      "tensor(0.1202)\n",
      "tensor(0.1382)\n",
      "tensor(0.1146)\n",
      "tensor(0.1625)\n",
      "tensor(0.1463)\n",
      "tensor(0.1251)\n",
      "tensor(0.1306)\n",
      "tensor(0.1207)\n",
      "tensor(0.1151)\n",
      "tensor(0.1080)\n",
      "tensor(0.1358)\n",
      "tensor(0.1287)\n",
      "tensor(0.1194)\n",
      "tensor(0.1228)\n",
      "tensor(0.1533)\n",
      "tensor(0.1287)\n",
      "tensor(0.1191)\n",
      "tensor(0.1395)\n",
      "tensor(0.1177)\n",
      "tensor(0.1245)\n",
      "tensor(0.1469)\n",
      "tensor(0.1037)\n",
      "tensor(0.1333)\n",
      "tensor(0.1597)\n",
      "tensor(0.1069)\n",
      "tensor(0.1258)\n",
      "tensor(0.1211)\n",
      "tensor(0.1553)\n",
      "tensor(0.1144)\n",
      "tensor(0.1547)\n",
      "tensor(0.1246)\n",
      "tensor(0.1089)\n",
      "tensor(0.1313)\n",
      "tensor(0.1374)\n",
      "tensor(0.1180)\n",
      "tensor(0.1371)\n",
      "tensor(0.1395)\n",
      "tensor(0.1502)\n",
      "tensor(0.1055)\n",
      "tensor(0.1601)\n",
      "tensor(0.1352)\n",
      "tensor(0.1329)\n",
      "tensor(0.1365)\n",
      "tensor(0.1308)\n",
      "tensor(0.1198)\n",
      "tensor(0.1425)\n",
      "tensor(0.1428)\n",
      "tensor(0.1397)\n",
      "tensor(0.1316)\n",
      "tensor(0.1231)\n",
      "tensor(0.0992)\n",
      "tensor(0.1460)\n",
      "tensor(0.1322)\n",
      "tensor(0.1677)\n",
      "tensor(0.1744)\n",
      "tensor(0.1022)\n",
      "tensor(0.1240)\n",
      "tensor(0.1409)\n",
      "tensor(0.1503)\n",
      "tensor(0.1250)\n",
      "tensor(0.1490)\n",
      "tensor(0.1099)\n",
      "tensor(0.1246)\n",
      "tensor(0.1249)\n",
      "tensor(0.1280)\n",
      "tensor(0.1337)\n",
      "tensor(0.1116)\n",
      "tensor(0.1597)\n",
      "tensor(0.1363)\n",
      "tensor(0.1191)\n",
      "tensor(0.1048)\n",
      "tensor(0.1385)\n",
      "tensor(0.1115)\n",
      "tensor(0.1628)\n",
      "tensor(0.1366)\n",
      "tensor(0.1410)\n",
      "tensor(0.1207)\n",
      "tensor(0.1254)\n",
      "tensor(0.1304)\n",
      "tensor(0.1296)\n",
      "tensor(0.1304)\n",
      "tensor(0.1711)\n",
      "tensor(0.1227)\n",
      "tensor(0.1379)\n",
      "tensor(0.1094)\n",
      "tensor(0.1221)\n",
      "tensor(0.1582)\n",
      "tensor(0.1197)\n",
      "tensor(0.1240)\n",
      "tensor(0.1105)\n",
      "tensor(0.1144)\n",
      "tensor(0.1183)\n",
      "tensor(0.1031)\n",
      "tensor(0.1339)\n",
      "tensor(0.1516)\n",
      "tensor(0.1454)\n",
      "tensor(0.1372)\n",
      "tensor(0.1205)\n",
      "tensor(0.1485)\n",
      "tensor(0.1704)\n",
      "tensor(0.1207)\n",
      "tensor(0.1114)\n",
      "tensor(0.1212)\n",
      "tensor(0.1307)\n",
      "tensor(0.1287)\n",
      "tensor(0.1308)\n",
      "tensor(0.1501)\n",
      "tensor(0.1314)\n",
      "tensor(0.1447)\n",
      "tensor(0.1264)\n",
      "tensor(0.1633)\n",
      "tensor(0.1626)\n",
      "tensor(0.1490)\n",
      "tensor(0.1632)\n",
      "tensor(0.1228)\n",
      "tensor(0.1479)\n",
      "tensor(0.1249)\n",
      "tensor(0.1106)\n",
      "tensor(0.1285)\n",
      "tensor(0.1169)\n",
      "tensor(0.1102)\n",
      "tensor(0.1123)\n",
      "tensor(0.1216)\n",
      "tensor(0.1704)\n",
      "tensor(0.1276)\n",
      "tensor(0.1431)\n",
      "tensor(0.1244)\n",
      "tensor(0.1562)\n",
      "tensor(0.1113)\n",
      "tensor(0.1264)\n",
      "tensor(0.1526)\n",
      "tensor(0.1178)\n",
      "tensor(0.1169)\n",
      "tensor(0.1177)\n",
      "tensor(0.1129)\n",
      "tensor(0.1064)\n",
      "tensor(0.1679)\n",
      "tensor(0.1774)\n",
      "tensor(0.1436)\n",
      "tensor(0.1290)\n",
      "tensor(0.1507)\n",
      "tensor(0.1350)\n",
      "tensor(0.1483)\n",
      "tensor(0.1333)\n",
      "tensor(0.1295)\n",
      "tensor(0.1139)\n",
      "tensor(0.1144)\n",
      "tensor(0.1180)\n",
      "tensor(0.1366)\n",
      "tensor(0.1284)\n",
      "tensor(0.1119)\n",
      "tensor(0.1277)\n",
      "tensor(0.1393)\n",
      "tensor(0.1524)\n",
      "tensor(0.1075)\n",
      "tensor(0.1480)\n",
      "tensor(0.1200)\n",
      "tensor(0.1312)\n",
      "tensor(0.1119)\n",
      "tensor(0.1521)\n",
      "tensor(0.1614)\n",
      "tensor(0.1140)\n",
      "tensor(0.1140)\n",
      "tensor(0.1332)\n",
      "tensor(0.1291)\n",
      "tensor(0.1053)\n",
      "tensor(0.1544)\n",
      "tensor(0.1334)\n",
      "tensor(0.1640)\n",
      "tensor(0.1337)\n",
      "tensor(0.1600)\n",
      "tensor(0.1524)\n",
      "tensor(0.1529)\n",
      "tensor(0.1051)\n",
      "tensor(0.1530)\n",
      "tensor(0.1441)\n",
      "tensor(0.1418)\n",
      "tensor(0.1543)\n",
      "tensor(0.1547)\n",
      "tensor(0.1331)\n",
      "tensor(0.1099)\n",
      "tensor(0.1119)\n",
      "tensor(0.1041)\n",
      "tensor(0.1246)\n",
      "tensor(0.1089)\n",
      "tensor(0.1043)\n",
      "tensor(0.1182)\n",
      "tensor(0.1214)\n",
      "tensor(0.1167)\n",
      "tensor(0.1228)\n",
      "tensor(0.1327)\n",
      "tensor(0.1228)\n",
      "tensor(0.1463)\n",
      "tensor(0.1385)\n",
      "tensor(0.1256)\n",
      "tensor(0.1255)\n",
      "tensor(0.1229)\n",
      "tensor(0.1267)\n",
      "tensor(0.1167)\n",
      "tensor(0.1049)\n",
      "tensor(0.0984)\n",
      "tensor(0.0974)\n",
      "tensor(0.1475)\n",
      "tensor(0.1495)\n",
      "tensor(0.1282)\n",
      "tensor(0.1596)\n",
      "tensor(0.1270)\n",
      "tensor(0.1171)\n",
      "tensor(0.1368)\n",
      "tensor(0.1278)\n",
      "tensor(0.1408)\n",
      "tensor(0.1388)\n",
      "tensor(0.1360)\n",
      "tensor(0.1152)\n",
      "tensor(0.1342)\n",
      "tensor(0.1380)\n",
      "tensor(0.1716)\n",
      "tensor(0.1255)\n",
      "tensor(0.1595)\n",
      "tensor(0.1208)\n",
      "tensor(0.1536)\n",
      "tensor(0.1192)\n",
      "tensor(0.1386)\n",
      "tensor(0.1507)\n",
      "tensor(0.1446)\n",
      "tensor(0.1246)\n",
      "tensor(0.1313)\n",
      "tensor(0.1258)\n",
      "tensor(0.1378)\n",
      "tensor(0.1266)\n",
      "tensor(0.1232)\n",
      "tensor(0.1201)\n",
      "tensor(0.1214)\n",
      "tensor(0.1471)\n",
      "tensor(0.1275)\n",
      "tensor(0.1250)\n",
      "tensor(0.1061)\n",
      "tensor(0.1663)\n",
      "tensor(0.1395)\n",
      "tensor(0.1269)\n",
      "tensor(0.1330)\n",
      "tensor(0.1617)\n",
      "tensor(0.1493)\n",
      "tensor(0.1784)\n",
      "tensor(0.1393)\n",
      "tensor(0.1145)\n",
      "tensor(0.1275)\n",
      "tensor(0.1302)\n",
      "tensor(0.1728)\n",
      "tensor(0.1458)\n",
      "tensor(0.1316)\n",
      "tensor(0.1410)\n",
      "tensor(0.1203)\n",
      "tensor(0.1204)\n",
      "tensor(0.1119)\n",
      "tensor(0.1283)\n",
      "tensor(0.1258)\n",
      "tensor(0.1180)\n",
      "tensor(0.1458)\n",
      "tensor(0.1241)\n",
      "tensor(0.1289)\n",
      "tensor(0.1340)\n",
      "tensor(0.1265)\n",
      "tensor(0.1206)\n",
      "tensor(0.1297)\n",
      "tensor(0.1240)\n",
      "tensor(0.1264)\n",
      "tensor(0.1261)\n",
      "tensor(0.1133)\n",
      "tensor(0.1159)\n",
      "tensor(0.1271)\n",
      "tensor(0.1024)\n",
      "tensor(0.1119)\n",
      "tensor(0.1103)\n",
      "tensor(0.1292)\n",
      "tensor(0.1248)\n",
      "tensor(0.1277)\n",
      "tensor(0.1224)\n",
      "tensor(0.1313)\n",
      "tensor(0.1031)\n",
      "tensor(0.1243)\n",
      "tensor(0.1306)\n",
      "tensor(0.1375)\n",
      "tensor(0.1311)\n",
      "tensor(0.1151)\n",
      "tensor(0.1226)\n",
      "tensor(0.1333)\n",
      "tensor(0.1071)\n",
      "tensor(0.1431)\n",
      "tensor(0.1485)\n",
      "tensor(0.1147)\n",
      "tensor(0.1065)\n",
      "tensor(0.1475)\n",
      "tensor(0.1488)\n",
      "tensor(0.1248)\n",
      "tensor(0.1117)\n",
      "tensor(0.1228)\n",
      "tensor(0.1358)\n",
      "tensor(0.1268)\n",
      "tensor(0.1010)\n",
      "tensor(0.1473)\n",
      "tensor(0.1188)\n",
      "tensor(0.1146)\n",
      "tensor(0.1123)\n",
      "tensor(0.1184)\n",
      "tensor(0.1094)\n",
      "tensor(0.1353)\n",
      "tensor(0.1253)\n",
      "tensor(0.1499)\n",
      "tensor(0.1235)\n",
      "tensor(0.1275)\n",
      "tensor(0.1126)\n",
      "tensor(0.1014)\n",
      "tensor(0.1311)\n",
      "tensor(0.1303)\n",
      "tensor(0.1372)\n",
      "tensor(0.1216)\n",
      "tensor(0.1015)\n",
      "tensor(0.1077)\n",
      "tensor(0.1483)\n",
      "tensor(0.1223)\n",
      "tensor(0.1338)\n",
      "tensor(0.1203)\n",
      "tensor(0.1092)\n",
      "tensor(0.1420)\n",
      "tensor(0.1314)\n",
      "tensor(0.1246)\n",
      "tensor(0.1099)\n",
      "tensor(0.1297)\n",
      "tensor(0.1460)\n",
      "tensor(0.1349)\n",
      "tensor(0.1287)\n",
      "tensor(0.1126)\n",
      "tensor(0.1378)\n",
      "tensor(0.1442)\n",
      "tensor(0.1556)\n",
      "tensor(0.1580)\n",
      "tensor(0.1565)\n",
      "tensor(0.1541)\n",
      "tensor(0.1351)\n",
      "tensor(0.1524)\n",
      "tensor(0.1092)\n",
      "tensor(0.1316)\n",
      "tensor(0.1204)\n",
      "tensor(0.1172)\n",
      "tensor(0.1421)\n",
      "tensor(0.1139)\n",
      "tensor(0.1321)\n",
      "tensor(0.1159)\n",
      "tensor(0.1478)\n",
      "tensor(0.1235)\n",
      "tensor(0.1276)\n",
      "tensor(0.1125)\n",
      "tensor(0.1169)\n",
      "tensor(0.1383)\n",
      "tensor(0.1069)\n",
      "tensor(0.1069)\n",
      "tensor(0.1078)\n",
      "tensor(0.1061)\n",
      "tensor(0.1008)\n",
      "tensor(0.1040)\n",
      "tensor(0.1034)\n",
      "tensor(0.1076)\n",
      "tensor(0.1018)\n",
      "tensor(0.1047)\n",
      "tensor(0.1090)\n",
      "tensor(0.1094)\n",
      "tensor(0.1139)\n",
      "tensor(0.1448)\n",
      "tensor(0.1522)\n",
      "tensor(0.1310)\n",
      "tensor(0.1332)\n",
      "tensor(0.1309)\n",
      "tensor(0.1144)\n",
      "tensor(0.1359)\n",
      "tensor(0.1437)\n",
      "tensor(0.1429)\n",
      "tensor(0.1348)\n",
      "tensor(0.1155)\n",
      "tensor(0.1057)\n",
      "tensor(0.1188)\n",
      "tensor(0.1712)\n",
      "tensor(0.1080)\n",
      "tensor(0.1174)\n",
      "tensor(0.1044)\n",
      "tensor(0.1114)\n",
      "tensor(0.1279)\n",
      "tensor(0.1130)\n",
      "tensor(0.1093)\n",
      "tensor(0.1482)\n",
      "tensor(0.1106)\n",
      "tensor(0.1130)\n",
      "tensor(0.1221)\n",
      "tensor(0.1084)\n",
      "tensor(0.1129)\n",
      "tensor(0.1180)\n",
      "tensor(0.1405)\n",
      "tensor(0.1146)\n",
      "tensor(0.1125)\n",
      "tensor(0.1100)\n",
      "tensor(0.1207)\n",
      "tensor(0.1317)\n",
      "tensor(0.1377)\n",
      "tensor(0.1258)\n",
      "tensor(0.1288)\n",
      "tensor(0.1300)\n",
      "tensor(0.1192)\n",
      "tensor(0.1395)\n",
      "tensor(0.1370)\n",
      "tensor(0.1627)\n",
      "tensor(0.1353)\n",
      "tensor(0.1625)\n",
      "tensor(0.1322)\n",
      "tensor(0.1447)\n",
      "tensor(0.1458)\n",
      "tensor(0.1284)\n",
      "tensor(0.1418)\n",
      "tensor(0.1385)\n",
      "tensor(0.1331)\n",
      "tensor(0.1341)\n",
      "tensor(0.1222)\n",
      "tensor(0.1070)\n",
      "tensor(0.1144)\n",
      "tensor(0.1155)\n",
      "tensor(0.1234)\n",
      "tensor(0.1330)\n",
      "tensor(0.1460)\n",
      "tensor(0.1359)\n",
      "tensor(0.1213)\n",
      "tensor(0.1151)\n",
      "tensor(0.1144)\n",
      "tensor(0.1134)\n",
      "tensor(0.1203)\n",
      "tensor(0.1202)\n",
      "tensor(0.1303)\n",
      "tensor(0.1208)\n",
      "tensor(0.1151)\n",
      "tensor(0.1060)\n",
      "tensor(0.1436)\n",
      "tensor(0.1044)\n",
      "tensor(0.1114)\n",
      "tensor(0.1115)\n",
      "tensor(0.1374)\n",
      "tensor(0.1374)\n",
      "tensor(0.1299)\n",
      "tensor(0.1109)\n",
      "tensor(0.1408)\n",
      "tensor(0.1379)\n",
      "tensor(0.1532)\n",
      "tensor(0.1156)\n",
      "tensor(0.1439)\n",
      "tensor(0.1477)\n",
      "tensor(0.1430)\n",
      "tensor(0.1313)\n",
      "tensor(0.1206)\n",
      "tensor(0.1079)\n",
      "tensor(0.1267)\n",
      "tensor(0.1249)\n",
      "tensor(0.1506)\n",
      "tensor(0.1617)\n",
      "tensor(0.1447)\n",
      "tensor(0.1309)\n",
      "tensor(0.1105)\n",
      "tensor(0.1329)\n",
      "tensor(0.1229)\n",
      "tensor(0.1121)\n",
      "tensor(0.1154)\n",
      "tensor(0.1242)\n",
      "tensor(0.1186)\n",
      "tensor(0.1132)\n",
      "tensor(0.1198)\n",
      "tensor(0.1698)\n",
      "tensor(0.1512)\n",
      "tensor(0.1610)\n",
      "tensor(0.1769)\n",
      "tensor(0.1520)\n",
      "tensor(0.1310)\n",
      "tensor(0.1330)\n",
      "tensor(0.1346)\n",
      "tensor(0.1563)\n",
      "tensor(0.1217)\n",
      "tensor(0.1501)\n",
      "tensor(0.1876)\n",
      "tensor(0.1365)\n",
      "tensor(0.1660)\n",
      "tensor(0.1389)\n",
      "tensor(0.1171)\n",
      "tensor(0.1288)\n",
      "tensor(0.1215)\n",
      "tensor(0.1226)\n",
      "tensor(0.1153)\n",
      "tensor(0.1131)\n",
      "tensor(0.1347)\n",
      "tensor(0.1241)\n",
      "tensor(0.1192)\n",
      "tensor(0.1456)\n",
      "tensor(0.1404)\n",
      "tensor(0.1340)\n",
      "tensor(0.1181)\n",
      "tensor(0.1143)\n",
      "tensor(0.1210)\n",
      "tensor(0.1419)\n",
      "tensor(0.1454)\n",
      "tensor(0.1254)\n",
      "tensor(0.1760)\n",
      "tensor(0.1338)\n",
      "tensor(0.1196)\n",
      "tensor(0.1070)\n",
      "tensor(0.1229)\n",
      "tensor(0.1178)\n",
      "tensor(0.1128)\n",
      "tensor(0.1516)\n",
      "tensor(0.1306)\n",
      "tensor(0.1212)\n",
      "tensor(0.1166)\n",
      "tensor(0.1227)\n",
      "tensor(0.1410)\n",
      "tensor(0.1480)\n",
      "tensor(0.1124)\n",
      "tensor(0.1171)\n",
      "tensor(0.1472)\n",
      "tensor(0.1121)\n",
      "tensor(0.1162)\n",
      "tensor(0.1205)\n",
      "tensor(0.1049)\n",
      "tensor(0.1058)\n",
      "tensor(0.1493)\n",
      "tensor(0.1205)\n",
      "tensor(0.1432)\n",
      "tensor(0.1078)\n",
      "tensor(0.1109)\n",
      "tensor(0.1246)\n",
      "tensor(0.0988)\n",
      "tensor(0.1523)\n",
      "tensor(0.1229)\n",
      "tensor(0.1364)\n",
      "tensor(0.1609)\n",
      "tensor(0.1180)\n",
      "tensor(0.1366)\n",
      "tensor(0.1178)\n",
      "tensor(0.1564)\n",
      "tensor(0.1182)\n",
      "tensor(0.1466)\n",
      "tensor(0.1304)\n",
      "tensor(0.1117)\n",
      "tensor(0.1477)\n",
      "tensor(0.1210)\n",
      "tensor(0.1083)\n",
      "tensor(0.1556)\n",
      "tensor(0.1462)\n",
      "tensor(0.1623)\n",
      "tensor(0.1416)\n",
      "tensor(0.1488)\n",
      "tensor(0.1707)\n",
      "tensor(0.1135)\n",
      "tensor(0.1460)\n",
      "tensor(0.1206)\n",
      "tensor(0.1434)\n",
      "tensor(0.1257)\n",
      "tensor(0.1021)\n",
      "tensor(0.1313)\n",
      "tensor(0.1642)\n",
      "tensor(0.1615)\n",
      "tensor(0.1630)\n",
      "tensor(0.1362)\n",
      "tensor(0.1290)\n",
      "tensor(0.1237)\n",
      "tensor(0.1257)\n",
      "tensor(0.1400)\n",
      "tensor(0.1547)\n",
      "tensor(0.1109)\n",
      "tensor(0.1000)\n",
      "tensor(0.1456)\n",
      "tensor(0.1502)\n",
      "tensor(0.1296)\n",
      "tensor(0.1271)\n",
      "tensor(0.1469)\n",
      "tensor(0.1274)\n",
      "tensor(0.1339)\n",
      "tensor(0.1271)\n",
      "tensor(0.1111)\n",
      "tensor(0.1245)\n",
      "tensor(0.1438)\n",
      "tensor(0.1254)\n",
      "tensor(0.1538)\n",
      "tensor(0.1181)\n",
      "tensor(0.1328)\n",
      "tensor(0.1095)\n",
      "tensor(0.1318)\n",
      "tensor(0.1340)\n",
      "tensor(0.1485)\n",
      "tensor(0.1179)\n",
      "tensor(0.1761)\n",
      "tensor(0.1332)\n",
      "tensor(0.1490)\n",
      "tensor(0.1149)\n",
      "tensor(0.1406)\n",
      "tensor(0.1348)\n",
      "tensor(0.1452)\n",
      "tensor(0.1523)\n",
      "tensor(0.1203)\n",
      "tensor(0.1160)\n",
      "tensor(0.1209)\n",
      "tensor(0.1038)\n",
      "tensor(0.1388)\n",
      "tensor(0.1067)\n",
      "tensor(0.1101)\n",
      "tensor(0.1046)\n",
      "tensor(0.1259)\n",
      "tensor(0.1190)\n",
      "tensor(0.1473)\n",
      "tensor(0.1278)\n",
      "tensor(0.1129)\n",
      "tensor(0.1600)\n",
      "tensor(0.1092)\n",
      "tensor(0.1202)\n",
      "tensor(0.1182)\n",
      "tensor(0.1503)\n",
      "tensor(0.1157)\n",
      "tensor(0.1075)\n",
      "tensor(0.1092)\n",
      "tensor(0.1326)\n",
      "tensor(0.1086)\n",
      "tensor(0.1079)\n",
      "tensor(0.1131)\n",
      "tensor(0.1989)\n",
      "tensor(0.1579)\n",
      "tensor(0.1692)\n",
      "tensor(0.1132)\n",
      "tensor(0.1202)\n",
      "tensor(0.1320)\n",
      "tensor(0.1127)\n",
      "tensor(0.1223)\n",
      "tensor(0.1086)\n",
      "tensor(0.1159)\n",
      "tensor(0.1391)\n",
      "tensor(0.1495)\n",
      "tensor(0.1186)\n",
      "tensor(0.1173)\n",
      "tensor(0.1493)\n",
      "tensor(0.1168)\n",
      "tensor(0.1311)\n",
      "tensor(0.1157)\n",
      "tensor(0.1124)\n",
      "tensor(0.1233)\n",
      "tensor(0.1438)\n",
      "tensor(0.1147)\n",
      "tensor(0.1616)\n",
      "tensor(0.1735)\n",
      "tensor(0.1197)\n",
      "tensor(0.1574)\n",
      "tensor(0.1122)\n",
      "tensor(0.1524)\n",
      "tensor(0.1186)\n",
      "tensor(0.1370)\n",
      "tensor(0.1262)\n",
      "tensor(0.1435)\n",
      "tensor(0.1189)\n",
      "tensor(0.1261)\n",
      "tensor(0.1278)\n",
      "tensor(0.1383)\n",
      "tensor(0.1124)\n",
      "tensor(0.1632)\n",
      "tensor(0.1345)\n",
      "tensor(0.1305)\n",
      "tensor(0.1086)\n",
      "tensor(0.1309)\n",
      "tensor(0.1472)\n",
      "tensor(0.1354)\n",
      "tensor(0.1290)\n",
      "tensor(0.1215)\n",
      "tensor(0.1179)\n",
      "tensor(0.1354)\n",
      "tensor(0.1283)\n",
      "tensor(0.1215)\n",
      "tensor(0.1062)\n",
      "tensor(0.1272)\n",
      "tensor(0.1183)\n",
      "tensor(0.1595)\n",
      "tensor(0.1261)\n",
      "tensor(0.1167)\n",
      "tensor(0.1213)\n",
      "tensor(0.1416)\n",
      "tensor(0.1307)\n",
      "tensor(0.1156)\n",
      "tensor(0.1627)\n",
      "tensor(0.1324)\n",
      "tensor(0.1317)\n",
      "tensor(0.1232)\n",
      "tensor(0.1287)\n",
      "tensor(0.1341)\n",
      "tensor(0.1115)\n",
      "tensor(0.1039)\n",
      "tensor(0.1209)\n",
      "tensor(0.1339)\n",
      "tensor(0.1334)\n",
      "tensor(0.1377)\n",
      "tensor(0.1236)\n",
      "tensor(0.1052)\n",
      "tensor(0.1088)\n",
      "tensor(0.1409)\n",
      "tensor(0.1202)\n",
      "tensor(0.1140)\n",
      "tensor(0.1174)\n",
      "tensor(0.1131)\n",
      "tensor(0.1160)\n",
      "tensor(0.1147)\n",
      "tensor(0.1194)\n",
      "tensor(0.1091)\n",
      "tensor(0.1083)\n",
      "tensor(0.1137)\n",
      "tensor(0.1132)\n",
      "tensor(0.1141)\n",
      "tensor(0.1094)\n",
      "tensor(0.1229)\n",
      "tensor(0.1156)\n",
      "tensor(0.1117)\n",
      "tensor(0.1381)\n",
      "tensor(0.1265)\n",
      "tensor(0.1053)\n",
      "tensor(0.1097)\n",
      "tensor(0.1100)\n",
      "tensor(0.1406)\n",
      "tensor(0.1200)\n",
      "tensor(0.1424)\n",
      "tensor(0.1586)\n",
      "tensor(0.1113)\n",
      "tensor(0.1413)\n",
      "tensor(0.1198)\n",
      "tensor(0.1134)\n",
      "tensor(0.1491)\n",
      "tensor(0.1143)\n",
      "tensor(0.1287)\n",
      "tensor(0.1141)\n",
      "tensor(0.1279)\n",
      "tensor(0.1499)\n",
      "tensor(0.1470)\n",
      "tensor(0.1293)\n",
      "tensor(0.1390)\n",
      "tensor(0.1044)\n",
      "tensor(0.1709)\n",
      "tensor(0.1413)\n",
      "tensor(0.1306)\n",
      "tensor(0.1324)\n",
      "tensor(0.1225)\n",
      "tensor(0.1411)\n",
      "tensor(0.1536)\n",
      "tensor(0.1254)\n",
      "tensor(0.1385)\n",
      "tensor(0.1338)\n",
      "tensor(0.1176)\n",
      "tensor(0.1305)\n",
      "tensor(0.1597)\n",
      "tensor(0.1258)\n",
      "tensor(0.1787)\n",
      "tensor(0.1222)\n",
      "tensor(0.1208)\n",
      "tensor(0.1281)\n",
      "tensor(0.1255)\n",
      "tensor(0.1331)\n",
      "tensor(0.1337)\n",
      "tensor(0.1323)\n",
      "tensor(0.1687)\n",
      "tensor(0.1137)\n",
      "tensor(0.1377)\n",
      "tensor(0.1090)\n",
      "tensor(0.1288)\n",
      "tensor(0.1346)\n",
      "tensor(0.1126)\n",
      "tensor(0.1435)\n",
      "tensor(0.1460)\n",
      "tensor(0.1188)\n",
      "tensor(0.1450)\n",
      "tensor(0.1513)\n",
      "tensor(0.1277)\n",
      "tensor(0.1114)\n",
      "tensor(0.1402)\n",
      "tensor(0.1318)\n",
      "tensor(0.1275)\n",
      "tensor(0.1454)\n",
      "tensor(0.1627)\n",
      "tensor(0.1332)\n",
      "tensor(0.1259)\n",
      "tensor(0.1251)\n",
      "tensor(0.1269)\n",
      "tensor(0.1519)\n",
      "tensor(0.1272)\n",
      "tensor(0.1076)\n",
      "tensor(0.1412)\n",
      "tensor(0.1757)\n",
      "tensor(0.1172)\n",
      "tensor(0.1580)\n",
      "tensor(0.1083)\n",
      "tensor(0.1122)\n",
      "tensor(0.1571)\n",
      "tensor(0.1099)\n",
      "tensor(0.1303)\n",
      "tensor(0.1577)\n",
      "tensor(0.1140)\n",
      "tensor(0.1415)\n",
      "tensor(0.1300)\n",
      "tensor(0.1656)\n",
      "tensor(0.1381)\n",
      "tensor(0.1384)\n",
      "tensor(0.1417)\n",
      "tensor(0.1262)\n",
      "tensor(0.1120)\n",
      "tensor(0.1463)\n",
      "tensor(0.1070)\n",
      "tensor(0.1586)\n",
      "tensor(0.1602)\n",
      "tensor(0.1481)\n",
      "tensor(0.1962)\n",
      "tensor(0.1220)\n",
      "tensor(0.1662)\n",
      "tensor(0.1690)\n",
      "tensor(0.1116)\n",
      "tensor(0.1485)\n",
      "tensor(0.1515)\n",
      "tensor(0.1077)\n",
      "tensor(0.1271)\n",
      "tensor(0.1294)\n",
      "tensor(0.1303)\n",
      "tensor(0.1086)\n",
      "tensor(0.1705)\n",
      "tensor(0.1507)\n",
      "tensor(0.1302)\n",
      "tensor(0.1059)\n",
      "tensor(0.1075)\n",
      "tensor(0.1493)\n",
      "tensor(0.1300)\n",
      "tensor(0.1587)\n",
      "tensor(0.1153)\n",
      "tensor(0.1463)\n",
      "tensor(0.1310)\n",
      "tensor(0.1714)\n",
      "tensor(0.1225)\n",
      "tensor(0.1664)\n",
      "tensor(0.1365)\n",
      "tensor(0.1141)\n",
      "tensor(0.1290)\n",
      "tensor(0.1652)\n",
      "tensor(0.1503)\n",
      "tensor(0.1192)\n",
      "tensor(0.1643)\n",
      "tensor(0.1082)\n",
      "tensor(0.1569)\n",
      "tensor(0.2144)\n",
      "tensor(0.1255)\n",
      "tensor(0.1670)\n",
      "tensor(0.1550)\n",
      "tensor(0.1256)\n",
      "tensor(0.1509)\n",
      "tensor(0.1719)\n",
      "tensor(0.1491)\n",
      "tensor(0.1187)\n",
      "tensor(0.1225)\n",
      "tensor(0.1230)\n",
      "tensor(0.1231)\n",
      "tensor(0.1333)\n",
      "tensor(0.1082)\n",
      "tensor(0.1156)\n",
      "tensor(0.1274)\n",
      "tensor(0.1223)\n",
      "tensor(0.1721)\n",
      "tensor(0.1169)\n",
      "tensor(0.1863)\n",
      "tensor(0.1712)\n",
      "tensor(0.1478)\n",
      "tensor(0.1237)\n",
      "tensor(0.1376)\n",
      "tensor(0.1391)\n",
      "tensor(0.1247)\n",
      "tensor(0.1319)\n",
      "tensor(0.1172)\n",
      "tensor(0.1101)\n",
      "tensor(0.1243)\n",
      "tensor(0.1048)\n",
      "tensor(0.1160)\n",
      "tensor(0.1626)\n",
      "tensor(0.1359)\n",
      "tensor(0.1504)\n",
      "tensor(0.1035)\n",
      "tensor(0.1806)\n",
      "tensor(0.1153)\n",
      "tensor(0.1056)\n",
      "tensor(0.1314)\n",
      "tensor(0.1072)\n",
      "tensor(0.1587)\n",
      "tensor(0.1223)\n",
      "tensor(0.0974)\n",
      "tensor(0.1188)\n",
      "tensor(0.1394)\n",
      "tensor(0.1357)\n",
      "tensor(0.1168)\n",
      "tensor(0.1146)\n",
      "tensor(0.1422)\n",
      "tensor(0.1214)\n",
      "tensor(0.1199)\n",
      "tensor(0.1373)\n",
      "tensor(0.1201)\n",
      "tensor(0.1199)\n",
      "tensor(0.1572)\n",
      "tensor(0.1371)\n",
      "tensor(0.1243)\n",
      "tensor(0.1343)\n",
      "tensor(0.1264)\n",
      "tensor(0.1448)\n",
      "tensor(0.1338)\n",
      "tensor(0.1173)\n",
      "tensor(0.1097)\n",
      "tensor(0.1260)\n",
      "tensor(0.1187)\n",
      "tensor(0.1292)\n",
      "tensor(0.1452)\n",
      "tensor(0.1347)\n",
      "tensor(0.1345)\n",
      "tensor(0.1253)\n",
      "tensor(0.1395)\n",
      "tensor(0.1271)\n",
      "tensor(0.1602)\n",
      "tensor(0.1639)\n",
      "tensor(0.1185)\n",
      "tensor(0.1184)\n",
      "tensor(0.1250)\n",
      "tensor(0.1450)\n",
      "tensor(0.1364)\n",
      "tensor(0.1611)\n",
      "tensor(0.1562)\n",
      "tensor(0.1231)\n",
      "tensor(0.1421)\n",
      "tensor(0.1568)\n",
      "tensor(0.1452)\n",
      "tensor(0.1089)\n",
      "tensor(0.1225)\n",
      "tensor(0.1122)\n",
      "tensor(0.1226)\n",
      "tensor(0.1163)\n",
      "tensor(0.1355)\n",
      "tensor(0.1400)\n",
      "tensor(0.1441)\n",
      "tensor(0.1023)\n",
      "tensor(0.1568)\n",
      "tensor(0.1340)\n",
      "tensor(0.1259)\n",
      "tensor(0.1327)\n",
      "tensor(0.1202)\n",
      "tensor(0.1315)\n",
      "tensor(0.1186)\n",
      "tensor(0.1105)\n",
      "tensor(0.1593)\n",
      "tensor(0.1366)\n",
      "tensor(0.1157)\n",
      "tensor(0.1557)\n",
      "tensor(0.1223)\n",
      "tensor(0.1468)\n",
      "tensor(0.1214)\n",
      "tensor(0.1196)\n",
      "tensor(0.1345)\n",
      "tensor(0.1090)\n",
      "tensor(0.1253)\n",
      "tensor(0.1192)\n",
      "tensor(0.1274)\n",
      "tensor(0.1119)\n",
      "tensor(0.1553)\n",
      "tensor(0.1255)\n",
      "tensor(0.1586)\n",
      "tensor(0.1199)\n",
      "tensor(0.1261)\n",
      "tensor(0.1197)\n",
      "tensor(0.1264)\n",
      "tensor(0.1146)\n",
      "tensor(0.1140)\n",
      "tensor(0.1224)\n",
      "tensor(0.1290)\n",
      "tensor(0.1250)\n",
      "tensor(0.1398)\n",
      "tensor(0.1238)\n",
      "tensor(0.1649)\n",
      "tensor(0.1214)\n",
      "tensor(0.1052)\n",
      "tensor(0.1168)\n",
      "tensor(0.1032)\n",
      "tensor(0.1209)\n",
      "tensor(0.1099)\n",
      "tensor(0.1305)\n",
      "tensor(0.1297)\n",
      "tensor(0.1396)\n",
      "tensor(0.1412)\n",
      "tensor(0.1230)\n",
      "tensor(0.1108)\n",
      "tensor(0.1233)\n",
      "tensor(0.1367)\n",
      "tensor(0.1209)\n",
      "tensor(0.1179)\n",
      "tensor(0.1237)\n",
      "tensor(0.1279)\n",
      "tensor(0.1275)\n",
      "tensor(0.1188)\n",
      "tensor(0.1319)\n",
      "tensor(0.1210)\n",
      "tensor(0.1316)\n",
      "tensor(0.1220)\n",
      "tensor(0.1267)\n"
     ]
    }
   ],
   "source": [
    "# what if we want to compare any image to the ideal_3 to see if for each image it's a 3 or not?\n",
    "# you would probably do that:\n",
    "for a_3 in three_tensors:\n",
    "    dist = mnist_distance(a_3 / 255, mean3)\n",
    "    print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'three_tensors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# broadcasting!\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# in ML we should avoid writing any loops, because we got optimized API to do stuff like that\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# first we need to convert the three_tensors into a tensor instead of a list\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mthree_tensors\u001b[49m), torch\u001b[38;5;241m.\u001b[39mstack(three_tensors)\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'three_tensors' is not defined"
     ]
    }
   ],
   "source": [
    "# broadcasting!\n",
    "# in ML we should avoid writing any loops, because we got optimized API to do stuff like that\n",
    "\n",
    "# first we need to convert the three_tensors into a tensor instead of a list\n",
    "type(three_tensors), torch.stack(three_tensors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36.3602, 36.2508, 36.5192, 44.7669, 40.2137, 52.9154, 42.7004,  ..., 20.8352, 41.6038, 29.9445, 26.8843, 40.9109, 28.8896,\n",
       "        35.8195])"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then we can let mnist_distance do the broadcasting\n",
    "\n",
    "stacked_threes = torch.stack(three_tensors).float()\n",
    "# if we don't specify which axis, we would get the mean of the mean\n",
    "# (stacked_threes-mean3).abs().mean((1, 2))\n",
    "\n",
    "# better way is to say last 2 dimension (last one and second to last)\n",
    "# /!\\ (-1, -2) is different than (-2, -1)\n",
    "(stacked_threes-mean3).abs().mean((-1, -2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1074, 0.1114, 0.1100, 0.1154, 0.1300, 0.1700, 0.1158,  ..., 0.1275, 0.1188, 0.1319, 0.1210, 0.1316, 0.1220, 0.1267])"
      ]
     },
     "execution_count": 957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a bit big, we forgot to normalize values\n",
    "\n",
    "# this doesn't work in brodacasting!\n",
    "# stacked_threes /= 255\n",
    "\n",
    "# only this work\n",
    "stacked_threes = stacked_threes / 255\n",
    "(stacked_threes-mean3).abs().mean((-1, -2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1074, 0.1114, 0.1100, 0.1154, 0.1300, 0.1700, 0.1158,  ..., 0.1275, 0.1188, 0.1319, 0.1210, 0.1316, 0.1220, 0.1267])"
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so that's the same result as \n",
    "mnist_distance(stacked_threes, mean3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(1.))"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cool but it still doesn't tell us if it's a 3 or not\n",
    "# how about this\n",
    "def is_3(x): return mnist_distance(x, mean3) < mnist_distance(x, mean7)\n",
    "\n",
    "# if it's not a 7, then it must be a 3! dumb yes, but for now it works\n",
    "# let's test this on a sample\n",
    "\n",
    "is_3(a_3), is_3(a_3).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False,  ..., False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as expected 7 are not 3\n",
    "is_3(valid_7_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  ..., False,  True,  True, False,  True,  True,  True])"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# however some 3 look like 7??? so the definition of the ideal 3 is not good enough\n",
    "is_3(valid_3_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9168), tensor(0.9815))"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the accuracy\n",
    "accuracy_3s =      is_3(valid_3_tens).float() .mean()\n",
    "accuracy_7s = (1 - is_3(valid_7_tens).float()).mean()\n",
    "\n",
    "accuracy_3s,accuracy_7s,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9492)"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the accuracy of the our \"model\"\n",
    "(accuracy_3s+accuracy_7s)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok cool, but here we are just comparing 3 and 7\n",
    "# we can figure out if it's a 3 or 7\n",
    "# but it's not perfect, we saw that sometimes we think 3 are 7\n",
    "#\n",
    "# and the main issue here also is that we only classify 3 and 7 not other numbers\n",
    "# our acc will be even worse if we include more cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's a gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember derivative of x^2 is 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  4., 10.], requires_grad=True)"
      ]
     },
     "execution_count": 1066,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def power(x): return (x**2).sum()\n",
    "\n",
    "xt = tensor([3., 4., 10.]).requires_grad_()\n",
    "xt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(125., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 1067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = power(xt)\n",
    "yt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  8., 20.])"
      ]
     },
     "execution_count": 1068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.backward()\n",
    "xt.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-End SGD Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.])"
      ]
     },
     "execution_count": 1069,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = torch.arange(0,20).float(); time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've added a bit of random noise, since measuring things manually isn't precise. This means it's not that easy to answer the question: what was the roller coaster's speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speeds = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1\n",
    "plt.scatter(times,speeds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cheat a bit, instead of trying a random function, seems like the data look like a quadratic, so let's try to fit a quadratic to these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 + x\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed earlier, that's fixed function, in order to optimize a function we need weights, so let's introduce some weights that we can tweak through SGD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, weights):\n",
    "    w1,w2,w3 = weights\n",
    "    return w1*(x**2) + (w2*x) + w3\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we optimize for? We need to define a cost function, that will tell us how far we are from the goal!\n",
    "This function will tell us the distance between our predicted points and the actual points, and our goal is to minimize this distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(preds, targets): return ((preds-targets)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5315, -2.2206, -1.5167], requires_grad=True)"
      ]
     },
     "execution_count": 1074,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step1: Initialize Param\n",
    "weights = torch.randn(3).requires_grad_()\n",
    "weights\n",
    "# our three pumps that will be used to adjust our function shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.]),\n",
       " tensor([ -1.5167,  -3.2058,  -3.8319,  -3.3949,  -1.8949,   0.6682,   4.2944,   8.9835,  14.7357,  21.5510,  29.4293,  38.3707,  48.3751,\n",
       "          59.4426,  71.5731,  84.7666,  99.0232, 114.3429, 130.7256, 148.1713], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 1075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step2: Forward pass - Calculate Predictions\n",
    "preds = f(time, weights)\n",
    "\n",
    "# xs and ys\n",
    "time, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_preds(preds, ax=None):\n",
    "    if ax is None: ax=plt.subplots()[1]\n",
    "    ax.scatter(time, speeds)\n",
    "    ax.scatter(time, to_np(preds), color='red')\n",
    "    ax.set_ylim(-300,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2434.1746, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 1078,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step3: Calculate Loss / Distance to target\n",
    "# we calculate our predictions to reality, (the observed speeds)\n",
    "loss = mse(preds, speeds)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13905.0312,   860.3478,    35.4228])"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step4: Compute Gradients\n",
    "loss.backward()\n",
    "weights.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step5: Adjust the pumps\n",
    "lr = 1e-5 #size of our step\n",
    "weights.data -= lr * weights.grad.data\n",
    "weights.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1041.5586, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 1081,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = f(times, weights)\n",
    "mse(preds, speeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGiCAYAAAASgEe5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0wElEQVR4nO3deXhTZaLH8V8KNAWlqdLSUCmbCwgiKDOUMjIj2qEoo/S6AS4jI4LDhRk2R8CFZbxaFXdlqN4r4H1cWO5VZkQuWllchoIKVAWFR7RCWVJUhgRQCrbn/tFJpoF0JSfJm34/z3MeyMmbk/dwGvLre97FYVmWJQAAAEMlRLsCAAAAp4IwAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMZmuYee+993TVVVcpIyNDDodDy5YtC3resizNmDFD7dq1U8uWLZWTk6Mvv/wyqMyBAwd00003KTk5WSkpKRo1apQOHz5sZ7UBAIBBbA0zR44cUa9evTR37tyQzz/yyCN6+umnVVBQoA0bNui0005Tbm6ujh49Gihz0003aevWrSosLNTy5cv13nvvacyYMXZWGwAAGMQRqYUmHQ6HXn/9deXl5UmqapXJyMjQlClTdOedd0qSvF6v0tPTtXDhQg0fPlxffPGFunfvro8++kg/+9nPJEkrV67UlVdeqd27dysjIyMSVQcAADGsebTeuKSkRB6PRzk5OYF9LpdLWVlZKioq0vDhw1VUVKSUlJRAkJGknJwcJSQkaMOGDfq3f/u3kMcuLy9XeXl54HFlZaUOHDigNm3ayOFw2HdSAAAgbCzL0qFDh5SRkaGEhJpvJkUtzHg8HklSenp60P709PTAcx6PR23btg16vnnz5jrzzDMDZULJz8/X7Nmzw1xjAAAQDaWlpWrfvn2Nz0ctzNhp+vTpmjx5cuCx1+tVhw4dVFpaquTk5CjWDAAAw73/vvSb39RdbvlyacCAU3orn8+nzMxMtW7dutZyUQszbrdbklRWVqZ27doF9peVlal3796BMvv37w963U8//aQDBw4EXh+K0+mU0+k8aX9ycjJhBgCAU+Hz1b9cmL5z6+oiErV5Zjp37iy3261Vq1YF9vl8Pm3YsEHZ2dmSpOzsbB08eFAbN24MlFm9erUqKyuVlZUV8ToDANDkVWuACEu5MLC1Zebw4cPasWNH4HFJSYmKi4t15plnqkOHDpo4caL+4z/+Q+eee646d+6s++67TxkZGYERT+eff74GDx6s0aNHq6CgQMePH9f48eM1fPhwRjIBABANAwZI7dtLe/ZIoQZEOxxVz5/iLaaGsDXMfPzxxxo4cGDgsb8fy6233qqFCxfqrrvu0pEjRzRmzBgdPHhQl1xyiVauXKmkpKTAa15++WWNHz9el19+uRISEnTttdfq6aeftrPaAACgJs2aSU89JV13XVVwqR5o/LeDnnyyqlyERGyemWjy+XxyuVzyer30mQEAIBxee02aMEHavftf+zIzq4LMNdeE5S3q+/0dl6OZAACAza65Rho6tGp00759VX1kBgyIaIuMH2EGAIB4VVFhb9ho1ky69NLwHa+RCDMAAMSjULeB2rev6u8SpttAsSJqQ7MBAIBNXnutqoNu9SAjVY1Auu66qufjCGEGAIB4UlFR1SITanyPf9/EiVXl4gRhBgCAePL++ye3yFRnWVJpaVW5OEGYAQAgnuzbF95yBiDMAAAQT2JwuQG7EWYAAIgn/uUGalqc0eGomtwugssN2I0wAwBAPPEvNyCdHGiitNyA3QgzAADEm2uukf7nf6Szzgre37591f44m2eGSfMAAIhHMbTcgN0IMwAARJOdSw7EyHIDdiPMAAAQLU1oyQE70WcGAIBoaGJLDtiJMNNIFZWWir76Xn8t3qOir75XRWWIaaMBAAilCS45YCduMzXCyi37NPuNz7XPezSwr50rSTOv6q7BF8TPJEQAAJs0ZMmBJtDn5VTRMtNAK7fs09iXNgUFGUnyeI9q7EubtHJL/EwPDQCwSZwsORArdylomWmAikpLs9/4XKEulSXJIWn2G5/r193dapZQw8yLAADEwZIDsXSXgpaZBviw5MBJLTLVWZL2eY/qw5IDkasUAMA8hi85EGt3KQgzDbD/UM1BpjHlAABNlMFLDtR1l0KquksRyVtOhJkGaNs6KazlAABNmKFLDsTiXQr6zDRA385nqp0rSR7v0ZCJ1CHJ7UpS385nRrpqAAC72DlDr4FLDsTiXQrCTAM0S3Bo5lXdNfalTXJIQYHG30g486rudP4FgHgRiRl6DVtyIBbvUnCbqYEGX9BO826+WG5X8EVyu5I07+aLmWcGAOIFM/SG5L9LUdOv7Q5VjWqK5F0Kh2WFmn4wvvh8PrlcLnm9XiUnJ4flmBWVlj4sOaD9h46qbeuqi0aLDADEiYoKqVOnmie2cziqWmhKSmL6lpBd/KOZpNB3KcL1y319v79pmWmkZgkOZZ/dRkN7n6Xss9sQZAAgnjRkht4mKNbuUtBnBgCAE8XJDL12GnxBO/26uzsm7lIQZgAAOFEczNAr2d8lwn+XItoIMwAAnMg/Q++ePaFXtvb3mYnRGXql2FpuwG70mQEA4EQGz9Arxd5yA3YjzMSoWFmJFABiXkWFtHat9OqrVX9WVITnuIbO0BuLyw3YjdtMMagpNQ0CwCmxe1I7A2fobchyA7HQ3yUcCDMxxt80eGJe9jcNMjEfAPyTf1K7E/u0+Ce1C1fric0z9Ia7k24sLjdgN8JMDKmradChqqbBX3d3M68NgKatoqKqRSZU51zLqurXMnFiVatKDLei2NESH4vLDdgt6n1mZs2aJYfDEbR169Yt8PzRo0c1btw4tWnTRqeffrquvfZalZWVRbHG9onFlUgBICbFwaR2dnXSjcXlBuwW9TAjST169NC+ffsC2wcffBB4btKkSXrjjTe0dOlSvfvuu9q7d6+uidFOV6eqKTYNAkCjGD6pnZ2ddP2LIks6KdDE66LIMRFmmjdvLrfbHdhSU1MlSV6vVy+88IIef/xxXXbZZerTp48WLFigdevWaf369VGudfg1xaZBAGgUwye1s7slPtaWG7BbTPSZ+fLLL5WRkaGkpCRlZ2crPz9fHTp00MaNG3X8+HHl5OQEynbr1k0dOnRQUVGR+vXrF/J45eXlKi8vDzz2+Xy2n0M4+JsGPd6jIdO6Q1U/iPHUNAgAjWL4pHaRaImPpeUG7Bb1lpmsrCwtXLhQK1eu1Lx581RSUqIBAwbo0KFD8ng8SkxMVEpKStBr0tPT5fF4ajxmfn6+XC5XYMvMzLT5LMKjKTYNAmgiwj0XjOGT2kWqJb6pLIoc9TBzxRVX6Prrr9eFF16o3NxcrVixQgcPHtSSJUsafczp06fL6/UGttLS0jDW2F5NrWkQQBPw2mtSp07SwIHSjTdW/dmpU9X+U2HopHZS0+yka6eYuM1UXUpKis477zzt2LFDv/71r3Xs2DEdPHgwqHWmrKxMbre7xmM4nU45nc4I1NYekWgatHvxMQCQZP9cMAZOaif9qyV+7Eub5JCCuhbQEt9wMRdmDh8+rK+++kq33HKL+vTpoxYtWmjVqlW69tprJUnbt2/Xrl27lJ2dHeWa2svOlUiZYRhARERqLhibJ7Wzi78l/sT/j938f9xgDssK9VMWOXfeeaeuuuoqdezYUXv37tXMmTNVXFyszz//XGlpaRo7dqxWrFihhQsXKjk5WX/4wx8kSevWrav3e/h8PrlcLnm9XiUnJ9t1KkaoaYZhf/bnVhaAsFm7tuqWUl3WrDEyjIQLLeU1q+/3d9RbZnbv3q0RI0bo+++/V1pami655BKtX79eaWlpkqQnnnhCCQkJuvbaa1VeXq7c3Fz95S9/iXKtzcQMwwAiyvC5YCLFzpb4piLqYWbRokW1Pp+UlKS5c+dq7ty5EapR/GqKi48BiCLD54KBOaI+mgmRwwzDACLKPxfMiUOn/RwOKTMzZueCgTkIM00IMwwDqFG454GRjJ8LBuYgzDQhzGsAICS75oGRjJ4LBuaI+mimSGA007/4RzNJoec1CMdoJnrmAwapaR4Yf8tJuAJHRYVxc8Eg+ur7/U2YaYLsnGeGOWwAg1RUVLXA7N4d+nn/+kYlJQQPRAVhphrCzMnsaD1hDhvAMMwDgxhnzDwziI5wz2vAHDaAgZgHBnGCDsAIi4bMYQMgRjAPTL1UVFoq+up7/bV4j4q++l4VlXF/Q8M4tMwgLJjDBrCZHR1o/fPA7NkTev0kf5+ZJjwPDP0AzUDLDMKCOWwAG9k1dJp5YGrl7wd4Yquzx3tUY1/apJVbuP0WKwgzCAvmsAFs4h86feKIoz17qvafaqBhHpiQ6uoHKFX1A+SWU2wgzCAsmiU4NPOq7pJ0UqDxP555VXc6/wINUVEhTZgQ+haQf9/Eiac+W+8110jffFM1aumVV6r+LClpskFGoh+gaQgzCJvBF7TTvJsvltsVfCvJ7UpiWDbQGO+/X/McMFJVoCktrSp3qpo1qxp+PWJE1Z9N9NaSH/0AzUIHYITV4Ava6dfd3bbOAMwMw2gyGDodNfQDNAthBmEX7jlsqmNkAWKWHaONGDodNf5+gB7v0ZD9ZhyqanWmH2Bs4DYTjMHIAsQsu0Yb+YdOnzjSyM/hkDIzm/TQacmeeWDoB2gWljOAESoqLV3y8OoaO+T5f0v6YOpl/OeCyLJ7oUb/8aXg9wj3QpCGsru1ltbg6GJtpmoIM+Yr+up7jfjP9XWWe3V0P9tucQEnidRCja+9VjWqqfr7ZGZWzQHTxINMJNaDo59e9LA2E+IKIwsQkxoy2uhUFmq85hpp6NDw98kxWCTXg7OzHyDCgzADIzCyADEpkqON/EOnIalh88AQROIfYQZGiOTIApqU41i4Rxwx2ihqaK1FdYQZGME/smDsS5vkkIICTThHFtDZL46F6nfSvn3V2kSN7XfCQo1RQ2stqmNoNoxh9wzDDP2OY3atb8RCjVHDenCojtFMMI4dt4EY+h3HIjHiiNFGUeH/BUQK3VrLMirmY2h2NYQZ1IWh33Fs7dqqSezqsmbNqXWwtWMG4DhiV180bg3HN4ZmAw0Qyc6EdDCuhR2BIFIjjhhtVCM7A0ck1oND7CPMAIpcZ0J+i6yFHR10JUYcRVlNE9v5+6KF41YQ88CADsCAItOZkA7GtbCrg67E+kZRVNfEdlLVxHbhWEsJTRthBpD9i8rxn3otKiqqWmRCdd/z75s4sapcYzDiqF7sWKyxIRPbAaeC20zAP/mHfp94G8gdhttAkZqt1Pb+OHb0aYnEkgDXXFO1IGOo21iMOLLt9icT2yFSCDNANXZ1JozEf+q298exq09LpDroGr6+kZ2jgezq08LEdogUwgxwAjs6E9r9n7rtnSz9fVpOvBXk79PyP//T+EATyQ66No44srNVzK6gavdijZFchgRNG31mgAiws4Nx9S+khMoK9dv1qa7+/F312/WpHJVV/UxOqT+O3X1a4qCD7sot+3TJw6s14j/Xa8KiYo34z/W65OHVYenUbWfHcbv7tNjdFw3wI8wAEWDnf+r+L6Tc7ev0QcEoLXr1bj39xhwtevVufVAwSoO2rzu1TpYN6dPSGP/soGtJqjzhqUr9s4N0DHfQtTNs2N1xPBK3P+1ehgSQCDNAxNj1n/r+Q1VBZt6yB+U+9F3wsQ99p3nLHlTu9nWN/0KKQJ+Wledla+zQ6fK0Tg3a72mdqrFDp2vledmNPrad7A4bdrecRKpPy+AL2umDqZfp1dH99NTw3np1dD99MPUyggzCxpg+M3PnztWcOXPk8XjUq1cvPfPMM+rbt2/0KsTU5WiEwRe006+7pmnbkjf1467datmhvbrd8Cs1a9H4j2LbVi00c9Xzkk7+7SRBVa0bM1c9r50PT2jU8SvS3arPT3Z9y530un8Ggn1d++vtc7PUd/dWtT38D+0//Qx92L6HrIRm+uQU+m2c+F7h7Ndi9yg1u1tOItmnhYntYCcjwszixYs1efJkFRQUKCsrS08++aRyc3O1fft2tW3bNvIVsmtUB+Lfa6+p2YQJ6lH9Z2faqf3s9N29Vc1OaJGpLkFSxqHvlL57q3Rewz8vH7bvoY6tU+U+9F3IptxKVbWg7GzfQ41pP6keCCoTmml9hwtPKhOOYet2dKK1O2zY3XLiv/059qVNcij0Yo30aYEJjLjN9Pjjj2v06NH63e9+p+7du6ugoECtWrXS/PnzI18ZO2cqra6iomqBvFdfrfqzsZ0r0XB2/dvb9LPTrMwT1nIn2v/Dcc2+fIyk0H1aJGn25WO0/4fjjTt+hIat29Gvxe6wEYmZqenTgngQ8y0zx44d08aNGzV9+vTAvoSEBOXk5KioqCjka8rLy1VeXh547PP5wlOZukZ1OBxVozqGDj21W06RaPmx8zaZ3bfg7Dy+Xf/2dv7s2Dy0uW3rJL3Vtb/G5t2tmaueV0a1ViBP61TNvnyM3uraXyMb+YVtdyCwc/ix3bdpItVywmKNMF3Mt8x89913qqioUHp6etD+9PR0eTyhf9PMz8+Xy+UKbJmZmeGpjN2jOqTItPy89prUqZM0cKB0441Vf3bqFPvHtvv4dv7b2/mzY/PQZv8X9ttd++uS37+g4SMe1B+v+pOGj3hQl/z+Bb3dtf8ptQ7Y3fpgZyfaSAw9jlTLib9Py9DeZyn77DYEGRgl5sNMY0yfPl1erzewlZaWhufAdo/qsHs+D8neL2y7g5idx7f7397Onx2b1x6q/oVt/bNPy9+6/0rrO1woK6HqmKfyhW13ILD7NlYkwgajgYDaxXyYSU1NVbNmzVRWVha0v6ysTG63O+RrnE6nkpOTg7awsHumUrtbfuz8wrY7DNh9fLv/7e3+2fGvPXTWWcH727c/tdl5/8nuL2w7jx+J4ceRCBu0nAA1i/k+M4mJierTp49WrVqlvLw8SVJlZaVWrVql8ePHR7Yy/ub8PXtCf6k6HFXPN3amUrtbfuxc0M/uxQLtPr7d//Z2/+xItq89ZHe/CruOH6nhxww9BqIn5sOMJE2ePFm33nqrfvazn6lv37568skndeTIEf3ud7+LbEX8zfnXXVf15VP9SykMzfm2//Zu5xe23WHA7uPb/W9v989O9fexae0hyf4vbDuOz/BjIP7F/G0mSRo2bJgeffRRzZgxQ71791ZxcbFWrlx5UqfgiLCzOd/uNWrs/MK2OwzYffxIrA9k860g1Izhx0B8c1hWqDbv+OLz+eRyueT1esPXf8au4cH+Tq5S6N/eT+VLr6KiauRPXbc6Skoafi52HjsSx5fs/bevjtmjo8bOla0BhF99v78JM7Eo1FwnmZlVtyFO9cvUzi9su8NAJMKGnf/2AIAGIcxUY1yYkSI/MVw4w5KdYSASYYOWEwCICYSZaowMM3ZjBmAAQIwjzFRDmAEAwDz1/f42YjQTAABATQgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjRTXMdOrUSQ6HI2h76KGHgsp8+umnGjBggJKSkpSZmalHHnkkSrUFAACxqHm0K/DnP/9Zo0ePDjxu3bp14O8+n0+DBg1STk6OCgoK9Nlnn+m2225TSkqKxowZE43qAgCAGBP1MNO6dWu53e6Qz7388ss6duyY5s+fr8TERPXo0UPFxcV6/PHHaw0z5eXlKi8vDzz2+XxhrzcAAIgNUe8z89BDD6lNmza66KKLNGfOHP3000+B54qKivTLX/5SiYmJgX25ubnavn27/vGPf9R4zPz8fLlcrsCWmZlp6zkAAIDoiWqY+eMf/6hFixZpzZo1uuOOO/Tggw/qrrvuCjzv8XiUnp4e9Br/Y4/HU+Nxp0+fLq/XG9hKS0vtOQEAABB1Yb/NNG3aND388MO1lvniiy/UrVs3TZ48ObDvwgsvVGJiou644w7l5+fL6XQ2ug5Op/OUXg8AAMwR9jAzZcoUjRw5stYyXbp0Cbk/KytLP/30k7755ht17dpVbrdbZWVlQWX8j2vqZwMAAJqWsIeZtLQ0paWlNeq1xcXFSkhIUNu2bSVJ2dnZuueee3T8+HG1aNFCklRYWKiuXbvqjDPOCFudAQCAuaLWZ6aoqEhPPvmkPvnkE3399dd6+eWXNWnSJN18882BoHLjjTcqMTFRo0aN0tatW7V48WI99dRTQbenAABA0xa1odlOp1OLFi3SrFmzVF5ers6dO2vSpElBQcXlcuntt9/WuHHj1KdPH6WmpmrGjBnMMQMAAAIclmVZ0a6E3Xw+n1wul7xer5KTk6NdHQAAUA/1/f6O+jwzAAAAp4IwAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGsy3MPPDAA+rfv79atWqllJSUkGV27dqlIUOGqFWrVmrbtq3+9Kc/6aeffgoqs3btWl188cVyOp0655xztHDhQruqDAAADGRbmDl27Jiuv/56jR07NuTzFRUVGjJkiI4dO6Z169bpxRdf1MKFCzVjxoxAmZKSEg0ZMkQDBw5UcXGxJk6cqNtvv11vvfWWXdUGAACGcViWZdn5BgsXLtTEiRN18ODBoP3/93//p9/85jfau3ev0tPTJUkFBQWaOnWqvv32WyUmJmrq1Kl68803tWXLlsDrhg8froMHD2rlypU1vmd5ebnKy8sDj30+nzIzM+X1epWcnBzeEwQAALbw+XxyuVx1fn9Hrc9MUVGRevbsGQgykpSbmyufz6etW7cGyuTk5AS9Ljc3V0VFRbUeOz8/Xy6XK7BlZmaG/wQAAEBMiFqY8Xg8QUFGUuCxx+OptYzP59OPP/5Y47GnT58ur9cb2EpLS8NcewAAECsaFGamTZsmh8NR67Zt2za76lpvTqdTycnJQRsAAIhPzRtSeMqUKRo5cmStZbp06VKvY7ndbn344YdB+8rKygLP+f/076teJjk5WS1btqxnrQEAQDxrUJhJS0tTWlpaWN44OztbDzzwgPbv36+2bdtKkgoLC5WcnKzu3bsHyqxYsSLodYWFhcrOzg5LHQAAgPls6zOza9cuFRcXa9euXaqoqFBxcbGKi4t1+PBhSdKgQYPUvXt33XLLLfrkk0/01ltv6d5779W4cePkdDolSb///e/19ddf66677tK2bdv0l7/8RUuWLNGkSZPsqjYAADCMbUOzR44cqRdffPGk/WvWrNGll14qSdq5c6fGjh2rtWvX6rTTTtOtt96qhx56SM2b/6vBaO3atZo0aZI+//xztW/fXvfdd1+dt7pOVN+hXQAAIHbU9/vb9nlmYgFhBgAA88T8PDMAAADhQJgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKPZFmYeeOAB9e/fX61atVJKSkrIMg6H46Rt0aJFQWXWrl2riy++WE6nU+ecc44WLlxoV5UBAICBbAszx44d0/XXX6+xY8fWWm7BggXat29fYMvLyws8V1JSoiFDhmjgwIEqLi7WxIkTdfvtt+utt96yq9oAAMAwze068OzZsyWpzpaUlJQUud3ukM8VFBSoc+fOeuyxxyRJ559/vj744AM98cQTys3NDWt9AQCAmaLeZ2bcuHFKTU1V3759NX/+fFmWFXiuqKhIOTk5QeVzc3NVVFRU6zHLy8vl8/mCNgAAEJ9sa5mpjz//+c+67LLL1KpVK7399tv693//dx0+fFh//OMfJUkej0fp6elBr0lPT5fP59OPP/6oli1bhjxufn5+oGUIAADEtwa1zEybNi1kp93q27Zt2+p9vPvuu0+/+MUvdNFFF2nq1Km66667NGfOnAafxImmT58ur9cb2EpLS0/5mAAAIDY1qGVmypQpGjlyZK1lunTp0ujKZGVl6f7771d5ebmcTqfcbrfKysqCypSVlSk5ObnGVhlJcjqdcjqdja4HAAAwR4PCTFpamtLS0uyqi4qLi3XGGWcEgkh2drZWrFgRVKawsFDZ2dm21QEAAJjFtj4zu3bt0oEDB7Rr1y5VVFSouLhYknTOOefo9NNP1xtvvKGysjL169dPSUlJKiws1IMPPqg777wzcIzf//73evbZZ3XXXXfptttu0+rVq7VkyRK9+eabdlUbAAAYxmFVHz4URiNHjtSLL7540v41a9bo0ksv1cqVKzV9+nTt2LFDlmXpnHPO0dixYzV69GglJPyrK8/atWs1adIkff7552rfvr3uu+++Om91ncjn88nlcsnr9So5OflUTw0AAERAfb+/bQszsYQwAwCAeer7/R31eWYAAABOBWEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxmW5j55ptvNGrUKHXu3FktW7bU2WefrZkzZ+rYsWNB5T799FMNGDBASUlJyszM1COPPHLSsZYuXapu3bopKSlJPXv21IoVK+yqNgAAMIxtYWbbtm2qrKzUc889p61bt+qJJ55QQUGB7r777kAZn8+nQYMGqWPHjtq4caPmzJmjWbNm6fnnnw+UWbdunUaMGKFRo0Zp8+bNysvLU15enrZs2WJX1QEAgEEclmVZkXqzOXPmaN68efr6668lSfPmzdM999wjj8ejxMRESdK0adO0bNkybdu2TZI0bNgwHTlyRMuXLw8cp1+/furdu7cKCgrq9b4+n08ul0ter1fJyclhPisAAGCH+n5/R7TPjNfr1Zlnnhl4XFRUpF/+8peBICNJubm52r59u/7xj38EyuTk5AQdJzc3V0VFRTW+T3l5uXw+X9AGAADiU8TCzI4dO/TMM8/ojjvuCOzzeDxKT08PKud/7PF4ai3jfz6U/Px8uVyuwJaZmRmu0wAAADGmwWFm2rRpcjgctW7+W0R+e/bs0eDBg3X99ddr9OjRYat8TaZPny6v1xvYSktLbX9PAAAQHc0b+oIpU6Zo5MiRtZbp0qVL4O979+7VwIED1b9//6COvZLkdrtVVlYWtM//2O1211rG/3woTqdTTqezznMBAADma3CYSUtLU1paWr3K7tmzRwMHDlSfPn20YMECJSQENwRlZ2frnnvu0fHjx9WiRQtJUmFhobp27aozzjgjUGbVqlWaOHFi4HWFhYXKzs5uaNUBAEAcsq3PzJ49e3TppZeqQ4cOevTRR/Xtt9/K4/EE9XW58cYblZiYqFGjRmnr1q1avHixnnrqKU2ePDlQZsKECVq5cqUee+wxbdu2TbNmzdLHH3+s8ePH21V1AABgkAa3zNRXYWGhduzYoR07dqh9+/ZBz/lHg7tcLr399tsaN26c+vTpo9TUVM2YMUNjxowJlO3fv79eeeUV3Xvvvbr77rt17rnnatmyZbrgggvsqjoAADBIROeZiRbmmQEAwDwxOc8MAABAuBFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBotoWZb775RqNGjVLnzp3VsmVLnX322Zo5c6aOHTsWVMbhcJy0rV+/PuhYS5cuVbdu3ZSUlKSePXtqxYoVdlUbAAAYprldB962bZsqKyv13HPP6ZxzztGWLVs0evRoHTlyRI8++mhQ2XfeeUc9evQIPG7Tpk3g7+vWrdOIESOUn5+v3/zmN3rllVeUl5enTZs26YILLrCr+gAAwBAOy7KsSL3ZnDlzNG/ePH399deSqlpmOnfurM2bN6t3794hXzNs2DAdOXJEy5cvD+zr16+fevfurYKCgnq9r8/nk8vlktfrVXJy8imfBwAAsF99v78j2mfG6/XqzDPPPGn/1VdfrbZt2+qSSy7R3/72t6DnioqKlJOTE7QvNzdXRUVFNb5PeXm5fD5f0AYAAOJTxMLMjh079Mwzz+iOO+4I7Dv99NP12GOPaenSpXrzzTd1ySWXKC8vLyjQeDwepaenBx0rPT1dHo+nxvfKz8+Xy+UKbJmZmeE/IQAAEBMaHGamTZsWstNu9W3btm1Br9mzZ48GDx6s66+/XqNHjw7sT01N1eTJk5WVlaWf//zneuihh3TzzTdrzpw5p3RS06dPl9frDWylpaWndDwAABC7GtwBeMqUKRo5cmStZbp06RL4+969ezVw4ED1799fzz//fJ3Hz8rKUmFhYeCx2+1WWVlZUJmysjK53e4aj+F0OuV0Out8LwAAYL4Gh5m0tDSlpaXVq+yePXs0cOBA9enTRwsWLFBCQt0NQcXFxWrXrl3gcXZ2tlatWqWJEycG9hUWFio7O7uhVQcAAHHItqHZe/bs0aWXXqqOHTvq0Ucf1bfffht4zt+q8uKLLyoxMVEXXXSRJOm1117T/Pnz9V//9V+BshMmTNCvfvUrPfbYYxoyZIgWLVqkjz/+uF6tPAAAIP7ZFmYKCwu1Y8cO7dixQ+3btw96rvpo8Pvvv187d+5U8+bN1a1bNy1evFjXXXdd4Pn+/fvrlVde0b333qu7775b5557rpYtW8YcMwAAQFKE55mJFuaZAQDAPDE5zwwAAEC4EWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDTCDAAAMBphBgAAGI0wAwAAjEaYAQAARiPMAAAAoxFmAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGA0wgwAADAaYQYAABiNMAMAAIxGmAEAAEYjzAAAAKMRZgAAgNEIMwAAwGiEGQAAYDRbw8zVV1+tDh06KCkpSe3atdMtt9yivXv3BpX59NNPNWDAACUlJSkzM1OPPPLIScdZunSpunXrpqSkJPXs2VMrVqyws9oAAMAgtoaZgQMHasmSJdq+fbv+93//V1999ZWuu+66wPM+n0+DBg1Sx44dtXHjRs2ZM0ezZs3S888/Hyizbt06jRgxQqNGjdLmzZuVl5envLw8bdmyxc6qAwAAQzgsy7Ii9WZ/+9vflJeXp/LycrVo0ULz5s3TPffcI4/Ho8TEREnStGnTtGzZMm3btk2SNGzYMB05ckTLly8PHKdfv37q3bu3CgoKQr5PeXm5ysvLA4+9Xq86dOig0tJSJScn23iGAAAgXHw+nzIzM3Xw4EG5XK6aC1oR8v3331s33HCD9Ytf/CKw75ZbbrGGDh0aVG716tWWJOvAgQOWZVlWZmam9cQTTwSVmTFjhnXhhRfW+F4zZ860JLGxsbGxsbHFwVZaWlprxmgum02dOlXPPvusfvjhB/Xr1y+ohcXj8ahz585B5dPT0wPPnXHGGfJ4PIF91ct4PJ4a33P69OmaPHly4HFlZaUOHDigNm3ayOFwhOO0JP0rMTaVFp+mdL6ca/xqSufLucavpnK+lmXp0KFDysjIqLVcg8PMtGnT9PDDD9da5osvvlC3bt0kSX/60580atQo7dy5U7Nnz9Zvf/tbLV++PKyh4kROp1NOpzNoX0pKim3vl5ycHNc/TCdqSufLucavpnS+nGv8agrnW+vtpX9qcJiZMmWKRo4cWWuZLl26BP6empqq1NRUnXfeeTr//POVmZmp9evXKzs7W263W2VlZUGv9T92u92BP0OV8T8PAACatgaHmbS0NKWlpTXqzSorKyUp0Dk3Oztb99xzj44fP64WLVpIkgoLC9W1a1edccYZgTKrVq3SxIkTA8cpLCxUdnZ2o+oAAADii21Dszds2KBnn31WxcXF2rlzp1avXq0RI0bo7LPPDgSRG2+8UYmJiRo1apS2bt2qxYsX66mnngrq7zJhwgStXLlSjz32mLZt26ZZs2bp448/1vjx4+2qer05nU7NnDnzpFta8aopnS/nGr+a0vlyrvGrqZ1vXWwbmv3ZZ59pwoQJ+uSTT3TkyBG1a9dOgwcP1r333quzzjorUO7TTz/VuHHj9NFHHyk1NVV/+MMfNHXq1KBjLV26VPfee6+++eYbnXvuuXrkkUd05ZVX2lFtAABgmIjOMwMAABBurM0EAACMRpgBAABGI8wAAACjEWYAAIDRCDN1mDt3rjp16qSkpCRlZWXpww8/rLX80qVL1a1bNyUlJalnz55asWJFhGp6avLz8/Xzn/9crVu3Vtu2bZWXl6ft27fX+pqFCxfK4XAEbUlJSRGqcePNmjXrpHr7Z6yuianXtVOnTiedq8Ph0Lhx40KWN+2avvfee7rqqquUkZEhh8OhZcuWBT1vWZZmzJihdu3aqWXLlsrJydGXX35Z53Eb+rmPhNrO9fjx45o6dap69uyp0047TRkZGfrtb3+rvXv31nrMxnwWIqGu6zpy5MiT6j148OA6jxuL11Wq+3xDfYYdDofmzJlT4zFj9drahTBTi8WLF2vy5MmaOXOmNm3apF69eik3N1f79+8PWX7dunUaMWKERo0apc2bNysvL095eXnasmVLhGvecO+++67GjRun9evXq7CwUMePH9egQYN05MiRWl+XnJysffv2BbadO3dGqManpkePHkH1/uCDD2osa/J1/eijj4LOs7CwUJJ0/fXX1/gak67pkSNH1KtXL82dOzfk84888oiefvppFRQUaMOGDTrttNOUm5uro0eP1njMhn7uI6W2c/3hhx+0adMm3Xfffdq0aZNee+01bd++XVdffXWdx23IZyFS6rqukjR48OCger/66qu1HjNWr6tU9/lWP899+/Zp/vz5cjgcuvbaa2s9bixeW9vUd9Xrpqhv377WuHHjAo8rKiqsjIwMKz8/P2T5G264wRoyZEjQvqysLOuOO+6wtZ522L9/vyXJevfdd2sss2DBAsvlckWuUmEyc+ZMq1evXvUuH0/XdcKECdbZZ59tVVZWhnze1GtqWZYlyXr99dcDjysrKy23223NmTMnsO/gwYOW0+m0Xn311RqP09DPfTSceK6hfPjhh5Yka+fOnTWWaehnIRpCneutt95qDR06tEHHMeG6Wlb9ru3QoUOtyy67rNYyJlzbcKJlpgbHjh3Txo0blZOTE9iXkJCgnJwcFRUVhXxNUVFRUHlJys3NrbF8LPN6vZKkM888s9Zyhw8fVseOHZWZmamhQ4dq69atkajeKfvyyy+VkZGhLl266KabbtKuXbtqLBsv1/XYsWN66aWXdNttt9W60Kup1/REJSUl8ng8QdfO5XIpKyurxmvXmM99rPJ6vXI4HHUustuQz0IsWbt2rdq2bauuXbtq7Nix+v7772ssG0/XtaysTG+++aZGjRpVZ1lTr21jEGZq8N1336miokLp6elB+9PT0+XxeEK+xuPxNKh8rKqsrNTEiRP1i1/8QhdccEGN5bp27ar58+frr3/9q1566SVVVlaqf//+2r17dwRr23BZWVlauHChVq5cqXnz5qmkpEQDBgzQoUOHQpaPl+u6bNkyHTx4sNaFYk29pqH4r09Drl1jPvex6OjRo5o6dapGjBhR64rKDf0sxIrBgwfrv//7v7Vq1So9/PDDevfdd3XFFVeooqIiZPl4ua6S9OKLL6p169a65pprai1n6rVtrAYvNIn4N27cOG3ZsqXO+6vZ2dlBC372799f559/vp577jndf//9dlez0a644orA3y+88EJlZWWpY8eOWrJkSb1+2zHVCy+8oCuuuEIZGRk1ljH1muJfjh8/rhtuuEGWZWnevHm1ljX1szB8+PDA33v27KkLL7xQZ599ttauXavLL788ijWz3/z583XTTTfV2THf1GvbWLTM1CA1NVXNmjVTWVlZ0P6ysjK53e6Qr3G73Q0qH4vGjx+v5cuXa82aNWrfvn2DXtuiRQtddNFF2rFjh021s0dKSorOO++8GusdD9d1586deuedd3T77bc36HWmXlNJgevTkGvXmM99LPEHmZ07d6qwsLDWVplQ6vosxKouXbooNTW1xnqbfl393n//fW3fvr3Bn2PJ3GtbX4SZGiQmJqpPnz5atWpVYF9lZaVWrVoV9JtrddnZ2UHlJamwsLDG8rHEsiyNHz9er7/+ulavXq3OnTs3+BgVFRX67LPP1K5dOxtqaJ/Dhw/rq6++qrHeJl9XvwULFqht27YaMmRIg15n6jWVpM6dO8vtdgddO5/Ppw0bNtR47RrzuY8V/iDz5Zdf6p133lGbNm0afIy6Pguxavfu3fr+++9rrLfJ17W6F154QX369FGvXr0a/FpTr229RbsHcixbtGiR5XQ6rYULF1qff/65NWbMGCslJcXyeDyWZVnWLbfcYk2bNi1Q/u9//7vVvHlz69FHH7W++OILa+bMmVaLFi2szz77LFqnUG9jx461XC6XtXbtWmvfvn2B7YcffgiUOfF8Z8+ebb311lvWV199ZW3cuNEaPny4lZSUZG3dujUap1BvU6ZMsdauXWuVlJRYf//7362cnBwrNTXV2r9/v2VZ8XVdLatq1EaHDh2sqVOnnvSc6df00KFD1ubNm63NmzdbkqzHH3/c2rx5c2AEz0MPPWSlpKRYf/3rX61PP/3UGjp0qNW5c2frxx9/DBzjsssus5555pnA47o+99FS27keO3bMuvrqq6327dtbxcXFQZ/h8vLywDFOPNe6PgvRUtu5Hjp0yLrzzjutoqIiq6SkxHrnnXesiy++2Dr33HOto0ePBo5hynW1rLp/ji3Lsrxer9WqVStr3rx5IY9hyrW1C2GmDs8884zVoUMHKzEx0erbt6+1fv36wHO/+tWvrFtvvTWo/JIlS6zzzjvPSkxMtHr06GG9+eabEa5x40gKuS1YsCBQ5sTznThxYuDfJj093bryyiutTZs2Rb7yDTRs2DCrXbt2VmJionXWWWdZw4YNs3bs2BF4Pp6uq2VZ1ltvvWVJsrZv337Sc6Zf0zVr1oT8ufWfU2VlpXXfffdZ6enpltPptC6//PKT/h06duxozZw5M2hfbZ/7aKntXEtKSmr8DK9ZsyZwjBPPta7PQrTUdq4//PCDNWjQICstLc1q0aKF1bFjR2v06NEnhRJTrqtl1f1zbFmW9dxzz1ktW7a0Dh48GPIYplxbuzgsy7JsbfoBAACwEX1mAACA0QgzAADAaIQZAABgNMIMAAAwGmEGAAAYjTADAACMRpgBAABGI8wAAACjEWYAAIDRCDMAAMBohBkAAGC0/weXpb5ByczQxAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(weights, prn=True):\n",
    "    preds = f(time, weights)\n",
    "    loss = mse(preds, speeds)\n",
    "    loss.backward()\n",
    "    weights.data -= lr * weights.grad.data\n",
    "    weights.grad = None\n",
    "    if prn: print(loss.item())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041.55859375\n",
      "778.0196533203125\n",
      "728.1363525390625\n",
      "718.6832885742188\n",
      "716.8809814453125\n",
      "716.5262451171875\n",
      "716.4456176757812\n",
      "716.4166870117188\n",
      "716.3975830078125\n",
      "716.3804931640625\n"
     ]
    }
   ],
   "source": [
    "for i in range(10): one_epoch(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is going down as expected! But what we don't see here is that we completely changed the shape of our function, the weights helped us carve the function to find the best quadratic function possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we reset the weights, to start the process from scratch (just for visualization)\n",
    "weights = torch.randn(3).requires_grad_()\n",
    "\n",
    "_,axs = plt.subplots(1,4,figsize=(12,3))\n",
    "for ax in axs: show_preds(one_epoch(weights, False), ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step7: stop\n",
    "# In practice we would need to look at the training loss and the metric\n",
    "# to see if training loss keeps decreasing and metric keep improving, we can continue,\n",
    "# otherwise we might be overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying our Simple SGD to MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap here are the steps for SGD, first we initialize the weights, then:\n",
    "1. we do a forward pass, we pass our data through the layers weights\n",
    "2. we calculate the loss\n",
    "3. we compute the gradients\n",
    "4. we update the weights with the gradients * learning rate\n",
    "5. we repeat until our metric get worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([1]))"
      ]
     },
     "execution_count": 1164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first reshape the tensors into tensors of pixels instead of 2d pixels\n",
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([1]))"
      ]
     },
     "execution_count": 1166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do the same for our validation set\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))\n",
    "x,y = valid_dset[0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Initialize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 1])"
      ]
     },
     "execution_count": 1168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(size, std=1.0):\n",
    "    return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "weights = init_weights((28*28, 1))\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), torch.Size([1]))"
      ]
     },
     "execution_count": 1299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The weights are not flexible enough, we also need a bias term, remember y=ax+c (or y=wx+b)\n",
    "def init_weights(size, std=1.0):\n",
    "    w = (torch.randn(size)*std).requires_grad_()\n",
    "    b = torch.randn(1).requires_grad_()\n",
    "    return w, b\n",
    "weights = init_weights((28*28, 1))\n",
    "# (our w here is actually our layers but it's ok)\n",
    "w, b = weights\n",
    "w.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([784, 1]), torch.Size([1]))"
      ]
     },
     "execution_count": 1263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, weights[0].shape, weights[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[46.1364],\n",
       "        [36.1163],\n",
       "        [42.8203],\n",
       "        [45.5632],\n",
       "        [42.2849],\n",
       "        [56.4122],\n",
       "        [51.6856],\n",
       "        ...,\n",
       "        [39.6319],\n",
       "        [25.2801],\n",
       "        [34.4028],\n",
       "        [47.6761],\n",
       "        [29.6784],\n",
       "        [34.0573],\n",
       "        [34.2799]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 1309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(inputs, weights):\n",
    "    w, b = weights\n",
    "    res = inputs@w + b\n",
    "    # res = res.sigmoid()\n",
    "    return res\n",
    "\n",
    "forward(train_x, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the forwad pass, what we basically do is multiply each row of pixel by 784 coeffs, these coeffs/weights, are like the judge of if this whole set of pixel (so image) is a 7 or a 3.\n",
    "\n",
    "Of course during the forwad pass their opinion is just garbage, because we haven't done anything than multiplying than random opinion really at this point.\n",
    "\n",
    "Think of what a neural net does (marie kondo), it organize data accross spaces, we moved the input into another space (the only problem is that the space doesn't make any sense right now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Metric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we said earlier our predictions, the judges opinion are garbage right now. What we did really thinking about marie kondo is: moving the data accross a new space, but that new space has not been shaped properly yet lol.\n",
    "\n",
    "Nonethless, we can get an idea on how well our spaces are organized in our model by calculting the accuracy of the logits/preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that we compare to valid_y this time, we compare the filter/judge opinions created to new data valid_x\n",
    "def calc_accuracy_7_or_3(weights, valid_x, valid_y):\n",
    "    # we calculate prediction on new inputs\n",
    "    preds = forward(inputs=valid_x, weights=weights)\n",
    "    # compare these predictions to expected predictions (reality)\n",
    "    corrects = preds.float().mean().item() == valid_y\n",
    "    return corrects.float().mean().item()\n",
    "    \n",
    "\n",
    "calc_accuracy_7_or_3(weights, valid_x, valid_y)\n",
    "# valid_y.shape, calc_accuracy_7_or_3(weights, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 ACCURACY! AS EXPECTED LOL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculating Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it's perfectly normal to have 0 accuracy, don't be discouraged, after all we haven't done anything that multiplying the pixels by random number. \n",
    "\n",
    "So what should we do now? How to predict a 7 or 3? Well I don't know, the thing is you forgot that we are not doing programming. We are doing machine learning, we are training the model to accomplish the task, we are not telling the model HOW to do the task.\n",
    "\n",
    "So, how do we ask the model to learn? We need to give it a target to reach first, we need to tell it a cost function to minimize.\n",
    "\n",
    "How do we calculate the loss? The distance to our target? Why not just use accuracy? Well let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6652, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 1358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a loss is essentially a distance between vectors\n",
    "def calc_loss(preds, targets):\n",
    "    # dist =  (preds - targets).abs().float()\n",
    "    preds = preds.sigmoid()\n",
    "    dist = torch.where(targets==1, 1-preds, preds)\n",
    "    return dist.mean()\n",
    "\n",
    "# we are doing almost the same as accuracy, but we are not using the equal sign, because the equal sign is not differentiable\n",
    "# it doesn't give us a continuous value, it only give us 0 (False) or 1 (True)\n",
    "\n",
    "# note we are using trainig dataset    \n",
    "preds = forward(inputs=train_x, weights=weights)\n",
    "loss = calc_loss(preds, tensor([1,0,1]))\n",
    "loss\n",
    "# loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Computing Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Update Gradients with Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "\n",
    "def update_weights(weights, lr):\n",
    "    with torch.no_grad():\n",
    "        w,b = weights\n",
    "        w.sub_(w.grad * lr)\n",
    "        w.grad.zero_() \n",
    "        b.sub_(b.grad * lr)\n",
    "        b.grad.zero_() \n",
    "\n",
    "\n",
    "update_weights(weights, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Monitor Metric in comparison to Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.3333, grad_fn=<MeanBackward0>), 0.0)"
      ]
     },
     "execution_count": 1333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, calc_accuracy_7_or_3(weights=weights, valid_x=valid_x, valid_y=valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Rinse and Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n",
      "epoch: 0 | loss: 6.3143205642700195 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 1 | loss: 5.487278461456299 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 2 | loss: 5.149522304534912 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 3 | loss: 4.961963653564453 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 4 | loss: 4.835623741149902 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 5 | loss: 4.733791828155518 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 6 | loss: 4.643887996673584 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 7 | loss: 4.563039302825928 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 8 | loss: 4.4902777671813965 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 9 | loss: 4.423573970794678 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 10 | loss: 4.362096786499023 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 11 | loss: 4.304668426513672 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 12 | loss: 4.250493049621582 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 13 | loss: 4.199545860290527 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 14 | loss: 4.151407241821289 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 15 | loss: 4.105076789855957 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 16 | loss: 4.060523509979248 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 17 | loss: 4.017495155334473 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 18 | loss: 3.975809097290039 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 19 | loss: 3.935135841369629 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 20 | loss: 3.895449161529541 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 21 | loss: 3.856858491897583 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 22 | loss: 3.8194162845611572 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 23 | loss: 3.7830607891082764 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 24 | loss: 3.747692108154297 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 25 | loss: 3.7133781909942627 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 26 | loss: 3.6800825595855713 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 27 | loss: 3.647751569747925 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 28 | loss: 3.6163058280944824 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 29 | loss: 3.5855700969696045 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 30 | loss: 3.5555756092071533 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 31 | loss: 3.5265207290649414 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 32 | loss: 3.4983410835266113 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 33 | loss: 3.470700979232788 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 34 | loss: 3.4436049461364746 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 35 | loss: 3.4171805381774902 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 36 | loss: 3.3914265632629395 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 37 | loss: 3.3663177490234375 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 38 | loss: 3.3418264389038086 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 39 | loss: 3.3181161880493164 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 40 | loss: 3.294955253601074 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 41 | loss: 3.2723424434661865 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 42 | loss: 3.250225067138672 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 43 | loss: 3.2284929752349854 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 44 | loss: 3.2072627544403076 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 45 | loss: 3.1864781379699707 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 46 | loss: 3.1659932136535645 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 47 | loss: 3.1459033489227295 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 48 | loss: 3.126142740249634 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 49 | loss: 3.106815814971924 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 50 | loss: 3.0879130363464355 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 51 | loss: 3.0694572925567627 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 52 | loss: 3.051384449005127 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 53 | loss: 3.0336172580718994 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 54 | loss: 3.0161001682281494 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 55 | loss: 2.9988949298858643 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 56 | loss: 2.982024908065796 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 57 | loss: 2.9654273986816406 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 58 | loss: 2.9491236209869385 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 59 | loss: 2.9330201148986816 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 60 | loss: 2.9172301292419434 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 61 | loss: 2.9017226696014404 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 62 | loss: 2.8864219188690186 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 63 | loss: 2.8713369369506836 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 64 | loss: 2.8564913272857666 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 65 | loss: 2.841857433319092 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 66 | loss: 2.8274648189544678 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 67 | loss: 2.8132848739624023 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 68 | loss: 2.7992894649505615 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 69 | loss: 2.7855639457702637 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 70 | loss: 2.772099494934082 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 71 | loss: 2.7588822841644287 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 72 | loss: 2.7459516525268555 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 73 | loss: 2.7332472801208496 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 74 | loss: 2.7206921577453613 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 75 | loss: 2.708362579345703 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 76 | loss: 2.696272134780884 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 77 | loss: 2.684366464614868 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 78 | loss: 2.6726722717285156 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 79 | loss: 2.6611669063568115 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 80 | loss: 2.6497998237609863 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 81 | loss: 2.6385498046875 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 82 | loss: 2.6274242401123047 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 83 | loss: 2.6164727210998535 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 84 | loss: 2.605710983276367 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 85 | loss: 2.5950746536254883 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 86 | loss: 2.5845935344696045 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 87 | loss: 2.5742874145507812 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 88 | loss: 2.564141273498535 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 89 | loss: 2.5541553497314453 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 90 | loss: 2.5442745685577393 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 91 | loss: 2.5345354080200195 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 92 | loss: 2.524928092956543 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 93 | loss: 2.5154237747192383 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 94 | loss: 2.506011486053467 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 95 | loss: 2.496702194213867 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 96 | loss: 2.487534999847412 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 97 | loss: 2.4784786701202393 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 98 | loss: 2.469517946243286 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n",
      "torch.Size([3, 1])\n",
      "epoch: 99 | loss: 2.460674285888672 | acc: 0.0\n",
      "tensor([[-0.9963],\n",
      "        [ 0.4365],\n",
      "        [-0.2921]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def one_epoch(epoch_idx, weights, lr):\n",
    "    preds = forward(inputs=train_x, weights=weights)\n",
    "    loss = calc_loss(preds, train_y)\n",
    "    loss.backward()\n",
    "    # update_weights(weights, lr)\n",
    "    with torch.no_grad():\n",
    "        w,b = weights\n",
    "        w.sub_(w.grad * lr)\n",
    "        w.grad.zero_() \n",
    "        b.sub_(b.grad * lr)\n",
    "        b.grad.zero_() \n",
    "    acc = calc_accuracy_7_or_3(weights=weights, valid_x=valid_x, valid_y=valid_y)\n",
    "    print(f'epoch: {epoch_idx} | loss: {loss} | acc: {acc}')\n",
    "    print(weights[0][:3])\n",
    "    return weights\n",
    "\n",
    "# _,axs = plt.subplots(1,4,figsize=(12,3))\n",
    "# for ax in axs: show_preds(one_epoch(weights), ax)\n",
    "# plt.tight_layout()\n",
    "lr = 0.1\n",
    "weights = init_weights((28*28, 1))\n",
    "for i in range(100):\n",
    "    one_epoch(i, weights, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Why it doesn't train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, what do you mean by it doesn't train?\n",
    "What should you expect?\n",
    "- the loss to go down\n",
    "- metric to go up\n",
    "\n",
    "Metric will not go up if training loss is not going down, so what is going on with the loss here? How can we have a negative loss?\n",
    "\n",
    "Let's check our loss function and see what we are feeding it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | loss: 6.053243160247803 | acc: 0.4676153063774109\n",
      "epoch: 1 | loss: 5.6034955978393555 | acc: 0.47448480129241943\n",
      "epoch: 2 | loss: 5.248191833496094 | acc: 0.47939157485961914\n",
      "epoch: 3 | loss: 4.974897861480713 | acc: 0.48822376132011414\n",
      "epoch: 4 | loss: 4.769471168518066 | acc: 0.491167813539505\n",
      "epoch: 5 | loss: 4.618328094482422 | acc: 0.4946025609970093\n",
      "epoch: 6 | loss: 4.504344940185547 | acc: 0.4950932264328003\n",
      "epoch: 7 | loss: 4.415410041809082 | acc: 0.5\n",
      "epoch: 8 | loss: 4.3465986251831055 | acc: 0.49803727865219116\n",
      "epoch: 9 | loss: 4.292709827423096 | acc: 0.5039254426956177\n",
      "epoch: 10 | loss: 4.248377799987793 | acc: 0.5068694949150085\n",
      "epoch: 11 | loss: 4.211176872253418 | acc: 0.5088322162628174\n",
      "epoch: 12 | loss: 4.179232597351074 | acc: 0.5093228816986084\n",
      "epoch: 13 | loss: 4.150620937347412 | acc: 0.5122669339179993\n",
      "epoch: 14 | loss: 4.124207973480225 | acc: 0.5147203207015991\n",
      "epoch: 15 | loss: 4.099379539489746 | acc: 0.5142296552658081\n",
      "epoch: 16 | loss: 4.075660705566406 | acc: 0.5107948780059814\n",
      "epoch: 17 | loss: 4.052694320678711 | acc: 0.5103042125701904\n",
      "epoch: 18 | loss: 4.030340671539307 | acc: 0.5098135471343994\n",
      "epoch: 19 | loss: 4.0087103843688965 | acc: 0.5093228816986084\n",
      "epoch: 20 | loss: 3.987647533416748 | acc: 0.5088322162628174\n",
      "epoch: 21 | loss: 3.967076063156128 | acc: 0.5093228816986084\n",
      "epoch: 22 | loss: 3.946786642074585 | acc: 0.5098135471343994\n",
      "epoch: 23 | loss: 3.9267139434814453 | acc: 0.5073601603507996\n",
      "epoch: 24 | loss: 3.90700101852417 | acc: 0.5078508257865906\n",
      "epoch: 25 | loss: 3.88761043548584 | acc: 0.5083414912223816\n",
      "epoch: 26 | loss: 3.8684990406036377 | acc: 0.5088322162628174\n",
      "epoch: 27 | loss: 3.849708318710327 | acc: 0.5083414912223816\n",
      "epoch: 28 | loss: 3.83113694190979 | acc: 0.5063788294792175\n",
      "epoch: 29 | loss: 3.8127729892730713 | acc: 0.5039254426956177\n",
      "epoch: 30 | loss: 3.7947330474853516 | acc: 0.5044161081314087\n",
      "epoch: 31 | loss: 3.777019739151001 | acc: 0.5029440522193909\n",
      "epoch: 32 | loss: 3.75951886177063 | acc: 0.5039254426956177\n",
      "epoch: 33 | loss: 3.742302179336548 | acc: 0.5039254426956177\n",
      "epoch: 34 | loss: 3.7253384590148926 | acc: 0.5034347176551819\n",
      "epoch: 35 | loss: 3.708597421646118 | acc: 0.5024533867835999\n",
      "epoch: 36 | loss: 3.6920666694641113 | acc: 0.5019627213478088\n",
      "epoch: 37 | loss: 3.675781011581421 | acc: 0.5019627213478088\n",
      "epoch: 38 | loss: 3.6597676277160645 | acc: 0.5024533867835999\n",
      "epoch: 39 | loss: 3.6439552307128906 | acc: 0.5014720559120178\n",
      "epoch: 40 | loss: 3.6283535957336426 | acc: 0.5019627213478088\n",
      "epoch: 41 | loss: 3.6129941940307617 | acc: 0.500981330871582\n",
      "epoch: 42 | loss: 3.597904920578003 | acc: 0.500981330871582\n",
      "epoch: 43 | loss: 3.582984209060669 | acc: 0.49852797389030457\n",
      "epoch: 44 | loss: 3.5682485103607178 | acc: 0.5\n",
      "epoch: 45 | loss: 3.5537357330322266 | acc: 0.5\n",
      "epoch: 46 | loss: 3.5393824577331543 | acc: 0.4990186393260956\n",
      "epoch: 47 | loss: 3.52524471282959 | acc: 0.49803727865219116\n",
      "epoch: 48 | loss: 3.511350393295288 | acc: 0.4990186393260956\n",
      "epoch: 49 | loss: 3.497788190841675 | acc: 0.4990186393260956\n",
      "epoch: 50 | loss: 3.4844777584075928 | acc: 0.49852797389030457\n",
      "epoch: 51 | loss: 3.4713895320892334 | acc: 0.49754661321640015\n",
      "epoch: 52 | loss: 3.458484172821045 | acc: 0.4960745871067047\n",
      "epoch: 53 | loss: 3.445767879486084 | acc: 0.4965652525424957\n",
      "epoch: 54 | loss: 3.4332056045532227 | acc: 0.4965652525424957\n",
      "epoch: 55 | loss: 3.4208571910858154 | acc: 0.49754661321640015\n",
      "epoch: 56 | loss: 3.408686637878418 | acc: 0.49754661321640015\n",
      "epoch: 57 | loss: 3.396714925765991 | acc: 0.49852797389030457\n",
      "epoch: 58 | loss: 3.3849799633026123 | acc: 0.4990186393260956\n",
      "epoch: 59 | loss: 3.373371124267578 | acc: 0.49803727865219116\n",
      "epoch: 60 | loss: 3.361896276473999 | acc: 0.499509334564209\n",
      "epoch: 61 | loss: 3.3505475521087646 | acc: 0.5014720559120178\n",
      "epoch: 62 | loss: 3.339397430419922 | acc: 0.5014720559120178\n",
      "epoch: 63 | loss: 3.328444004058838 | acc: 0.500490665435791\n",
      "epoch: 64 | loss: 3.31764554977417 | acc: 0.4990186393260956\n",
      "epoch: 65 | loss: 3.306966543197632 | acc: 0.49852797389030457\n",
      "epoch: 66 | loss: 3.2963638305664062 | acc: 0.49705594778060913\n",
      "epoch: 67 | loss: 3.2859132289886475 | acc: 0.4965652525424957\n",
      "epoch: 68 | loss: 3.2756009101867676 | acc: 0.4960745871067047\n",
      "epoch: 69 | loss: 3.2653863430023193 | acc: 0.4960745871067047\n",
      "epoch: 70 | loss: 3.255296230316162 | acc: 0.4960745871067047\n",
      "epoch: 71 | loss: 3.2453579902648926 | acc: 0.4946025609970093\n",
      "epoch: 72 | loss: 3.2355408668518066 | acc: 0.4950932264328003\n",
      "epoch: 73 | loss: 3.225853681564331 | acc: 0.4955838918685913\n",
      "epoch: 74 | loss: 3.2163102626800537 | acc: 0.49705594778060913\n",
      "epoch: 75 | loss: 3.206864833831787 | acc: 0.4960745871067047\n",
      "epoch: 76 | loss: 3.1975209712982178 | acc: 0.4960745871067047\n",
      "epoch: 77 | loss: 3.1883022785186768 | acc: 0.4965652525424957\n",
      "epoch: 78 | loss: 3.1792731285095215 | acc: 0.4965652525424957\n",
      "epoch: 79 | loss: 3.1703712940216064 | acc: 0.4960745871067047\n",
      "epoch: 80 | loss: 3.161545515060425 | acc: 0.4960745871067047\n",
      "epoch: 81 | loss: 3.152819871902466 | acc: 0.4955838918685913\n",
      "epoch: 82 | loss: 3.1441993713378906 | acc: 0.49362120032310486\n",
      "epoch: 83 | loss: 3.135668992996216 | acc: 0.49313053488731384\n",
      "epoch: 84 | loss: 3.127236843109131 | acc: 0.49263983964920044\n",
      "epoch: 85 | loss: 3.1189420223236084 | acc: 0.4921491742134094\n",
      "epoch: 86 | loss: 3.1107873916625977 | acc: 0.4921491742134094\n",
      "epoch: 87 | loss: 3.102727174758911 | acc: 0.49263983964920044\n",
      "epoch: 88 | loss: 3.0947792530059814 | acc: 0.49263983964920044\n",
      "epoch: 89 | loss: 3.0869319438934326 | acc: 0.4921491742134094\n",
      "epoch: 90 | loss: 3.0791938304901123 | acc: 0.491658478975296\n",
      "epoch: 91 | loss: 3.0715487003326416 | acc: 0.491658478975296\n",
      "epoch: 92 | loss: 3.063992977142334 | acc: 0.491167813539505\n",
      "epoch: 93 | loss: 3.056548833847046 | acc: 0.490677148103714\n",
      "epoch: 94 | loss: 3.049226760864258 | acc: 0.490677148103714\n",
      "epoch: 95 | loss: 3.0419647693634033 | acc: 0.491167813539505\n",
      "epoch: 96 | loss: 3.034789800643921 | acc: 0.48969578742980957\n",
      "epoch: 97 | loss: 3.027709722518921 | acc: 0.48920509219169617\n",
      "epoch: 98 | loss: 3.020751476287842 | acc: 0.48822376132011414\n",
      "epoch: 99 | loss: 3.013881206512451 | acc: 0.48822376132011414\n",
      "epoch: 100 | loss: 3.007085084915161 | acc: 0.4867517054080963\n",
      "epoch: 101 | loss: 3.000373125076294 | acc: 0.4867517054080963\n",
      "epoch: 102 | loss: 2.993762254714966 | acc: 0.4867517054080963\n",
      "epoch: 103 | loss: 2.987217426300049 | acc: 0.4872424006462097\n",
      "epoch: 104 | loss: 2.980746030807495 | acc: 0.48773306608200073\n",
      "epoch: 105 | loss: 2.97434663772583 | acc: 0.4872424006462097\n",
      "epoch: 106 | loss: 2.967996597290039 | acc: 0.4867517054080963\n",
      "epoch: 107 | loss: 2.9617350101470947 | acc: 0.4862610399723053\n",
      "epoch: 108 | loss: 2.9555482864379883 | acc: 0.4857703745365143\n",
      "epoch: 109 | loss: 2.9494404792785645 | acc: 0.4862610399723053\n",
      "epoch: 110 | loss: 2.9434125423431396 | acc: 0.4862610399723053\n",
      "epoch: 111 | loss: 2.9374334812164307 | acc: 0.4862610399723053\n",
      "epoch: 112 | loss: 2.9315195083618164 | acc: 0.4867517054080963\n",
      "epoch: 113 | loss: 2.925659656524658 | acc: 0.4862610399723053\n",
      "epoch: 114 | loss: 2.9198524951934814 | acc: 0.4862610399723053\n",
      "epoch: 115 | loss: 2.914095163345337 | acc: 0.4872424006462097\n",
      "epoch: 116 | loss: 2.9084012508392334 | acc: 0.48773306608200073\n",
      "epoch: 117 | loss: 2.902754068374634 | acc: 0.48773306608200073\n",
      "epoch: 118 | loss: 2.8971731662750244 | acc: 0.48773306608200073\n",
      "epoch: 119 | loss: 2.8916537761688232 | acc: 0.48773306608200073\n",
      "epoch: 120 | loss: 2.8862130641937256 | acc: 0.48773306608200073\n",
      "epoch: 121 | loss: 2.880819320678711 | acc: 0.48822376132011414\n",
      "epoch: 122 | loss: 2.8754847049713135 | acc: 0.4867517054080963\n",
      "epoch: 123 | loss: 2.8702261447906494 | acc: 0.4867517054080963\n",
      "epoch: 124 | loss: 2.8650293350219727 | acc: 0.4867517054080963\n",
      "epoch: 125 | loss: 2.8598694801330566 | acc: 0.4867517054080963\n",
      "epoch: 126 | loss: 2.8547520637512207 | acc: 0.4872424006462097\n",
      "epoch: 127 | loss: 2.8496978282928467 | acc: 0.48773306608200073\n",
      "epoch: 128 | loss: 2.8446874618530273 | acc: 0.48920509219169617\n",
      "epoch: 129 | loss: 2.839724540710449 | acc: 0.48920509219169617\n",
      "epoch: 130 | loss: 2.8348236083984375 | acc: 0.48871442675590515\n",
      "epoch: 131 | loss: 2.8299615383148193 | acc: 0.48871442675590515\n",
      "epoch: 132 | loss: 2.825153350830078 | acc: 0.48773306608200073\n",
      "epoch: 133 | loss: 2.820404291152954 | acc: 0.4867517054080963\n",
      "epoch: 134 | loss: 2.815702199935913 | acc: 0.48773306608200073\n",
      "epoch: 135 | loss: 2.8110413551330566 | acc: 0.48773306608200073\n",
      "epoch: 136 | loss: 2.8064279556274414 | acc: 0.48773306608200073\n",
      "epoch: 137 | loss: 2.8018674850463867 | acc: 0.4872424006462097\n",
      "epoch: 138 | loss: 2.7973432540893555 | acc: 0.48773306608200073\n",
      "epoch: 139 | loss: 2.792865753173828 | acc: 0.4872424006462097\n",
      "epoch: 140 | loss: 2.7884316444396973 | acc: 0.4867517054080963\n",
      "epoch: 141 | loss: 2.7840230464935303 | acc: 0.4862610399723053\n",
      "epoch: 142 | loss: 2.779658317565918 | acc: 0.4857703745365143\n",
      "epoch: 143 | loss: 2.775334596633911 | acc: 0.48478901386260986\n",
      "epoch: 144 | loss: 2.7710564136505127 | acc: 0.4857703745365143\n",
      "epoch: 145 | loss: 2.7668137550354004 | acc: 0.4852796792984009\n",
      "epoch: 146 | loss: 2.7626049518585205 | acc: 0.48478901386260986\n",
      "epoch: 147 | loss: 2.7584304809570312 | acc: 0.48478901386260986\n",
      "epoch: 148 | loss: 2.754282236099243 | acc: 0.48478901386260986\n",
      "epoch: 149 | loss: 2.75016713142395 | acc: 0.48478901386260986\n",
      "epoch: 150 | loss: 2.7460744380950928 | acc: 0.4852796792984009\n",
      "epoch: 151 | loss: 2.74200701713562 | acc: 0.48429831862449646\n",
      "epoch: 152 | loss: 2.737962007522583 | acc: 0.48429831862449646\n",
      "epoch: 153 | loss: 2.733940362930298 | acc: 0.48478901386260986\n",
      "epoch: 154 | loss: 2.729945421218872 | acc: 0.48429831862449646\n",
      "epoch: 155 | loss: 2.725975751876831 | acc: 0.48478901386260986\n",
      "epoch: 156 | loss: 2.7220423221588135 | acc: 0.48478901386260986\n",
      "epoch: 157 | loss: 2.7181406021118164 | acc: 0.48429831862449646\n",
      "epoch: 158 | loss: 2.7142562866210938 | acc: 0.48429831862449646\n",
      "epoch: 159 | loss: 2.7104005813598633 | acc: 0.4857703745365143\n",
      "epoch: 160 | loss: 2.706580638885498 | acc: 0.48478901386260986\n",
      "epoch: 161 | loss: 2.7027995586395264 | acc: 0.48478901386260986\n",
      "epoch: 162 | loss: 2.6990535259246826 | acc: 0.48478901386260986\n",
      "epoch: 163 | loss: 2.6953461170196533 | acc: 0.48429831862449646\n",
      "epoch: 164 | loss: 2.6916708946228027 | acc: 0.4852796792984009\n",
      "epoch: 165 | loss: 2.6880054473876953 | acc: 0.48429831862449646\n",
      "epoch: 166 | loss: 2.6843578815460205 | acc: 0.48429831862449646\n",
      "epoch: 167 | loss: 2.680755138397217 | acc: 0.48429831862449646\n",
      "epoch: 168 | loss: 2.677165985107422 | acc: 0.48429831862449646\n",
      "epoch: 169 | loss: 2.6735987663269043 | acc: 0.48478901386260986\n",
      "epoch: 170 | loss: 2.6700501441955566 | acc: 0.48478901386260986\n",
      "epoch: 171 | loss: 2.6665236949920654 | acc: 0.48478901386260986\n",
      "epoch: 172 | loss: 2.663029193878174 | acc: 0.48478901386260986\n",
      "epoch: 173 | loss: 2.6595706939697266 | acc: 0.48429831862449646\n",
      "epoch: 174 | loss: 2.65612530708313 | acc: 0.48478901386260986\n",
      "epoch: 175 | loss: 2.652709722518921 | acc: 0.48478901386260986\n",
      "epoch: 176 | loss: 2.64932918548584 | acc: 0.48478901386260986\n",
      "epoch: 177 | loss: 2.6459720134735107 | acc: 0.48478901386260986\n",
      "epoch: 178 | loss: 2.64263653755188 | acc: 0.48429831862449646\n",
      "epoch: 179 | loss: 2.639331340789795 | acc: 0.48380765318870544\n",
      "epoch: 180 | loss: 2.636054515838623 | acc: 0.48429831862449646\n",
      "epoch: 181 | loss: 2.6328067779541016 | acc: 0.48429831862449646\n",
      "epoch: 182 | loss: 2.629581928253174 | acc: 0.48429831862449646\n",
      "epoch: 183 | loss: 2.6263697147369385 | acc: 0.48429831862449646\n",
      "epoch: 184 | loss: 2.6231822967529297 | acc: 0.48331698775291443\n",
      "epoch: 185 | loss: 2.620023727416992 | acc: 0.48380765318870544\n",
      "epoch: 186 | loss: 2.6168782711029053 | acc: 0.48429831862449646\n",
      "epoch: 187 | loss: 2.613754987716675 | acc: 0.48478901386260986\n",
      "epoch: 188 | loss: 2.6106512546539307 | acc: 0.48380765318870544\n",
      "epoch: 189 | loss: 2.6075620651245117 | acc: 0.48478901386260986\n",
      "epoch: 190 | loss: 2.604485511779785 | acc: 0.48429831862449646\n",
      "epoch: 191 | loss: 2.601430892944336 | acc: 0.48478901386260986\n",
      "epoch: 192 | loss: 2.59838604927063 | acc: 0.48478901386260986\n",
      "epoch: 193 | loss: 2.59535813331604 | acc: 0.48429831862449646\n",
      "epoch: 194 | loss: 2.592353105545044 | acc: 0.48429831862449646\n",
      "epoch: 195 | loss: 2.5893616676330566 | acc: 0.48478901386260986\n",
      "epoch: 196 | loss: 2.586376667022705 | acc: 0.48478901386260986\n",
      "epoch: 197 | loss: 2.5834085941314697 | acc: 0.48478901386260986\n",
      "epoch: 198 | loss: 2.5804638862609863 | acc: 0.48429831862449646\n",
      "epoch: 199 | loss: 2.5775434970855713 | acc: 0.48429831862449646\n",
      "epoch: 200 | loss: 2.5746371746063232 | acc: 0.48429831862449646\n",
      "epoch: 201 | loss: 2.571751356124878 | acc: 0.48380765318870544\n",
      "epoch: 202 | loss: 2.5688836574554443 | acc: 0.48380765318870544\n",
      "epoch: 203 | loss: 2.566026449203491 | acc: 0.48331698775291443\n",
      "epoch: 204 | loss: 2.563194990158081 | acc: 0.48331698775291443\n",
      "epoch: 205 | loss: 2.5603713989257812 | acc: 0.482826292514801\n",
      "epoch: 206 | loss: 2.557556629180908 | acc: 0.482826292514801\n",
      "epoch: 207 | loss: 2.5547685623168945 | acc: 0.482826292514801\n",
      "epoch: 208 | loss: 2.551992177963257 | acc: 0.48233562707901\n",
      "epoch: 209 | loss: 2.5492241382598877 | acc: 0.482826292514801\n",
      "epoch: 210 | loss: 2.5464606285095215 | acc: 0.48233562707901\n",
      "epoch: 211 | loss: 2.5437042713165283 | acc: 0.48233562707901\n",
      "epoch: 212 | loss: 2.540956497192383 | acc: 0.48233562707901\n",
      "epoch: 213 | loss: 2.538228750228882 | acc: 0.48233562707901\n",
      "epoch: 214 | loss: 2.5355305671691895 | acc: 0.48331698775291443\n",
      "epoch: 215 | loss: 2.532850742340088 | acc: 0.48429831862449646\n",
      "epoch: 216 | loss: 2.5301806926727295 | acc: 0.48429831862449646\n",
      "epoch: 217 | loss: 2.5275237560272217 | acc: 0.48429831862449646\n",
      "epoch: 218 | loss: 2.5248804092407227 | acc: 0.48478901386260986\n",
      "epoch: 219 | loss: 2.5222511291503906 | acc: 0.48478901386260986\n",
      "epoch: 220 | loss: 2.5196290016174316 | acc: 0.4852796792984009\n",
      "epoch: 221 | loss: 2.5170176029205322 | acc: 0.48478901386260986\n",
      "epoch: 222 | loss: 2.514416456222534 | acc: 0.48478901386260986\n",
      "epoch: 223 | loss: 2.511824369430542 | acc: 0.48478901386260986\n",
      "epoch: 224 | loss: 2.5092434883117676 | acc: 0.48429831862449646\n",
      "epoch: 225 | loss: 2.506671667098999 | acc: 0.48429831862449646\n",
      "epoch: 226 | loss: 2.504110336303711 | acc: 0.4852796792984009\n",
      "epoch: 227 | loss: 2.5015718936920166 | acc: 0.48478901386260986\n",
      "epoch: 228 | loss: 2.499060869216919 | acc: 0.4852796792984009\n",
      "epoch: 229 | loss: 2.496565103530884 | acc: 0.48478901386260986\n",
      "epoch: 230 | loss: 2.494077682495117 | acc: 0.48429831862449646\n",
      "epoch: 231 | loss: 2.4915997982025146 | acc: 0.48429831862449646\n",
      "epoch: 232 | loss: 2.48913311958313 | acc: 0.48429831862449646\n",
      "epoch: 233 | loss: 2.4866740703582764 | acc: 0.48429831862449646\n",
      "epoch: 234 | loss: 2.484220266342163 | acc: 0.48380765318870544\n",
      "epoch: 235 | loss: 2.481776714324951 | acc: 0.48380765318870544\n",
      "epoch: 236 | loss: 2.479340076446533 | acc: 0.48380765318870544\n",
      "epoch: 237 | loss: 2.4769086837768555 | acc: 0.48380765318870544\n",
      "epoch: 238 | loss: 2.474484443664551 | acc: 0.48380765318870544\n",
      "epoch: 239 | loss: 2.4720659255981445 | acc: 0.48478901386260986\n",
      "epoch: 240 | loss: 2.469655752182007 | acc: 0.48478901386260986\n",
      "epoch: 241 | loss: 2.467257261276245 | acc: 0.48478901386260986\n",
      "epoch: 242 | loss: 2.4648661613464355 | acc: 0.48478901386260986\n",
      "epoch: 243 | loss: 2.462486505508423 | acc: 0.4857703745365143\n",
      "epoch: 244 | loss: 2.460120439529419 | acc: 0.4857703745365143\n",
      "epoch: 245 | loss: 2.4577720165252686 | acc: 0.4857703745365143\n",
      "epoch: 246 | loss: 2.4554355144500732 | acc: 0.4857703745365143\n",
      "epoch: 247 | loss: 2.4531044960021973 | acc: 0.4862610399723053\n",
      "epoch: 248 | loss: 2.450782299041748 | acc: 0.4862610399723053\n",
      "epoch: 249 | loss: 2.4484643936157227 | acc: 0.4862610399723053\n",
      "epoch: 250 | loss: 2.4461541175842285 | acc: 0.4862610399723053\n",
      "epoch: 251 | loss: 2.443849802017212 | acc: 0.4862610399723053\n",
      "epoch: 252 | loss: 2.441553831100464 | acc: 0.4857703745365143\n",
      "epoch: 253 | loss: 2.4392664432525635 | acc: 0.4862610399723053\n",
      "epoch: 254 | loss: 2.436984062194824 | acc: 0.4852796792984009\n",
      "epoch: 255 | loss: 2.4347105026245117 | acc: 0.4852796792984009\n",
      "epoch: 256 | loss: 2.4324381351470947 | acc: 0.4852796792984009\n",
      "epoch: 257 | loss: 2.4301741123199463 | acc: 0.4857703745365143\n",
      "epoch: 258 | loss: 2.427919864654541 | acc: 0.4867517054080963\n",
      "epoch: 259 | loss: 2.425673723220825 | acc: 0.4867517054080963\n",
      "epoch: 260 | loss: 2.4234349727630615 | acc: 0.4867517054080963\n",
      "epoch: 261 | loss: 2.4212088584899902 | acc: 0.4872424006462097\n",
      "epoch: 262 | loss: 2.418987274169922 | acc: 0.4867517054080963\n",
      "epoch: 263 | loss: 2.4167706966400146 | acc: 0.4862610399723053\n",
      "epoch: 264 | loss: 2.414557933807373 | acc: 0.4862610399723053\n",
      "epoch: 265 | loss: 2.412353992462158 | acc: 0.48478901386260986\n",
      "epoch: 266 | loss: 2.410156011581421 | acc: 0.4852796792984009\n",
      "epoch: 267 | loss: 2.4079673290252686 | acc: 0.4852796792984009\n",
      "epoch: 268 | loss: 2.4057819843292236 | acc: 0.4852796792984009\n",
      "epoch: 269 | loss: 2.40360164642334 | acc: 0.4862610399723053\n",
      "epoch: 270 | loss: 2.4014246463775635 | acc: 0.4867517054080963\n",
      "epoch: 271 | loss: 2.399254083633423 | acc: 0.48773306608200073\n",
      "epoch: 272 | loss: 2.397094249725342 | acc: 0.48871442675590515\n",
      "epoch: 273 | loss: 2.3949477672576904 | acc: 0.48871442675590515\n",
      "epoch: 274 | loss: 2.3928067684173584 | acc: 0.48871442675590515\n",
      "epoch: 275 | loss: 2.3906753063201904 | acc: 0.48822376132011414\n",
      "epoch: 276 | loss: 2.388554334640503 | acc: 0.48871442675590515\n",
      "epoch: 277 | loss: 2.3864407539367676 | acc: 0.48822376132011414\n",
      "epoch: 278 | loss: 2.3843331336975098 | acc: 0.48871442675590515\n",
      "epoch: 279 | loss: 2.3822343349456787 | acc: 0.48871442675590515\n",
      "epoch: 280 | loss: 2.380143404006958 | acc: 0.48920509219169617\n",
      "epoch: 281 | loss: 2.378059148788452 | acc: 0.48920509219169617\n",
      "epoch: 282 | loss: 2.3759846687316895 | acc: 0.48920509219169617\n",
      "epoch: 283 | loss: 2.3739187717437744 | acc: 0.4901864528656006\n",
      "epoch: 284 | loss: 2.3718574047088623 | acc: 0.490677148103714\n",
      "epoch: 285 | loss: 2.369802474975586 | acc: 0.4901864528656006\n",
      "epoch: 286 | loss: 2.3677561283111572 | acc: 0.490677148103714\n",
      "epoch: 287 | loss: 2.3657190799713135 | acc: 0.491167813539505\n",
      "epoch: 288 | loss: 2.363687753677368 | acc: 0.491658478975296\n",
      "epoch: 289 | loss: 2.361668586730957 | acc: 0.491658478975296\n",
      "epoch: 290 | loss: 2.3596558570861816 | acc: 0.491167813539505\n",
      "epoch: 291 | loss: 2.357651948928833 | acc: 0.491167813539505\n",
      "epoch: 292 | loss: 2.3556580543518066 | acc: 0.491167813539505\n",
      "epoch: 293 | loss: 2.353668212890625 | acc: 0.491167813539505\n",
      "epoch: 294 | loss: 2.3516852855682373 | acc: 0.491658478975296\n",
      "epoch: 295 | loss: 2.3497087955474854 | acc: 0.491658478975296\n",
      "epoch: 296 | loss: 2.34773325920105 | acc: 0.491658478975296\n",
      "epoch: 297 | loss: 2.3457627296447754 | acc: 0.4921491742134094\n",
      "epoch: 298 | loss: 2.3437938690185547 | acc: 0.4921491742134094\n",
      "epoch: 299 | loss: 2.3418309688568115 | acc: 0.4921491742134094\n",
      "epoch: 300 | loss: 2.339874029159546 | acc: 0.4921491742134094\n",
      "epoch: 301 | loss: 2.337926149368286 | acc: 0.4921491742134094\n",
      "epoch: 302 | loss: 2.3359873294830322 | acc: 0.4921491742134094\n",
      "epoch: 303 | loss: 2.334059000015259 | acc: 0.49263983964920044\n",
      "epoch: 304 | loss: 2.3321359157562256 | acc: 0.49313053488731384\n",
      "epoch: 305 | loss: 2.330219030380249 | acc: 0.49362120032310486\n",
      "epoch: 306 | loss: 2.328305244445801 | acc: 0.49362120032310486\n",
      "epoch: 307 | loss: 2.3263936042785645 | acc: 0.4941118657588959\n",
      "epoch: 308 | loss: 2.3244876861572266 | acc: 0.4941118657588959\n",
      "epoch: 309 | loss: 2.322589159011841 | acc: 0.4941118657588959\n",
      "epoch: 310 | loss: 2.3206944465637207 | acc: 0.4941118657588959\n",
      "epoch: 311 | loss: 2.318803310394287 | acc: 0.4941118657588959\n",
      "epoch: 312 | loss: 2.3169143199920654 | acc: 0.4946025609970093\n",
      "epoch: 313 | loss: 2.315033435821533 | acc: 0.4950932264328003\n",
      "epoch: 314 | loss: 2.3131604194641113 | acc: 0.4950932264328003\n",
      "epoch: 315 | loss: 2.311293601989746 | acc: 0.4950932264328003\n",
      "epoch: 316 | loss: 2.309433937072754 | acc: 0.4946025609970093\n",
      "epoch: 317 | loss: 2.3075790405273438 | acc: 0.4946025609970093\n",
      "epoch: 318 | loss: 2.3057284355163574 | acc: 0.4946025609970093\n",
      "epoch: 319 | loss: 2.303882598876953 | acc: 0.4941118657588959\n",
      "epoch: 320 | loss: 2.302041530609131 | acc: 0.4941118657588959\n",
      "epoch: 321 | loss: 2.30020809173584 | acc: 0.4941118657588959\n",
      "epoch: 322 | loss: 2.2983813285827637 | acc: 0.4941118657588959\n",
      "epoch: 323 | loss: 2.296562433242798 | acc: 0.49362120032310486\n",
      "epoch: 324 | loss: 2.294748067855835 | acc: 0.49362120032310486\n",
      "epoch: 325 | loss: 2.2929396629333496 | acc: 0.49313053488731384\n",
      "epoch: 326 | loss: 2.291135549545288 | acc: 0.49313053488731384\n",
      "epoch: 327 | loss: 2.289337396621704 | acc: 0.49313053488731384\n",
      "epoch: 328 | loss: 2.2875430583953857 | acc: 0.49313053488731384\n",
      "epoch: 329 | loss: 2.285750389099121 | acc: 0.49313053488731384\n",
      "epoch: 330 | loss: 2.2839598655700684 | acc: 0.49313053488731384\n",
      "epoch: 331 | loss: 2.2821710109710693 | acc: 0.49313053488731384\n",
      "epoch: 332 | loss: 2.2803869247436523 | acc: 0.49263983964920044\n",
      "epoch: 333 | loss: 2.2786076068878174 | acc: 0.49263983964920044\n",
      "epoch: 334 | loss: 2.2768332958221436 | acc: 0.49263983964920044\n",
      "epoch: 335 | loss: 2.275062322616577 | acc: 0.4921491742134094\n",
      "epoch: 336 | loss: 2.273292303085327 | acc: 0.4921491742134094\n",
      "epoch: 337 | loss: 2.2715260982513428 | acc: 0.4921491742134094\n",
      "epoch: 338 | loss: 2.2697629928588867 | acc: 0.491658478975296\n",
      "epoch: 339 | loss: 2.268005847930908 | acc: 0.49313053488731384\n",
      "epoch: 340 | loss: 2.266251564025879 | acc: 0.4921491742134094\n",
      "epoch: 341 | loss: 2.2645046710968018 | acc: 0.49263983964920044\n",
      "epoch: 342 | loss: 2.2627694606781006 | acc: 0.49263983964920044\n",
      "epoch: 343 | loss: 2.2610411643981934 | acc: 0.49263983964920044\n",
      "epoch: 344 | loss: 2.259317636489868 | acc: 0.4921491742134094\n",
      "epoch: 345 | loss: 2.257603168487549 | acc: 0.4921491742134094\n",
      "epoch: 346 | loss: 2.2558934688568115 | acc: 0.4921491742134094\n",
      "epoch: 347 | loss: 2.2541873455047607 | acc: 0.4921491742134094\n",
      "epoch: 348 | loss: 2.2524850368499756 | acc: 0.4921491742134094\n",
      "epoch: 349 | loss: 2.250784158706665 | acc: 0.491658478975296\n",
      "epoch: 350 | loss: 2.2490851879119873 | acc: 0.491658478975296\n",
      "epoch: 351 | loss: 2.2473881244659424 | acc: 0.491658478975296\n",
      "epoch: 352 | loss: 2.245694875717163 | acc: 0.491658478975296\n",
      "epoch: 353 | loss: 2.2440054416656494 | acc: 0.491658478975296\n",
      "epoch: 354 | loss: 2.2423202991485596 | acc: 0.491167813539505\n",
      "epoch: 355 | loss: 2.2406365871429443 | acc: 0.491658478975296\n",
      "epoch: 356 | loss: 2.238954782485962 | acc: 0.49263983964920044\n",
      "epoch: 357 | loss: 2.237274169921875 | acc: 0.49263983964920044\n",
      "epoch: 358 | loss: 2.235595464706421 | acc: 0.49263983964920044\n",
      "epoch: 359 | loss: 2.233919858932495 | acc: 0.49263983964920044\n",
      "epoch: 360 | loss: 2.2322471141815186 | acc: 0.49263983964920044\n",
      "epoch: 361 | loss: 2.230576753616333 | acc: 0.49263983964920044\n",
      "epoch: 362 | loss: 2.2289085388183594 | acc: 0.49263983964920044\n",
      "epoch: 363 | loss: 2.2272424697875977 | acc: 0.49263983964920044\n",
      "epoch: 364 | loss: 2.2255773544311523 | acc: 0.4921491742134094\n",
      "epoch: 365 | loss: 2.2239155769348145 | acc: 0.4921491742134094\n",
      "epoch: 366 | loss: 2.222256898880005 | acc: 0.4921491742134094\n",
      "epoch: 367 | loss: 2.2206008434295654 | acc: 0.4921491742134094\n",
      "epoch: 368 | loss: 2.2189462184906006 | acc: 0.4921491742134094\n",
      "epoch: 369 | loss: 2.217294216156006 | acc: 0.4921491742134094\n",
      "epoch: 370 | loss: 2.2156460285186768 | acc: 0.4921491742134094\n",
      "epoch: 371 | loss: 2.2140002250671387 | acc: 0.4921491742134094\n",
      "epoch: 372 | loss: 2.2123570442199707 | acc: 0.4921491742134094\n",
      "epoch: 373 | loss: 2.2107183933258057 | acc: 0.491658478975296\n",
      "epoch: 374 | loss: 2.209080457687378 | acc: 0.491658478975296\n",
      "epoch: 375 | loss: 2.207444429397583 | acc: 0.491658478975296\n",
      "epoch: 376 | loss: 2.2058138847351074 | acc: 0.491167813539505\n",
      "epoch: 377 | loss: 2.204190492630005 | acc: 0.491167813539505\n",
      "epoch: 378 | loss: 2.202572822570801 | acc: 0.491167813539505\n",
      "epoch: 379 | loss: 2.200958013534546 | acc: 0.491167813539505\n",
      "epoch: 380 | loss: 2.1993470191955566 | acc: 0.491167813539505\n",
      "epoch: 381 | loss: 2.1977384090423584 | acc: 0.491167813539505\n",
      "epoch: 382 | loss: 2.1961350440979004 | acc: 0.491167813539505\n",
      "epoch: 383 | loss: 2.1945362091064453 | acc: 0.491167813539505\n",
      "epoch: 384 | loss: 2.1929421424865723 | acc: 0.491167813539505\n",
      "epoch: 385 | loss: 2.1913516521453857 | acc: 0.491167813539505\n",
      "epoch: 386 | loss: 2.189762830734253 | acc: 0.491167813539505\n",
      "epoch: 387 | loss: 2.1881794929504395 | acc: 0.491167813539505\n",
      "epoch: 388 | loss: 2.1865994930267334 | acc: 0.491658478975296\n",
      "epoch: 389 | loss: 2.185023069381714 | acc: 0.491167813539505\n",
      "epoch: 390 | loss: 2.1834475994110107 | acc: 0.491658478975296\n",
      "epoch: 391 | loss: 2.1818771362304688 | acc: 0.4921491742134094\n",
      "epoch: 392 | loss: 2.1803107261657715 | acc: 0.49263983964920044\n",
      "epoch: 393 | loss: 2.1787455081939697 | acc: 0.49263983964920044\n",
      "epoch: 394 | loss: 2.177182674407959 | acc: 0.49263983964920044\n",
      "epoch: 395 | loss: 2.1756227016448975 | acc: 0.49263983964920044\n",
      "epoch: 396 | loss: 2.174067735671997 | acc: 0.49263983964920044\n",
      "epoch: 397 | loss: 2.1725172996520996 | acc: 0.49263983964920044\n",
      "epoch: 398 | loss: 2.1709678173065186 | acc: 0.4921491742134094\n",
      "epoch: 399 | loss: 2.169421434402466 | acc: 0.4921491742134094\n",
      "epoch: 400 | loss: 2.167877435684204 | acc: 0.4921491742134094\n",
      "epoch: 401 | loss: 2.1663355827331543 | acc: 0.49313053488731384\n",
      "epoch: 402 | loss: 2.164794683456421 | acc: 0.49313053488731384\n",
      "epoch: 403 | loss: 2.1632559299468994 | acc: 0.49313053488731384\n",
      "epoch: 404 | loss: 2.1617207527160645 | acc: 0.49362120032310486\n",
      "epoch: 405 | loss: 2.160187244415283 | acc: 0.49362120032310486\n",
      "epoch: 406 | loss: 2.1586568355560303 | acc: 0.49313053488731384\n",
      "epoch: 407 | loss: 2.1571295261383057 | acc: 0.49313053488731384\n",
      "epoch: 408 | loss: 2.155606269836426 | acc: 0.49263983964920044\n",
      "epoch: 409 | loss: 2.1540846824645996 | acc: 0.49263983964920044\n",
      "epoch: 410 | loss: 2.152566432952881 | acc: 0.49263983964920044\n",
      "epoch: 411 | loss: 2.151048183441162 | acc: 0.49263983964920044\n",
      "epoch: 412 | loss: 2.1495304107666016 | acc: 0.49263983964920044\n",
      "epoch: 413 | loss: 2.1480135917663574 | acc: 0.49263983964920044\n",
      "epoch: 414 | loss: 2.146501064300537 | acc: 0.49263983964920044\n",
      "epoch: 415 | loss: 2.144990921020508 | acc: 0.49263983964920044\n",
      "epoch: 416 | loss: 2.143482208251953 | acc: 0.49263983964920044\n",
      "epoch: 417 | loss: 2.1419739723205566 | acc: 0.49313053488731384\n",
      "epoch: 418 | loss: 2.140468120574951 | acc: 0.49263983964920044\n",
      "epoch: 419 | loss: 2.138967990875244 | acc: 0.49313053488731384\n",
      "epoch: 420 | loss: 2.1374707221984863 | acc: 0.49263983964920044\n",
      "epoch: 421 | loss: 2.1359760761260986 | acc: 0.49263983964920044\n",
      "epoch: 422 | loss: 2.1344830989837646 | acc: 0.49313053488731384\n",
      "epoch: 423 | loss: 2.1329948902130127 | acc: 0.49313053488731384\n",
      "epoch: 424 | loss: 2.13151216506958 | acc: 0.49313053488731384\n",
      "epoch: 425 | loss: 2.1300318241119385 | acc: 0.49263983964920044\n",
      "epoch: 426 | loss: 2.1285548210144043 | acc: 0.49263983964920044\n",
      "epoch: 427 | loss: 2.1270787715911865 | acc: 0.49263983964920044\n",
      "epoch: 428 | loss: 2.1256051063537598 | acc: 0.49263983964920044\n",
      "epoch: 429 | loss: 2.124133825302124 | acc: 0.49263983964920044\n",
      "epoch: 430 | loss: 2.1226649284362793 | acc: 0.4921491742134094\n",
      "epoch: 431 | loss: 2.1211965084075928 | acc: 0.4921491742134094\n",
      "epoch: 432 | loss: 2.1197290420532227 | acc: 0.49263983964920044\n",
      "epoch: 433 | loss: 2.118265151977539 | acc: 0.49263983964920044\n",
      "epoch: 434 | loss: 2.116802453994751 | acc: 0.49263983964920044\n",
      "epoch: 435 | loss: 2.115342378616333 | acc: 0.49263983964920044\n",
      "epoch: 436 | loss: 2.113884449005127 | acc: 0.49263983964920044\n",
      "epoch: 437 | loss: 2.1124298572540283 | acc: 0.49263983964920044\n",
      "epoch: 438 | loss: 2.110980749130249 | acc: 0.49263983964920044\n",
      "epoch: 439 | loss: 2.1095364093780518 | acc: 0.4921491742134094\n",
      "epoch: 440 | loss: 2.108093500137329 | acc: 0.49263983964920044\n",
      "epoch: 441 | loss: 2.106653928756714 | acc: 0.49263983964920044\n",
      "epoch: 442 | loss: 2.1052188873291016 | acc: 0.49313053488731384\n",
      "epoch: 443 | loss: 2.103787422180176 | acc: 0.49263983964920044\n",
      "epoch: 444 | loss: 2.102358102798462 | acc: 0.49263983964920044\n",
      "epoch: 445 | loss: 2.100931167602539 | acc: 0.4921491742134094\n",
      "epoch: 446 | loss: 2.099506378173828 | acc: 0.4921491742134094\n",
      "epoch: 447 | loss: 2.0980844497680664 | acc: 0.491658478975296\n",
      "epoch: 448 | loss: 2.096665143966675 | acc: 0.491658478975296\n",
      "epoch: 449 | loss: 2.0952467918395996 | acc: 0.491167813539505\n",
      "epoch: 450 | loss: 2.093829393386841 | acc: 0.490677148103714\n",
      "epoch: 451 | loss: 2.0924136638641357 | acc: 0.490677148103714\n",
      "epoch: 452 | loss: 2.0910019874572754 | acc: 0.491167813539505\n",
      "epoch: 453 | loss: 2.0895917415618896 | acc: 0.491167813539505\n",
      "epoch: 454 | loss: 2.0881845951080322 | acc: 0.490677148103714\n",
      "epoch: 455 | loss: 2.086780309677124 | acc: 0.490677148103714\n",
      "epoch: 456 | loss: 2.085381507873535 | acc: 0.491167813539505\n",
      "epoch: 457 | loss: 2.083984136581421 | acc: 0.491167813539505\n",
      "epoch: 458 | loss: 2.082589864730835 | acc: 0.491658478975296\n",
      "epoch: 459 | loss: 2.081200122833252 | acc: 0.4921491742134094\n",
      "epoch: 460 | loss: 2.079812526702881 | acc: 0.4921491742134094\n",
      "epoch: 461 | loss: 2.078425884246826 | acc: 0.4921491742134094\n",
      "epoch: 462 | loss: 2.0770411491394043 | acc: 0.4921491742134094\n",
      "epoch: 463 | loss: 2.0756587982177734 | acc: 0.4921491742134094\n",
      "epoch: 464 | loss: 2.0742785930633545 | acc: 0.4921491742134094\n",
      "epoch: 465 | loss: 2.0729005336761475 | acc: 0.4921491742134094\n",
      "epoch: 466 | loss: 2.071524143218994 | acc: 0.49313053488731384\n",
      "epoch: 467 | loss: 2.0701498985290527 | acc: 0.49313053488731384\n",
      "epoch: 468 | loss: 2.068777561187744 | acc: 0.49313053488731384\n",
      "epoch: 469 | loss: 2.067410469055176 | acc: 0.49313053488731384\n",
      "epoch: 470 | loss: 2.066049098968506 | acc: 0.49313053488731384\n",
      "epoch: 471 | loss: 2.0646908283233643 | acc: 0.49313053488731384\n",
      "epoch: 472 | loss: 2.06333327293396 | acc: 0.49313053488731384\n",
      "epoch: 473 | loss: 2.061976671218872 | acc: 0.49362120032310486\n",
      "epoch: 474 | loss: 2.0606210231781006 | acc: 0.4941118657588959\n",
      "epoch: 475 | loss: 2.059267520904541 | acc: 0.4941118657588959\n",
      "epoch: 476 | loss: 2.0579159259796143 | acc: 0.4941118657588959\n",
      "epoch: 477 | loss: 2.056565761566162 | acc: 0.4946025609970093\n",
      "epoch: 478 | loss: 2.05521821975708 | acc: 0.4946025609970093\n",
      "epoch: 479 | loss: 2.053875207901001 | acc: 0.4946025609970093\n",
      "epoch: 480 | loss: 2.052532911300659 | acc: 0.4946025609970093\n",
      "epoch: 481 | loss: 2.05119252204895 | acc: 0.4941118657588959\n",
      "epoch: 482 | loss: 2.0498545169830322 | acc: 0.4946025609970093\n",
      "epoch: 483 | loss: 2.0485188961029053 | acc: 0.4941118657588959\n",
      "epoch: 484 | loss: 2.0471866130828857 | acc: 0.4941118657588959\n",
      "epoch: 485 | loss: 2.0458555221557617 | acc: 0.4941118657588959\n",
      "epoch: 486 | loss: 2.044525384902954 | acc: 0.4941118657588959\n",
      "epoch: 487 | loss: 2.0431971549987793 | acc: 0.4941118657588959\n",
      "epoch: 488 | loss: 2.0418715476989746 | acc: 0.49313053488731384\n",
      "epoch: 489 | loss: 2.040548086166382 | acc: 0.49313053488731384\n",
      "epoch: 490 | loss: 2.0392282009124756 | acc: 0.49313053488731384\n",
      "epoch: 491 | loss: 2.0379109382629395 | acc: 0.49263983964920044\n",
      "epoch: 492 | loss: 2.0365960597991943 | acc: 0.49313053488731384\n",
      "epoch: 493 | loss: 2.035282850265503 | acc: 0.49313053488731384\n",
      "epoch: 494 | loss: 2.033971071243286 | acc: 0.49362120032310486\n",
      "epoch: 495 | loss: 2.032660722732544 | acc: 0.49362120032310486\n",
      "epoch: 496 | loss: 2.0313518047332764 | acc: 0.4941118657588959\n",
      "epoch: 497 | loss: 2.030043601989746 | acc: 0.4941118657588959\n",
      "epoch: 498 | loss: 2.028738260269165 | acc: 0.4941118657588959\n",
      "epoch: 499 | loss: 2.027435779571533 | acc: 0.4941118657588959\n",
      "epoch: 500 | loss: 2.0261359214782715 | acc: 0.49362120032310486\n",
      "epoch: 501 | loss: 2.0248398780822754 | acc: 0.49313053488731384\n",
      "epoch: 502 | loss: 2.0235464572906494 | acc: 0.49313053488731384\n",
      "epoch: 503 | loss: 2.022256851196289 | acc: 0.49313053488731384\n",
      "epoch: 504 | loss: 2.020968198776245 | acc: 0.49263983964920044\n",
      "epoch: 505 | loss: 2.0196797847747803 | acc: 0.49263983964920044\n",
      "epoch: 506 | loss: 2.0183916091918945 | acc: 0.49263983964920044\n",
      "epoch: 507 | loss: 2.0171058177948 | acc: 0.4921491742134094\n",
      "epoch: 508 | loss: 2.015824556350708 | acc: 0.4921491742134094\n",
      "epoch: 509 | loss: 2.014545440673828 | acc: 0.4921491742134094\n",
      "epoch: 510 | loss: 2.0132672786712646 | acc: 0.49263983964920044\n",
      "epoch: 511 | loss: 2.0119917392730713 | acc: 0.49263983964920044\n",
      "epoch: 512 | loss: 2.0107192993164062 | acc: 0.49263983964920044\n",
      "epoch: 513 | loss: 2.009448289871216 | acc: 0.4921491742134094\n",
      "epoch: 514 | loss: 2.0081775188446045 | acc: 0.4921491742134094\n",
      "epoch: 515 | loss: 2.006908416748047 | acc: 0.491658478975296\n",
      "epoch: 516 | loss: 2.0056400299072266 | acc: 0.491658478975296\n",
      "epoch: 517 | loss: 2.0043728351593018 | acc: 0.4921491742134094\n",
      "epoch: 518 | loss: 2.003106117248535 | acc: 0.491658478975296\n",
      "epoch: 519 | loss: 2.0018422603607178 | acc: 0.491658478975296\n",
      "epoch: 520 | loss: 2.000579595565796 | acc: 0.4921491742134094\n",
      "epoch: 521 | loss: 1.9993181228637695 | acc: 0.4921491742134094\n",
      "epoch: 522 | loss: 1.9980592727661133 | acc: 0.49263983964920044\n",
      "epoch: 523 | loss: 1.9968024492263794 | acc: 0.49263983964920044\n",
      "epoch: 524 | loss: 1.9955470561981201 | acc: 0.49263983964920044\n",
      "epoch: 525 | loss: 1.9942920207977295 | acc: 0.49263983964920044\n",
      "epoch: 526 | loss: 1.9930386543273926 | acc: 0.49263983964920044\n",
      "epoch: 527 | loss: 1.9917874336242676 | acc: 0.49263983964920044\n",
      "epoch: 528 | loss: 1.990538477897644 | acc: 0.49263983964920044\n",
      "epoch: 529 | loss: 1.9892911911010742 | acc: 0.49313053488731384\n",
      "epoch: 530 | loss: 1.9880446195602417 | acc: 0.49313053488731384\n",
      "epoch: 531 | loss: 1.9867998361587524 | acc: 0.4941118657588959\n",
      "epoch: 532 | loss: 1.985556721687317 | acc: 0.4941118657588959\n",
      "epoch: 533 | loss: 1.9843158721923828 | acc: 0.49362120032310486\n",
      "epoch: 534 | loss: 1.983078956604004 | acc: 0.4941118657588959\n",
      "epoch: 535 | loss: 1.9818438291549683 | acc: 0.4941118657588959\n",
      "epoch: 536 | loss: 1.9806108474731445 | acc: 0.4941118657588959\n",
      "epoch: 537 | loss: 1.9793787002563477 | acc: 0.4941118657588959\n",
      "epoch: 538 | loss: 1.978148341178894 | acc: 0.4941118657588959\n",
      "epoch: 539 | loss: 1.97691810131073 | acc: 0.4941118657588959\n",
      "epoch: 540 | loss: 1.9756886959075928 | acc: 0.4941118657588959\n",
      "epoch: 541 | loss: 1.9744606018066406 | acc: 0.4946025609970093\n",
      "epoch: 542 | loss: 1.9732365608215332 | acc: 0.4950932264328003\n",
      "epoch: 543 | loss: 1.9720138311386108 | acc: 0.4950932264328003\n",
      "epoch: 544 | loss: 1.9707938432693481 | acc: 0.4955838918685913\n",
      "epoch: 545 | loss: 1.9695740938186646 | acc: 0.4955838918685913\n",
      "epoch: 546 | loss: 1.9683552980422974 | acc: 0.4955838918685913\n",
      "epoch: 547 | loss: 1.9671415090560913 | acc: 0.4955838918685913\n",
      "epoch: 548 | loss: 1.9659323692321777 | acc: 0.4960745871067047\n",
      "epoch: 549 | loss: 1.964725375175476 | acc: 0.4960745871067047\n",
      "epoch: 550 | loss: 1.96351957321167 | acc: 0.4965652525424957\n",
      "epoch: 551 | loss: 1.9623167514801025 | acc: 0.4955838918685913\n",
      "epoch: 552 | loss: 1.9611151218414307 | acc: 0.4960745871067047\n",
      "epoch: 553 | loss: 1.9599143266677856 | acc: 0.4960745871067047\n",
      "epoch: 554 | loss: 1.9587159156799316 | acc: 0.4960745871067047\n",
      "epoch: 555 | loss: 1.9575220346450806 | acc: 0.4960745871067047\n",
      "epoch: 556 | loss: 1.956329107284546 | acc: 0.4955838918685913\n",
      "epoch: 557 | loss: 1.9551379680633545 | acc: 0.4955838918685913\n",
      "epoch: 558 | loss: 1.9539496898651123 | acc: 0.4960745871067047\n",
      "epoch: 559 | loss: 1.9527645111083984 | acc: 0.4960745871067047\n",
      "epoch: 560 | loss: 1.951581358909607 | acc: 0.4955838918685913\n",
      "epoch: 561 | loss: 1.950400471687317 | acc: 0.4950932264328003\n",
      "epoch: 562 | loss: 1.9492202997207642 | acc: 0.4950932264328003\n",
      "epoch: 563 | loss: 1.948042392730713 | acc: 0.4950932264328003\n",
      "epoch: 564 | loss: 1.9468685388565063 | acc: 0.4950932264328003\n",
      "epoch: 565 | loss: 1.9456969499588013 | acc: 0.4955838918685913\n",
      "epoch: 566 | loss: 1.944527268409729 | acc: 0.4955838918685913\n",
      "epoch: 567 | loss: 1.9433587789535522 | acc: 0.4955838918685913\n",
      "epoch: 568 | loss: 1.9421921968460083 | acc: 0.4955838918685913\n",
      "epoch: 569 | loss: 1.9410277605056763 | acc: 0.4955838918685913\n",
      "epoch: 570 | loss: 1.9398643970489502 | acc: 0.4955838918685913\n",
      "epoch: 571 | loss: 1.9387024641036987 | acc: 0.4955838918685913\n",
      "epoch: 572 | loss: 1.9375436305999756 | acc: 0.4955838918685913\n",
      "epoch: 573 | loss: 1.936387300491333 | acc: 0.4955838918685913\n",
      "epoch: 574 | loss: 1.9352326393127441 | acc: 0.4955838918685913\n",
      "epoch: 575 | loss: 1.9340802431106567 | acc: 0.4960745871067047\n",
      "epoch: 576 | loss: 1.9329296350479126 | acc: 0.49705594778060913\n",
      "epoch: 577 | loss: 1.9317808151245117 | acc: 0.49705594778060913\n",
      "epoch: 578 | loss: 1.9306328296661377 | acc: 0.49705594778060913\n",
      "epoch: 579 | loss: 1.929486870765686 | acc: 0.49705594778060913\n",
      "epoch: 580 | loss: 1.9283435344696045 | acc: 0.49705594778060913\n",
      "epoch: 581 | loss: 1.927202820777893 | acc: 0.49705594778060913\n",
      "epoch: 582 | loss: 1.9260631799697876 | acc: 0.49705594778060913\n",
      "epoch: 583 | loss: 1.9249235391616821 | acc: 0.49705594778060913\n",
      "epoch: 584 | loss: 1.923784613609314 | acc: 0.49705594778060913\n",
      "epoch: 585 | loss: 1.9226468801498413 | acc: 0.4965652525424957\n",
      "epoch: 586 | loss: 1.9215110540390015 | acc: 0.4965652525424957\n",
      "epoch: 587 | loss: 1.9203763008117676 | acc: 0.4965652525424957\n",
      "epoch: 588 | loss: 1.9192432165145874 | acc: 0.4965652525424957\n",
      "epoch: 589 | loss: 1.9181121587753296 | acc: 0.4965652525424957\n",
      "epoch: 590 | loss: 1.9169830083847046 | acc: 0.4955838918685913\n",
      "epoch: 591 | loss: 1.9158564805984497 | acc: 0.4955838918685913\n",
      "epoch: 592 | loss: 1.9147306680679321 | acc: 0.4955838918685913\n",
      "epoch: 593 | loss: 1.9136059284210205 | acc: 0.4955838918685913\n",
      "epoch: 594 | loss: 1.9124835729599 | acc: 0.4955838918685913\n",
      "epoch: 595 | loss: 1.9113624095916748 | acc: 0.4955838918685913\n",
      "epoch: 596 | loss: 1.9102427959442139 | acc: 0.4950932264328003\n",
      "epoch: 597 | loss: 1.9091237783432007 | acc: 0.4950932264328003\n",
      "epoch: 598 | loss: 1.9080078601837158 | acc: 0.4950932264328003\n",
      "epoch: 599 | loss: 1.9068934917449951 | acc: 0.4950932264328003\n",
      "epoch: 600 | loss: 1.9057801961898804 | acc: 0.4950932264328003\n",
      "epoch: 601 | loss: 1.9046677350997925 | acc: 0.4946025609970093\n",
      "epoch: 602 | loss: 1.9035576581954956 | acc: 0.4941118657588959\n",
      "epoch: 603 | loss: 1.9024510383605957 | acc: 0.4941118657588959\n",
      "epoch: 604 | loss: 1.9013460874557495 | acc: 0.4941118657588959\n",
      "epoch: 605 | loss: 1.9002437591552734 | acc: 0.4946025609970093\n",
      "epoch: 606 | loss: 1.8991435766220093 | acc: 0.4946025609970093\n",
      "epoch: 607 | loss: 1.8980445861816406 | acc: 0.4946025609970093\n",
      "epoch: 608 | loss: 1.8969470262527466 | acc: 0.4946025609970093\n",
      "epoch: 609 | loss: 1.8958510160446167 | acc: 0.4950932264328003\n",
      "epoch: 610 | loss: 1.8947564363479614 | acc: 0.4950932264328003\n",
      "epoch: 611 | loss: 1.8936643600463867 | acc: 0.4950932264328003\n",
      "epoch: 612 | loss: 1.8925750255584717 | acc: 0.4950932264328003\n",
      "epoch: 613 | loss: 1.891485571861267 | acc: 0.4950932264328003\n",
      "epoch: 614 | loss: 1.8903974294662476 | acc: 0.4955838918685913\n",
      "epoch: 615 | loss: 1.8893115520477295 | acc: 0.4955838918685913\n",
      "epoch: 616 | loss: 1.888228178024292 | acc: 0.4960745871067047\n",
      "epoch: 617 | loss: 1.8871458768844604 | acc: 0.4960745871067047\n",
      "epoch: 618 | loss: 1.8860645294189453 | acc: 0.4960745871067047\n",
      "epoch: 619 | loss: 1.8849846124649048 | acc: 0.4960745871067047\n",
      "epoch: 620 | loss: 1.8839062452316284 | acc: 0.4955838918685913\n",
      "epoch: 621 | loss: 1.8828314542770386 | acc: 0.4960745871067047\n",
      "epoch: 622 | loss: 1.8817572593688965 | acc: 0.4960745871067047\n",
      "epoch: 623 | loss: 1.880684494972229 | acc: 0.4960745871067047\n",
      "epoch: 624 | loss: 1.879612922668457 | acc: 0.4960745871067047\n",
      "epoch: 625 | loss: 1.878541350364685 | acc: 0.4960745871067047\n",
      "epoch: 626 | loss: 1.8774702548980713 | acc: 0.4960745871067047\n",
      "epoch: 627 | loss: 1.876400113105774 | acc: 0.4960745871067047\n",
      "epoch: 628 | loss: 1.8753318786621094 | acc: 0.4960745871067047\n",
      "epoch: 629 | loss: 1.874265193939209 | acc: 0.4960745871067047\n",
      "epoch: 630 | loss: 1.8732012510299683 | acc: 0.4960745871067047\n",
      "epoch: 631 | loss: 1.87213933467865 | acc: 0.4960745871067047\n",
      "epoch: 632 | loss: 1.8710780143737793 | acc: 0.4960745871067047\n",
      "epoch: 633 | loss: 1.870018720626831 | acc: 0.4955838918685913\n",
      "epoch: 634 | loss: 1.868962287902832 | acc: 0.4960745871067047\n",
      "epoch: 635 | loss: 1.8679075241088867 | acc: 0.4955838918685913\n",
      "epoch: 636 | loss: 1.8668545484542847 | acc: 0.4955838918685913\n",
      "epoch: 637 | loss: 1.8658030033111572 | acc: 0.4960745871067047\n",
      "epoch: 638 | loss: 1.8647538423538208 | acc: 0.4960745871067047\n",
      "epoch: 639 | loss: 1.863706350326538 | acc: 0.4960745871067047\n",
      "epoch: 640 | loss: 1.8626596927642822 | acc: 0.4960745871067047\n",
      "epoch: 641 | loss: 1.8616130352020264 | acc: 0.4960745871067047\n",
      "epoch: 642 | loss: 1.8605667352676392 | acc: 0.4960745871067047\n",
      "epoch: 643 | loss: 1.8595219850540161 | acc: 0.4960745871067047\n",
      "epoch: 644 | loss: 1.8584786653518677 | acc: 0.4960745871067047\n",
      "epoch: 645 | loss: 1.8574360609054565 | acc: 0.4955838918685913\n",
      "epoch: 646 | loss: 1.8563939332962036 | acc: 0.4960745871067047\n",
      "epoch: 647 | loss: 1.855352759361267 | acc: 0.4960745871067047\n",
      "epoch: 648 | loss: 1.854313850402832 | acc: 0.4960745871067047\n",
      "epoch: 649 | loss: 1.8532774448394775 | acc: 0.4960745871067047\n",
      "epoch: 650 | loss: 1.8522437810897827 | acc: 0.4960745871067047\n",
      "epoch: 651 | loss: 1.8512123823165894 | acc: 0.4960745871067047\n",
      "epoch: 652 | loss: 1.850183367729187 | acc: 0.4960745871067047\n",
      "epoch: 653 | loss: 1.8491564989089966 | acc: 0.4960745871067047\n",
      "epoch: 654 | loss: 1.848130464553833 | acc: 0.4960745871067047\n",
      "epoch: 655 | loss: 1.8471053838729858 | acc: 0.4960745871067047\n",
      "epoch: 656 | loss: 1.846082091331482 | acc: 0.4965652525424957\n",
      "epoch: 657 | loss: 1.8450599908828735 | acc: 0.4965652525424957\n",
      "epoch: 658 | loss: 1.8440402746200562 | acc: 0.4965652525424957\n",
      "epoch: 659 | loss: 1.8430213928222656 | acc: 0.4965652525424957\n",
      "epoch: 660 | loss: 1.8420058488845825 | acc: 0.4965652525424957\n",
      "epoch: 661 | loss: 1.8409909009933472 | acc: 0.4965652525424957\n",
      "epoch: 662 | loss: 1.839978814125061 | acc: 0.4965652525424957\n",
      "epoch: 663 | loss: 1.83896803855896 | acc: 0.4965652525424957\n",
      "epoch: 664 | loss: 1.8379582166671753 | acc: 0.4965652525424957\n",
      "epoch: 665 | loss: 1.8369503021240234 | acc: 0.4965652525424957\n",
      "epoch: 666 | loss: 1.8359438180923462 | acc: 0.49754661321640015\n",
      "epoch: 667 | loss: 1.8349393606185913 | acc: 0.49803727865219116\n",
      "epoch: 668 | loss: 1.833936333656311 | acc: 0.49852797389030457\n",
      "epoch: 669 | loss: 1.832933783531189 | acc: 0.49852797389030457\n",
      "epoch: 670 | loss: 1.831933617591858 | acc: 0.49852797389030457\n",
      "epoch: 671 | loss: 1.8309358358383179 | acc: 0.49852797389030457\n",
      "epoch: 672 | loss: 1.8299388885498047 | acc: 0.4990186393260956\n",
      "epoch: 673 | loss: 1.8289430141448975 | acc: 0.49852797389030457\n",
      "epoch: 674 | loss: 1.8279482126235962 | acc: 0.49852797389030457\n",
      "epoch: 675 | loss: 1.8269543647766113 | acc: 0.49852797389030457\n",
      "epoch: 676 | loss: 1.825961947441101 | acc: 0.4990186393260956\n",
      "epoch: 677 | loss: 1.8249714374542236 | acc: 0.4990186393260956\n",
      "epoch: 678 | loss: 1.8239823579788208 | acc: 0.4990186393260956\n",
      "epoch: 679 | loss: 1.8229948282241821 | acc: 0.4990186393260956\n",
      "epoch: 680 | loss: 1.8220078945159912 | acc: 0.4990186393260956\n",
      "epoch: 681 | loss: 1.8210227489471436 | acc: 0.49852797389030457\n",
      "epoch: 682 | loss: 1.8200385570526123 | acc: 0.49852797389030457\n",
      "epoch: 683 | loss: 1.8190561532974243 | acc: 0.49803727865219116\n",
      "epoch: 684 | loss: 1.8180747032165527 | acc: 0.49803727865219116\n",
      "epoch: 685 | loss: 1.817094326019287 | acc: 0.49803727865219116\n",
      "epoch: 686 | loss: 1.8161152601242065 | acc: 0.49803727865219116\n",
      "epoch: 687 | loss: 1.8151403665542603 | acc: 0.49852797389030457\n",
      "epoch: 688 | loss: 1.8141686916351318 | acc: 0.49852797389030457\n",
      "epoch: 689 | loss: 1.8131978511810303 | acc: 0.49803727865219116\n",
      "epoch: 690 | loss: 1.8122286796569824 | acc: 0.4990186393260956\n",
      "epoch: 691 | loss: 1.8112609386444092 | acc: 0.4990186393260956\n",
      "epoch: 692 | loss: 1.8102937936782837 | acc: 0.4990186393260956\n",
      "epoch: 693 | loss: 1.8093279600143433 | acc: 0.4990186393260956\n",
      "epoch: 694 | loss: 1.8083630800247192 | acc: 0.49852797389030457\n",
      "epoch: 695 | loss: 1.8074012994766235 | acc: 0.49852797389030457\n",
      "epoch: 696 | loss: 1.8064407110214233 | acc: 0.49803727865219116\n",
      "epoch: 697 | loss: 1.8054803609848022 | acc: 0.49754661321640015\n",
      "epoch: 698 | loss: 1.8045209646224976 | acc: 0.49754661321640015\n",
      "epoch: 699 | loss: 1.8035635948181152 | acc: 0.49754661321640015\n",
      "epoch: 700 | loss: 1.802606463432312 | acc: 0.49754661321640015\n",
      "epoch: 701 | loss: 1.8016501665115356 | acc: 0.49754661321640015\n",
      "epoch: 702 | loss: 1.8006961345672607 | acc: 0.49754661321640015\n",
      "epoch: 703 | loss: 1.799742579460144 | acc: 0.49754661321640015\n",
      "epoch: 704 | loss: 1.7987900972366333 | acc: 0.49754661321640015\n",
      "epoch: 705 | loss: 1.7978402376174927 | acc: 0.49754661321640015\n",
      "epoch: 706 | loss: 1.796891212463379 | acc: 0.49705594778060913\n",
      "epoch: 707 | loss: 1.7959474325180054 | acc: 0.49705594778060913\n",
      "epoch: 708 | loss: 1.795006513595581 | acc: 0.49705594778060913\n",
      "epoch: 709 | loss: 1.7940666675567627 | acc: 0.49754661321640015\n",
      "epoch: 710 | loss: 1.7931275367736816 | acc: 0.49754661321640015\n",
      "epoch: 711 | loss: 1.792191982269287 | acc: 0.49754661321640015\n",
      "epoch: 712 | loss: 1.7912566661834717 | acc: 0.49754661321640015\n",
      "epoch: 713 | loss: 1.7903226613998413 | acc: 0.49754661321640015\n",
      "epoch: 714 | loss: 1.789389729499817 | acc: 0.49803727865219116\n",
      "epoch: 715 | loss: 1.788459062576294 | acc: 0.49803727865219116\n",
      "epoch: 716 | loss: 1.7875289916992188 | acc: 0.49803727865219116\n",
      "epoch: 717 | loss: 1.7865995168685913 | acc: 0.49803727865219116\n",
      "epoch: 718 | loss: 1.785671591758728 | acc: 0.49754661321640015\n",
      "epoch: 719 | loss: 1.784745454788208 | acc: 0.49754661321640015\n",
      "epoch: 720 | loss: 1.7838207483291626 | acc: 0.49754661321640015\n",
      "epoch: 721 | loss: 1.782896637916565 | acc: 0.49754661321640015\n",
      "epoch: 722 | loss: 1.7819730043411255 | acc: 0.49754661321640015\n",
      "epoch: 723 | loss: 1.7810498476028442 | acc: 0.4965652525424957\n",
      "epoch: 724 | loss: 1.7801271677017212 | acc: 0.4960745871067047\n",
      "epoch: 725 | loss: 1.7792048454284668 | acc: 0.4960745871067047\n",
      "epoch: 726 | loss: 1.778283953666687 | acc: 0.4965652525424957\n",
      "epoch: 727 | loss: 1.7773642539978027 | acc: 0.4965652525424957\n",
      "epoch: 728 | loss: 1.7764451503753662 | acc: 0.4965652525424957\n",
      "epoch: 729 | loss: 1.7755266427993774 | acc: 0.4965652525424957\n",
      "epoch: 730 | loss: 1.7746104001998901 | acc: 0.4965652525424957\n",
      "epoch: 731 | loss: 1.7736971378326416 | acc: 0.4965652525424957\n",
      "epoch: 732 | loss: 1.7727869749069214 | acc: 0.4965652525424957\n",
      "epoch: 733 | loss: 1.7718768119812012 | acc: 0.4965652525424957\n",
      "epoch: 734 | loss: 1.77096688747406 | acc: 0.4960745871067047\n",
      "epoch: 735 | loss: 1.7700575590133667 | acc: 0.4960745871067047\n",
      "epoch: 736 | loss: 1.769148826599121 | acc: 0.4960745871067047\n",
      "epoch: 737 | loss: 1.7682411670684814 | acc: 0.4965652525424957\n",
      "epoch: 738 | loss: 1.7673345804214478 | acc: 0.4965652525424957\n",
      "epoch: 739 | loss: 1.7664291858673096 | acc: 0.4955838918685913\n",
      "epoch: 740 | loss: 1.765524983406067 | acc: 0.4955838918685913\n",
      "epoch: 741 | loss: 1.764621615409851 | acc: 0.4960745871067047\n",
      "epoch: 742 | loss: 1.7637194395065308 | acc: 0.4960745871067047\n",
      "epoch: 743 | loss: 1.7628178596496582 | acc: 0.4955838918685913\n",
      "epoch: 744 | loss: 1.7619174718856812 | acc: 0.4955838918685913\n",
      "epoch: 745 | loss: 1.7610177993774414 | acc: 0.4965652525424957\n",
      "epoch: 746 | loss: 1.760120153427124 | acc: 0.4965652525424957\n",
      "epoch: 747 | loss: 1.7592229843139648 | acc: 0.4960745871067047\n",
      "epoch: 748 | loss: 1.7583271265029907 | acc: 0.4965652525424957\n",
      "epoch: 749 | loss: 1.7574318647384644 | acc: 0.4965652525424957\n",
      "epoch: 750 | loss: 1.7565377950668335 | acc: 0.4960745871067047\n",
      "epoch: 751 | loss: 1.7556449174880981 | acc: 0.4965652525424957\n",
      "epoch: 752 | loss: 1.7547520399093628 | acc: 0.4965652525424957\n",
      "epoch: 753 | loss: 1.7538594007492065 | acc: 0.4965652525424957\n",
      "epoch: 754 | loss: 1.7529702186584473 | acc: 0.49754661321640015\n",
      "epoch: 755 | loss: 1.7520833015441895 | acc: 0.49705594778060913\n",
      "epoch: 756 | loss: 1.7511978149414062 | acc: 0.49754661321640015\n",
      "epoch: 757 | loss: 1.7503128051757812 | acc: 0.49803727865219116\n",
      "epoch: 758 | loss: 1.7494279146194458 | acc: 0.49803727865219116\n",
      "epoch: 759 | loss: 1.7485431432724 | acc: 0.49803727865219116\n",
      "epoch: 760 | loss: 1.7476602792739868 | acc: 0.49803727865219116\n",
      "epoch: 761 | loss: 1.7467790842056274 | acc: 0.49754661321640015\n",
      "epoch: 762 | loss: 1.7458988428115845 | acc: 0.49754661321640015\n",
      "epoch: 763 | loss: 1.7450191974639893 | acc: 0.49803727865219116\n",
      "epoch: 764 | loss: 1.7441401481628418 | acc: 0.49803727865219116\n",
      "epoch: 765 | loss: 1.7432621717453003 | acc: 0.49754661321640015\n",
      "epoch: 766 | loss: 1.7423845529556274 | acc: 0.49754661321640015\n",
      "epoch: 767 | loss: 1.7415072917938232 | acc: 0.49803727865219116\n",
      "epoch: 768 | loss: 1.740630030632019 | acc: 0.4990186393260956\n",
      "epoch: 769 | loss: 1.7397534847259521 | acc: 0.4990186393260956\n",
      "epoch: 770 | loss: 1.738877773284912 | acc: 0.499509334564209\n",
      "epoch: 771 | loss: 1.7380026578903198 | acc: 0.499509334564209\n",
      "epoch: 772 | loss: 1.7371275424957275 | acc: 0.499509334564209\n",
      "epoch: 773 | loss: 1.7362537384033203 | acc: 0.499509334564209\n",
      "epoch: 774 | loss: 1.7353827953338623 | acc: 0.5\n",
      "epoch: 775 | loss: 1.7345139980316162 | acc: 0.5\n",
      "epoch: 776 | loss: 1.7336466312408447 | acc: 0.500490665435791\n",
      "epoch: 777 | loss: 1.732781171798706 | acc: 0.5014720559120178\n",
      "epoch: 778 | loss: 1.7319164276123047 | acc: 0.500490665435791\n",
      "epoch: 779 | loss: 1.7310540676116943 | acc: 0.5\n",
      "epoch: 780 | loss: 1.730193018913269 | acc: 0.5\n",
      "epoch: 781 | loss: 1.7293325662612915 | acc: 0.499509334564209\n",
      "epoch: 782 | loss: 1.72847318649292 | acc: 0.499509334564209\n",
      "epoch: 783 | loss: 1.7276146411895752 | acc: 0.499509334564209\n",
      "epoch: 784 | loss: 1.7267574071884155 | acc: 0.4990186393260956\n",
      "epoch: 785 | loss: 1.7259018421173096 | acc: 0.49852797389030457\n",
      "epoch: 786 | loss: 1.7250478267669678 | acc: 0.49852797389030457\n",
      "epoch: 787 | loss: 1.7241953611373901 | acc: 0.49852797389030457\n",
      "epoch: 788 | loss: 1.7233428955078125 | acc: 0.49852797389030457\n",
      "epoch: 789 | loss: 1.72249174118042 | acc: 0.49852797389030457\n",
      "epoch: 790 | loss: 1.7216415405273438 | acc: 0.49852797389030457\n",
      "epoch: 791 | loss: 1.7207913398742676 | acc: 0.49852797389030457\n",
      "epoch: 792 | loss: 1.71994149684906 | acc: 0.49852797389030457\n",
      "epoch: 793 | loss: 1.719092845916748 | acc: 0.4990186393260956\n",
      "epoch: 794 | loss: 1.7182445526123047 | acc: 0.4990186393260956\n",
      "epoch: 795 | loss: 1.717396855354309 | acc: 0.4990186393260956\n",
      "epoch: 796 | loss: 1.7165499925613403 | acc: 0.49852797389030457\n",
      "epoch: 797 | loss: 1.7157038450241089 | acc: 0.49852797389030457\n",
      "epoch: 798 | loss: 1.7148590087890625 | acc: 0.49852797389030457\n",
      "epoch: 799 | loss: 1.714015245437622 | acc: 0.49852797389030457\n",
      "epoch: 800 | loss: 1.7131723165512085 | acc: 0.49852797389030457\n",
      "epoch: 801 | loss: 1.7123298645019531 | acc: 0.49852797389030457\n",
      "epoch: 802 | loss: 1.7114895582199097 | acc: 0.49852797389030457\n",
      "epoch: 803 | loss: 1.7106513977050781 | acc: 0.49852797389030457\n",
      "epoch: 804 | loss: 1.7098140716552734 | acc: 0.49852797389030457\n",
      "epoch: 805 | loss: 1.7089776992797852 | acc: 0.49852797389030457\n",
      "epoch: 806 | loss: 1.7081434726715088 | acc: 0.49852797389030457\n",
      "epoch: 807 | loss: 1.7073107957839966 | acc: 0.4990186393260956\n",
      "epoch: 808 | loss: 1.70648193359375 | acc: 0.499509334564209\n",
      "epoch: 809 | loss: 1.7056539058685303 | acc: 0.499509334564209\n",
      "epoch: 810 | loss: 1.7048262357711792 | acc: 0.499509334564209\n",
      "epoch: 811 | loss: 1.7039998769760132 | acc: 0.499509334564209\n",
      "epoch: 812 | loss: 1.7031745910644531 | acc: 0.49852797389030457\n",
      "epoch: 813 | loss: 1.7023496627807617 | acc: 0.49852797389030457\n",
      "epoch: 814 | loss: 1.7015254497528076 | acc: 0.49803727865219116\n",
      "epoch: 815 | loss: 1.7007027864456177 | acc: 0.49803727865219116\n",
      "epoch: 816 | loss: 1.6998810768127441 | acc: 0.49803727865219116\n",
      "epoch: 817 | loss: 1.6990609169006348 | acc: 0.49803727865219116\n",
      "epoch: 818 | loss: 1.698241114616394 | acc: 0.49803727865219116\n",
      "epoch: 819 | loss: 1.6974222660064697 | acc: 0.49803727865219116\n",
      "epoch: 820 | loss: 1.696603536605835 | acc: 0.49754661321640015\n",
      "epoch: 821 | loss: 1.695784568786621 | acc: 0.49705594778060913\n",
      "epoch: 822 | loss: 1.6949666738510132 | acc: 0.49705594778060913\n",
      "epoch: 823 | loss: 1.6941492557525635 | acc: 0.49705594778060913\n",
      "epoch: 824 | loss: 1.693332314491272 | acc: 0.49705594778060913\n",
      "epoch: 825 | loss: 1.6925160884857178 | acc: 0.49754661321640015\n",
      "epoch: 826 | loss: 1.6917004585266113 | acc: 0.49754661321640015\n",
      "epoch: 827 | loss: 1.6908862590789795 | acc: 0.49754661321640015\n",
      "epoch: 828 | loss: 1.690072774887085 | acc: 0.49754661321640015\n",
      "epoch: 829 | loss: 1.6892602443695068 | acc: 0.49754661321640015\n",
      "epoch: 830 | loss: 1.688448190689087 | acc: 0.49852797389030457\n",
      "epoch: 831 | loss: 1.6876367330551147 | acc: 0.49852797389030457\n",
      "epoch: 832 | loss: 1.686827540397644 | acc: 0.49852797389030457\n",
      "epoch: 833 | loss: 1.6860196590423584 | acc: 0.49852797389030457\n",
      "epoch: 834 | loss: 1.6852118968963623 | acc: 0.4990186393260956\n",
      "epoch: 835 | loss: 1.6844054460525513 | acc: 0.4990186393260956\n",
      "epoch: 836 | loss: 1.6836000680923462 | acc: 0.4990186393260956\n",
      "epoch: 837 | loss: 1.6827950477600098 | acc: 0.4990186393260956\n",
      "epoch: 838 | loss: 1.6819912195205688 | acc: 0.499509334564209\n",
      "epoch: 839 | loss: 1.6811875104904175 | acc: 0.499509334564209\n",
      "epoch: 840 | loss: 1.6803854703903198 | acc: 0.499509334564209\n",
      "epoch: 841 | loss: 1.679584264755249 | acc: 0.5\n",
      "epoch: 842 | loss: 1.6787835359573364 | acc: 0.5\n",
      "epoch: 843 | loss: 1.6779839992523193 | acc: 0.5\n",
      "epoch: 844 | loss: 1.6771855354309082 | acc: 0.5\n",
      "epoch: 845 | loss: 1.6763889789581299 | acc: 0.5\n",
      "epoch: 846 | loss: 1.6755945682525635 | acc: 0.5\n",
      "epoch: 847 | loss: 1.6748013496398926 | acc: 0.5\n",
      "epoch: 848 | loss: 1.6740093231201172 | acc: 0.5\n",
      "epoch: 849 | loss: 1.673217535018921 | acc: 0.500490665435791\n",
      "epoch: 850 | loss: 1.672426462173462 | acc: 0.500490665435791\n",
      "epoch: 851 | loss: 1.6716365814208984 | acc: 0.500490665435791\n",
      "epoch: 852 | loss: 1.670846939086914 | acc: 0.500490665435791\n",
      "epoch: 853 | loss: 1.6700583696365356 | acc: 0.5\n",
      "epoch: 854 | loss: 1.6692705154418945 | acc: 0.5\n",
      "epoch: 855 | loss: 1.6684826612472534 | acc: 0.5\n",
      "epoch: 856 | loss: 1.6676956415176392 | acc: 0.5\n",
      "epoch: 857 | loss: 1.6669113636016846 | acc: 0.5\n",
      "epoch: 858 | loss: 1.6661276817321777 | acc: 0.5\n",
      "epoch: 859 | loss: 1.6653445959091187 | acc: 0.499509334564209\n",
      "epoch: 860 | loss: 1.6645616292953491 | acc: 0.4990186393260956\n",
      "epoch: 861 | loss: 1.663779854774475 | acc: 0.499509334564209\n",
      "epoch: 862 | loss: 1.6630001068115234 | acc: 0.499509334564209\n",
      "epoch: 863 | loss: 1.6622205972671509 | acc: 0.4990186393260956\n",
      "epoch: 864 | loss: 1.661441683769226 | acc: 0.4990186393260956\n",
      "epoch: 865 | loss: 1.6606649160385132 | acc: 0.4990186393260956\n",
      "epoch: 866 | loss: 1.6598899364471436 | acc: 0.4990186393260956\n",
      "epoch: 867 | loss: 1.6591161489486694 | acc: 0.4990186393260956\n",
      "epoch: 868 | loss: 1.65834379196167 | acc: 0.4990186393260956\n",
      "epoch: 869 | loss: 1.6575716733932495 | acc: 0.4990186393260956\n",
      "epoch: 870 | loss: 1.6567996740341187 | acc: 0.4990186393260956\n",
      "epoch: 871 | loss: 1.6560282707214355 | acc: 0.4990186393260956\n",
      "epoch: 872 | loss: 1.6552577018737793 | acc: 0.49852797389030457\n",
      "epoch: 873 | loss: 1.6544873714447021 | acc: 0.49852797389030457\n",
      "epoch: 874 | loss: 1.653718113899231 | acc: 0.49852797389030457\n",
      "epoch: 875 | loss: 1.6529492139816284 | acc: 0.49852797389030457\n",
      "epoch: 876 | loss: 1.6521806716918945 | acc: 0.49852797389030457\n",
      "epoch: 877 | loss: 1.6514135599136353 | acc: 0.49852797389030457\n",
      "epoch: 878 | loss: 1.6506468057632446 | acc: 0.49852797389030457\n",
      "epoch: 879 | loss: 1.6498812437057495 | acc: 0.49803727865219116\n",
      "epoch: 880 | loss: 1.6491159200668335 | acc: 0.49803727865219116\n",
      "epoch: 881 | loss: 1.6483511924743652 | acc: 0.49852797389030457\n",
      "epoch: 882 | loss: 1.647586703300476 | acc: 0.49852797389030457\n",
      "epoch: 883 | loss: 1.6468228101730347 | acc: 0.49852797389030457\n",
      "epoch: 884 | loss: 1.6460601091384888 | acc: 0.49852797389030457\n",
      "epoch: 885 | loss: 1.6452977657318115 | acc: 0.49852797389030457\n",
      "epoch: 886 | loss: 1.6445366144180298 | acc: 0.49852797389030457\n",
      "epoch: 887 | loss: 1.6437757015228271 | acc: 0.49852797389030457\n",
      "epoch: 888 | loss: 1.6430151462554932 | acc: 0.49852797389030457\n",
      "epoch: 889 | loss: 1.6422559022903442 | acc: 0.49803727865219116\n",
      "epoch: 890 | loss: 1.641497254371643 | acc: 0.49803727865219116\n",
      "epoch: 891 | loss: 1.6407390832901 | acc: 0.49852797389030457\n",
      "epoch: 892 | loss: 1.6399829387664795 | acc: 0.4990186393260956\n",
      "epoch: 893 | loss: 1.6392278671264648 | acc: 0.499509334564209\n",
      "epoch: 894 | loss: 1.6384739875793457 | acc: 0.499509334564209\n",
      "epoch: 895 | loss: 1.6377202272415161 | acc: 0.499509334564209\n",
      "epoch: 896 | loss: 1.6369669437408447 | acc: 0.499509334564209\n",
      "epoch: 897 | loss: 1.636215329170227 | acc: 0.4990186393260956\n",
      "epoch: 898 | loss: 1.635464072227478 | acc: 0.4990186393260956\n",
      "epoch: 899 | loss: 1.6347132921218872 | acc: 0.49852797389030457\n",
      "epoch: 900 | loss: 1.6339625120162964 | acc: 0.49803727865219116\n",
      "epoch: 901 | loss: 1.6332117319107056 | acc: 0.49803727865219116\n",
      "epoch: 902 | loss: 1.6324617862701416 | acc: 0.49803727865219116\n",
      "epoch: 903 | loss: 1.631712555885315 | acc: 0.49803727865219116\n",
      "epoch: 904 | loss: 1.6309642791748047 | acc: 0.49803727865219116\n",
      "epoch: 905 | loss: 1.6302164793014526 | acc: 0.49803727865219116\n",
      "epoch: 906 | loss: 1.6294695138931274 | acc: 0.49852797389030457\n",
      "epoch: 907 | loss: 1.6287232637405396 | acc: 0.49852797389030457\n",
      "epoch: 908 | loss: 1.6279783248901367 | acc: 0.49852797389030457\n",
      "epoch: 909 | loss: 1.6272343397140503 | acc: 0.49852797389030457\n",
      "epoch: 910 | loss: 1.6264913082122803 | acc: 0.49852797389030457\n",
      "epoch: 911 | loss: 1.6257493495941162 | acc: 0.49852797389030457\n",
      "epoch: 912 | loss: 1.6250077486038208 | acc: 0.49852797389030457\n",
      "epoch: 913 | loss: 1.6242663860321045 | acc: 0.49852797389030457\n",
      "epoch: 914 | loss: 1.623525857925415 | acc: 0.49852797389030457\n",
      "epoch: 915 | loss: 1.6227853298187256 | acc: 0.49852797389030457\n",
      "epoch: 916 | loss: 1.6220453977584839 | acc: 0.49852797389030457\n",
      "epoch: 917 | loss: 1.6213054656982422 | acc: 0.49852797389030457\n",
      "epoch: 918 | loss: 1.6205663681030273 | acc: 0.49803727865219116\n",
      "epoch: 919 | loss: 1.6198281049728394 | acc: 0.49803727865219116\n",
      "epoch: 920 | loss: 1.6190900802612305 | acc: 0.49803727865219116\n",
      "epoch: 921 | loss: 1.6183531284332275 | acc: 0.49852797389030457\n",
      "epoch: 922 | loss: 1.617616891860962 | acc: 0.49852797389030457\n",
      "epoch: 923 | loss: 1.6168817281723022 | acc: 0.4990186393260956\n",
      "epoch: 924 | loss: 1.616147756576538 | acc: 0.49852797389030457\n",
      "epoch: 925 | loss: 1.6154142618179321 | acc: 0.4990186393260956\n",
      "epoch: 926 | loss: 1.614681601524353 | acc: 0.4990186393260956\n",
      "epoch: 927 | loss: 1.6139492988586426 | acc: 0.4990186393260956\n",
      "epoch: 928 | loss: 1.6132172346115112 | acc: 0.499509334564209\n",
      "epoch: 929 | loss: 1.612485408782959 | acc: 0.499509334564209\n",
      "epoch: 930 | loss: 1.6117547750473022 | acc: 0.499509334564209\n",
      "epoch: 931 | loss: 1.6110244989395142 | acc: 0.499509334564209\n",
      "epoch: 932 | loss: 1.610294222831726 | acc: 0.499509334564209\n",
      "epoch: 933 | loss: 1.6095640659332275 | acc: 0.499509334564209\n",
      "epoch: 934 | loss: 1.6088342666625977 | acc: 0.499509334564209\n",
      "epoch: 935 | loss: 1.608104944229126 | acc: 0.499509334564209\n",
      "epoch: 936 | loss: 1.6073769330978394 | acc: 0.499509334564209\n",
      "epoch: 937 | loss: 1.6066501140594482 | acc: 0.499509334564209\n",
      "epoch: 938 | loss: 1.605924367904663 | acc: 0.5\n",
      "epoch: 939 | loss: 1.6051998138427734 | acc: 0.5\n",
      "epoch: 940 | loss: 1.6044764518737793 | acc: 0.500490665435791\n",
      "epoch: 941 | loss: 1.6037538051605225 | acc: 0.500490665435791\n",
      "epoch: 942 | loss: 1.6030312776565552 | acc: 0.500490665435791\n",
      "epoch: 943 | loss: 1.6023097038269043 | acc: 0.500490665435791\n",
      "epoch: 944 | loss: 1.6015880107879639 | acc: 0.500490665435791\n",
      "epoch: 945 | loss: 1.600866675376892 | acc: 0.500490665435791\n",
      "epoch: 946 | loss: 1.600147008895874 | acc: 0.500490665435791\n",
      "epoch: 947 | loss: 1.5994285345077515 | acc: 0.500490665435791\n",
      "epoch: 948 | loss: 1.5987111330032349 | acc: 0.500490665435791\n",
      "epoch: 949 | loss: 1.5979950428009033 | acc: 0.500490665435791\n",
      "epoch: 950 | loss: 1.597279667854309 | acc: 0.500490665435791\n",
      "epoch: 951 | loss: 1.5965651273727417 | acc: 0.500490665435791\n",
      "epoch: 952 | loss: 1.595853567123413 | acc: 0.500490665435791\n",
      "epoch: 953 | loss: 1.5951433181762695 | acc: 0.5014720559120178\n",
      "epoch: 954 | loss: 1.5944331884384155 | acc: 0.5019627213478088\n",
      "epoch: 955 | loss: 1.5937254428863525 | acc: 0.5019627213478088\n",
      "epoch: 956 | loss: 1.5930192470550537 | acc: 0.5019627213478088\n",
      "epoch: 957 | loss: 1.5923136472702026 | acc: 0.5024533867835999\n",
      "epoch: 958 | loss: 1.5916091203689575 | acc: 0.5024533867835999\n",
      "epoch: 959 | loss: 1.5909054279327393 | acc: 0.5029440522193909\n",
      "epoch: 960 | loss: 1.5902025699615479 | acc: 0.5034347176551819\n",
      "epoch: 961 | loss: 1.5895003080368042 | acc: 0.5034347176551819\n",
      "epoch: 962 | loss: 1.5887994766235352 | acc: 0.5034347176551819\n",
      "epoch: 963 | loss: 1.5880992412567139 | acc: 0.5034347176551819\n",
      "epoch: 964 | loss: 1.5873997211456299 | acc: 0.5024533867835999\n",
      "epoch: 965 | loss: 1.5867000818252563 | acc: 0.5024533867835999\n",
      "epoch: 966 | loss: 1.5860010385513306 | acc: 0.5024533867835999\n",
      "epoch: 967 | loss: 1.5853022336959839 | acc: 0.5024533867835999\n",
      "epoch: 968 | loss: 1.5846037864685059 | acc: 0.5024533867835999\n",
      "epoch: 969 | loss: 1.5839065313339233 | acc: 0.5024533867835999\n",
      "epoch: 970 | loss: 1.583211064338684 | acc: 0.5024533867835999\n",
      "epoch: 971 | loss: 1.582517147064209 | acc: 0.5034347176551819\n",
      "epoch: 972 | loss: 1.581823706626892 | acc: 0.5034347176551819\n",
      "epoch: 973 | loss: 1.5811312198638916 | acc: 0.5039254426956177\n",
      "epoch: 974 | loss: 1.5804399251937866 | acc: 0.5044161081314087\n",
      "epoch: 975 | loss: 1.5797510147094727 | acc: 0.5034347176551819\n",
      "epoch: 976 | loss: 1.5790640115737915 | acc: 0.5039254426956177\n",
      "epoch: 977 | loss: 1.5783778429031372 | acc: 0.5044161081314087\n",
      "epoch: 978 | loss: 1.577692985534668 | acc: 0.5044161081314087\n",
      "epoch: 979 | loss: 1.5770094394683838 | acc: 0.5044161081314087\n",
      "epoch: 980 | loss: 1.5763274431228638 | acc: 0.5044161081314087\n",
      "epoch: 981 | loss: 1.5756455659866333 | acc: 0.5044161081314087\n",
      "epoch: 982 | loss: 1.5749647617340088 | acc: 0.5044161081314087\n",
      "epoch: 983 | loss: 1.5742847919464111 | acc: 0.5044161081314087\n",
      "epoch: 984 | loss: 1.573604702949524 | acc: 0.5044161081314087\n",
      "epoch: 985 | loss: 1.57292640209198 | acc: 0.5044161081314087\n",
      "epoch: 986 | loss: 1.572248935699463 | acc: 0.5044161081314087\n",
      "epoch: 987 | loss: 1.571572184562683 | acc: 0.5044161081314087\n",
      "epoch: 988 | loss: 1.5708961486816406 | acc: 0.5044161081314087\n",
      "epoch: 989 | loss: 1.5702204704284668 | acc: 0.5044161081314087\n",
      "epoch: 990 | loss: 1.5695453882217407 | acc: 0.5044161081314087\n",
      "epoch: 991 | loss: 1.5688717365264893 | acc: 0.5049067735671997\n",
      "epoch: 992 | loss: 1.568198323249817 | acc: 0.5049067735671997\n",
      "epoch: 993 | loss: 1.5675255060195923 | acc: 0.5049067735671997\n",
      "epoch: 994 | loss: 1.5668548345565796 | acc: 0.5049067735671997\n",
      "epoch: 995 | loss: 1.5661848783493042 | acc: 0.5049067735671997\n",
      "epoch: 996 | loss: 1.5655162334442139 | acc: 0.5049067735671997\n",
      "epoch: 997 | loss: 1.5648488998413086 | acc: 0.5049067735671997\n",
      "epoch: 998 | loss: 1.5641833543777466 | acc: 0.5049067735671997\n",
      "epoch: 999 | loss: 1.5635178089141846 | acc: 0.5053974390029907\n"
     ]
    }
   ],
   "source": [
    "def forward(inputs, weights):\n",
    "    w, b = weights\n",
    "    res = inputs@w + b\n",
    "    # res = res.sigmoid()\n",
    "    return res\n",
    "\n",
    "# note that we compare to valid_y this time, we compare the filter/judge opinions created to new data valid_x\n",
    "def calc_accuracy_7_or_3(weights, valid_x, valid_y):\n",
    "    # we calculate prediction on new inputs\n",
    "    preds = forward(inputs=valid_x, weights=weights)\n",
    "    # compare these predictions to expected predictions (reality)\n",
    "    corrects = (preds.sigmoid() > 0.5) == valid_y\n",
    "    return corrects.float().mean()\n",
    "    # corrects = preds.float().mean().item() == valid_y\n",
    "    # return corrects.float().mean().item()\n",
    "\n",
    "def calc_loss(preds, targets):\n",
    "    # print(targets[:5])\n",
    "    # the problem is that we are not handling negative value correctly\n",
    "    preds = preds.sigmoid()\n",
    "    # dist =  (preds - targets).abs().float()\n",
    "    dist = torch.where(targets==1, 1-preds, preds)\n",
    "    return dist.mean()\n",
    "\n",
    "lr = 0.03\n",
    "# 0. init weight\n",
    "weights = init_weights((28*28, 1))\n",
    "\n",
    "for epoch_idx in range(1000):\n",
    "    # 1. forward pass\n",
    "    w, b = weights\n",
    "    preds = train_x@w + b\n",
    "\n",
    "    # 2. calculate loss\n",
    "    loss = calc_loss(preds=preds, targets=train_y)\n",
    "\n",
    "    # 3. backpropagate gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # 4. update weights\n",
    "    with torch.no_grad():\n",
    "        w.sub_(w.grad * lr)\n",
    "        w.grad.zero_() \n",
    "        b.sub_(b.grad * lr)\n",
    "        b.grad.zero_() \n",
    "\n",
    "    # 5. calc accuracy\n",
    "    acc = calc_accuracy_7_or_3(weights=weights, valid_x=valid_x, valid_y=valid_y)\n",
    "    print(f'epoch: {epoch_idx} | loss: {loss} | acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss is now going down, but accuracy doesn't improve at all?! Let's check what are the values of our predictions. Then we will double check the accuracy function as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Check your activation function/weights and gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's one thing to say we let the model learn stuff, and not let it adjust mysterious logits, it's another thing to just hope that it will reach a target if we didn't tell you how to reach it.\n",
    "\n",
    "The problem is at the end of the forward pass, we don't have activation function to define, what is a 3 or what is a 7, or did we? I DUNNO? I THOUGHT JUST HAVING A LABEL_Y SAYING THIS ROW IS 1 SHOUDL MAKE THE MODEL TRY TO REACH FOR 1??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dl \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(dset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m      2\u001b[0m xb,yb\u001b[38;5;241m=\u001b[39m first(dl)\n\u001b[1;32m      3\u001b[0m xb\u001b[38;5;241m.\u001b[39mshape, yb\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb,yb= first(dl)\n",
    "xb.shape, yb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), torch.Size([1]))"
      ]
     },
     "execution_count": 1516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = init_weights((28*28,1))\n",
    "weights[0].shape, weights[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for validation set\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | loss: 0.0062 | acc: 0.977\n",
      "epoch 1 | loss: 0.0062 | acc: 0.977\n",
      "epoch 2 | loss: 0.0062 | acc: 0.977\n",
      "epoch 3 | loss: 0.0062 | acc: 0.977\n",
      "epoch 4 | loss: 0.0062 | acc: 0.977\n",
      "epoch 5 | loss: 0.0062 | acc: 0.977\n",
      "epoch 6 | loss: 0.0062 | acc: 0.977\n",
      "epoch 7 | loss: 0.0062 | acc: 0.977\n",
      "epoch 8 | loss: 0.0062 | acc: 0.977\n",
      "epoch 9 | loss: 0.0062 | acc: 0.977\n",
      "epoch 10 | loss: 0.0062 | acc: 0.9774\n",
      "epoch 11 | loss: 0.0062 | acc: 0.9774\n",
      "epoch 12 | loss: 0.0062 | acc: 0.9774\n",
      "epoch 13 | loss: 0.0062 | acc: 0.9774\n",
      "epoch 14 | loss: 0.0062 | acc: 0.9774\n",
      "epoch 15 | loss: 0.0062 | acc: 0.9774\n",
      "epoch 16 | loss: 0.0062 | acc: 0.9774\n",
      "epoch 17 | loss: 0.0062 | acc: 0.9774\n",
      "epoch 18 | loss: 0.0062 | acc: 0.9774\n",
      "epoch 19 | loss: 0.0062 | acc: 0.9774\n"
     ]
    }
   ],
   "source": [
    "def calc_accuracy(preds, yb):\n",
    "    preds = preds.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def calc_loss(preds, targets):\n",
    "    preds = preds.sigmoid()\n",
    "    # dist =  (preds - targets).abs().float()\n",
    "    # return dist.mean()\n",
    "    dist = torch.where(targets==1, 1-preds, preds)\n",
    "    return dist.mean()\n",
    "\n",
    "def model(weights, x):\n",
    "    w, b = weights\n",
    "    res = x@w+ b\n",
    "    return res\n",
    "\n",
    "def calc_grad(model, x, y, weights):\n",
    "    preds = model(weights, x)\n",
    "    loss = calc_loss(preds=preds, targets=y)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def validate_epoch(model, weights, valid_dl):\n",
    "    accs = [calc_accuracy(model(weights, x=xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "\n",
    "def train_epoch(model, lr, weights):\n",
    "    loss = []\n",
    "    for xb,yb in dl:\n",
    "        loss.append(calc_grad(model, xb, yb, weights=weights))\n",
    "        for w in weights: #weights and biases\n",
    "            w.data -= w.grad*lr\n",
    "            w.grad.zero_()\n",
    "    return round(torch.stack(loss).mean().item(), 4)\n",
    "\n",
    "lr = 1.\n",
    "for i in range(20):\n",
    "    loss = train_epoch(model, lr, weights=weights)\n",
    "    acc = validate_epoch(model, weights=weights, valid_dl=valid_dl)\n",
    "    print(f'epoch {i} | loss: {loss} | acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Optimizer using Frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 1531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,1)\n",
    "w,b = linear_model.parameters()\n",
    "w.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1575,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, valid_dl):\n",
    "    accs = [calc_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "def calc_grad(model, x, y):\n",
    "    preds = model(x)\n",
    "    loss = calc_loss(preds=preds, targets=y)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "def train_epoch(model, opt):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(model=model, x=xb, y=yb)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "def train_model(model, opt, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model, opt)\n",
    "        print(validate_epoch(model, valid_dl=valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977\n",
      "0.977\n",
      "0.9765\n",
      "0.977\n",
      "0.977\n",
      "0.977\n",
      "0.978\n",
      "0.9785\n",
      "0.9785\n",
      "0.9795\n",
      "0.9789\n",
      "0.9789\n",
      "0.9789\n",
      "0.9789\n",
      "0.9789\n",
      "0.9789\n",
      "0.9794\n",
      "0.9794\n",
      "0.9794\n",
      "0.9794\n"
     ]
    }
   ],
   "source": [
    "opt = BasicOptim(linear_model.parameters(), lr)\n",
    "train_model(linear_model, opt, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastAI SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932\n",
      "0.7573\n",
      "0.8554\n",
      "0.9155\n",
      "0.9346\n",
      "0.9492\n",
      "0.9555\n",
      "0.9624\n",
      "0.9653\n",
      "0.9673\n",
      "0.9692\n",
      "0.9717\n",
      "0.9721\n",
      "0.9731\n",
      "0.9746\n",
      "0.9746\n",
      "0.9755\n",
      "0.976\n",
      "0.9765\n",
      "0.9765\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, opt, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastAI Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>calc_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.507504</td>\n",
       "      <td>0.511275</td>\n",
       "      <td>0.374877</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.504809</td>\n",
       "      <td>0.451502</td>\n",
       "      <td>0.425908</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.498959</td>\n",
       "      <td>0.355736</td>\n",
       "      <td>0.535819</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.488851</td>\n",
       "      <td>0.286866</td>\n",
       "      <td>0.682041</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.474726</td>\n",
       "      <td>0.260834</td>\n",
       "      <td>0.836605</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.457978</td>\n",
       "      <td>0.247087</td>\n",
       "      <td>0.913641</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.440325</td>\n",
       "      <td>0.234638</td>\n",
       "      <td>0.939156</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.423025</td>\n",
       "      <td>0.224470</td>\n",
       "      <td>0.948970</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.406803</td>\n",
       "      <td>0.214958</td>\n",
       "      <td>0.953386</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.392096</td>\n",
       "      <td>0.207204</td>\n",
       "      <td>0.956330</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.379148</td>\n",
       "      <td>0.200840</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.368066</td>\n",
       "      <td>0.194710</td>\n",
       "      <td>0.959274</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.358850</td>\n",
       "      <td>0.189875</td>\n",
       "      <td>0.959764</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.351425</td>\n",
       "      <td>0.186651</td>\n",
       "      <td>0.958292</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.345661</td>\n",
       "      <td>0.184140</td>\n",
       "      <td>0.957802</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.341389</td>\n",
       "      <td>0.182190</td>\n",
       "      <td>0.957802</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.338410</td>\n",
       "      <td>0.180833</td>\n",
       "      <td>0.957802</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.336499</td>\n",
       "      <td>0.180041</td>\n",
       "      <td>0.958292</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.335407</td>\n",
       "      <td>0.179682</td>\n",
       "      <td>0.957802</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.334870</td>\n",
       "      <td>0.179595</td>\n",
       "      <td>0.957311</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = DataLoaders(dl, valid_dl)\n",
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "                loss_func=calc_loss, metrics=calc_accuracy)\n",
    "     \n",
    "learn.fit_one_cycle(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why we need Nonlinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many linear function = same as one linear with more weights.\n",
    "\n",
    "Composing two linear function = another linear function\n",
    "\n",
    "We don't want data to just pass through layer1 and end in layer2. \n",
    "\n",
    "We want to create a logic gate that says, these pixels have passed through layer1 and we have detected that they belong to a 3 at 5%\n",
    "\n",
    "That's same as saying something similar in code:\n",
    "\n",
    "```python\n",
    "if px[:50] > 100:\n",
    "  return activated_filter_3_at_50_pct\n",
    "else:\n",
    "  return not_sure\n",
    "```\n",
    "\n",
    "\n",
    "Without activation functions we are just doing\n",
    "\n",
    "```python\n",
    "res = l1(x*3)\n",
    "res2 = l2(x*10)\n",
    "res3 = l3(...)\n",
    "\n",
    "etc without really applying any logic gate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1587,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_net(xb): \n",
    "    res = xb@w1 + b1\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>calc_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.474109</td>\n",
       "      <td>0.279716</td>\n",
       "      <td>0.493131</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.421577</td>\n",
       "      <td>0.309252</td>\n",
       "      <td>0.505888</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.265262</td>\n",
       "      <td>0.295970</td>\n",
       "      <td>0.678116</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.142547</td>\n",
       "      <td>0.169579</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.081008</td>\n",
       "      <td>0.102445</td>\n",
       "      <td>0.922964</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.053166</td>\n",
       "      <td>0.070826</td>\n",
       "      <td>0.943081</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.040275</td>\n",
       "      <td>0.054369</td>\n",
       "      <td>0.959764</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.033971</td>\n",
       "      <td>0.047083</td>\n",
       "      <td>0.962709</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.030639</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.964671</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.028725</td>\n",
       "      <td>0.038003</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.027553</td>\n",
       "      <td>0.035557</td>\n",
       "      <td>0.967615</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.026802</td>\n",
       "      <td>0.032848</td>\n",
       "      <td>0.970559</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.026308</td>\n",
       "      <td>0.031170</td>\n",
       "      <td>0.971050</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.025969</td>\n",
       "      <td>0.030405</td>\n",
       "      <td>0.971541</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.025723</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.030414</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.970559</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>0.031581</td>\n",
       "      <td>0.970559</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.025178</td>\n",
       "      <td>0.031650</td>\n",
       "      <td>0.970069</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.025098</td>\n",
       "      <td>0.031544</td>\n",
       "      <td>0.970069</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")\n",
    "\n",
    "\n",
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=calc_loss, metrics=calc_accuracy)\n",
    "\n",
    "learn.fit_one_cycle(20, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(L(learn.recorder.values).itemgot(2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final accuracy 0.9700686931610107'"
      ]
     },
     "execution_count": 1594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'final accuracy {learn.recorder.values[-1][2]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got almost 1.5% more than our linear model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a from Scratch Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_distance(a,b): return (a-b).abs().mean((-1, -2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), torch.Size([6265, 28, 28]))"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tensorize(path):\n",
    "    tens = torch.stack([tensor(Image.open(o)) \n",
    "                                for o in (path).ls()])\n",
    "    return tens.float() / tens.max()\n",
    "\n",
    "three_tens = tensorize(path/'train/3')\n",
    "seven_tens = tensorize(path/'train/7')\n",
    "three_tens.shape, seven_tens.shape\n",
    "\n",
    "# val_indep = \n",
    "# val_dep = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 28, 28])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can't stack again since the tensors have different sizes\n",
    "# currently for torch, these two tensors look like a tensor of orange and a tensor of bananas\n",
    "\n",
    "# to tell torch we don't really care about the 6131 or 6265, it doesn't have meaning\n",
    "# it's just a list that we want to concatenate,\n",
    "# we use cat and tell it to do that over the first dim\n",
    "trn_indep = torch.cat((three_tens, seven_tens), dim=0)\n",
    "trn_indep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to follow the same order (threes first, then sevens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131]), torch.Size([6265]), torch.Size([12396]))"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# three_tens.shape[0]\n",
    "# # # Create a tensor of size [6131] filled with 3s\n",
    "# full_3 = torch.full((three_tens.shape[0],), 3)\n",
    "\n",
    "# # Create a tensor of size [6265] filled with 7s\n",
    "# full_7 = torch.full((seven_tens.shape[0],), 7)\n",
    "\n",
    "# # Concatenate the two tensors to get a single tensor with the desired values\n",
    "# trn_dep = torch.cat((full_3, full_7), dim=0)\n",
    "# full_3.shape, full_7.shape, trn_dep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a random image and see if we got a matching label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be a 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random_index = np.random.randint(0, trn_indep.shape[0])\n",
    "# show_image(trn_indep[random_index])\n",
    "# print('this should be a ' + str(trn_dep[random_index].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a function to summarize all this preprocessing and also apply exactly the same thing to the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be a 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(root_path, set_path):\n",
    "    three_tens = tensorize(root_path/set_path/'3')\n",
    "    seven_tens = tensorize(root_path/set_path/'7')\n",
    "    indep = torch.cat((three_tens, seven_tens), dim=0)\n",
    "\n",
    "    # actually we don't need to do one hot encoding\n",
    "    # calc_loss expects raw scores (logits)\n",
    "    # Create a tensor of size [6131] filled with 3s\n",
    "    full_3 = torch.full((three_tens.shape[0], ), 3, dtype=torch.long)\n",
    "\n",
    "    # Create a tensor of size [6265] filled with 7s\n",
    "    full_7 = torch.full((seven_tens.shape[0], ), 7, dtype=torch.long)\n",
    "\n",
    "    # Concatenate the two tensors to get a single tensor with the desired values\n",
    "    dep = torch.cat((full_3, full_7), dim=0)\n",
    "    return indep, dep\n",
    "\n",
    "\n",
    "def pick_random_image(indep, dep):\n",
    "    random_index = np.random.randint(0, indep.shape[0])\n",
    "    show_image(indep[random_index])\n",
    "    print('this should be a ' + str(dep[random_index].item())) \n",
    "\n",
    "trn_indep, trn_dep = preprocess(path, 'train')\n",
    "pick_random_image(indep=trn_indep, dep=trn_dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the same with validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be a 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_indep, val_dep = preprocess(path, 'valid')\n",
    "pick_random_image(indep=val_indep, dep=val_dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how can i squash the pred to be either 3 or 7???\n",
    "\n",
    "# ALSO NOT SURE IF WE STILL WANT SIGMOID AS ACTIVAITON FUNCITON??\n",
    "\n",
    "# def mnist_distance(a,b): return (a-b).abs().mean((-1, -2))\n",
    "\n",
    "\n",
    "def acc(w):\n",
    "    preds = calc_preds(w, val_indep)\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate accuracy by comparing predictions to true labels.\n",
    "    \n",
    "    Args:\n",
    "    - predictions (torch.Tensor): Raw model predictions (logits).\n",
    "    - labels (torch.Tensor): True labels (class indices).\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy (torch.Tensor): The accuracy of the predictions.\n",
    "    \"\"\"\n",
    "    # Convert logits to class indices (highest probability class)\n",
    "    _, predicted_classes = torch.max(preds, 1)\n",
    "    \n",
    "    # Compare predicted classes to true classes\n",
    "    correct_predictions = (predicted_classes == val_dep).float()  # Convert boolean to float for mean calculation\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions.mean()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "    # return error_rate(preds, targ=val_dep).item()\n",
    "    # return mnist_distance(preds, val_dep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_layer(layer, n, adjust=-0.3, n_adjust=4):\n",
    "    # somehow these two lines fuck everything up?\n",
    "    # i think broadcasting just doesn't work with += and /=\n",
    "    # layer += adjust\n",
    "    # layer /= (n * n_adjust)\n",
    "    return (layer + adjust) / n * n_adjust\n",
    "\n",
    "\n",
    "def init_weights(n_in, n_out):\n",
    "    print('n_in: ', n_in)\n",
    "    print('n_out: ',n_out)\n",
    "    layerIn = torch.rand(n_in, 128)\n",
    "    layerIn = normalize_layer(layerIn, 128)\n",
    "\n",
    "    layer2 = torch.rand(layerIn.shape[-1], 64)    \n",
    "    layer2 = normalize_layer(layer2, 64)\n",
    "\n",
    "    layerOut = torch.rand(layer2.shape[-1], n_out)\n",
    "    layerOut = normalize_layer(layerOut, n_out)\n",
    "\n",
    "    # -0.5 * 0.1 are adjust help that we only figure out after trial and error\n",
    "    const1 = (torch.rand(1)[0] - 0.5) * 0.1\n",
    "    const2 = (torch.rand(1)[0] - 0.5) * 0.1\n",
    "    const3 = (torch.rand(1)[0] - 0.5) * 0.1\n",
    "\n",
    "    layers = [layerIn, layer2, layerOut]\n",
    "    consts = [const1, const2, const3]\n",
    "    for l in layers+consts: l.requires_grad_()\n",
    "\n",
    "    return layers, consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(w, indeps):\n",
    "    layers, consts = w\n",
    "    n = len(layers)\n",
    "    res = indeps\n",
    "    for i, l in enumerate(layers):\n",
    "        res = res@l + consts[i]\n",
    "        # we add ReLU for every layers aside of the last one!\n",
    "        if i != n-1:\n",
    "            res = F.relu(res)\n",
    "    # we want to use softmax since we doing multi classification\n",
    "    # but we don't need to do it here, cuz cross entropy will already do it for us\n",
    "    return res\n",
    "\n",
    "\n",
    "def calc_loss(w, indeps, deps):\n",
    "    preds = calc_preds(w, indeps)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    return loss_fn(preds, deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_weights(w, lr):\n",
    "#     layers,consts = w\n",
    "#     for layer in layers+consts:\n",
    "#         layer.sub_(layer.grad * lr)\n",
    "#         layer.grad.zero_()\n",
    "\n",
    "def one_epoch(epoch_idx, lr, trn_indep, trn_dep, w):\n",
    "    loss = calc_loss(w, indeps=trn_indep, deps=trn_dep)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        layers,consts = w\n",
    "        for layer in layers+consts:\n",
    "            layer.sub_(layer.grad * lr)\n",
    "            layer.grad.zero_()\n",
    "    print(f'Epoch {epoch_idx+1}: {loss.item()}, Accuracy: {acc(w)}')\n",
    "\n",
    "def sgd(epochs, lr, trn_indep, trn_dep, w):\n",
    "    for epoch_idx in range(epochs):\n",
    "        one_epoch(epoch_idx, lr, trn_indep, trn_dep, w)\n",
    "        \n",
    "\n",
    "def train_deep_net(epochs, lr, trn_indep, trn_dep):\n",
    "    torch.manual_seed(442)\n",
    "    n_in = trn_indep.shape[-1]\n",
    "    n_out = 10\n",
    "    \n",
    "    w = init_weights(n_in, n_out)\n",
    "    sgd(epochs, lr, trn_indep, trn_dep, w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a bigger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 1, 28, 28]), torch.Size([60000]))"
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "path.ls()\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),    # Convert to grayscale if they're not already\n",
    "    transforms.ToTensor(),     # Convert images to PyTorch tensors\n",
    "    # transforms.Normalize((0.5,), (0.5,))\n",
    "    # our custom arch converge better without it\n",
    "    # it might be related ot how we structured our arch and how we initialized our weights as well\n",
    "])\n",
    "\n",
    "def tensorize_folder(path):\n",
    "    dataset = ImageFolder(path, transform=transform)\n",
    "    dataloader = DataLoader(dataset, shuffle=False)\n",
    "    data_array = [data for data, _ in dataloader]\n",
    "    label_array = [label for _, label in dataloader]\n",
    "    data_tensor = torch.cat(data_array, dim=0)\n",
    "    label_tensor = torch.cat(label_array, dim=0)\n",
    "    return data_tensor, label_tensor\n",
    "\n",
    "trn_indep, trn_dep = tensorize_folder(path/'training')\n",
    "val_indep, val_dep = tensorize_folder(path/'testing')\n",
    "\n",
    "trn_indep.shape, trn_dep.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000]))"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reshape_to_rows_of_pixels(tns):\n",
    "    if tns.ndim == 4:\n",
    "        return tns.reshape(*tns.shape[:-3], -1)\n",
    "    else:\n",
    "        return tns\n",
    "\n",
    "trn_indep = reshape_to_rows_of_pixels(trn_indep)\n",
    "trn_dep = reshape_to_rows_of_pixels(trn_dep)\n",
    "val_indep = reshape_to_rows_of_pixels(val_indep)\n",
    "val_dep = reshape_to_rows_of_pixels(val_dep)\n",
    "\n",
    "\n",
    "trn_indep.shape, trn_dep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:42593 this should be a 7\n",
      "idx:6618 this should be a 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pick_random_image(indep, dep):\n",
    "    random_index = np.random.randint(0, indep.shape[0])\n",
    "    tns = indep[random_index]\n",
    "    if tns.ndim < 2:\n",
    "        show_image(indep[random_index].view(28, 28))\n",
    "    else:\n",
    "        show_image(indep[random_index]) \n",
    "    print(f'idx:{random_index} this should be a ' + str(dep[random_index].item())) \n",
    "\n",
    "pick_random_image(trn_indep, trn_dep)\n",
    "pick_random_image(val_indep, val_dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([10000, 784]))"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_indep.shape, val_indep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training we need to turn one image into a single tensor instead of a 2d tensor (why??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]),\n",
       " torch.Size([60000]),\n",
       " torch.Size([10000, 784]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if trn_indep.ndim == 3:\n",
    "    trn_indep = trn_indep.reshape(*trn_indep.shape[:-2], -1)\n",
    "if val_indep.ndim == 3:\n",
    "    val_indep = val_indep.reshape(*val_indep.shape[:-2], -1)\n",
    "\n",
    "trn_indep.shape, trn_dep.shape, val_indep.shape, val_dep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "lr = 0.3\n",
    "trained_coeffs = train_deep_net(epochs, lr=lr, trn_indep=trn_indep, trn_dep=trn_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(0)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(6)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(6)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(0)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(0)\n",
      "tensor(3)\n",
      "tensor(6)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(0)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(0)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(0)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(7)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(9)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "if stacked_threes.ndim == 3:\n",
    "    stacked_threes = stacked_threes.reshape(*stacked_threes.shape[:-2], -1)\n",
    "if stacked_sevens.ndim == 3:\n",
    "    stacked_sevens = stacked_sevens.reshape(*stacked_sevens.shape[:-2], -1)\n",
    "\n",
    "for img_tns in stacked_threes:\n",
    "    # print('this should be a ' + str(dep[random_index].argmax()))\n",
    "    preds = calc_preds(trained_coeffs, img_tns)\n",
    "    # Convert logits to class indices (highest probability class)\n",
    "    predicted_class = torch.argmax(preds)\n",
    "    print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit-recognizer.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0   \n",
       "1       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0   \n",
       "2       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0   \n",
       "3       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0   \n",
       "4       0       0       0       0       0       0       0       0       0       0  ...         0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kagtool.datasets.kaggle_downloader import KaggleDownloader\n",
    "\n",
    "dataset_name = 'digit-recognizer'\n",
    "creds = ''\n",
    "\n",
    "path = KaggleDownloader(dataset_name, creds).load_or_fetch_kaggle_dataset()\n",
    "tst_df = pd.read_csv(path/'test.csv')\n",
    "tst_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28000, 784])"
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_indep = torch.tensor(tst_df.values, dtype=torch.float)\n",
    "tst_indep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageId,Label\n",
      "1,2\n",
      "2,0\n",
      "3,9\n",
      "4,9\n",
      "5,3\n",
      "6,7\n",
      "7,0\n",
      "8,3\n",
      "9,0\n"
     ]
    }
   ],
   "source": [
    "preds = calc_preds(trained_coeffs, tst_indep)\n",
    "\n",
    "tst_df['ImageId'] = range(1, len(tst_df) + 1)\n",
    "tst_df['Label'] = torch.argmax(preds, dim=1)\n",
    "sub_df = tst_df[['ImageId','Label']]\n",
    "sub_df.to_csv('sub.csv', index=False)\n",
    "\n",
    "!head sub.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_in:  784\n",
      "n_out:  10\n",
      "Epoch 1: 2.6047489643096924, Accuracy: 0.09799999743700027\n",
      "Epoch 2: 2.721940279006958, Accuracy: 0.08940000087022781\n",
      "Epoch 3: 2.3067405223846436, Accuracy: 0.0908999964594841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 2.30497145652771, Accuracy: 0.09109999984502792\n",
      "Epoch 5: 2.3040037155151367, Accuracy: 0.09120000153779984\n",
      "Epoch 6: 2.3033523559570312, Accuracy: 0.09179999679327011\n",
      "Epoch 7: 2.302839994430542, Accuracy: 0.09179999679327011\n",
      "Epoch 8: 2.3023743629455566, Accuracy: 0.09220000356435776\n",
      "Epoch 9: 2.3018887042999268, Accuracy: 0.09189999848604202\n",
      "Epoch 10: 2.301318407058716, Accuracy: 0.0925000011920929\n",
      "Epoch 11: 2.3005685806274414, Accuracy: 0.09440000355243683\n",
      "Epoch 12: 2.2994909286499023, Accuracy: 0.0940999984741211\n",
      "Epoch 13: 2.2978010177612305, Accuracy: 0.09480000287294388\n",
      "Epoch 14: 2.2949421405792236, Accuracy: 0.09520000219345093\n",
      "Epoch 15: 2.289860963821411, Accuracy: 0.09619999676942825\n",
      "Epoch 16: 2.2807650566101074, Accuracy: 0.09489999711513519\n",
      "Epoch 17: 2.265516757965088, Accuracy: 0.09830000251531601\n",
      "Epoch 18: 2.2451012134552, Accuracy: 0.10010000318288803\n",
      "Epoch 19: 2.2236034870147705, Accuracy: 0.1054999977350235\n",
      "Epoch 20: 2.202540159225464, Accuracy: 0.15639999508857727\n",
      "Epoch 21: 2.1830482482910156, Accuracy: 0.21050000190734863\n",
      "Epoch 22: 2.1643784046173096, Accuracy: 0.2459000051021576\n",
      "Epoch 23: 2.1449365615844727, Accuracy: 0.27309998869895935\n",
      "Epoch 24: 2.1235997676849365, Accuracy: 0.2971000075340271\n",
      "Epoch 25: 2.0996227264404297, Accuracy: 0.3156000077724457\n",
      "Epoch 26: 2.072273015975952, Accuracy: 0.334199994802475\n",
      "Epoch 27: 2.040970802307129, Accuracy: 0.357699990272522\n",
      "Epoch 28: 2.005342721939087, Accuracy: 0.3865000009536743\n",
      "Epoch 29: 1.9648163318634033, Accuracy: 0.42320001125335693\n",
      "Epoch 30: 1.9187227487564087, Accuracy: 0.4544999897480011\n",
      "Epoch 31: 1.8664699792861938, Accuracy: 0.5072000026702881\n",
      "Epoch 32: 1.808049201965332, Accuracy: 0.5195000171661377\n",
      "Epoch 33: 1.744089961051941, Accuracy: 0.5623999834060669\n",
      "Epoch 34: 1.6794297695159912, Accuracy: 0.5360000133514404\n",
      "Epoch 35: 1.6277862787246704, Accuracy: 0.48240000009536743\n",
      "Epoch 36: 1.6621627807617188, Accuracy: 0.3377000093460083\n",
      "Epoch 37: 1.7150152921676636, Accuracy: 0.32330000400543213\n",
      "Epoch 38: 2.092318296432495, Accuracy: 0.4997999966144562\n",
      "Epoch 39: 1.6950573921203613, Accuracy: 0.49380001425743103\n",
      "Epoch 40: 1.3727705478668213, Accuracy: 0.6001999974250793\n",
      "Epoch 41: 1.3485087156295776, Accuracy: 0.5845000147819519\n",
      "Epoch 42: 1.4524255990982056, Accuracy: 0.6604999899864197\n",
      "Epoch 43: 1.3418867588043213, Accuracy: 0.6021999716758728\n",
      "Epoch 44: 1.269559383392334, Accuracy: 0.4140999913215637\n",
      "Epoch 45: 1.7158770561218262, Accuracy: 0.35899999737739563\n",
      "Epoch 46: 1.770612359046936, Accuracy: 0.7287999987602234\n",
      "Epoch 47: 1.3680287599563599, Accuracy: 0.7677000164985657\n",
      "Epoch 48: 0.9916819930076599, Accuracy: 0.7361999750137329\n",
      "Epoch 49: 0.9108511805534363, Accuracy: 0.7063000202178955\n",
      "Epoch 50: 0.944812536239624, Accuracy: 0.5659999847412109\n",
      "Epoch 51: 1.3397090435028076, Accuracy: 0.5611000061035156\n",
      "Epoch 52: 1.235284686088562, Accuracy: 0.6820999979972839\n",
      "Epoch 53: 1.0128192901611328, Accuracy: 0.7936999797821045\n",
      "Epoch 54: 0.7702938914299011, Accuracy: 0.7634000182151794\n",
      "Epoch 55: 0.7713401317596436, Accuracy: 0.6198999881744385\n",
      "Epoch 56: 1.0230854749679565, Accuracy: 0.5457000136375427\n",
      "Epoch 57: 1.4338321685791016, Accuracy: 0.6029999852180481\n",
      "Epoch 58: 1.1072001457214355, Accuracy: 0.7526000142097473\n",
      "Epoch 59: 0.8031972646713257, Accuracy: 0.839900016784668\n",
      "Epoch 60: 0.6680006980895996, Accuracy: 0.8281999826431274\n",
      "Epoch 61: 0.6349583864212036, Accuracy: 0.82669997215271\n",
      "Epoch 62: 0.6416601538658142, Accuracy: 0.7594000101089478\n",
      "Epoch 63: 0.7487040758132935, Accuracy: 0.717199981212616\n",
      "Epoch 64: 1.0007189512252808, Accuracy: 0.7125999927520752\n",
      "Epoch 65: 0.9225714206695557, Accuracy: 0.7842000126838684\n",
      "Epoch 66: 0.7467488050460815, Accuracy: 0.829200029373169\n",
      "Epoch 67: 0.6330289244651794, Accuracy: 0.8152999877929688\n",
      "Epoch 68: 0.6254393458366394, Accuracy: 0.8208000063896179\n",
      "Epoch 69: 0.6267901062965393, Accuracy: 0.7796000242233276\n",
      "Epoch 70: 0.6821022033691406, Accuracy: 0.7692000269889832\n",
      "Epoch 71: 0.7092172503471375, Accuracy: 0.7333999872207642\n",
      "Epoch 72: 0.7697106599807739, Accuracy: 0.7817000150680542\n",
      "Epoch 73: 0.6794381737709045, Accuracy: 0.8154000043869019\n",
      "Epoch 74: 0.5936201810836792, Accuracy: 0.8370000123977661\n",
      "Epoch 75: 0.5453171730041504, Accuracy: 0.8345999717712402\n",
      "Epoch 76: 0.5313929915428162, Accuracy: 0.8149999976158142\n",
      "Epoch 77: 0.5459986925125122, Accuracy: 0.7918000221252441\n",
      "Epoch 78: 0.6132373213768005, Accuracy: 0.7324000000953674\n",
      "Epoch 79: 0.7744280099868774, Accuracy: 0.6970000267028809\n",
      "Epoch 80: 0.8404675722122192, Accuracy: 0.7064999938011169\n",
      "Epoch 81: 0.8293929100036621, Accuracy: 0.8158000111579895\n",
      "Epoch 82: 0.6432215571403503, Accuracy: 0.8637999892234802\n",
      "Epoch 83: 0.50741046667099, Accuracy: 0.8708000183105469\n",
      "Epoch 84: 0.48294275999069214, Accuracy: 0.8690999746322632\n",
      "Epoch 85: 0.4757738709449768, Accuracy: 0.866599977016449\n",
      "Epoch 86: 0.48094576597213745, Accuracy: 0.8504999876022339\n",
      "Epoch 87: 0.5027252435684204, Accuracy: 0.8348000049591064\n",
      "Epoch 88: 0.5485931634902954, Accuracy: 0.7957000136375427\n",
      "Epoch 89: 0.6352689266204834, Accuracy: 0.7818999886512756\n",
      "Epoch 90: 0.6703318953514099, Accuracy: 0.7985000014305115\n",
      "Epoch 91: 0.6230283379554749, Accuracy: 0.8486999869346619\n",
      "Epoch 92: 0.5290066003799438, Accuracy: 0.8708999752998352\n",
      "Epoch 93: 0.46832406520843506, Accuracy: 0.8780999779701233\n",
      "Epoch 94: 0.4478550851345062, Accuracy: 0.8788999915122986\n",
      "Epoch 95: 0.4389618933200836, Accuracy: 0.8795999884605408\n",
      "Epoch 96: 0.4345424175262451, Accuracy: 0.8736000061035156\n",
      "Epoch 97: 0.43813368678092957, Accuracy: 0.8722000122070312\n",
      "Epoch 98: 0.4421066641807556, Accuracy: 0.8551999926567078\n",
      "Epoch 99: 0.4658786654472351, Accuracy: 0.8482999801635742\n",
      "Epoch 100: 0.4800177812576294, Accuracy: 0.816100001335144\n",
      "Epoch 101: 0.5339516401290894, Accuracy: 0.8237000107765198\n",
      "Epoch 102: 0.518096387386322, Accuracy: 0.8281000256538391\n",
      "Epoch 103: 0.5142454504966736, Accuracy: 0.8615999817848206\n",
      "Epoch 104: 0.4585215449333191, Accuracy: 0.8751999735832214\n",
      "Epoch 105: 0.43122628331184387, Accuracy: 0.885200023651123\n",
      "Epoch 106: 0.412014901638031, Accuracy: 0.8863000273704529\n",
      "Epoch 107: 0.40335556864738464, Accuracy: 0.8899000287055969\n",
      "Epoch 108: 0.3969708979129791, Accuracy: 0.8902999758720398\n",
      "Epoch 109: 0.39353638887405396, Accuracy: 0.8906000256538391\n",
      "Epoch 110: 0.391084760427475, Accuracy: 0.8913999795913696\n",
      "Epoch 111: 0.38992539048194885, Accuracy: 0.8902999758720398\n",
      "Epoch 112: 0.3901398479938507, Accuracy: 0.8903999924659729\n",
      "Epoch 113: 0.3907150328159332, Accuracy: 0.8881000280380249\n",
      "Epoch 114: 0.39440712332725525, Accuracy: 0.8859999775886536\n",
      "Epoch 115: 0.396001935005188, Accuracy: 0.8823999762535095\n",
      "Epoch 116: 0.4037613868713379, Accuracy: 0.8823000192642212\n",
      "Epoch 117: 0.40266284346580505, Accuracy: 0.8784999847412109\n",
      "Epoch 118: 0.4113876521587372, Accuracy: 0.8827000260353088\n",
      "Epoch 119: 0.4018358290195465, Accuracy: 0.8812999725341797\n",
      "Epoch 120: 0.40477418899536133, Accuracy: 0.8884000182151794\n",
      "Epoch 121: 0.389751136302948, Accuracy: 0.8895000219345093\n",
      "Epoch 122: 0.3878299593925476, Accuracy: 0.8944000005722046\n",
      "Epoch 123: 0.37573301792144775, Accuracy: 0.8944000005722046\n",
      "Epoch 124: 0.37344756722450256, Accuracy: 0.8981000185012817\n",
      "Epoch 125: 0.365665078163147, Accuracy: 0.8973000049591064\n",
      "Epoch 126: 0.36427435278892517, Accuracy: 0.9006999731063843\n",
      "Epoch 127: 0.3591492474079132, Accuracy: 0.8988999724388123\n",
      "Epoch 128: 0.35851284861564636, Accuracy: 0.9021000266075134\n",
      "Epoch 129: 0.35483333468437195, Accuracy: 0.8992000222206116\n",
      "Epoch 130: 0.3548487424850464, Accuracy: 0.902899980545044\n",
      "Epoch 131: 0.35199296474456787, Accuracy: 0.8995000123977661\n",
      "Epoch 132: 0.3526795208454132, Accuracy: 0.9020000100135803\n",
      "Epoch 133: 0.35037893056869507, Accuracy: 0.8992000222206116\n",
      "Epoch 134: 0.3518000841140747, Accuracy: 0.9017999768257141\n",
      "Epoch 135: 0.3499724268913269, Accuracy: 0.8999999761581421\n",
      "Epoch 136: 0.35220977663993835, Accuracy: 0.9017999768257141\n",
      "Epoch 137: 0.35081079602241516, Accuracy: 0.8999999761581421\n",
      "Epoch 138: 0.3537434935569763, Accuracy: 0.9007999897003174\n",
      "Epoch 139: 0.35272839665412903, Accuracy: 0.8988999724388123\n",
      "Epoch 140: 0.35596948862075806, Accuracy: 0.8996999859809875\n",
      "Epoch 141: 0.35516080260276794, Accuracy: 0.8988000154495239\n",
      "Epoch 142: 0.3578417897224426, Accuracy: 0.9007999897003174\n",
      "Epoch 143: 0.3568374216556549, Accuracy: 0.8996999859809875\n",
      "Epoch 144: 0.35793861746788025, Accuracy: 0.9003999829292297\n",
      "Epoch 145: 0.3561255633831024, Accuracy: 0.9007999897003174\n",
      "Epoch 146: 0.35501813888549805, Accuracy: 0.900600016117096\n",
      "Epoch 147: 0.351958304643631, Accuracy: 0.902400016784668\n",
      "Epoch 148: 0.34916025400161743, Accuracy: 0.9027000069618225\n",
      "Epoch 149: 0.3452811539173126, Accuracy: 0.9042999744415283\n",
      "Epoch 150: 0.34187543392181396, Accuracy: 0.9039000272750854\n",
      "Epoch 151: 0.3379673957824707, Accuracy: 0.9071000218391418\n",
      "Epoch 152: 0.33488425612449646, Accuracy: 0.9057999849319458\n",
      "Epoch 153: 0.3314686417579651, Accuracy: 0.90829998254776\n",
      "Epoch 154: 0.3290557861328125, Accuracy: 0.9078999757766724\n",
      "Epoch 155: 0.32621556520462036, Accuracy: 0.9089999794960022\n",
      "Epoch 156: 0.3244180381298065, Accuracy: 0.9078999757766724\n",
      "Epoch 157: 0.3221052587032318, Accuracy: 0.909600019454956\n",
      "Epoch 158: 0.32081884145736694, Accuracy: 0.9085999727249146\n",
      "Epoch 159: 0.318907767534256, Accuracy: 0.9097999930381775\n",
      "Epoch 160: 0.31799089908599854, Accuracy: 0.909500002861023\n",
      "Epoch 161: 0.3163903057575226, Accuracy: 0.9103999733924866\n",
      "Epoch 162: 0.31579193472862244, Accuracy: 0.9103999733924866\n",
      "Epoch 163: 0.31445378065109253, Accuracy: 0.9108999967575073\n",
      "Epoch 164: 0.3141205608844757, Accuracy: 0.9104999899864197\n",
      "Epoch 165: 0.3130168318748474, Accuracy: 0.911300003528595\n",
      "Epoch 166: 0.31293386220932007, Accuracy: 0.9103000164031982\n",
      "Epoch 167: 0.31205838918685913, Accuracy: 0.9125000238418579\n",
      "Epoch 168: 0.3121846616268158, Accuracy: 0.9099000096321106\n",
      "Epoch 169: 0.31154167652130127, Accuracy: 0.9121000170707703\n",
      "Epoch 170: 0.31179648637771606, Accuracy: 0.9093000292778015\n",
      "Epoch 171: 0.31134718656539917, Accuracy: 0.9117000102996826\n",
      "Epoch 172: 0.31158682703971863, Accuracy: 0.9088000059127808\n",
      "Epoch 173: 0.3112196624279022, Accuracy: 0.9118000268936157\n",
      "Epoch 174: 0.311195969581604, Accuracy: 0.9088000059127808\n",
      "Epoch 175: 0.3107224106788635, Accuracy: 0.9120000004768372\n",
      "Epoch 176: 0.3101732134819031, Accuracy: 0.9089000225067139\n",
      "Epoch 177: 0.3093976676464081, Accuracy: 0.9121999740600586\n",
      "Epoch 178: 0.3081918954849243, Accuracy: 0.9111999869346619\n",
      "Epoch 179: 0.3069775104522705, Accuracy: 0.9129999876022339\n",
      "Epoch 180: 0.3051929473876953, Accuracy: 0.9120000004768372\n",
      "Epoch 181: 0.30362245440483093, Accuracy: 0.9138000011444092\n",
      "Epoch 182: 0.30156248807907104, Accuracy: 0.9140999913215637\n",
      "Epoch 183: 0.2998407483100891, Accuracy: 0.9150000214576721\n",
      "Epoch 184: 0.29779645800590515, Accuracy: 0.9143000245094299\n",
      "Epoch 185: 0.29614001512527466, Accuracy: 0.9164999723434448\n",
      "Epoch 186: 0.29429832100868225, Accuracy: 0.9154000282287598\n",
      "Epoch 187: 0.29280510544776917, Accuracy: 0.9172999858856201\n",
      "Epoch 188: 0.2912074625492096, Accuracy: 0.9172999858856201\n",
      "Epoch 189: 0.28987768292427063, Accuracy: 0.9182000160217285\n",
      "Epoch 190: 0.28849777579307556, Accuracy: 0.9176999926567078\n",
      "Epoch 191: 0.28732946515083313, Accuracy: 0.9190000295639038\n",
      "Epoch 192: 0.28612515330314636, Accuracy: 0.9182999730110168\n",
      "Epoch 193: 0.285089373588562, Accuracy: 0.9200999736785889\n",
      "Epoch 194: 0.2840087115764618, Accuracy: 0.9186000227928162\n",
      "Epoch 195: 0.2830790877342224, Accuracy: 0.9205999970436096\n",
      "Epoch 196: 0.28210341930389404, Accuracy: 0.9190000295639038\n",
      "Epoch 197: 0.28125134110450745, Accuracy: 0.9208999872207642\n",
      "Epoch 198: 0.2803501486778259, Accuracy: 0.9200999736785889\n",
      "Epoch 199: 0.27955886721611023, Accuracy: 0.9207000136375427\n",
      "Epoch 200: 0.2787128686904907, Accuracy: 0.9205999970436096\n",
      "Epoch 201: 0.27797237038612366, Accuracy: 0.9211999773979187\n",
      "Epoch 202: 0.2771660387516022, Accuracy: 0.9211000204086304\n",
      "Epoch 203: 0.27646031975746155, Accuracy: 0.9214000105857849\n",
      "Epoch 204: 0.2756901681423187, Accuracy: 0.9218000173568726\n",
      "Epoch 205: 0.2750258147716522, Accuracy: 0.9215999841690063\n",
      "Epoch 206: 0.2742862403392792, Accuracy: 0.9218000173568726\n",
      "Epoch 207: 0.27365386486053467, Accuracy: 0.9218999743461609\n",
      "Epoch 208: 0.27293989062309265, Accuracy: 0.9222000241279602\n",
      "Epoch 209: 0.2723371684551239, Accuracy: 0.9222999811172485\n",
      "Epoch 210: 0.2716456353664398, Accuracy: 0.9223999977111816\n",
      "Epoch 211: 0.27106863260269165, Accuracy: 0.9232000112533569\n",
      "Epoch 212: 0.2703990042209625, Accuracy: 0.9229000210762024\n",
      "Epoch 213: 0.2698502242565155, Accuracy: 0.9235000014305115\n",
      "Epoch 214: 0.26919984817504883, Accuracy: 0.92330002784729\n",
      "Epoch 215: 0.2686815857887268, Accuracy: 0.9239000082015991\n",
      "Epoch 216: 0.26805219054222107, Accuracy: 0.9236000180244446\n",
      "Epoch 217: 0.26757121086120605, Accuracy: 0.9240000247955322\n",
      "Epoch 218: 0.26695892214775085, Accuracy: 0.923799991607666\n",
      "Epoch 219: 0.26651567220687866, Accuracy: 0.9240999817848206\n",
      "Epoch 220: 0.2659217417240143, Accuracy: 0.9240000247955322\n",
      "Epoch 221: 0.26550766825675964, Accuracy: 0.9240999817848206\n",
      "Epoch 222: 0.26492902636528015, Accuracy: 0.9243000149726868\n",
      "Epoch 223: 0.2645469605922699, Accuracy: 0.9243000149726868\n",
      "Epoch 224: 0.26397350430488586, Accuracy: 0.9247000217437744\n",
      "Epoch 225: 0.26361599564552307, Accuracy: 0.9248999953269958\n",
      "Epoch 226: 0.2630392014980316, Accuracy: 0.9246000051498413\n",
      "Epoch 227: 0.26270368695259094, Accuracy: 0.925000011920929\n",
      "Epoch 228: 0.2621125876903534, Accuracy: 0.9254000186920166\n",
      "Epoch 229: 0.2617921829223633, Accuracy: 0.925000011920929\n",
      "Epoch 230: 0.26118409633636475, Accuracy: 0.9258000254631042\n",
      "Epoch 231: 0.2608678340911865, Accuracy: 0.9251000285148621\n",
      "Epoch 232: 0.26022985577583313, Accuracy: 0.9259999990463257\n",
      "Epoch 233: 0.2599044740200043, Accuracy: 0.9247000217437744\n",
      "Epoch 234: 0.25923559069633484, Accuracy: 0.9262999892234802\n",
      "Epoch 235: 0.2588900625705719, Accuracy: 0.9254000186920166\n",
      "Epoch 236: 0.258188396692276, Accuracy: 0.9262999892234802\n",
      "Epoch 237: 0.2578221261501312, Accuracy: 0.925599992275238\n",
      "Epoch 238: 0.25707629323005676, Accuracy: 0.9262999892234802\n",
      "Epoch 239: 0.2566726803779602, Accuracy: 0.9258000254631042\n",
      "Epoch 240: 0.25588446855545044, Accuracy: 0.9266999959945679\n",
      "Epoch 241: 0.2554321885108948, Accuracy: 0.9261000156402588\n",
      "Epoch 242: 0.25461795926094055, Accuracy: 0.9269000291824341\n",
      "Epoch 243: 0.2541169226169586, Accuracy: 0.9269000291824341\n",
      "Epoch 244: 0.25327736139297485, Accuracy: 0.927299976348877\n",
      "Epoch 245: 0.25273364782333374, Accuracy: 0.9269999861717224\n",
      "Epoch 246: 0.2518767714500427, Accuracy: 0.9276999831199646\n",
      "Epoch 247: 0.25129663944244385, Accuracy: 0.9279000163078308\n",
      "Epoch 248: 0.2504490613937378, Accuracy: 0.9279000163078308\n",
      "Epoch 249: 0.24984712898731232, Accuracy: 0.9286999702453613\n",
      "Epoch 250: 0.24901500344276428, Accuracy: 0.9283999800682068\n",
      "Epoch 251: 0.24839910864830017, Accuracy: 0.9294999837875366\n",
      "Epoch 252: 0.24758446216583252, Accuracy: 0.9290000200271606\n",
      "Epoch 253: 0.24696588516235352, Accuracy: 0.9301999807357788\n",
      "Epoch 254: 0.24617698788642883, Accuracy: 0.9297000169754028\n",
      "Epoch 255: 0.2455577850341797, Accuracy: 0.9305999875068665\n",
      "Epoch 256: 0.24480053782463074, Accuracy: 0.9298999905586243\n",
      "Epoch 257: 0.24418288469314575, Accuracy: 0.9311000108718872\n",
      "Epoch 258: 0.24344708025455475, Accuracy: 0.9297000169754028\n",
      "Epoch 259: 0.24283868074417114, Accuracy: 0.9312999844551086\n",
      "Epoch 260: 0.24212540686130524, Accuracy: 0.9300000071525574\n",
      "Epoch 261: 0.2415306568145752, Accuracy: 0.9318000078201294\n",
      "Epoch 262: 0.24084070324897766, Accuracy: 0.9302999973297119\n",
      "Epoch 263: 0.24025586247444153, Accuracy: 0.9316999912261963\n",
      "Epoch 264: 0.23959071934223175, Accuracy: 0.9307000041007996\n",
      "Epoch 265: 0.2390137016773224, Accuracy: 0.9320999979972839\n",
      "Epoch 266: 0.23836715519428253, Accuracy: 0.9308000206947327\n",
      "Epoch 267: 0.2377990335226059, Accuracy: 0.9326000213623047\n",
      "Epoch 268: 0.23717498779296875, Accuracy: 0.9311000108718872\n",
      "Epoch 269: 0.236619234085083, Accuracy: 0.9327999949455261\n",
      "Epoch 270: 0.23601514101028442, Accuracy: 0.9312999844551086\n",
      "Epoch 271: 0.23547643423080444, Accuracy: 0.9330000281333923\n",
      "Epoch 272: 0.2348921149969101, Accuracy: 0.9314000010490417\n",
      "Epoch 273: 0.2343629002571106, Accuracy: 0.9332000017166138\n",
      "Epoch 274: 0.2337944656610489, Accuracy: 0.9319000244140625\n",
      "Epoch 275: 0.2332744151353836, Accuracy: 0.9333999752998352\n",
      "Epoch 276: 0.23272231221199036, Accuracy: 0.9325000047683716\n",
      "Epoch 277: 0.23221106827259064, Accuracy: 0.9337999820709229\n",
      "Epoch 278: 0.23167011141777039, Accuracy: 0.9327999949455261\n",
      "Epoch 279: 0.2311667799949646, Accuracy: 0.934499979019165\n",
      "Epoch 280: 0.2306341975927353, Accuracy: 0.9332000017166138\n",
      "Epoch 281: 0.23013964295387268, Accuracy: 0.9344000220298767\n",
      "Epoch 282: 0.2296151965856552, Accuracy: 0.9333999752998352\n",
      "Epoch 283: 0.22913019359111786, Accuracy: 0.9348999857902527\n",
      "Epoch 284: 0.22861605882644653, Accuracy: 0.9337000250816345\n",
      "Epoch 285: 0.22813250124454498, Accuracy: 0.9352999925613403\n",
      "Epoch 286: 0.22762951254844666, Accuracy: 0.9336000084877014\n",
      "Epoch 287: 0.22715362906455994, Accuracy: 0.9354000091552734\n",
      "Epoch 288: 0.22665618360042572, Accuracy: 0.933899998664856\n",
      "Epoch 289: 0.22618989646434784, Accuracy: 0.9355999827384949\n",
      "Epoch 290: 0.22570063173770905, Accuracy: 0.9341999888420105\n",
      "Epoch 291: 0.22523722052574158, Accuracy: 0.9359999895095825\n",
      "Epoch 292: 0.22474874556064606, Accuracy: 0.9341999888420105\n",
      "Epoch 293: 0.2242884784936905, Accuracy: 0.9362999796867371\n",
      "Epoch 294: 0.2238064557313919, Accuracy: 0.934499979019165\n",
      "Epoch 295: 0.22335098683834076, Accuracy: 0.9366999864578247\n",
      "Epoch 296: 0.22287334501743317, Accuracy: 0.9350000023841858\n",
      "Epoch 297: 0.22242185473442078, Accuracy: 0.9366999864578247\n",
      "Epoch 298: 0.22195173799991608, Accuracy: 0.9350000023841858\n",
      "Epoch 299: 0.221504807472229, Accuracy: 0.9370999932289124\n",
      "Epoch 300: 0.22103683650493622, Accuracy: 0.9354000091552734\n",
      "Epoch 301: 0.22059057652950287, Accuracy: 0.9373000264167786\n",
      "Epoch 302: 0.22012366354465485, Accuracy: 0.9358000159263611\n",
      "Epoch 303: 0.21968242526054382, Accuracy: 0.9375\n",
      "Epoch 304: 0.21921730041503906, Accuracy: 0.9361000061035156\n",
      "Epoch 305: 0.21878021955490112, Accuracy: 0.9373999834060669\n",
      "Epoch 306: 0.21832138299942017, Accuracy: 0.9363999962806702\n",
      "Epoch 307: 0.2178891897201538, Accuracy: 0.9376000165939331\n",
      "Epoch 308: 0.21743109822273254, Accuracy: 0.9366999864578247\n",
      "Epoch 309: 0.21700182557106018, Accuracy: 0.9379000067710876\n",
      "Epoch 310: 0.21654962003231049, Accuracy: 0.9369000196456909\n",
      "Epoch 311: 0.21612198650836945, Accuracy: 0.9380999803543091\n",
      "Epoch 312: 0.21567457914352417, Accuracy: 0.9373999834060669\n",
      "Epoch 313: 0.21525004506111145, Accuracy: 0.9383000135421753\n",
      "Epoch 314: 0.21480515599250793, Accuracy: 0.9379000067710876\n",
      "Epoch 315: 0.21438433229923248, Accuracy: 0.9387000203132629\n",
      "Epoch 316: 0.2139422595500946, Accuracy: 0.9383000135421753\n",
      "Epoch 317: 0.21352235972881317, Accuracy: 0.939300000667572\n",
      "Epoch 318: 0.21307958662509918, Accuracy: 0.9384999871253967\n",
      "Epoch 319: 0.21266232430934906, Accuracy: 0.9395999908447266\n",
      "Epoch 320: 0.2122192233800888, Accuracy: 0.9387000203132629\n",
      "Epoch 321: 0.21179886162281036, Accuracy: 0.9395999908447266\n",
      "Epoch 322: 0.21135902404785156, Accuracy: 0.9391000270843506\n",
      "Epoch 323: 0.2109408676624298, Accuracy: 0.9395999908447266\n",
      "Epoch 324: 0.21049733459949493, Accuracy: 0.9394999742507935\n",
      "Epoch 325: 0.2100813239812851, Accuracy: 0.9399999976158142\n",
      "Epoch 326: 0.2096404880285263, Accuracy: 0.9398000240325928\n",
      "Epoch 327: 0.209224134683609, Accuracy: 0.9401000142097473\n",
      "Epoch 328: 0.20878712832927704, Accuracy: 0.9401000142097473\n",
      "Epoch 329: 0.20837196707725525, Accuracy: 0.9401000142097473\n",
      "Epoch 330: 0.2079385370016098, Accuracy: 0.9401999711990356\n",
      "Epoch 331: 0.20752321183681488, Accuracy: 0.9402999877929688\n",
      "Epoch 332: 0.20709611475467682, Accuracy: 0.9405999779701233\n",
      "Epoch 333: 0.20668098330497742, Accuracy: 0.940500020980835\n",
      "Epoch 334: 0.20625293254852295, Accuracy: 0.9406999945640564\n",
      "Epoch 335: 0.20583543181419373, Accuracy: 0.9405999779701233\n",
      "Epoch 336: 0.20540867745876312, Accuracy: 0.9409000277519226\n",
      "Epoch 337: 0.204995796084404, Accuracy: 0.9409000277519226\n",
      "Epoch 338: 0.20457114279270172, Accuracy: 0.9412999749183655\n",
      "Epoch 339: 0.20416082441806793, Accuracy: 0.941100001335144\n",
      "Epoch 340: 0.2037346363067627, Accuracy: 0.9413999915122986\n",
      "Epoch 341: 0.20332540571689606, Accuracy: 0.9415000081062317\n",
      "Epoch 342: 0.20290040969848633, Accuracy: 0.9416000247001648\n",
      "Epoch 343: 0.20249530673027039, Accuracy: 0.9415000081062317\n",
      "Epoch 344: 0.20207686722278595, Accuracy: 0.9416999816894531\n",
      "Epoch 345: 0.2016749233007431, Accuracy: 0.9416000247001648\n",
      "Epoch 346: 0.20126095414161682, Accuracy: 0.9417999982833862\n",
      "Epoch 347: 0.20086179673671722, Accuracy: 0.9417999982833862\n",
      "Epoch 348: 0.20045116543769836, Accuracy: 0.9420999884605408\n",
      "Epoch 349: 0.2000531256198883, Accuracy: 0.9422000050544739\n",
      "Epoch 350: 0.19964423775672913, Accuracy: 0.942300021648407\n",
      "Epoch 351: 0.1992505043745041, Accuracy: 0.9420999884605408\n",
      "Epoch 352: 0.1988449990749359, Accuracy: 0.9426000118255615\n",
      "Epoch 353: 0.19845376908779144, Accuracy: 0.9424999952316284\n",
      "Epoch 354: 0.19805356860160828, Accuracy: 0.942799985408783\n",
      "Epoch 355: 0.1976671814918518, Accuracy: 0.9430000185966492\n",
      "Epoch 356: 0.1972721517086029, Accuracy: 0.9429000020027161\n",
      "Epoch 357: 0.1968897581100464, Accuracy: 0.9434999823570251\n",
      "Epoch 358: 0.196497842669487, Accuracy: 0.9434000253677368\n",
      "Epoch 359: 0.19611701369285583, Accuracy: 0.9437000155448914\n",
      "Epoch 360: 0.1957278698682785, Accuracy: 0.9435999989509583\n",
      "Epoch 361: 0.19534900784492493, Accuracy: 0.9438999891281128\n",
      "Epoch 362: 0.19496163725852966, Accuracy: 0.9438999891281128\n",
      "Epoch 363: 0.19458532333374023, Accuracy: 0.944100022315979\n",
      "Epoch 364: 0.19419845938682556, Accuracy: 0.9441999793052673\n",
      "Epoch 365: 0.19382578134536743, Accuracy: 0.9442999958992004\n",
      "Epoch 366: 0.19344063103199005, Accuracy: 0.944599986076355\n",
      "Epoch 367: 0.19306820631027222, Accuracy: 0.9442999958992004\n",
      "Epoch 368: 0.19268609583377838, Accuracy: 0.9448000192642212\n",
      "Epoch 369: 0.1923139989376068, Accuracy: 0.9442999958992004\n",
      "Epoch 370: 0.1919359564781189, Accuracy: 0.9452000260353088\n",
      "Epoch 371: 0.19156549870967865, Accuracy: 0.9444000124931335\n",
      "Epoch 372: 0.1911887228488922, Accuracy: 0.9455999732017517\n",
      "Epoch 373: 0.1908188760280609, Accuracy: 0.9445000290870667\n",
      "Epoch 374: 0.19044405221939087, Accuracy: 0.945900022983551\n",
      "Epoch 375: 0.19007804989814758, Accuracy: 0.9447000026702881\n",
      "Epoch 376: 0.1897084265947342, Accuracy: 0.9460999965667725\n",
      "Epoch 377: 0.18934644758701324, Accuracy: 0.9448999762535095\n",
      "Epoch 378: 0.18898038566112518, Accuracy: 0.9460999965667725\n",
      "Epoch 379: 0.18862424790859222, Accuracy: 0.9451000094413757\n",
      "Epoch 380: 0.1882624626159668, Accuracy: 0.9460999965667725\n",
      "Epoch 381: 0.18790684640407562, Accuracy: 0.9452999830245972\n",
      "Epoch 382: 0.18754784762859344, Accuracy: 0.9463000297546387\n",
      "Epoch 383: 0.187196284532547, Accuracy: 0.9452999830245972\n",
      "Epoch 384: 0.18683992326259613, Accuracy: 0.9463000297546387\n",
      "Epoch 385: 0.1864914894104004, Accuracy: 0.9452999830245972\n",
      "Epoch 386: 0.1861390918493271, Accuracy: 0.9465000033378601\n",
      "Epoch 387: 0.1857932060956955, Accuracy: 0.9456999897956848\n",
      "Epoch 388: 0.18544581532478333, Accuracy: 0.9465000033378601\n",
      "Epoch 389: 0.1851017326116562, Accuracy: 0.9455999732017517\n",
      "Epoch 390: 0.18475715816020966, Accuracy: 0.9466999769210815\n",
      "Epoch 391: 0.18441544473171234, Accuracy: 0.945900022983551\n",
      "Epoch 392: 0.18407288193702698, Accuracy: 0.9470999836921692\n",
      "Epoch 393: 0.1837335228919983, Accuracy: 0.9460999965667725\n",
      "Epoch 394: 0.18339477479457855, Accuracy: 0.9473999738693237\n",
      "Epoch 395: 0.1830567568540573, Accuracy: 0.9463000297546387\n",
      "Epoch 396: 0.1827203929424286, Accuracy: 0.9472000002861023\n",
      "Epoch 397: 0.18238449096679688, Accuracy: 0.9466000199317932\n",
      "Epoch 398: 0.18204987049102783, Accuracy: 0.9473000168800354\n",
      "Epoch 399: 0.18171843886375427, Accuracy: 0.9469000101089478\n",
      "Epoch 400: 0.18138648569583893, Accuracy: 0.9472000002861023\n",
      "Epoch 401: 0.18105702102184296, Accuracy: 0.9473000168800354\n",
      "Epoch 402: 0.18072789907455444, Accuracy: 0.9473000168800354\n",
      "Epoch 403: 0.18040096759796143, Accuracy: 0.9473000168800354\n",
      "Epoch 404: 0.18007434904575348, Accuracy: 0.9473999738693237\n",
      "Epoch 405: 0.17974868416786194, Accuracy: 0.9474999904632568\n",
      "Epoch 406: 0.1794241964817047, Accuracy: 0.9476000070571899\n",
      "Epoch 407: 0.1791001856327057, Accuracy: 0.947700023651123\n",
      "Epoch 408: 0.17877893149852753, Accuracy: 0.9476000070571899\n",
      "Epoch 409: 0.17845721542835236, Accuracy: 0.9480000138282776\n",
      "Epoch 410: 0.17813760042190552, Accuracy: 0.9477999806404114\n",
      "Epoch 411: 0.17781759798526764, Accuracy: 0.9480000138282776\n",
      "Epoch 412: 0.1774994432926178, Accuracy: 0.9480999708175659\n",
      "Epoch 413: 0.17718183994293213, Accuracy: 0.9480999708175659\n",
      "Epoch 414: 0.17686541378498077, Accuracy: 0.9484999775886536\n",
      "Epoch 415: 0.17655138671398163, Accuracy: 0.948199987411499\n",
      "Epoch 416: 0.17623713612556458, Accuracy: 0.9485999941825867\n",
      "Epoch 417: 0.17592410743236542, Accuracy: 0.9480999708175659\n",
      "Epoch 418: 0.17561355233192444, Accuracy: 0.9485999941825867\n",
      "Epoch 419: 0.17530253529548645, Accuracy: 0.9480000138282776\n",
      "Epoch 420: 0.17499254643917084, Accuracy: 0.9484000205993652\n",
      "Epoch 421: 0.17468377947807312, Accuracy: 0.948199987411499\n",
      "Epoch 422: 0.1743762493133545, Accuracy: 0.9484000205993652\n",
      "Epoch 423: 0.17406946420669556, Accuracy: 0.948199987411499\n",
      "Epoch 424: 0.17376387119293213, Accuracy: 0.9483000040054321\n",
      "Epoch 425: 0.17346011102199554, Accuracy: 0.9485999941825867\n",
      "Epoch 426: 0.17315661907196045, Accuracy: 0.9483000040054321\n",
      "Epoch 427: 0.1728547066450119, Accuracy: 0.9487000107765198\n",
      "Epoch 428: 0.17255306243896484, Accuracy: 0.9484999775886536\n",
      "Epoch 429: 0.17225316166877747, Accuracy: 0.9491000175476074\n",
      "Epoch 430: 0.17195314168930054, Accuracy: 0.9487000107765198\n",
      "Epoch 431: 0.1716560572385788, Accuracy: 0.9491000175476074\n",
      "Epoch 432: 0.1713586300611496, Accuracy: 0.9488000273704529\n",
      "Epoch 433: 0.17106372117996216, Accuracy: 0.9492999911308289\n",
      "Epoch 434: 0.17076827585697174, Accuracy: 0.9490000009536743\n",
      "Epoch 435: 0.1704745888710022, Accuracy: 0.9492999911308289\n",
      "Epoch 436: 0.17018093168735504, Accuracy: 0.9491999745368958\n",
      "Epoch 437: 0.1698894053697586, Accuracy: 0.949400007724762\n",
      "Epoch 438: 0.16959761083126068, Accuracy: 0.9492999911308289\n",
      "Epoch 439: 0.16930748522281647, Accuracy: 0.949400007724762\n",
      "Epoch 440: 0.16901859641075134, Accuracy: 0.9492999911308289\n",
      "Epoch 441: 0.16872933506965637, Accuracy: 0.9495000243186951\n",
      "Epoch 442: 0.16844165325164795, Accuracy: 0.9495000243186951\n",
      "Epoch 443: 0.16815342009067535, Accuracy: 0.949400007724762\n",
      "Epoch 444: 0.16786593198776245, Accuracy: 0.9495999813079834\n",
      "Epoch 445: 0.16758011281490326, Accuracy: 0.949400007724762\n",
      "Epoch 446: 0.16729344427585602, Accuracy: 0.9495999813079834\n",
      "Epoch 447: 0.16700853407382965, Accuracy: 0.9495000243186951\n",
      "Epoch 448: 0.1667231321334839, Accuracy: 0.9498000144958496\n",
      "Epoch 449: 0.16643886268138885, Accuracy: 0.9495999813079834\n",
      "Epoch 450: 0.16615517437458038, Accuracy: 0.9498999714851379\n",
      "Epoch 451: 0.165871724486351, Accuracy: 0.9496999979019165\n",
      "Epoch 452: 0.16559015214443207, Accuracy: 0.9498999714851379\n",
      "Epoch 453: 0.16530820727348328, Accuracy: 0.949999988079071\n",
      "Epoch 454: 0.1650291085243225, Accuracy: 0.9498999714851379\n",
      "Epoch 455: 0.16474944353103638, Accuracy: 0.9502000212669373\n",
      "Epoch 456: 0.16447192430496216, Accuracy: 0.949999988079071\n",
      "Epoch 457: 0.16419439017772675, Accuracy: 0.9502999782562256\n",
      "Epoch 458: 0.16391804814338684, Accuracy: 0.9501000046730042\n",
      "Epoch 459: 0.16364307701587677, Accuracy: 0.9505000114440918\n",
      "Epoch 460: 0.16336899995803833, Accuracy: 0.9502000212669373\n",
      "Epoch 461: 0.16309550404548645, Accuracy: 0.9506000280380249\n",
      "Epoch 462: 0.16282257437705994, Accuracy: 0.9502000212669373\n",
      "Epoch 463: 0.16255217790603638, Accuracy: 0.9509000182151794\n",
      "Epoch 464: 0.1622815579175949, Accuracy: 0.9502999782562256\n",
      "Epoch 465: 0.16201277077198029, Accuracy: 0.9509999752044678\n",
      "Epoch 466: 0.16174378991127014, Accuracy: 0.9503999948501587\n",
      "Epoch 467: 0.16147661209106445, Accuracy: 0.9513999819755554\n",
      "Epoch 468: 0.16120915114879608, Accuracy: 0.9505000114440918\n",
      "Epoch 469: 0.1609429568052292, Accuracy: 0.9513999819755554\n",
      "Epoch 470: 0.16067706048488617, Accuracy: 0.9506999850273132\n",
      "Epoch 471: 0.16041189432144165, Accuracy: 0.9513999819755554\n",
      "Epoch 472: 0.1601477563381195, Accuracy: 0.9508000016212463\n",
      "Epoch 473: 0.15988416969776154, Accuracy: 0.9514999985694885\n",
      "Epoch 474: 0.15962128341197968, Accuracy: 0.9509999752044678\n",
      "Epoch 475: 0.15935951471328735, Accuracy: 0.9514999985694885\n",
      "Epoch 476: 0.15909820795059204, Accuracy: 0.9510999917984009\n",
      "Epoch 477: 0.15883769094944, Accuracy: 0.95169997215271\n",
      "Epoch 478: 0.1585780382156372, Accuracy: 0.9513000249862671\n",
      "Epoch 479: 0.1583194136619568, Accuracy: 0.95169997215271\n",
      "Epoch 480: 0.1580614596605301, Accuracy: 0.9514999985694885\n",
      "Epoch 481: 0.15780413150787354, Accuracy: 0.95169997215271\n",
      "Epoch 482: 0.1575472503900528, Accuracy: 0.9516000151634216\n",
      "Epoch 483: 0.15729162096977234, Accuracy: 0.9519000053405762\n",
      "Epoch 484: 0.15703649818897247, Accuracy: 0.9517999887466431\n",
      "Epoch 485: 0.1567825824022293, Accuracy: 0.9520000219345093\n",
      "Epoch 486: 0.1565287560224533, Accuracy: 0.9519000053405762\n",
      "Epoch 487: 0.15627603232860565, Accuracy: 0.9520999789237976\n",
      "Epoch 488: 0.15602336823940277, Accuracy: 0.9519000053405762\n",
      "Epoch 489: 0.15577179193496704, Accuracy: 0.9521999955177307\n",
      "Epoch 490: 0.15552064776420593, Accuracy: 0.9519000053405762\n",
      "Epoch 491: 0.15527068078517914, Accuracy: 0.9521999955177307\n",
      "Epoch 492: 0.15502125024795532, Accuracy: 0.9520000219345093\n",
      "Epoch 493: 0.15477240085601807, Accuracy: 0.9523000121116638\n",
      "Epoch 494: 0.15452441573143005, Accuracy: 0.9520999789237976\n",
      "Epoch 495: 0.15427759289741516, Accuracy: 0.9524999856948853\n",
      "Epoch 496: 0.15403124690055847, Accuracy: 0.9523000121116638\n",
      "Epoch 497: 0.1537855565547943, Accuracy: 0.9526000022888184\n",
      "Epoch 498: 0.1535404920578003, Accuracy: 0.9524999856948853\n",
      "Epoch 499: 0.15329666435718536, Accuracy: 0.9531999826431274\n",
      "Epoch 500: 0.15305320918560028, Accuracy: 0.9528999924659729\n",
      "Epoch 501: 0.1528109908103943, Accuracy: 0.9534000158309937\n",
      "Epoch 502: 0.15256918966770172, Accuracy: 0.9531000256538391\n",
      "Epoch 503: 0.1523282527923584, Accuracy: 0.953499972820282\n",
      "Epoch 504: 0.15208768844604492, Accuracy: 0.9532999992370605\n",
      "Epoch 505: 0.1518479883670807, Accuracy: 0.9539999961853027\n",
      "Epoch 506: 0.15160925686359406, Accuracy: 0.953499972820282\n",
      "Epoch 507: 0.15137101709842682, Accuracy: 0.954200029373169\n",
      "Epoch 508: 0.1511334329843521, Accuracy: 0.953499972820282\n",
      "Epoch 509: 0.15089623630046844, Accuracy: 0.954200029373169\n",
      "Epoch 510: 0.15066000819206238, Accuracy: 0.953499972820282\n",
      "Epoch 511: 0.1504240185022354, Accuracy: 0.954200029373169\n",
      "Epoch 512: 0.15018907189369202, Accuracy: 0.9538000226020813\n",
      "Epoch 513: 0.1499548703432083, Accuracy: 0.9544000029563904\n",
      "Epoch 514: 0.14972130954265594, Accuracy: 0.9538999795913696\n",
      "Epoch 515: 0.14948831498622894, Accuracy: 0.9545000195503235\n",
      "Epoch 516: 0.14925654232501984, Accuracy: 0.9542999863624573\n",
      "Epoch 517: 0.14902529120445251, Accuracy: 0.9545000195503235\n",
      "Epoch 518: 0.14879466593265533, Accuracy: 0.9545000195503235\n",
      "Epoch 519: 0.14856474101543427, Accuracy: 0.9545999765396118\n",
      "Epoch 520: 0.14833520352840424, Accuracy: 0.9546999931335449\n",
      "Epoch 521: 0.14810633659362793, Accuracy: 0.9546999931335449\n",
      "Epoch 522: 0.14787812530994415, Accuracy: 0.9550999999046326\n",
      "Epoch 523: 0.14765086770057678, Accuracy: 0.954800009727478\n",
      "Epoch 524: 0.14742381870746613, Accuracy: 0.9550999999046326\n",
      "Epoch 525: 0.147197425365448, Accuracy: 0.9550999999046326\n",
      "Epoch 526: 0.14697177708148956, Accuracy: 0.9552000164985657\n",
      "Epoch 527: 0.14674663543701172, Accuracy: 0.9555000066757202\n",
      "Epoch 528: 0.14652223885059357, Accuracy: 0.955299973487854\n",
      "Epoch 529: 0.14629828929901123, Accuracy: 0.9556999802589417\n",
      "Epoch 530: 0.14607501029968262, Accuracy: 0.9555000066757202\n",
      "Epoch 531: 0.14585207402706146, Accuracy: 0.9556999802589417\n",
      "Epoch 532: 0.14563000202178955, Accuracy: 0.9557999968528748\n",
      "Epoch 533: 0.14540860056877136, Accuracy: 0.9559999704360962\n",
      "Epoch 534: 0.1451881229877472, Accuracy: 0.9557999968528748\n",
      "Epoch 535: 0.14496774971485138, Accuracy: 0.9560999870300293\n",
      "Epoch 536: 0.1447482705116272, Accuracy: 0.9559000134468079\n",
      "Epoch 537: 0.14452894032001495, Accuracy: 0.9560999870300293\n",
      "Epoch 538: 0.14430998265743256, Accuracy: 0.9559000134468079\n",
      "Epoch 539: 0.14409145712852478, Accuracy: 0.9562000036239624\n",
      "Epoch 540: 0.14387348294258118, Accuracy: 0.9559000134468079\n",
      "Epoch 541: 0.14365583658218384, Accuracy: 0.9562000036239624\n",
      "Epoch 542: 0.14343908429145813, Accuracy: 0.9559999704360962\n",
      "Epoch 543: 0.14322270452976227, Accuracy: 0.9562000036239624\n",
      "Epoch 544: 0.14300672709941864, Accuracy: 0.9559000134468079\n",
      "Epoch 545: 0.14279146492481232, Accuracy: 0.9563000202178955\n",
      "Epoch 546: 0.14257732033729553, Accuracy: 0.9559999704360962\n",
      "Epoch 547: 0.1423637866973877, Accuracy: 0.9563000202178955\n",
      "Epoch 548: 0.14215098321437836, Accuracy: 0.9563999772071838\n",
      "Epoch 549: 0.14193843305110931, Accuracy: 0.9563999772071838\n",
      "Epoch 550: 0.14172637462615967, Accuracy: 0.9564999938011169\n",
      "Epoch 551: 0.14151495695114136, Accuracy: 0.95660001039505\n",
      "Epoch 552: 0.1413041055202484, Accuracy: 0.9567000269889832\n",
      "Epoch 553: 0.14109356701374054, Accuracy: 0.9567000269889832\n",
      "Epoch 554: 0.1408834308385849, Accuracy: 0.9567999839782715\n",
      "Epoch 555: 0.14067389070987701, Accuracy: 0.9567999839782715\n",
      "Epoch 556: 0.1404651403427124, Accuracy: 0.957099974155426\n",
      "Epoch 557: 0.14025700092315674, Accuracy: 0.9570000171661377\n",
      "Epoch 558: 0.14004941284656525, Accuracy: 0.9571999907493591\n",
      "Epoch 559: 0.1398424357175827, Accuracy: 0.957099974155426\n",
      "Epoch 560: 0.13963590562343597, Accuracy: 0.9571999907493591\n",
      "Epoch 561: 0.13942977786064148, Accuracy: 0.9573000073432922\n",
      "Epoch 562: 0.13922421634197235, Accuracy: 0.957099974155426\n",
      "Epoch 563: 0.13901881873607635, Accuracy: 0.9574000239372253\n",
      "Epoch 564: 0.13881421089172363, Accuracy: 0.957099974155426\n",
      "Epoch 565: 0.13860996067523956, Accuracy: 0.9574999809265137\n",
      "Epoch 566: 0.13840638101100922, Accuracy: 0.9573000073432922\n",
      "Epoch 567: 0.13820293545722961, Accuracy: 0.9575999975204468\n",
      "Epoch 568: 0.13800032436847687, Accuracy: 0.9573000073432922\n",
      "Epoch 569: 0.13779804110527039, Accuracy: 0.9578999876976013\n",
      "Epoch 570: 0.13759660720825195, Accuracy: 0.9573000073432922\n",
      "Epoch 571: 0.13739562034606934, Accuracy: 0.9578999876976013\n",
      "Epoch 572: 0.13719531893730164, Accuracy: 0.9577000141143799\n",
      "Epoch 573: 0.13699547946453094, Accuracy: 0.9578999876976013\n",
      "Epoch 574: 0.13679607212543488, Accuracy: 0.9577000141143799\n",
      "Epoch 575: 0.136597141623497, Accuracy: 0.9580000042915344\n",
      "Epoch 576: 0.1363985687494278, Accuracy: 0.9577000141143799\n",
      "Epoch 577: 0.13620062172412872, Accuracy: 0.9580000042915344\n",
      "Epoch 578: 0.1360030621290207, Accuracy: 0.9580000042915344\n",
      "Epoch 579: 0.13580617308616638, Accuracy: 0.9581999778747559\n",
      "Epoch 580: 0.13560941815376282, Accuracy: 0.9581000208854675\n",
      "Epoch 581: 0.1354132890701294, Accuracy: 0.958299994468689\n",
      "Epoch 582: 0.13521745800971985, Accuracy: 0.9584000110626221\n",
      "Epoch 583: 0.1350223869085312, Accuracy: 0.9585999846458435\n",
      "Epoch 584: 0.13482779264450073, Accuracy: 0.9585000276565552\n",
      "Epoch 585: 0.1346336305141449, Accuracy: 0.9587000012397766\n",
      "Epoch 586: 0.13443982601165771, Accuracy: 0.9587000012397766\n",
      "Epoch 587: 0.13424639403820038, Accuracy: 0.958899974822998\n",
      "Epoch 588: 0.13405346870422363, Accuracy: 0.9587000012397766\n",
      "Epoch 589: 0.1338612139225006, Accuracy: 0.9589999914169312\n",
      "Epoch 590: 0.13366957008838654, Accuracy: 0.9587000012397766\n",
      "Epoch 591: 0.13347835838794708, Accuracy: 0.9591000080108643\n",
      "Epoch 592: 0.13328750431537628, Accuracy: 0.958899974822998\n",
      "Epoch 593: 0.1330970972776413, Accuracy: 0.9592000246047974\n",
      "Epoch 594: 0.13290724158287048, Accuracy: 0.9591000080108643\n",
      "Epoch 595: 0.13271787762641907, Accuracy: 0.9592999815940857\n",
      "Epoch 596: 0.1325291097164154, Accuracy: 0.9592999815940857\n",
      "Epoch 597: 0.13234087824821472, Accuracy: 0.9593999981880188\n",
      "Epoch 598: 0.13215303421020508, Accuracy: 0.9592999815940857\n",
      "Epoch 599: 0.1319655179977417, Accuracy: 0.9593999981880188\n",
      "Epoch 600: 0.13177864253520966, Accuracy: 0.9592999815940857\n",
      "Epoch 601: 0.1315920203924179, Accuracy: 0.9593999981880188\n",
      "Epoch 602: 0.13140571117401123, Accuracy: 0.9592999815940857\n",
      "Epoch 603: 0.13122011721134186, Accuracy: 0.9593999981880188\n",
      "Epoch 604: 0.13103483617305756, Accuracy: 0.9592999815940857\n",
      "Epoch 605: 0.1308499574661255, Accuracy: 0.9593999981880188\n",
      "Epoch 606: 0.13066543638706207, Accuracy: 0.9592999815940857\n",
      "Epoch 607: 0.13048142194747925, Accuracy: 0.9595000147819519\n",
      "Epoch 608: 0.13029786944389343, Accuracy: 0.9592999815940857\n",
      "Epoch 609: 0.13011454045772552, Accuracy: 0.9595000147819519\n",
      "Epoch 610: 0.12993161380290985, Accuracy: 0.9592999815940857\n",
      "Epoch 611: 0.1297493726015091, Accuracy: 0.9595000147819519\n",
      "Epoch 612: 0.12956762313842773, Accuracy: 0.9592999815940857\n",
      "Epoch 613: 0.129386305809021, Accuracy: 0.9595000147819519\n",
      "Epoch 614: 0.12920519709587097, Accuracy: 0.9593999981880188\n",
      "Epoch 615: 0.12902459502220154, Accuracy: 0.9595999717712402\n",
      "Epoch 616: 0.12884435057640076, Accuracy: 0.9595000147819519\n",
      "Epoch 617: 0.12866441905498505, Accuracy: 0.9598000049591064\n",
      "Epoch 618: 0.1284848153591156, Accuracy: 0.9595999717712402\n",
      "Epoch 619: 0.12830545008182526, Accuracy: 0.9598000049591064\n",
      "Epoch 620: 0.12812656164169312, Accuracy: 0.9595999717712402\n",
      "Epoch 621: 0.12794791162014008, Accuracy: 0.9599000215530396\n",
      "Epoch 622: 0.12776967883110046, Accuracy: 0.9596999883651733\n",
      "Epoch 623: 0.12759172916412354, Accuracy: 0.9599000215530396\n",
      "Epoch 624: 0.12741418182849884, Accuracy: 0.9599000215530396\n",
      "Epoch 625: 0.12723715603351593, Accuracy: 0.9599999785423279\n",
      "Epoch 626: 0.1270604282617569, Accuracy: 0.9599000215530396\n",
      "Epoch 627: 0.12688401341438293, Accuracy: 0.9602000117301941\n",
      "Epoch 628: 0.12670806050300598, Accuracy: 0.9599000215530396\n",
      "Epoch 629: 0.12653270363807678, Accuracy: 0.9602000117301941\n",
      "Epoch 630: 0.12635767459869385, Accuracy: 0.9599999785423279\n",
      "Epoch 631: 0.12618307769298553, Accuracy: 0.9602000117301941\n",
      "Epoch 632: 0.12600931525230408, Accuracy: 0.960099995136261\n",
      "Epoch 633: 0.12583591043949127, Accuracy: 0.9602000117301941\n",
      "Epoch 634: 0.12566322088241577, Accuracy: 0.9599999785423279\n",
      "Epoch 635: 0.1254907250404358, Accuracy: 0.9603000283241272\n",
      "Epoch 636: 0.12531869113445282, Accuracy: 0.9599999785423279\n",
      "Epoch 637: 0.1251470446586609, Accuracy: 0.9603999853134155\n",
      "Epoch 638: 0.12497592717409134, Accuracy: 0.9602000117301941\n",
      "Epoch 639: 0.12480513751506805, Accuracy: 0.9605000019073486\n",
      "Epoch 640: 0.1246349960565567, Accuracy: 0.9602000117301941\n",
      "Epoch 641: 0.12446507811546326, Accuracy: 0.9605000019073486\n",
      "Epoch 642: 0.12429579347372055, Accuracy: 0.9605000019073486\n",
      "Epoch 643: 0.12412658333778381, Accuracy: 0.9606000185012817\n",
      "Epoch 644: 0.12395787239074707, Accuracy: 0.9606000185012817\n",
      "Epoch 645: 0.12378939986228943, Accuracy: 0.9606999754905701\n",
      "Epoch 646: 0.12362141162157059, Accuracy: 0.9606999754905701\n",
      "Epoch 647: 0.12345359474420547, Accuracy: 0.9609000086784363\n",
      "Epoch 648: 0.12328631430864334, Accuracy: 0.9609000086784363\n",
      "Epoch 649: 0.12311934679746628, Accuracy: 0.9609000086784363\n",
      "Epoch 650: 0.12295286357402802, Accuracy: 0.9610000252723694\n",
      "Epoch 651: 0.12278702110052109, Accuracy: 0.9610000252723694\n",
      "Epoch 652: 0.12262154370546341, Accuracy: 0.9610999822616577\n",
      "Epoch 653: 0.12245628982782364, Accuracy: 0.9610999822616577\n",
      "Epoch 654: 0.12229162454605103, Accuracy: 0.9610999822616577\n",
      "Epoch 655: 0.1221272274851799, Accuracy: 0.9613000154495239\n",
      "Epoch 656: 0.12196330726146698, Accuracy: 0.9610999822616577\n",
      "Epoch 657: 0.121799536049366, Accuracy: 0.9613000154495239\n",
      "Epoch 658: 0.12163594365119934, Accuracy: 0.9610999822616577\n",
      "Epoch 659: 0.12147271633148193, Accuracy: 0.9613000154495239\n",
      "Epoch 660: 0.12131009995937347, Accuracy: 0.9611999988555908\n",
      "Epoch 661: 0.12114764004945755, Accuracy: 0.9613000154495239\n",
      "Epoch 662: 0.12098562717437744, Accuracy: 0.9613000154495239\n",
      "Epoch 663: 0.1208239495754242, Accuracy: 0.9613999724388123\n",
      "Epoch 664: 0.12066290527582169, Accuracy: 0.9613999724388123\n",
      "Epoch 665: 0.12050189077854156, Accuracy: 0.9613999724388123\n",
      "Epoch 666: 0.12034124881029129, Accuracy: 0.9614999890327454\n",
      "Epoch 667: 0.12018076330423355, Accuracy: 0.9617000222206116\n",
      "Epoch 668: 0.12002076208591461, Accuracy: 0.9614999890327454\n",
      "Epoch 669: 0.1198611706495285, Accuracy: 0.961899995803833\n",
      "Epoch 670: 0.11970215290784836, Accuracy: 0.9617000222206116\n",
      "Epoch 671: 0.11954347789287567, Accuracy: 0.9620000123977661\n",
      "Epoch 672: 0.1193854957818985, Accuracy: 0.9617000222206116\n",
      "Epoch 673: 0.11922740936279297, Accuracy: 0.9620000123977661\n",
      "Epoch 674: 0.11907017230987549, Accuracy: 0.9617000222206116\n",
      "Epoch 675: 0.11891309916973114, Accuracy: 0.961899995803833\n",
      "Epoch 676: 0.11875662952661514, Accuracy: 0.9617000222206116\n",
      "Epoch 677: 0.1186002567410469, Accuracy: 0.9620000123977661\n",
      "Epoch 678: 0.11844463646411896, Accuracy: 0.9617999792098999\n",
      "Epoch 679: 0.1182892918586731, Accuracy: 0.9621000289916992\n",
      "Epoch 680: 0.11813431233167648, Accuracy: 0.961899995803833\n",
      "Epoch 681: 0.11797979474067688, Accuracy: 0.9620000123977661\n",
      "Epoch 682: 0.11782562732696533, Accuracy: 0.961899995803833\n",
      "Epoch 683: 0.11767170578241348, Accuracy: 0.9620000123977661\n",
      "Epoch 684: 0.11751813441514969, Accuracy: 0.9620000123977661\n",
      "Epoch 685: 0.11736446619033813, Accuracy: 0.961899995803833\n",
      "Epoch 686: 0.11721169203519821, Accuracy: 0.9621000289916992\n",
      "Epoch 687: 0.11705873161554337, Accuracy: 0.9621999859809875\n",
      "Epoch 688: 0.11690636724233627, Accuracy: 0.9621000289916992\n",
      "Epoch 689: 0.1167539581656456, Accuracy: 0.9621999859809875\n",
      "Epoch 690: 0.1166018545627594, Accuracy: 0.9621999859809875\n",
      "Epoch 691: 0.11645016819238663, Accuracy: 0.9623000025749207\n",
      "Epoch 692: 0.1162986159324646, Accuracy: 0.9623000025749207\n",
      "Epoch 693: 0.11614743620157242, Accuracy: 0.9623000025749207\n",
      "Epoch 694: 0.11599662154912949, Accuracy: 0.9621999859809875\n",
      "Epoch 695: 0.11584604531526566, Accuracy: 0.9624000191688538\n",
      "Epoch 696: 0.11569603532552719, Accuracy: 0.9623000025749207\n",
      "Epoch 697: 0.11554629355669022, Accuracy: 0.9624000191688538\n",
      "Epoch 698: 0.11539709568023682, Accuracy: 0.9623000025749207\n",
      "Epoch 699: 0.11524790525436401, Accuracy: 0.9624000191688538\n",
      "Epoch 700: 0.1150992214679718, Accuracy: 0.9621999859809875\n",
      "Epoch 701: 0.11495077610015869, Accuracy: 0.9624000191688538\n",
      "Epoch 702: 0.11480283737182617, Accuracy: 0.9621999859809875\n",
      "Epoch 703: 0.11465523391962051, Accuracy: 0.9624999761581421\n",
      "Epoch 704: 0.11450782418251038, Accuracy: 0.9624000191688538\n",
      "Epoch 705: 0.11436081677675247, Accuracy: 0.9627000093460083\n",
      "Epoch 706: 0.11421394348144531, Accuracy: 0.9624999761581421\n",
      "Epoch 707: 0.1140674501657486, Accuracy: 0.9627000093460083\n",
      "Epoch 708: 0.11392129957675934, Accuracy: 0.9627000093460083\n",
      "Epoch 709: 0.11377541720867157, Accuracy: 0.9627000093460083\n",
      "Epoch 710: 0.11362992227077484, Accuracy: 0.9627000093460083\n",
      "Epoch 711: 0.11348453164100647, Accuracy: 0.9628000259399414\n",
      "Epoch 712: 0.11333974450826645, Accuracy: 0.9627000093460083\n",
      "Epoch 713: 0.11319506168365479, Accuracy: 0.9628000259399414\n",
      "Epoch 714: 0.11305084079504013, Accuracy: 0.9627000093460083\n",
      "Epoch 715: 0.11290667206048965, Accuracy: 0.9628999829292297\n",
      "Epoch 716: 0.11276278644800186, Accuracy: 0.9629999995231628\n",
      "Epoch 717: 0.11261926591396332, Accuracy: 0.9628000259399414\n",
      "Epoch 718: 0.11247604340314865, Accuracy: 0.963100016117096\n",
      "Epoch 719: 0.11233318597078323, Accuracy: 0.9628000259399414\n",
      "Epoch 720: 0.11219056695699692, Accuracy: 0.9631999731063843\n",
      "Epoch 721: 0.11204849183559418, Accuracy: 0.9628999829292297\n",
      "Epoch 722: 0.11190656572580338, Accuracy: 0.9631999731063843\n",
      "Epoch 723: 0.11176507920026779, Accuracy: 0.9631999731063843\n",
      "Epoch 724: 0.1116238608956337, Accuracy: 0.9631999731063843\n",
      "Epoch 725: 0.11148323863744736, Accuracy: 0.9632999897003174\n",
      "Epoch 726: 0.11134278029203415, Accuracy: 0.9634000062942505\n",
      "Epoch 727: 0.11120259016752243, Accuracy: 0.9635000228881836\n",
      "Epoch 728: 0.11106261610984802, Accuracy: 0.9634000062942505\n",
      "Epoch 729: 0.11092285066843033, Accuracy: 0.9635999798774719\n",
      "Epoch 730: 0.11078358441591263, Accuracy: 0.9635000228881836\n",
      "Epoch 731: 0.11064448952674866, Accuracy: 0.9634000062942505\n",
      "Epoch 732: 0.11050558090209961, Accuracy: 0.9635999798774719\n",
      "Epoch 733: 0.11036679893732071, Accuracy: 0.9634000062942505\n",
      "Epoch 734: 0.11022857576608658, Accuracy: 0.963699996471405\n",
      "Epoch 735: 0.11009040474891663, Accuracy: 0.9635000228881836\n",
      "Epoch 736: 0.10995260626077652, Accuracy: 0.9639000296592712\n",
      "Epoch 737: 0.10981503129005432, Accuracy: 0.9635000228881836\n",
      "Epoch 738: 0.10967777669429779, Accuracy: 0.9639999866485596\n",
      "Epoch 739: 0.10954073071479797, Accuracy: 0.9635000228881836\n",
      "Epoch 740: 0.109404057264328, Accuracy: 0.9639999866485596\n",
      "Epoch 741: 0.10926751792430878, Accuracy: 0.963699996471405\n",
      "Epoch 742: 0.10913128405809402, Accuracy: 0.9639000296592712\n",
      "Epoch 743: 0.10899519175291061, Accuracy: 0.963699996471405\n",
      "Epoch 744: 0.10885971039533615, Accuracy: 0.9639000296592712\n",
      "Epoch 745: 0.10872424393892288, Accuracy: 0.963699996471405\n",
      "Epoch 746: 0.10858923196792603, Accuracy: 0.9639999866485596\n",
      "Epoch 747: 0.10845405608415604, Accuracy: 0.963699996471405\n",
      "Epoch 748: 0.10831931978464127, Accuracy: 0.9639999866485596\n",
      "Epoch 749: 0.10818493366241455, Accuracy: 0.9638000130653381\n",
      "Epoch 750: 0.10805099457502365, Accuracy: 0.9639999866485596\n",
      "Epoch 751: 0.10791733860969543, Accuracy: 0.9639999866485596\n",
      "Epoch 752: 0.10778401792049408, Accuracy: 0.9639999866485596\n",
      "Epoch 753: 0.10765103250741959, Accuracy: 0.9639999866485596\n",
      "Epoch 754: 0.10751854628324509, Accuracy: 0.9639999866485596\n",
      "Epoch 755: 0.10738595575094223, Accuracy: 0.9639999866485596\n",
      "Epoch 756: 0.10725405067205429, Accuracy: 0.9641000032424927\n",
      "Epoch 757: 0.10712207108736038, Accuracy: 0.9639999866485596\n",
      "Epoch 758: 0.10699057579040527, Accuracy: 0.9642000198364258\n",
      "Epoch 759: 0.10685910284519196, Accuracy: 0.9639999866485596\n",
      "Epoch 760: 0.10672806203365326, Accuracy: 0.9641000032424927\n",
      "Epoch 761: 0.10659722983837128, Accuracy: 0.9639999866485596\n",
      "Epoch 762: 0.10646659880876541, Accuracy: 0.9642000198364258\n",
      "Epoch 763: 0.10633645951747894, Accuracy: 0.9641000032424927\n",
      "Epoch 764: 0.10620656609535217, Accuracy: 0.9642999768257141\n",
      "Epoch 765: 0.10607721656560898, Accuracy: 0.9641000032424927\n",
      "Epoch 766: 0.10594787448644638, Accuracy: 0.9642999768257141\n",
      "Epoch 767: 0.1058187335729599, Accuracy: 0.9643999934196472\n",
      "Epoch 768: 0.10568983107805252, Accuracy: 0.9642999768257141\n",
      "Epoch 769: 0.10556109994649887, Accuracy: 0.9643999934196472\n",
      "Epoch 770: 0.10543239116668701, Accuracy: 0.9642999768257141\n",
      "Epoch 771: 0.10530366748571396, Accuracy: 0.9643999934196472\n",
      "Epoch 772: 0.10517535358667374, Accuracy: 0.9642999768257141\n",
      "Epoch 773: 0.10504703223705292, Accuracy: 0.9646000266075134\n",
      "Epoch 774: 0.1049191802740097, Accuracy: 0.9646000266075134\n",
      "Epoch 775: 0.1047915518283844, Accuracy: 0.9646000266075134\n",
      "Epoch 776: 0.10466410964727402, Accuracy: 0.9646000266075134\n",
      "Epoch 777: 0.10453732311725616, Accuracy: 0.9646000266075134\n",
      "Epoch 778: 0.10441062599420547, Accuracy: 0.9646999835968018\n",
      "Epoch 779: 0.10428463667631149, Accuracy: 0.9646000266075134\n",
      "Epoch 780: 0.10415838658809662, Accuracy: 0.9648000001907349\n",
      "Epoch 781: 0.10403288900852203, Accuracy: 0.9646999835968018\n",
      "Epoch 782: 0.1039067730307579, Accuracy: 0.964900016784668\n",
      "Epoch 783: 0.10378137230873108, Accuracy: 0.9648000001907349\n",
      "Epoch 784: 0.10365598648786545, Accuracy: 0.964900016784668\n",
      "Epoch 785: 0.10353124886751175, Accuracy: 0.9648000001907349\n",
      "Epoch 786: 0.10340629518032074, Accuracy: 0.964900016784668\n",
      "Epoch 787: 0.10328204184770584, Accuracy: 0.9649999737739563\n",
      "Epoch 788: 0.10315797477960587, Accuracy: 0.964900016784668\n",
      "Epoch 789: 0.10303396731615067, Accuracy: 0.9649999737739563\n",
      "Epoch 790: 0.10291021317243576, Accuracy: 0.964900016784668\n",
      "Epoch 791: 0.10278628021478653, Accuracy: 0.9649999737739563\n",
      "Epoch 792: 0.1026626005768776, Accuracy: 0.9649999737739563\n",
      "Epoch 793: 0.10253899544477463, Accuracy: 0.9649999737739563\n",
      "Epoch 794: 0.10241559892892838, Accuracy: 0.9649999737739563\n",
      "Epoch 795: 0.10229256004095078, Accuracy: 0.9648000001907349\n",
      "Epoch 796: 0.10216985642910004, Accuracy: 0.9649999737739563\n",
      "Epoch 797: 0.10204719752073288, Accuracy: 0.964900016784668\n",
      "Epoch 798: 0.10192537307739258, Accuracy: 0.9649999737739563\n",
      "Epoch 799: 0.10180376470088959, Accuracy: 0.964900016784668\n",
      "Epoch 800: 0.10168244689702988, Accuracy: 0.9649999737739563\n",
      "Epoch 801: 0.10156150162220001, Accuracy: 0.9648000001907349\n",
      "Epoch 802: 0.10144104063510895, Accuracy: 0.9650999903678894\n",
      "Epoch 803: 0.10132065415382385, Accuracy: 0.9648000001907349\n",
      "Epoch 804: 0.10120078921318054, Accuracy: 0.9650999903678894\n",
      "Epoch 805: 0.10108073800802231, Accuracy: 0.9648000001907349\n",
      "Epoch 806: 0.10096121579408646, Accuracy: 0.9650999903678894\n",
      "Epoch 807: 0.10084143280982971, Accuracy: 0.964900016784668\n",
      "Epoch 808: 0.1007222980260849, Accuracy: 0.9650999903678894\n",
      "Epoch 809: 0.1006033718585968, Accuracy: 0.964900016784668\n",
      "Epoch 810: 0.1004849374294281, Accuracy: 0.9652000069618225\n",
      "Epoch 811: 0.1003669872879982, Accuracy: 0.964900016784668\n",
      "Epoch 812: 0.10024856775999069, Accuracy: 0.9652000069618225\n",
      "Epoch 813: 0.1001305803656578, Accuracy: 0.964900016784668\n",
      "Epoch 814: 0.10001224279403687, Accuracy: 0.9652000069618225\n",
      "Epoch 815: 0.09989393502473831, Accuracy: 0.9649999737739563\n",
      "Epoch 816: 0.09977573901414871, Accuracy: 0.9652000069618225\n",
      "Epoch 817: 0.09965799748897552, Accuracy: 0.9649999737739563\n",
      "Epoch 818: 0.09954111278057098, Accuracy: 0.9652000069618225\n",
      "Epoch 819: 0.09942467510700226, Accuracy: 0.9649999737739563\n",
      "Epoch 820: 0.09930888563394547, Accuracy: 0.9652000069618225\n",
      "Epoch 821: 0.09919338673353195, Accuracy: 0.9649999737739563\n",
      "Epoch 822: 0.09907843172550201, Accuracy: 0.9652000069618225\n",
      "Epoch 823: 0.09896312654018402, Accuracy: 0.9649999737739563\n",
      "Epoch 824: 0.09884834289550781, Accuracy: 0.9652000069618225\n",
      "Epoch 825: 0.09873342514038086, Accuracy: 0.9650999903678894\n",
      "Epoch 826: 0.09861844033002853, Accuracy: 0.965399980545044\n",
      "Epoch 827: 0.09850352257490158, Accuracy: 0.9652000069618225\n",
      "Epoch 828: 0.09838913381099701, Accuracy: 0.9656000137329102\n",
      "Epoch 829: 0.09827430546283722, Accuracy: 0.9652000069618225\n",
      "Epoch 830: 0.09816040843725204, Accuracy: 0.9656000137329102\n",
      "Epoch 831: 0.09804657846689224, Accuracy: 0.9652000069618225\n",
      "Epoch 832: 0.09793278574943542, Accuracy: 0.9656000137329102\n",
      "Epoch 833: 0.09781993925571442, Accuracy: 0.9653000235557556\n",
      "Epoch 834: 0.09770645201206207, Accuracy: 0.9656999707221985\n",
      "Epoch 835: 0.09759410470724106, Accuracy: 0.9653000235557556\n",
      "Epoch 836: 0.09748052805662155, Accuracy: 0.9656999707221985\n",
      "Epoch 837: 0.09736883640289307, Accuracy: 0.965399980545044\n",
      "Epoch 838: 0.09725557267665863, Accuracy: 0.9657999873161316\n",
      "Epoch 839: 0.09714354574680328, Accuracy: 0.965399980545044\n",
      "Epoch 840: 0.09703035652637482, Accuracy: 0.9657999873161316\n",
      "Epoch 841: 0.09691882878541946, Accuracy: 0.965399980545044\n",
      "Epoch 842: 0.09680607169866562, Accuracy: 0.9659000039100647\n",
      "Epoch 843: 0.09669483453035355, Accuracy: 0.965499997138977\n",
      "Epoch 844: 0.09658289700746536, Accuracy: 0.9657999873161316\n",
      "Epoch 845: 0.0964716374874115, Accuracy: 0.965499997138977\n",
      "Epoch 846: 0.09636019915342331, Accuracy: 0.9659000039100647\n",
      "Epoch 847: 0.09624972939491272, Accuracy: 0.9656999707221985\n",
      "Epoch 848: 0.09613876789808273, Accuracy: 0.9660000205039978\n",
      "Epoch 849: 0.09602826088666916, Accuracy: 0.9656999707221985\n",
      "Epoch 850: 0.09591817855834961, Accuracy: 0.9660000205039978\n",
      "Epoch 851: 0.09580764174461365, Accuracy: 0.9656000137329102\n",
      "Epoch 852: 0.09569837898015976, Accuracy: 0.9660000205039978\n",
      "Epoch 853: 0.09558811038732529, Accuracy: 0.9656999707221985\n",
      "Epoch 854: 0.09547870606184006, Accuracy: 0.9660000205039978\n",
      "Epoch 855: 0.09536914527416229, Accuracy: 0.9657999873161316\n",
      "Epoch 856: 0.0952608659863472, Accuracy: 0.9660000205039978\n",
      "Epoch 857: 0.09515216201543808, Accuracy: 0.9657999873161316\n",
      "Epoch 858: 0.09504442662000656, Accuracy: 0.9660000205039978\n",
      "Epoch 859: 0.0949360653758049, Accuracy: 0.9659000039100647\n",
      "Epoch 860: 0.09482903778553009, Accuracy: 0.9661999940872192\n",
      "Epoch 861: 0.0947204977273941, Accuracy: 0.9659000039100647\n",
      "Epoch 862: 0.09461387246847153, Accuracy: 0.9661999940872192\n",
      "Epoch 863: 0.09450656920671463, Accuracy: 0.9659000039100647\n",
      "Epoch 864: 0.09440065920352936, Accuracy: 0.9661999940872192\n",
      "Epoch 865: 0.09429407864809036, Accuracy: 0.9659000039100647\n",
      "Epoch 866: 0.09418820589780807, Accuracy: 0.9663000106811523\n",
      "Epoch 867: 0.09408286958932877, Accuracy: 0.9659000039100647\n",
      "Epoch 868: 0.09397811442613602, Accuracy: 0.9664000272750854\n",
      "Epoch 869: 0.093873031437397, Accuracy: 0.9661999940872192\n",
      "Epoch 870: 0.09376832842826843, Accuracy: 0.9664999842643738\n",
      "Epoch 871: 0.09366276860237122, Accuracy: 0.9661999940872192\n",
      "Epoch 872: 0.09355934709310532, Accuracy: 0.9668999910354614\n",
      "Epoch 873: 0.09345358610153198, Accuracy: 0.9661999940872192\n",
      "Epoch 874: 0.0933505967259407, Accuracy: 0.9671000242233276\n",
      "Epoch 875: 0.09324558079242706, Accuracy: 0.9664000272750854\n",
      "Epoch 876: 0.0931428000330925, Accuracy: 0.9674000144004822\n",
      "Epoch 877: 0.09303668141365051, Accuracy: 0.9664000272750854\n",
      "Epoch 878: 0.092934250831604, Accuracy: 0.9674000144004822\n",
      "Epoch 879: 0.09282875806093216, Accuracy: 0.9664999842643738\n",
      "Epoch 880: 0.0927269235253334, Accuracy: 0.9674999713897705\n",
      "Epoch 881: 0.09262170642614365, Accuracy: 0.9664999842643738\n",
      "Epoch 882: 0.09252011030912399, Accuracy: 0.9674999713897705\n",
      "Epoch 883: 0.0924152284860611, Accuracy: 0.9664999842643738\n",
      "Epoch 884: 0.09231434762477875, Accuracy: 0.9674000144004822\n",
      "Epoch 885: 0.09220947325229645, Accuracy: 0.9664999842643738\n",
      "Epoch 886: 0.09210759401321411, Accuracy: 0.9674000144004822\n",
      "Epoch 887: 0.09200304001569748, Accuracy: 0.9664999842643738\n",
      "Epoch 888: 0.09190244972705841, Accuracy: 0.9674999713897705\n",
      "Epoch 889: 0.09179729223251343, Accuracy: 0.9670000076293945\n",
      "Epoch 890: 0.09169565886259079, Accuracy: 0.9674999713897705\n",
      "Epoch 891: 0.09158913046121597, Accuracy: 0.967199981212616\n",
      "Epoch 892: 0.091486856341362, Accuracy: 0.9675999879837036\n",
      "Epoch 893: 0.09138185530900955, Accuracy: 0.9672999978065491\n",
      "Epoch 894: 0.09128020703792572, Accuracy: 0.9675999879837036\n",
      "Epoch 895: 0.09117549657821655, Accuracy: 0.9672999978065491\n",
      "Epoch 896: 0.09107422828674316, Accuracy: 0.9675999879837036\n",
      "Epoch 897: 0.09096982330083847, Accuracy: 0.9674999713897705\n",
      "Epoch 898: 0.09086889773607254, Accuracy: 0.9675999879837036\n",
      "Epoch 899: 0.09076542407274246, Accuracy: 0.9674999713897705\n",
      "Epoch 900: 0.09066542237997055, Accuracy: 0.9675999879837036\n",
      "Epoch 901: 0.0905630812048912, Accuracy: 0.9674999713897705\n",
      "Epoch 902: 0.09046532958745956, Accuracy: 0.9675999879837036\n",
      "Epoch 903: 0.09036335349082947, Accuracy: 0.9674999713897705\n",
      "Epoch 904: 0.09026626497507095, Accuracy: 0.9678000211715698\n",
      "Epoch 905: 0.09016406536102295, Accuracy: 0.9674999713897705\n",
      "Epoch 906: 0.09006725251674652, Accuracy: 0.9678999781608582\n",
      "Epoch 907: 0.08996526151895523, Accuracy: 0.9674999713897705\n",
      "Epoch 908: 0.0898691788315773, Accuracy: 0.9678999781608582\n",
      "Epoch 909: 0.0897677093744278, Accuracy: 0.9674999713897705\n",
      "Epoch 910: 0.0896710678935051, Accuracy: 0.9678999781608582\n",
      "Epoch 911: 0.0895705297589302, Accuracy: 0.9675999879837036\n",
      "Epoch 912: 0.08947311341762543, Accuracy: 0.9679999947547913\n",
      "Epoch 913: 0.08937317132949829, Accuracy: 0.9678000211715698\n",
      "Epoch 914: 0.0892760157585144, Accuracy: 0.9679999947547913\n",
      "Epoch 915: 0.08917586505413055, Accuracy: 0.9678999781608582\n",
      "Epoch 916: 0.08907847851514816, Accuracy: 0.9681000113487244\n",
      "Epoch 917: 0.08897938579320908, Accuracy: 0.9678999781608582\n",
      "Epoch 918: 0.08888279646635056, Accuracy: 0.9682000279426575\n",
      "Epoch 919: 0.08878341317176819, Accuracy: 0.9678999781608582\n",
      "Epoch 920: 0.08868823945522308, Accuracy: 0.9682999849319458\n",
      "Epoch 921: 0.08858921378850937, Accuracy: 0.9679999947547913\n",
      "Epoch 922: 0.08849294483661652, Accuracy: 0.9682999849319458\n",
      "Epoch 923: 0.0883941799402237, Accuracy: 0.9679999947547913\n",
      "Epoch 924: 0.08829943090677261, Accuracy: 0.9682999849319458\n",
      "Epoch 925: 0.0882013589143753, Accuracy: 0.9679999947547913\n",
      "Epoch 926: 0.08810657262802124, Accuracy: 0.9682999849319458\n",
      "Epoch 927: 0.08800897002220154, Accuracy: 0.9679999947547913\n",
      "Epoch 928: 0.08791548013687134, Accuracy: 0.9684000015258789\n",
      "Epoch 929: 0.08781813830137253, Accuracy: 0.9679999947547913\n",
      "Epoch 930: 0.0877247303724289, Accuracy: 0.968500018119812\n",
      "Epoch 931: 0.0876270979642868, Accuracy: 0.9679999947547913\n",
      "Epoch 932: 0.08753352612257004, Accuracy: 0.968500018119812\n",
      "Epoch 933: 0.08743693679571152, Accuracy: 0.9679999947547913\n",
      "Epoch 934: 0.0873425155878067, Accuracy: 0.9685999751091003\n",
      "Epoch 935: 0.08724655956029892, Accuracy: 0.9679999947547913\n",
      "Epoch 936: 0.0871533751487732, Accuracy: 0.9688000082969666\n",
      "Epoch 937: 0.0870579332113266, Accuracy: 0.9679999947547913\n",
      "Epoch 938: 0.08696399629116058, Accuracy: 0.9688000082969666\n",
      "Epoch 939: 0.08686911314725876, Accuracy: 0.9681000113487244\n",
      "Epoch 940: 0.0867764949798584, Accuracy: 0.968999981880188\n",
      "Epoch 941: 0.08668191730976105, Accuracy: 0.9682000279426575\n",
      "Epoch 942: 0.08659037202596664, Accuracy: 0.968999981880188\n",
      "Epoch 943: 0.08649618178606033, Accuracy: 0.9682000279426575\n",
      "Epoch 944: 0.0864047035574913, Accuracy: 0.968999981880188\n",
      "Epoch 945: 0.08631017804145813, Accuracy: 0.9682000279426575\n",
      "Epoch 946: 0.08621825277805328, Accuracy: 0.968999981880188\n",
      "Epoch 947: 0.08612463623285294, Accuracy: 0.9682999849319458\n",
      "Epoch 948: 0.08603357523679733, Accuracy: 0.968999981880188\n",
      "Epoch 949: 0.08594077080488205, Accuracy: 0.968500018119812\n",
      "Epoch 950: 0.08584963530302048, Accuracy: 0.9690999984741211\n",
      "Epoch 951: 0.08575662970542908, Accuracy: 0.9686999917030334\n",
      "Epoch 952: 0.08566629141569138, Accuracy: 0.9690999984741211\n",
      "Epoch 953: 0.08557295054197311, Accuracy: 0.9686999917030334\n",
      "Epoch 954: 0.08548307418823242, Accuracy: 0.9692000150680542\n",
      "Epoch 955: 0.08539024740457535, Accuracy: 0.9688000082969666\n",
      "Epoch 956: 0.08530042320489883, Accuracy: 0.9692000150680542\n",
      "Epoch 957: 0.08520805090665817, Accuracy: 0.968999981880188\n",
      "Epoch 958: 0.0851203128695488, Accuracy: 0.9692000150680542\n",
      "Epoch 959: 0.08502887934446335, Accuracy: 0.9692000150680542\n",
      "Epoch 960: 0.08494193851947784, Accuracy: 0.9692000150680542\n",
      "Epoch 961: 0.08485051989555359, Accuracy: 0.9690999984741211\n",
      "Epoch 962: 0.08476351201534271, Accuracy: 0.9693999886512756\n",
      "Epoch 963: 0.08467304706573486, Accuracy: 0.9690999984741211\n",
      "Epoch 964: 0.08458603173494339, Accuracy: 0.9695000052452087\n",
      "Epoch 965: 0.08449569344520569, Accuracy: 0.9692000150680542\n",
      "Epoch 966: 0.08440949022769928, Accuracy: 0.9695000052452087\n",
      "Epoch 967: 0.08431971073150635, Accuracy: 0.9692000150680542\n",
      "Epoch 968: 0.0842345729470253, Accuracy: 0.9695000052452087\n",
      "Epoch 969: 0.08414578437805176, Accuracy: 0.9692000150680542\n",
      "Epoch 970: 0.08406195789575577, Accuracy: 0.9695000052452087\n",
      "Epoch 971: 0.08397344499826431, Accuracy: 0.9692000150680542\n",
      "Epoch 972: 0.08389125019311905, Accuracy: 0.9695000052452087\n",
      "Epoch 973: 0.08380240201950073, Accuracy: 0.9693999886512756\n",
      "Epoch 974: 0.08371903747320175, Accuracy: 0.9696000218391418\n",
      "Epoch 975: 0.08363030850887299, Accuracy: 0.9693999886512756\n",
      "Epoch 976: 0.08354777842760086, Accuracy: 0.9696000218391418\n",
      "Epoch 977: 0.08345983177423477, Accuracy: 0.9693999886512756\n",
      "Epoch 978: 0.08337874710559845, Accuracy: 0.9696000218391418\n",
      "Epoch 979: 0.0832914412021637, Accuracy: 0.9696000218391418\n",
      "Epoch 980: 0.08321025967597961, Accuracy: 0.9696000218391418\n",
      "Epoch 981: 0.08312015235424042, Accuracy: 0.9695000052452087\n",
      "Epoch 982: 0.08303838223218918, Accuracy: 0.9696000218391418\n",
      "Epoch 983: 0.08294855803251266, Accuracy: 0.9695000052452087\n",
      "Epoch 984: 0.0828675851225853, Accuracy: 0.9696000218391418\n",
      "Epoch 985: 0.08277751505374908, Accuracy: 0.9695000052452087\n",
      "Epoch 986: 0.08269575983285904, Accuracy: 0.9696000218391418\n",
      "Epoch 987: 0.082606740295887, Accuracy: 0.9695000052452087\n",
      "Epoch 988: 0.08252336084842682, Accuracy: 0.9696000218391418\n",
      "Epoch 989: 0.08243408054113388, Accuracy: 0.9695000052452087\n",
      "Epoch 990: 0.08235141634941101, Accuracy: 0.9696000218391418\n",
      "Epoch 991: 0.08226197957992554, Accuracy: 0.9695000052452087\n",
      "Epoch 992: 0.08218010514974594, Accuracy: 0.9696000218391418\n",
      "Epoch 993: 0.0820910707116127, Accuracy: 0.9696000218391418\n",
      "Epoch 994: 0.08200990408658981, Accuracy: 0.9696999788284302\n",
      "Epoch 995: 0.0819217637181282, Accuracy: 0.9696000218391418\n",
      "Epoch 996: 0.08184143155813217, Accuracy: 0.9696999788284302\n",
      "Epoch 997: 0.08175388723611832, Accuracy: 0.9696000218391418\n",
      "Epoch 998: 0.08167374134063721, Accuracy: 0.9696999788284302\n",
      "Epoch 999: 0.08158668875694275, Accuracy: 0.9696000218391418\n",
      "Epoch 1000: 0.08150739967823029, Accuracy: 0.9696999788284302\n",
      "n_in:  784\n",
      "n_out:  10\n",
      "Epoch 1: 2.6047489643096924, Accuracy: 0.09799999743700027\n",
      "Epoch 2: 2.721940279006958, Accuracy: 0.08940000087022781\n",
      "Epoch 3: 2.3067405223846436, Accuracy: 0.0908999964594841\n",
      "Epoch 4: 2.30497145652771, Accuracy: 0.09109999984502792\n",
      "Epoch 5: 2.3040037155151367, Accuracy: 0.09120000153779984\n",
      "Epoch 6: 2.3033523559570312, Accuracy: 0.09179999679327011\n",
      "Epoch 7: 2.302839994430542, Accuracy: 0.09179999679327011\n",
      "Epoch 8: 2.3023743629455566, Accuracy: 0.09220000356435776\n",
      "Epoch 9: 2.3018887042999268, Accuracy: 0.09189999848604202\n",
      "Epoch 10: 2.301318407058716, Accuracy: 0.0925000011920929\n",
      "Epoch 11: 2.3005685806274414, Accuracy: 0.09440000355243683\n",
      "Epoch 12: 2.2994909286499023, Accuracy: 0.0940999984741211\n",
      "Epoch 13: 2.2978010177612305, Accuracy: 0.09480000287294388\n",
      "Epoch 14: 2.2949421405792236, Accuracy: 0.09520000219345093\n",
      "Epoch 15: 2.289860963821411, Accuracy: 0.09619999676942825\n",
      "Epoch 16: 2.2807650566101074, Accuracy: 0.09489999711513519\n",
      "Epoch 17: 2.265516757965088, Accuracy: 0.09830000251531601\n",
      "Epoch 18: 2.2451012134552, Accuracy: 0.10010000318288803\n",
      "Epoch 19: 2.2236034870147705, Accuracy: 0.1054999977350235\n",
      "Epoch 20: 2.202540159225464, Accuracy: 0.15639999508857727\n",
      "Epoch 21: 2.1830482482910156, Accuracy: 0.21050000190734863\n",
      "Epoch 22: 2.1643784046173096, Accuracy: 0.2459000051021576\n",
      "Epoch 23: 2.1449365615844727, Accuracy: 0.27309998869895935\n",
      "Epoch 24: 2.1235997676849365, Accuracy: 0.2971000075340271\n",
      "Epoch 25: 2.0996227264404297, Accuracy: 0.3156000077724457\n",
      "Epoch 26: 2.072273015975952, Accuracy: 0.334199994802475\n",
      "Epoch 27: 2.040970802307129, Accuracy: 0.357699990272522\n",
      "Epoch 28: 2.005342721939087, Accuracy: 0.3865000009536743\n",
      "Epoch 29: 1.9648163318634033, Accuracy: 0.42320001125335693\n",
      "Epoch 30: 1.9187227487564087, Accuracy: 0.4544999897480011\n",
      "Epoch 31: 1.8664699792861938, Accuracy: 0.5072000026702881\n",
      "Epoch 32: 1.808049201965332, Accuracy: 0.5195000171661377\n",
      "Epoch 33: 1.744089961051941, Accuracy: 0.5623999834060669\n",
      "Epoch 34: 1.6794297695159912, Accuracy: 0.5360000133514404\n",
      "Epoch 35: 1.6277862787246704, Accuracy: 0.48240000009536743\n",
      "Epoch 36: 1.6621627807617188, Accuracy: 0.3377000093460083\n",
      "Epoch 37: 1.7150152921676636, Accuracy: 0.32330000400543213\n",
      "Epoch 38: 2.092318296432495, Accuracy: 0.4997999966144562\n",
      "Epoch 39: 1.6950573921203613, Accuracy: 0.49380001425743103\n",
      "Epoch 40: 1.3727705478668213, Accuracy: 0.6001999974250793\n",
      "Epoch 41: 1.3485087156295776, Accuracy: 0.5845000147819519\n",
      "Epoch 42: 1.4524255990982056, Accuracy: 0.6604999899864197\n",
      "Epoch 43: 1.3418867588043213, Accuracy: 0.6021999716758728\n",
      "Epoch 44: 1.269559383392334, Accuracy: 0.4140999913215637\n",
      "Epoch 45: 1.7158770561218262, Accuracy: 0.35899999737739563\n",
      "Epoch 46: 1.770612359046936, Accuracy: 0.7287999987602234\n",
      "Epoch 47: 1.3680287599563599, Accuracy: 0.7677000164985657\n",
      "Epoch 48: 0.9916819930076599, Accuracy: 0.7361999750137329\n",
      "Epoch 49: 0.9108511805534363, Accuracy: 0.7063000202178955\n",
      "Epoch 50: 0.944812536239624, Accuracy: 0.5659999847412109\n",
      "Epoch 51: 1.3397090435028076, Accuracy: 0.5611000061035156\n",
      "Epoch 52: 1.235284686088562, Accuracy: 0.6820999979972839\n",
      "Epoch 53: 1.0128192901611328, Accuracy: 0.7936999797821045\n",
      "Epoch 54: 0.7702938914299011, Accuracy: 0.7634000182151794\n",
      "Epoch 55: 0.7713401317596436, Accuracy: 0.6198999881744385\n",
      "Epoch 56: 1.0230854749679565, Accuracy: 0.5457000136375427\n",
      "Epoch 57: 1.4338321685791016, Accuracy: 0.6029999852180481\n",
      "Epoch 58: 1.1072001457214355, Accuracy: 0.7526000142097473\n",
      "Epoch 59: 0.8031972646713257, Accuracy: 0.839900016784668\n",
      "Epoch 60: 0.6680006980895996, Accuracy: 0.8281999826431274\n",
      "Epoch 61: 0.6349583864212036, Accuracy: 0.82669997215271\n",
      "Epoch 62: 0.6416601538658142, Accuracy: 0.7594000101089478\n",
      "Epoch 63: 0.7487040758132935, Accuracy: 0.717199981212616\n",
      "Epoch 64: 1.0007189512252808, Accuracy: 0.7125999927520752\n",
      "Epoch 65: 0.9225714206695557, Accuracy: 0.7842000126838684\n",
      "Epoch 66: 0.7467488050460815, Accuracy: 0.829200029373169\n",
      "Epoch 67: 0.6330289244651794, Accuracy: 0.8152999877929688\n",
      "Epoch 68: 0.6254393458366394, Accuracy: 0.8208000063896179\n",
      "Epoch 69: 0.6267901062965393, Accuracy: 0.7796000242233276\n",
      "Epoch 70: 0.6821022033691406, Accuracy: 0.7692000269889832\n",
      "Epoch 71: 0.7092172503471375, Accuracy: 0.7333999872207642\n",
      "Epoch 72: 0.7697106599807739, Accuracy: 0.7817000150680542\n",
      "Epoch 73: 0.6794381737709045, Accuracy: 0.8154000043869019\n",
      "Epoch 74: 0.5936201810836792, Accuracy: 0.8370000123977661\n",
      "Epoch 75: 0.5453171730041504, Accuracy: 0.8345999717712402\n",
      "Epoch 76: 0.5313929915428162, Accuracy: 0.8149999976158142\n",
      "Epoch 77: 0.5459986925125122, Accuracy: 0.7918000221252441\n",
      "Epoch 78: 0.6132373213768005, Accuracy: 0.7324000000953674\n",
      "Epoch 79: 0.7744280099868774, Accuracy: 0.6970000267028809\n",
      "Epoch 80: 0.8404675722122192, Accuracy: 0.7064999938011169\n",
      "Epoch 81: 0.8293929100036621, Accuracy: 0.8158000111579895\n",
      "Epoch 82: 0.6432215571403503, Accuracy: 0.8637999892234802\n",
      "Epoch 83: 0.50741046667099, Accuracy: 0.8708000183105469\n",
      "Epoch 84: 0.48294275999069214, Accuracy: 0.8690999746322632\n",
      "Epoch 85: 0.4757738709449768, Accuracy: 0.866599977016449\n",
      "Epoch 86: 0.48094576597213745, Accuracy: 0.8504999876022339\n",
      "Epoch 87: 0.5027252435684204, Accuracy: 0.8348000049591064\n",
      "Epoch 88: 0.5485931634902954, Accuracy: 0.7957000136375427\n",
      "Epoch 89: 0.6352689266204834, Accuracy: 0.7818999886512756\n",
      "Epoch 90: 0.6703318953514099, Accuracy: 0.7985000014305115\n",
      "Epoch 91: 0.6230283379554749, Accuracy: 0.8486999869346619\n",
      "Epoch 92: 0.5290066003799438, Accuracy: 0.8708999752998352\n",
      "Epoch 93: 0.46832406520843506, Accuracy: 0.8780999779701233\n",
      "Epoch 94: 0.4478550851345062, Accuracy: 0.8788999915122986\n",
      "Epoch 95: 0.4389618933200836, Accuracy: 0.8795999884605408\n",
      "Epoch 96: 0.4345424175262451, Accuracy: 0.8736000061035156\n",
      "Epoch 97: 0.43813368678092957, Accuracy: 0.8722000122070312\n",
      "Epoch 98: 0.4421066641807556, Accuracy: 0.8551999926567078\n",
      "Epoch 99: 0.4658786654472351, Accuracy: 0.8482999801635742\n",
      "Epoch 100: 0.4800177812576294, Accuracy: 0.816100001335144\n",
      "Epoch 101: 0.5339516401290894, Accuracy: 0.8237000107765198\n",
      "Epoch 102: 0.518096387386322, Accuracy: 0.8281000256538391\n",
      "Epoch 103: 0.5142454504966736, Accuracy: 0.8615999817848206\n",
      "Epoch 104: 0.4585215449333191, Accuracy: 0.8751999735832214\n",
      "Epoch 105: 0.43122628331184387, Accuracy: 0.885200023651123\n",
      "Epoch 106: 0.412014901638031, Accuracy: 0.8863000273704529\n",
      "Epoch 107: 0.40335556864738464, Accuracy: 0.8899000287055969\n",
      "Epoch 108: 0.3969708979129791, Accuracy: 0.8902999758720398\n",
      "Epoch 109: 0.39353638887405396, Accuracy: 0.8906000256538391\n",
      "Epoch 110: 0.391084760427475, Accuracy: 0.8913999795913696\n",
      "Epoch 111: 0.38992539048194885, Accuracy: 0.8902999758720398\n",
      "Epoch 112: 0.3901398479938507, Accuracy: 0.8903999924659729\n",
      "Epoch 113: 0.3907150328159332, Accuracy: 0.8881000280380249\n",
      "Epoch 114: 0.39440712332725525, Accuracy: 0.8859999775886536\n",
      "Epoch 115: 0.396001935005188, Accuracy: 0.8823999762535095\n",
      "Epoch 116: 0.4037613868713379, Accuracy: 0.8823000192642212\n",
      "Epoch 117: 0.40266284346580505, Accuracy: 0.8784999847412109\n",
      "Epoch 118: 0.4113876521587372, Accuracy: 0.8827000260353088\n",
      "Epoch 119: 0.4018358290195465, Accuracy: 0.8812999725341797\n",
      "Epoch 120: 0.40477418899536133, Accuracy: 0.8884000182151794\n",
      "Epoch 121: 0.389751136302948, Accuracy: 0.8895000219345093\n",
      "Epoch 122: 0.3878299593925476, Accuracy: 0.8944000005722046\n",
      "Epoch 123: 0.37573301792144775, Accuracy: 0.8944000005722046\n",
      "Epoch 124: 0.37344756722450256, Accuracy: 0.8981000185012817\n",
      "Epoch 125: 0.365665078163147, Accuracy: 0.8973000049591064\n",
      "Epoch 126: 0.36427435278892517, Accuracy: 0.9006999731063843\n",
      "Epoch 127: 0.3591492474079132, Accuracy: 0.8988999724388123\n",
      "Epoch 128: 0.35851284861564636, Accuracy: 0.9021000266075134\n",
      "Epoch 129: 0.35483333468437195, Accuracy: 0.8992000222206116\n",
      "Epoch 130: 0.3548487424850464, Accuracy: 0.902899980545044\n",
      "Epoch 131: 0.35199296474456787, Accuracy: 0.8995000123977661\n",
      "Epoch 132: 0.3526795208454132, Accuracy: 0.9020000100135803\n",
      "Epoch 133: 0.35037893056869507, Accuracy: 0.8992000222206116\n",
      "Epoch 134: 0.3518000841140747, Accuracy: 0.9017999768257141\n",
      "Epoch 135: 0.3499724268913269, Accuracy: 0.8999999761581421\n",
      "Epoch 136: 0.35220977663993835, Accuracy: 0.9017999768257141\n",
      "Epoch 137: 0.35081079602241516, Accuracy: 0.8999999761581421\n",
      "Epoch 138: 0.3537434935569763, Accuracy: 0.9007999897003174\n",
      "Epoch 139: 0.35272839665412903, Accuracy: 0.8988999724388123\n",
      "Epoch 140: 0.35596948862075806, Accuracy: 0.8996999859809875\n",
      "Epoch 141: 0.35516080260276794, Accuracy: 0.8988000154495239\n",
      "Epoch 142: 0.3578417897224426, Accuracy: 0.9007999897003174\n",
      "Epoch 143: 0.3568374216556549, Accuracy: 0.8996999859809875\n",
      "Epoch 144: 0.35793861746788025, Accuracy: 0.9003999829292297\n",
      "Epoch 145: 0.3561255633831024, Accuracy: 0.9007999897003174\n",
      "Epoch 146: 0.35501813888549805, Accuracy: 0.900600016117096\n",
      "Epoch 147: 0.351958304643631, Accuracy: 0.902400016784668\n",
      "Epoch 148: 0.34916025400161743, Accuracy: 0.9027000069618225\n",
      "Epoch 149: 0.3452811539173126, Accuracy: 0.9042999744415283\n",
      "Epoch 150: 0.34187543392181396, Accuracy: 0.9039000272750854\n",
      "Epoch 151: 0.3379673957824707, Accuracy: 0.9071000218391418\n",
      "Epoch 152: 0.33488425612449646, Accuracy: 0.9057999849319458\n",
      "Epoch 153: 0.3314686417579651, Accuracy: 0.90829998254776\n",
      "Epoch 154: 0.3290557861328125, Accuracy: 0.9078999757766724\n",
      "Epoch 155: 0.32621556520462036, Accuracy: 0.9089999794960022\n",
      "Epoch 156: 0.3244180381298065, Accuracy: 0.9078999757766724\n",
      "Epoch 157: 0.3221052587032318, Accuracy: 0.909600019454956\n",
      "Epoch 158: 0.32081884145736694, Accuracy: 0.9085999727249146\n",
      "Epoch 159: 0.318907767534256, Accuracy: 0.9097999930381775\n",
      "Epoch 160: 0.31799089908599854, Accuracy: 0.909500002861023\n",
      "Epoch 161: 0.3163903057575226, Accuracy: 0.9103999733924866\n",
      "Epoch 162: 0.31579193472862244, Accuracy: 0.9103999733924866\n",
      "Epoch 163: 0.31445378065109253, Accuracy: 0.9108999967575073\n",
      "Epoch 164: 0.3141205608844757, Accuracy: 0.9104999899864197\n",
      "Epoch 165: 0.3130168318748474, Accuracy: 0.911300003528595\n",
      "Epoch 166: 0.31293386220932007, Accuracy: 0.9103000164031982\n",
      "Epoch 167: 0.31205838918685913, Accuracy: 0.9125000238418579\n",
      "Epoch 168: 0.3121846616268158, Accuracy: 0.9099000096321106\n",
      "Epoch 169: 0.31154167652130127, Accuracy: 0.9121000170707703\n",
      "Epoch 170: 0.31179648637771606, Accuracy: 0.9093000292778015\n",
      "Epoch 171: 0.31134718656539917, Accuracy: 0.9117000102996826\n",
      "Epoch 172: 0.31158682703971863, Accuracy: 0.9088000059127808\n",
      "Epoch 173: 0.3112196624279022, Accuracy: 0.9118000268936157\n",
      "Epoch 174: 0.311195969581604, Accuracy: 0.9088000059127808\n",
      "Epoch 175: 0.3107224106788635, Accuracy: 0.9120000004768372\n",
      "Epoch 176: 0.3101732134819031, Accuracy: 0.9089000225067139\n",
      "Epoch 177: 0.3093976676464081, Accuracy: 0.9121999740600586\n",
      "Epoch 178: 0.3081918954849243, Accuracy: 0.9111999869346619\n",
      "Epoch 179: 0.3069775104522705, Accuracy: 0.9129999876022339\n",
      "Epoch 180: 0.3051929473876953, Accuracy: 0.9120000004768372\n",
      "Epoch 181: 0.30362245440483093, Accuracy: 0.9138000011444092\n",
      "Epoch 182: 0.30156248807907104, Accuracy: 0.9140999913215637\n",
      "Epoch 183: 0.2998407483100891, Accuracy: 0.9150000214576721\n",
      "Epoch 184: 0.29779645800590515, Accuracy: 0.9143000245094299\n",
      "Epoch 185: 0.29614001512527466, Accuracy: 0.9164999723434448\n",
      "Epoch 186: 0.29429832100868225, Accuracy: 0.9154000282287598\n",
      "Epoch 187: 0.29280510544776917, Accuracy: 0.9172999858856201\n",
      "Epoch 188: 0.2912074625492096, Accuracy: 0.9172999858856201\n",
      "Epoch 189: 0.28987768292427063, Accuracy: 0.9182000160217285\n",
      "Epoch 190: 0.28849777579307556, Accuracy: 0.9176999926567078\n",
      "Epoch 191: 0.28732946515083313, Accuracy: 0.9190000295639038\n",
      "Epoch 192: 0.28612515330314636, Accuracy: 0.9182999730110168\n",
      "Epoch 193: 0.285089373588562, Accuracy: 0.9200999736785889\n",
      "Epoch 194: 0.2840087115764618, Accuracy: 0.9186000227928162\n",
      "Epoch 195: 0.2830790877342224, Accuracy: 0.9205999970436096\n",
      "Epoch 196: 0.28210341930389404, Accuracy: 0.9190000295639038\n",
      "Epoch 197: 0.28125134110450745, Accuracy: 0.9208999872207642\n",
      "Epoch 198: 0.2803501486778259, Accuracy: 0.9200999736785889\n",
      "Epoch 199: 0.27955886721611023, Accuracy: 0.9207000136375427\n",
      "Epoch 200: 0.2787128686904907, Accuracy: 0.9205999970436096\n",
      "Epoch 201: 0.27797237038612366, Accuracy: 0.9211999773979187\n",
      "Epoch 202: 0.2771660387516022, Accuracy: 0.9211000204086304\n",
      "Epoch 203: 0.27646031975746155, Accuracy: 0.9214000105857849\n",
      "Epoch 204: 0.2756901681423187, Accuracy: 0.9218000173568726\n",
      "Epoch 205: 0.2750258147716522, Accuracy: 0.9215999841690063\n",
      "Epoch 206: 0.2742862403392792, Accuracy: 0.9218000173568726\n",
      "Epoch 207: 0.27365386486053467, Accuracy: 0.9218999743461609\n",
      "Epoch 208: 0.27293989062309265, Accuracy: 0.9222000241279602\n",
      "Epoch 209: 0.2723371684551239, Accuracy: 0.9222999811172485\n",
      "Epoch 210: 0.2716456353664398, Accuracy: 0.9223999977111816\n",
      "Epoch 211: 0.27106863260269165, Accuracy: 0.9232000112533569\n",
      "Epoch 212: 0.2703990042209625, Accuracy: 0.9229000210762024\n",
      "Epoch 213: 0.2698502242565155, Accuracy: 0.9235000014305115\n",
      "Epoch 214: 0.26919984817504883, Accuracy: 0.92330002784729\n",
      "Epoch 215: 0.2686815857887268, Accuracy: 0.9239000082015991\n",
      "Epoch 216: 0.26805219054222107, Accuracy: 0.9236000180244446\n",
      "Epoch 217: 0.26757121086120605, Accuracy: 0.9240000247955322\n",
      "Epoch 218: 0.26695892214775085, Accuracy: 0.923799991607666\n",
      "Epoch 219: 0.26651567220687866, Accuracy: 0.9240999817848206\n",
      "Epoch 220: 0.2659217417240143, Accuracy: 0.9240000247955322\n",
      "Epoch 221: 0.26550766825675964, Accuracy: 0.9240999817848206\n",
      "Epoch 222: 0.26492902636528015, Accuracy: 0.9243000149726868\n",
      "Epoch 223: 0.2645469605922699, Accuracy: 0.9243000149726868\n",
      "Epoch 224: 0.26397350430488586, Accuracy: 0.9247000217437744\n",
      "Epoch 225: 0.26361599564552307, Accuracy: 0.9248999953269958\n",
      "Epoch 226: 0.2630392014980316, Accuracy: 0.9246000051498413\n",
      "Epoch 227: 0.26270368695259094, Accuracy: 0.925000011920929\n",
      "Epoch 228: 0.2621125876903534, Accuracy: 0.9254000186920166\n",
      "Epoch 229: 0.2617921829223633, Accuracy: 0.925000011920929\n",
      "Epoch 230: 0.26118409633636475, Accuracy: 0.9258000254631042\n",
      "Epoch 231: 0.2608678340911865, Accuracy: 0.9251000285148621\n",
      "Epoch 232: 0.26022985577583313, Accuracy: 0.9259999990463257\n",
      "Epoch 233: 0.2599044740200043, Accuracy: 0.9247000217437744\n",
      "Epoch 234: 0.25923559069633484, Accuracy: 0.9262999892234802\n",
      "Epoch 235: 0.2588900625705719, Accuracy: 0.9254000186920166\n",
      "Epoch 236: 0.258188396692276, Accuracy: 0.9262999892234802\n",
      "Epoch 237: 0.2578221261501312, Accuracy: 0.925599992275238\n",
      "Epoch 238: 0.25707629323005676, Accuracy: 0.9262999892234802\n",
      "Epoch 239: 0.2566726803779602, Accuracy: 0.9258000254631042\n",
      "Epoch 240: 0.25588446855545044, Accuracy: 0.9266999959945679\n",
      "Epoch 241: 0.2554321885108948, Accuracy: 0.9261000156402588\n",
      "Epoch 242: 0.25461795926094055, Accuracy: 0.9269000291824341\n",
      "Epoch 243: 0.2541169226169586, Accuracy: 0.9269000291824341\n",
      "Epoch 244: 0.25327736139297485, Accuracy: 0.927299976348877\n",
      "Epoch 245: 0.25273364782333374, Accuracy: 0.9269999861717224\n",
      "Epoch 246: 0.2518767714500427, Accuracy: 0.9276999831199646\n",
      "Epoch 247: 0.25129663944244385, Accuracy: 0.9279000163078308\n",
      "Epoch 248: 0.2504490613937378, Accuracy: 0.9279000163078308\n",
      "Epoch 249: 0.24984712898731232, Accuracy: 0.9286999702453613\n",
      "Epoch 250: 0.24901500344276428, Accuracy: 0.9283999800682068\n",
      "Epoch 251: 0.24839910864830017, Accuracy: 0.9294999837875366\n",
      "Epoch 252: 0.24758446216583252, Accuracy: 0.9290000200271606\n",
      "Epoch 253: 0.24696588516235352, Accuracy: 0.9301999807357788\n",
      "Epoch 254: 0.24617698788642883, Accuracy: 0.9297000169754028\n",
      "Epoch 255: 0.2455577850341797, Accuracy: 0.9305999875068665\n",
      "Epoch 256: 0.24480053782463074, Accuracy: 0.9298999905586243\n",
      "Epoch 257: 0.24418288469314575, Accuracy: 0.9311000108718872\n",
      "Epoch 258: 0.24344708025455475, Accuracy: 0.9297000169754028\n",
      "Epoch 259: 0.24283868074417114, Accuracy: 0.9312999844551086\n",
      "Epoch 260: 0.24212540686130524, Accuracy: 0.9300000071525574\n",
      "Epoch 261: 0.2415306568145752, Accuracy: 0.9318000078201294\n",
      "Epoch 262: 0.24084070324897766, Accuracy: 0.9302999973297119\n",
      "Epoch 263: 0.24025586247444153, Accuracy: 0.9316999912261963\n",
      "Epoch 264: 0.23959071934223175, Accuracy: 0.9307000041007996\n",
      "Epoch 265: 0.2390137016773224, Accuracy: 0.9320999979972839\n",
      "Epoch 266: 0.23836715519428253, Accuracy: 0.9308000206947327\n",
      "Epoch 267: 0.2377990335226059, Accuracy: 0.9326000213623047\n",
      "Epoch 268: 0.23717498779296875, Accuracy: 0.9311000108718872\n",
      "Epoch 269: 0.236619234085083, Accuracy: 0.9327999949455261\n",
      "Epoch 270: 0.23601514101028442, Accuracy: 0.9312999844551086\n",
      "Epoch 271: 0.23547643423080444, Accuracy: 0.9330000281333923\n",
      "Epoch 272: 0.2348921149969101, Accuracy: 0.9314000010490417\n",
      "Epoch 273: 0.2343629002571106, Accuracy: 0.9332000017166138\n",
      "Epoch 274: 0.2337944656610489, Accuracy: 0.9319000244140625\n",
      "Epoch 275: 0.2332744151353836, Accuracy: 0.9333999752998352\n",
      "Epoch 276: 0.23272231221199036, Accuracy: 0.9325000047683716\n",
      "Epoch 277: 0.23221106827259064, Accuracy: 0.9337999820709229\n",
      "Epoch 278: 0.23167011141777039, Accuracy: 0.9327999949455261\n",
      "Epoch 279: 0.2311667799949646, Accuracy: 0.934499979019165\n",
      "Epoch 280: 0.2306341975927353, Accuracy: 0.9332000017166138\n",
      "Epoch 281: 0.23013964295387268, Accuracy: 0.9344000220298767\n",
      "Epoch 282: 0.2296151965856552, Accuracy: 0.9333999752998352\n",
      "Epoch 283: 0.22913019359111786, Accuracy: 0.9348999857902527\n",
      "Epoch 284: 0.22861605882644653, Accuracy: 0.9337000250816345\n",
      "Epoch 285: 0.22813250124454498, Accuracy: 0.9352999925613403\n",
      "Epoch 286: 0.22762951254844666, Accuracy: 0.9336000084877014\n",
      "Epoch 287: 0.22715362906455994, Accuracy: 0.9354000091552734\n",
      "Epoch 288: 0.22665618360042572, Accuracy: 0.933899998664856\n",
      "Epoch 289: 0.22618989646434784, Accuracy: 0.9355999827384949\n",
      "Epoch 290: 0.22570063173770905, Accuracy: 0.9341999888420105\n",
      "Epoch 291: 0.22523722052574158, Accuracy: 0.9359999895095825\n",
      "Epoch 292: 0.22474874556064606, Accuracy: 0.9341999888420105\n",
      "Epoch 293: 0.2242884784936905, Accuracy: 0.9362999796867371\n",
      "Epoch 294: 0.2238064557313919, Accuracy: 0.934499979019165\n",
      "Epoch 295: 0.22335098683834076, Accuracy: 0.9366999864578247\n",
      "Epoch 296: 0.22287334501743317, Accuracy: 0.9350000023841858\n",
      "Epoch 297: 0.22242185473442078, Accuracy: 0.9366999864578247\n",
      "Epoch 298: 0.22195173799991608, Accuracy: 0.9350000023841858\n",
      "Epoch 299: 0.221504807472229, Accuracy: 0.9370999932289124\n",
      "Epoch 300: 0.22103683650493622, Accuracy: 0.9354000091552734\n",
      "Epoch 301: 0.22059057652950287, Accuracy: 0.9373000264167786\n",
      "Epoch 302: 0.22012366354465485, Accuracy: 0.9358000159263611\n",
      "Epoch 303: 0.21968242526054382, Accuracy: 0.9375\n",
      "Epoch 304: 0.21921730041503906, Accuracy: 0.9361000061035156\n",
      "Epoch 305: 0.21878021955490112, Accuracy: 0.9373999834060669\n",
      "Epoch 306: 0.21832138299942017, Accuracy: 0.9363999962806702\n",
      "Epoch 307: 0.2178891897201538, Accuracy: 0.9376000165939331\n",
      "Epoch 308: 0.21743109822273254, Accuracy: 0.9366999864578247\n",
      "Epoch 309: 0.21700182557106018, Accuracy: 0.9379000067710876\n",
      "Epoch 310: 0.21654962003231049, Accuracy: 0.9369000196456909\n",
      "Epoch 311: 0.21612198650836945, Accuracy: 0.9380999803543091\n",
      "Epoch 312: 0.21567457914352417, Accuracy: 0.9373999834060669\n",
      "Epoch 313: 0.21525004506111145, Accuracy: 0.9383000135421753\n",
      "Epoch 314: 0.21480515599250793, Accuracy: 0.9379000067710876\n",
      "Epoch 315: 0.21438433229923248, Accuracy: 0.9387000203132629\n",
      "Epoch 316: 0.2139422595500946, Accuracy: 0.9383000135421753\n",
      "Epoch 317: 0.21352235972881317, Accuracy: 0.939300000667572\n",
      "Epoch 318: 0.21307958662509918, Accuracy: 0.9384999871253967\n",
      "Epoch 319: 0.21266232430934906, Accuracy: 0.9395999908447266\n",
      "Epoch 320: 0.2122192233800888, Accuracy: 0.9387000203132629\n",
      "Epoch 321: 0.21179886162281036, Accuracy: 0.9395999908447266\n",
      "Epoch 322: 0.21135902404785156, Accuracy: 0.9391000270843506\n",
      "Epoch 323: 0.2109408676624298, Accuracy: 0.9395999908447266\n",
      "Epoch 324: 0.21049733459949493, Accuracy: 0.9394999742507935\n",
      "Epoch 325: 0.2100813239812851, Accuracy: 0.9399999976158142\n",
      "Epoch 326: 0.2096404880285263, Accuracy: 0.9398000240325928\n",
      "Epoch 327: 0.209224134683609, Accuracy: 0.9401000142097473\n",
      "Epoch 328: 0.20878712832927704, Accuracy: 0.9401000142097473\n",
      "Epoch 329: 0.20837196707725525, Accuracy: 0.9401000142097473\n",
      "Epoch 330: 0.2079385370016098, Accuracy: 0.9401999711990356\n",
      "Epoch 331: 0.20752321183681488, Accuracy: 0.9402999877929688\n",
      "Epoch 332: 0.20709611475467682, Accuracy: 0.9405999779701233\n",
      "Epoch 333: 0.20668098330497742, Accuracy: 0.940500020980835\n",
      "Epoch 334: 0.20625293254852295, Accuracy: 0.9406999945640564\n",
      "Epoch 335: 0.20583543181419373, Accuracy: 0.9405999779701233\n",
      "Epoch 336: 0.20540867745876312, Accuracy: 0.9409000277519226\n",
      "Epoch 337: 0.204995796084404, Accuracy: 0.9409000277519226\n",
      "Epoch 338: 0.20457114279270172, Accuracy: 0.9412999749183655\n",
      "Epoch 339: 0.20416082441806793, Accuracy: 0.941100001335144\n",
      "Epoch 340: 0.2037346363067627, Accuracy: 0.9413999915122986\n",
      "Epoch 341: 0.20332540571689606, Accuracy: 0.9415000081062317\n",
      "Epoch 342: 0.20290040969848633, Accuracy: 0.9416000247001648\n",
      "Epoch 343: 0.20249530673027039, Accuracy: 0.9415000081062317\n",
      "Epoch 344: 0.20207686722278595, Accuracy: 0.9416999816894531\n",
      "Epoch 345: 0.2016749233007431, Accuracy: 0.9416000247001648\n",
      "Epoch 346: 0.20126095414161682, Accuracy: 0.9417999982833862\n",
      "Epoch 347: 0.20086179673671722, Accuracy: 0.9417999982833862\n",
      "Epoch 348: 0.20045116543769836, Accuracy: 0.9420999884605408\n",
      "Epoch 349: 0.2000531256198883, Accuracy: 0.9422000050544739\n",
      "Epoch 350: 0.19964423775672913, Accuracy: 0.942300021648407\n",
      "Epoch 351: 0.1992505043745041, Accuracy: 0.9420999884605408\n",
      "Epoch 352: 0.1988449990749359, Accuracy: 0.9426000118255615\n",
      "Epoch 353: 0.19845376908779144, Accuracy: 0.9424999952316284\n",
      "Epoch 354: 0.19805356860160828, Accuracy: 0.942799985408783\n",
      "Epoch 355: 0.1976671814918518, Accuracy: 0.9430000185966492\n",
      "Epoch 356: 0.1972721517086029, Accuracy: 0.9429000020027161\n",
      "Epoch 357: 0.1968897581100464, Accuracy: 0.9434999823570251\n",
      "Epoch 358: 0.196497842669487, Accuracy: 0.9434000253677368\n",
      "Epoch 359: 0.19611701369285583, Accuracy: 0.9437000155448914\n",
      "Epoch 360: 0.1957278698682785, Accuracy: 0.9435999989509583\n",
      "Epoch 361: 0.19534900784492493, Accuracy: 0.9438999891281128\n",
      "Epoch 362: 0.19496163725852966, Accuracy: 0.9438999891281128\n",
      "Epoch 363: 0.19458532333374023, Accuracy: 0.944100022315979\n",
      "Epoch 364: 0.19419845938682556, Accuracy: 0.9441999793052673\n",
      "Epoch 365: 0.19382578134536743, Accuracy: 0.9442999958992004\n",
      "Epoch 366: 0.19344063103199005, Accuracy: 0.944599986076355\n",
      "Epoch 367: 0.19306820631027222, Accuracy: 0.9442999958992004\n",
      "Epoch 368: 0.19268609583377838, Accuracy: 0.9448000192642212\n",
      "Epoch 369: 0.1923139989376068, Accuracy: 0.9442999958992004\n",
      "Epoch 370: 0.1919359564781189, Accuracy: 0.9452000260353088\n",
      "Epoch 371: 0.19156549870967865, Accuracy: 0.9444000124931335\n",
      "Epoch 372: 0.1911887228488922, Accuracy: 0.9455999732017517\n",
      "Epoch 373: 0.1908188760280609, Accuracy: 0.9445000290870667\n",
      "Epoch 374: 0.19044405221939087, Accuracy: 0.945900022983551\n",
      "Epoch 375: 0.19007804989814758, Accuracy: 0.9447000026702881\n",
      "Epoch 376: 0.1897084265947342, Accuracy: 0.9460999965667725\n",
      "Epoch 377: 0.18934644758701324, Accuracy: 0.9448999762535095\n",
      "Epoch 378: 0.18898038566112518, Accuracy: 0.9460999965667725\n",
      "Epoch 379: 0.18862424790859222, Accuracy: 0.9451000094413757\n",
      "Epoch 380: 0.1882624626159668, Accuracy: 0.9460999965667725\n",
      "Epoch 381: 0.18790684640407562, Accuracy: 0.9452999830245972\n",
      "Epoch 382: 0.18754784762859344, Accuracy: 0.9463000297546387\n",
      "Epoch 383: 0.187196284532547, Accuracy: 0.9452999830245972\n",
      "Epoch 384: 0.18683992326259613, Accuracy: 0.9463000297546387\n",
      "Epoch 385: 0.1864914894104004, Accuracy: 0.9452999830245972\n",
      "Epoch 386: 0.1861390918493271, Accuracy: 0.9465000033378601\n",
      "Epoch 387: 0.1857932060956955, Accuracy: 0.9456999897956848\n",
      "Epoch 388: 0.18544581532478333, Accuracy: 0.9465000033378601\n",
      "Epoch 389: 0.1851017326116562, Accuracy: 0.9455999732017517\n",
      "Epoch 390: 0.18475715816020966, Accuracy: 0.9466999769210815\n",
      "Epoch 391: 0.18441544473171234, Accuracy: 0.945900022983551\n",
      "Epoch 392: 0.18407288193702698, Accuracy: 0.9470999836921692\n",
      "Epoch 393: 0.1837335228919983, Accuracy: 0.9460999965667725\n",
      "Epoch 394: 0.18339477479457855, Accuracy: 0.9473999738693237\n",
      "Epoch 395: 0.1830567568540573, Accuracy: 0.9463000297546387\n",
      "Epoch 396: 0.1827203929424286, Accuracy: 0.9472000002861023\n",
      "Epoch 397: 0.18238449096679688, Accuracy: 0.9466000199317932\n",
      "Epoch 398: 0.18204987049102783, Accuracy: 0.9473000168800354\n",
      "Epoch 399: 0.18171843886375427, Accuracy: 0.9469000101089478\n",
      "Epoch 400: 0.18138648569583893, Accuracy: 0.9472000002861023\n",
      "Epoch 401: 0.18105702102184296, Accuracy: 0.9473000168800354\n",
      "Epoch 402: 0.18072789907455444, Accuracy: 0.9473000168800354\n",
      "Epoch 403: 0.18040096759796143, Accuracy: 0.9473000168800354\n",
      "Epoch 404: 0.18007434904575348, Accuracy: 0.9473999738693237\n",
      "Epoch 405: 0.17974868416786194, Accuracy: 0.9474999904632568\n",
      "Epoch 406: 0.1794241964817047, Accuracy: 0.9476000070571899\n",
      "Epoch 407: 0.1791001856327057, Accuracy: 0.947700023651123\n",
      "Epoch 408: 0.17877893149852753, Accuracy: 0.9476000070571899\n",
      "Epoch 409: 0.17845721542835236, Accuracy: 0.9480000138282776\n",
      "Epoch 410: 0.17813760042190552, Accuracy: 0.9477999806404114\n",
      "Epoch 411: 0.17781759798526764, Accuracy: 0.9480000138282776\n",
      "Epoch 412: 0.1774994432926178, Accuracy: 0.9480999708175659\n",
      "Epoch 413: 0.17718183994293213, Accuracy: 0.9480999708175659\n",
      "Epoch 414: 0.17686541378498077, Accuracy: 0.9484999775886536\n",
      "Epoch 415: 0.17655138671398163, Accuracy: 0.948199987411499\n",
      "Epoch 416: 0.17623713612556458, Accuracy: 0.9485999941825867\n",
      "Epoch 417: 0.17592410743236542, Accuracy: 0.9480999708175659\n",
      "Epoch 418: 0.17561355233192444, Accuracy: 0.9485999941825867\n",
      "Epoch 419: 0.17530253529548645, Accuracy: 0.9480000138282776\n",
      "Epoch 420: 0.17499254643917084, Accuracy: 0.9484000205993652\n",
      "Epoch 421: 0.17468377947807312, Accuracy: 0.948199987411499\n",
      "Epoch 422: 0.1743762493133545, Accuracy: 0.9484000205993652\n",
      "Epoch 423: 0.17406946420669556, Accuracy: 0.948199987411499\n",
      "Epoch 424: 0.17376387119293213, Accuracy: 0.9483000040054321\n",
      "Epoch 425: 0.17346011102199554, Accuracy: 0.9485999941825867\n",
      "Epoch 426: 0.17315661907196045, Accuracy: 0.9483000040054321\n",
      "Epoch 427: 0.1728547066450119, Accuracy: 0.9487000107765198\n",
      "Epoch 428: 0.17255306243896484, Accuracy: 0.9484999775886536\n",
      "Epoch 429: 0.17225316166877747, Accuracy: 0.9491000175476074\n",
      "Epoch 430: 0.17195314168930054, Accuracy: 0.9487000107765198\n",
      "Epoch 431: 0.1716560572385788, Accuracy: 0.9491000175476074\n",
      "Epoch 432: 0.1713586300611496, Accuracy: 0.9488000273704529\n",
      "Epoch 433: 0.17106372117996216, Accuracy: 0.9492999911308289\n",
      "Epoch 434: 0.17076827585697174, Accuracy: 0.9490000009536743\n",
      "Epoch 435: 0.1704745888710022, Accuracy: 0.9492999911308289\n",
      "Epoch 436: 0.17018093168735504, Accuracy: 0.9491999745368958\n",
      "Epoch 437: 0.1698894053697586, Accuracy: 0.949400007724762\n",
      "Epoch 438: 0.16959761083126068, Accuracy: 0.9492999911308289\n",
      "Epoch 439: 0.16930748522281647, Accuracy: 0.949400007724762\n",
      "Epoch 440: 0.16901859641075134, Accuracy: 0.9492999911308289\n",
      "Epoch 441: 0.16872933506965637, Accuracy: 0.9495000243186951\n",
      "Epoch 442: 0.16844165325164795, Accuracy: 0.9495000243186951\n",
      "Epoch 443: 0.16815342009067535, Accuracy: 0.949400007724762\n",
      "Epoch 444: 0.16786593198776245, Accuracy: 0.9495999813079834\n",
      "Epoch 445: 0.16758011281490326, Accuracy: 0.949400007724762\n",
      "Epoch 446: 0.16729344427585602, Accuracy: 0.9495999813079834\n",
      "Epoch 447: 0.16700853407382965, Accuracy: 0.9495000243186951\n",
      "Epoch 448: 0.1667231321334839, Accuracy: 0.9498000144958496\n",
      "Epoch 449: 0.16643886268138885, Accuracy: 0.9495999813079834\n",
      "Epoch 450: 0.16615517437458038, Accuracy: 0.9498999714851379\n",
      "Epoch 451: 0.165871724486351, Accuracy: 0.9496999979019165\n",
      "Epoch 452: 0.16559015214443207, Accuracy: 0.9498999714851379\n",
      "Epoch 453: 0.16530820727348328, Accuracy: 0.949999988079071\n",
      "Epoch 454: 0.1650291085243225, Accuracy: 0.9498999714851379\n",
      "Epoch 455: 0.16474944353103638, Accuracy: 0.9502000212669373\n",
      "Epoch 456: 0.16447192430496216, Accuracy: 0.949999988079071\n",
      "Epoch 457: 0.16419439017772675, Accuracy: 0.9502999782562256\n",
      "Epoch 458: 0.16391804814338684, Accuracy: 0.9501000046730042\n",
      "Epoch 459: 0.16364307701587677, Accuracy: 0.9505000114440918\n",
      "Epoch 460: 0.16336899995803833, Accuracy: 0.9502000212669373\n",
      "Epoch 461: 0.16309550404548645, Accuracy: 0.9506000280380249\n",
      "Epoch 462: 0.16282257437705994, Accuracy: 0.9502000212669373\n",
      "Epoch 463: 0.16255217790603638, Accuracy: 0.9509000182151794\n",
      "Epoch 464: 0.1622815579175949, Accuracy: 0.9502999782562256\n",
      "Epoch 465: 0.16201277077198029, Accuracy: 0.9509999752044678\n",
      "Epoch 466: 0.16174378991127014, Accuracy: 0.9503999948501587\n",
      "Epoch 467: 0.16147661209106445, Accuracy: 0.9513999819755554\n",
      "Epoch 468: 0.16120915114879608, Accuracy: 0.9505000114440918\n",
      "Epoch 469: 0.1609429568052292, Accuracy: 0.9513999819755554\n",
      "Epoch 470: 0.16067706048488617, Accuracy: 0.9506999850273132\n",
      "Epoch 471: 0.16041189432144165, Accuracy: 0.9513999819755554\n",
      "Epoch 472: 0.1601477563381195, Accuracy: 0.9508000016212463\n",
      "Epoch 473: 0.15988416969776154, Accuracy: 0.9514999985694885\n",
      "Epoch 474: 0.15962128341197968, Accuracy: 0.9509999752044678\n",
      "Epoch 475: 0.15935951471328735, Accuracy: 0.9514999985694885\n",
      "Epoch 476: 0.15909820795059204, Accuracy: 0.9510999917984009\n",
      "Epoch 477: 0.15883769094944, Accuracy: 0.95169997215271\n",
      "Epoch 478: 0.1585780382156372, Accuracy: 0.9513000249862671\n",
      "Epoch 479: 0.1583194136619568, Accuracy: 0.95169997215271\n",
      "Epoch 480: 0.1580614596605301, Accuracy: 0.9514999985694885\n",
      "Epoch 481: 0.15780413150787354, Accuracy: 0.95169997215271\n",
      "Epoch 482: 0.1575472503900528, Accuracy: 0.9516000151634216\n",
      "Epoch 483: 0.15729162096977234, Accuracy: 0.9519000053405762\n",
      "Epoch 484: 0.15703649818897247, Accuracy: 0.9517999887466431\n",
      "Epoch 485: 0.1567825824022293, Accuracy: 0.9520000219345093\n",
      "Epoch 486: 0.1565287560224533, Accuracy: 0.9519000053405762\n",
      "Epoch 487: 0.15627603232860565, Accuracy: 0.9520999789237976\n",
      "Epoch 488: 0.15602336823940277, Accuracy: 0.9519000053405762\n",
      "Epoch 489: 0.15577179193496704, Accuracy: 0.9521999955177307\n",
      "Epoch 490: 0.15552064776420593, Accuracy: 0.9519000053405762\n",
      "Epoch 491: 0.15527068078517914, Accuracy: 0.9521999955177307\n",
      "Epoch 492: 0.15502125024795532, Accuracy: 0.9520000219345093\n",
      "Epoch 493: 0.15477240085601807, Accuracy: 0.9523000121116638\n",
      "Epoch 494: 0.15452441573143005, Accuracy: 0.9520999789237976\n",
      "Epoch 495: 0.15427759289741516, Accuracy: 0.9524999856948853\n",
      "Epoch 496: 0.15403124690055847, Accuracy: 0.9523000121116638\n",
      "Epoch 497: 0.1537855565547943, Accuracy: 0.9526000022888184\n",
      "Epoch 498: 0.1535404920578003, Accuracy: 0.9524999856948853\n",
      "Epoch 499: 0.15329666435718536, Accuracy: 0.9531999826431274\n",
      "Epoch 500: 0.15305320918560028, Accuracy: 0.9528999924659729\n",
      "Epoch 501: 0.1528109908103943, Accuracy: 0.9534000158309937\n",
      "Epoch 502: 0.15256918966770172, Accuracy: 0.9531000256538391\n",
      "Epoch 503: 0.1523282527923584, Accuracy: 0.953499972820282\n",
      "Epoch 504: 0.15208768844604492, Accuracy: 0.9532999992370605\n",
      "Epoch 505: 0.1518479883670807, Accuracy: 0.9539999961853027\n",
      "Epoch 506: 0.15160925686359406, Accuracy: 0.953499972820282\n",
      "Epoch 507: 0.15137101709842682, Accuracy: 0.954200029373169\n",
      "Epoch 508: 0.1511334329843521, Accuracy: 0.953499972820282\n",
      "Epoch 509: 0.15089623630046844, Accuracy: 0.954200029373169\n",
      "Epoch 510: 0.15066000819206238, Accuracy: 0.953499972820282\n",
      "Epoch 511: 0.1504240185022354, Accuracy: 0.954200029373169\n",
      "Epoch 512: 0.15018907189369202, Accuracy: 0.9538000226020813\n",
      "Epoch 513: 0.1499548703432083, Accuracy: 0.9544000029563904\n",
      "Epoch 514: 0.14972130954265594, Accuracy: 0.9538999795913696\n",
      "Epoch 515: 0.14948831498622894, Accuracy: 0.9545000195503235\n",
      "Epoch 516: 0.14925654232501984, Accuracy: 0.9542999863624573\n",
      "Epoch 517: 0.14902529120445251, Accuracy: 0.9545000195503235\n",
      "Epoch 518: 0.14879466593265533, Accuracy: 0.9545000195503235\n",
      "Epoch 519: 0.14856474101543427, Accuracy: 0.9545999765396118\n",
      "Epoch 520: 0.14833520352840424, Accuracy: 0.9546999931335449\n",
      "Epoch 521: 0.14810633659362793, Accuracy: 0.9546999931335449\n",
      "Epoch 522: 0.14787812530994415, Accuracy: 0.9550999999046326\n",
      "Epoch 523: 0.14765086770057678, Accuracy: 0.954800009727478\n",
      "Epoch 524: 0.14742381870746613, Accuracy: 0.9550999999046326\n",
      "Epoch 525: 0.147197425365448, Accuracy: 0.9550999999046326\n",
      "Epoch 526: 0.14697177708148956, Accuracy: 0.9552000164985657\n",
      "Epoch 527: 0.14674663543701172, Accuracy: 0.9555000066757202\n",
      "Epoch 528: 0.14652223885059357, Accuracy: 0.955299973487854\n",
      "Epoch 529: 0.14629828929901123, Accuracy: 0.9556999802589417\n",
      "Epoch 530: 0.14607501029968262, Accuracy: 0.9555000066757202\n",
      "Epoch 531: 0.14585207402706146, Accuracy: 0.9556999802589417\n",
      "Epoch 532: 0.14563000202178955, Accuracy: 0.9557999968528748\n",
      "Epoch 533: 0.14540860056877136, Accuracy: 0.9559999704360962\n",
      "Epoch 534: 0.1451881229877472, Accuracy: 0.9557999968528748\n",
      "Epoch 535: 0.14496774971485138, Accuracy: 0.9560999870300293\n",
      "Epoch 536: 0.1447482705116272, Accuracy: 0.9559000134468079\n",
      "Epoch 537: 0.14452894032001495, Accuracy: 0.9560999870300293\n",
      "Epoch 538: 0.14430998265743256, Accuracy: 0.9559000134468079\n",
      "Epoch 539: 0.14409145712852478, Accuracy: 0.9562000036239624\n",
      "Epoch 540: 0.14387348294258118, Accuracy: 0.9559000134468079\n",
      "Epoch 541: 0.14365583658218384, Accuracy: 0.9562000036239624\n",
      "Epoch 542: 0.14343908429145813, Accuracy: 0.9559999704360962\n",
      "Epoch 543: 0.14322270452976227, Accuracy: 0.9562000036239624\n",
      "Epoch 544: 0.14300672709941864, Accuracy: 0.9559000134468079\n",
      "Epoch 545: 0.14279146492481232, Accuracy: 0.9563000202178955\n",
      "Epoch 546: 0.14257732033729553, Accuracy: 0.9559999704360962\n",
      "Epoch 547: 0.1423637866973877, Accuracy: 0.9563000202178955\n",
      "Epoch 548: 0.14215098321437836, Accuracy: 0.9563999772071838\n",
      "Epoch 549: 0.14193843305110931, Accuracy: 0.9563999772071838\n",
      "Epoch 550: 0.14172637462615967, Accuracy: 0.9564999938011169\n",
      "Epoch 551: 0.14151495695114136, Accuracy: 0.95660001039505\n",
      "Epoch 552: 0.1413041055202484, Accuracy: 0.9567000269889832\n",
      "Epoch 553: 0.14109356701374054, Accuracy: 0.9567000269889832\n",
      "Epoch 554: 0.1408834308385849, Accuracy: 0.9567999839782715\n",
      "Epoch 555: 0.14067389070987701, Accuracy: 0.9567999839782715\n",
      "Epoch 556: 0.1404651403427124, Accuracy: 0.957099974155426\n",
      "Epoch 557: 0.14025700092315674, Accuracy: 0.9570000171661377\n",
      "Epoch 558: 0.14004941284656525, Accuracy: 0.9571999907493591\n",
      "Epoch 559: 0.1398424357175827, Accuracy: 0.957099974155426\n",
      "Epoch 560: 0.13963590562343597, Accuracy: 0.9571999907493591\n",
      "Epoch 561: 0.13942977786064148, Accuracy: 0.9573000073432922\n",
      "Epoch 562: 0.13922421634197235, Accuracy: 0.957099974155426\n",
      "Epoch 563: 0.13901881873607635, Accuracy: 0.9574000239372253\n",
      "Epoch 564: 0.13881421089172363, Accuracy: 0.957099974155426\n",
      "Epoch 565: 0.13860996067523956, Accuracy: 0.9574999809265137\n",
      "Epoch 566: 0.13840638101100922, Accuracy: 0.9573000073432922\n",
      "Epoch 567: 0.13820293545722961, Accuracy: 0.9575999975204468\n",
      "Epoch 568: 0.13800032436847687, Accuracy: 0.9573000073432922\n",
      "Epoch 569: 0.13779804110527039, Accuracy: 0.9578999876976013\n",
      "Epoch 570: 0.13759660720825195, Accuracy: 0.9573000073432922\n",
      "Epoch 571: 0.13739562034606934, Accuracy: 0.9578999876976013\n",
      "Epoch 572: 0.13719531893730164, Accuracy: 0.9577000141143799\n",
      "Epoch 573: 0.13699547946453094, Accuracy: 0.9578999876976013\n",
      "Epoch 574: 0.13679607212543488, Accuracy: 0.9577000141143799\n",
      "Epoch 575: 0.136597141623497, Accuracy: 0.9580000042915344\n",
      "Epoch 576: 0.1363985687494278, Accuracy: 0.9577000141143799\n",
      "Epoch 577: 0.13620062172412872, Accuracy: 0.9580000042915344\n",
      "Epoch 578: 0.1360030621290207, Accuracy: 0.9580000042915344\n",
      "Epoch 579: 0.13580617308616638, Accuracy: 0.9581999778747559\n",
      "Epoch 580: 0.13560941815376282, Accuracy: 0.9581000208854675\n",
      "Epoch 581: 0.1354132890701294, Accuracy: 0.958299994468689\n",
      "Epoch 582: 0.13521745800971985, Accuracy: 0.9584000110626221\n",
      "Epoch 583: 0.1350223869085312, Accuracy: 0.9585999846458435\n",
      "Epoch 584: 0.13482779264450073, Accuracy: 0.9585000276565552\n",
      "Epoch 585: 0.1346336305141449, Accuracy: 0.9587000012397766\n",
      "Epoch 586: 0.13443982601165771, Accuracy: 0.9587000012397766\n",
      "Epoch 587: 0.13424639403820038, Accuracy: 0.958899974822998\n",
      "Epoch 588: 0.13405346870422363, Accuracy: 0.9587000012397766\n",
      "Epoch 589: 0.1338612139225006, Accuracy: 0.9589999914169312\n",
      "Epoch 590: 0.13366957008838654, Accuracy: 0.9587000012397766\n",
      "Epoch 591: 0.13347835838794708, Accuracy: 0.9591000080108643\n",
      "Epoch 592: 0.13328750431537628, Accuracy: 0.958899974822998\n",
      "Epoch 593: 0.1330970972776413, Accuracy: 0.9592000246047974\n",
      "Epoch 594: 0.13290724158287048, Accuracy: 0.9591000080108643\n",
      "Epoch 595: 0.13271787762641907, Accuracy: 0.9592999815940857\n",
      "Epoch 596: 0.1325291097164154, Accuracy: 0.9592999815940857\n",
      "Epoch 597: 0.13234087824821472, Accuracy: 0.9593999981880188\n",
      "Epoch 598: 0.13215303421020508, Accuracy: 0.9592999815940857\n",
      "Epoch 599: 0.1319655179977417, Accuracy: 0.9593999981880188\n",
      "Epoch 600: 0.13177864253520966, Accuracy: 0.9592999815940857\n",
      "Epoch 601: 0.1315920203924179, Accuracy: 0.9593999981880188\n",
      "Epoch 602: 0.13140571117401123, Accuracy: 0.9592999815940857\n",
      "Epoch 603: 0.13122011721134186, Accuracy: 0.9593999981880188\n",
      "Epoch 604: 0.13103483617305756, Accuracy: 0.9592999815940857\n",
      "Epoch 605: 0.1308499574661255, Accuracy: 0.9593999981880188\n",
      "Epoch 606: 0.13066543638706207, Accuracy: 0.9592999815940857\n",
      "Epoch 607: 0.13048142194747925, Accuracy: 0.9595000147819519\n",
      "Epoch 608: 0.13029786944389343, Accuracy: 0.9592999815940857\n",
      "Epoch 609: 0.13011454045772552, Accuracy: 0.9595000147819519\n",
      "Epoch 610: 0.12993161380290985, Accuracy: 0.9592999815940857\n",
      "Epoch 611: 0.1297493726015091, Accuracy: 0.9595000147819519\n",
      "Epoch 612: 0.12956762313842773, Accuracy: 0.9592999815940857\n",
      "Epoch 613: 0.129386305809021, Accuracy: 0.9595000147819519\n",
      "Epoch 614: 0.12920519709587097, Accuracy: 0.9593999981880188\n",
      "Epoch 615: 0.12902459502220154, Accuracy: 0.9595999717712402\n",
      "Epoch 616: 0.12884435057640076, Accuracy: 0.9595000147819519\n",
      "Epoch 617: 0.12866441905498505, Accuracy: 0.9598000049591064\n",
      "Epoch 618: 0.1284848153591156, Accuracy: 0.9595999717712402\n",
      "Epoch 619: 0.12830545008182526, Accuracy: 0.9598000049591064\n",
      "Epoch 620: 0.12812656164169312, Accuracy: 0.9595999717712402\n",
      "Epoch 621: 0.12794791162014008, Accuracy: 0.9599000215530396\n",
      "Epoch 622: 0.12776967883110046, Accuracy: 0.9596999883651733\n",
      "Epoch 623: 0.12759172916412354, Accuracy: 0.9599000215530396\n",
      "Epoch 624: 0.12741418182849884, Accuracy: 0.9599000215530396\n",
      "Epoch 625: 0.12723715603351593, Accuracy: 0.9599999785423279\n",
      "Epoch 626: 0.1270604282617569, Accuracy: 0.9599000215530396\n",
      "Epoch 627: 0.12688401341438293, Accuracy: 0.9602000117301941\n",
      "Epoch 628: 0.12670806050300598, Accuracy: 0.9599000215530396\n",
      "Epoch 629: 0.12653270363807678, Accuracy: 0.9602000117301941\n",
      "Epoch 630: 0.12635767459869385, Accuracy: 0.9599999785423279\n",
      "Epoch 631: 0.12618307769298553, Accuracy: 0.9602000117301941\n",
      "Epoch 632: 0.12600931525230408, Accuracy: 0.960099995136261\n",
      "Epoch 633: 0.12583591043949127, Accuracy: 0.9602000117301941\n",
      "Epoch 634: 0.12566322088241577, Accuracy: 0.9599999785423279\n",
      "Epoch 635: 0.1254907250404358, Accuracy: 0.9603000283241272\n",
      "Epoch 636: 0.12531869113445282, Accuracy: 0.9599999785423279\n",
      "Epoch 637: 0.1251470446586609, Accuracy: 0.9603999853134155\n",
      "Epoch 638: 0.12497592717409134, Accuracy: 0.9602000117301941\n",
      "Epoch 639: 0.12480513751506805, Accuracy: 0.9605000019073486\n",
      "Epoch 640: 0.1246349960565567, Accuracy: 0.9602000117301941\n",
      "Epoch 641: 0.12446507811546326, Accuracy: 0.9605000019073486\n",
      "Epoch 642: 0.12429579347372055, Accuracy: 0.9605000019073486\n",
      "Epoch 643: 0.12412658333778381, Accuracy: 0.9606000185012817\n",
      "Epoch 644: 0.12395787239074707, Accuracy: 0.9606000185012817\n",
      "Epoch 645: 0.12378939986228943, Accuracy: 0.9606999754905701\n",
      "Epoch 646: 0.12362141162157059, Accuracy: 0.9606999754905701\n",
      "Epoch 647: 0.12345359474420547, Accuracy: 0.9609000086784363\n",
      "Epoch 648: 0.12328631430864334, Accuracy: 0.9609000086784363\n",
      "Epoch 649: 0.12311934679746628, Accuracy: 0.9609000086784363\n",
      "Epoch 650: 0.12295286357402802, Accuracy: 0.9610000252723694\n",
      "Epoch 651: 0.12278702110052109, Accuracy: 0.9610000252723694\n",
      "Epoch 652: 0.12262154370546341, Accuracy: 0.9610999822616577\n",
      "Epoch 653: 0.12245628982782364, Accuracy: 0.9610999822616577\n",
      "Epoch 654: 0.12229162454605103, Accuracy: 0.9610999822616577\n",
      "Epoch 655: 0.1221272274851799, Accuracy: 0.9613000154495239\n",
      "Epoch 656: 0.12196330726146698, Accuracy: 0.9610999822616577\n",
      "Epoch 657: 0.121799536049366, Accuracy: 0.9613000154495239\n",
      "Epoch 658: 0.12163594365119934, Accuracy: 0.9610999822616577\n",
      "Epoch 659: 0.12147271633148193, Accuracy: 0.9613000154495239\n",
      "Epoch 660: 0.12131009995937347, Accuracy: 0.9611999988555908\n",
      "Epoch 661: 0.12114764004945755, Accuracy: 0.9613000154495239\n",
      "Epoch 662: 0.12098562717437744, Accuracy: 0.9613000154495239\n",
      "Epoch 663: 0.1208239495754242, Accuracy: 0.9613999724388123\n",
      "Epoch 664: 0.12066290527582169, Accuracy: 0.9613999724388123\n",
      "Epoch 665: 0.12050189077854156, Accuracy: 0.9613999724388123\n",
      "Epoch 666: 0.12034124881029129, Accuracy: 0.9614999890327454\n",
      "Epoch 667: 0.12018076330423355, Accuracy: 0.9617000222206116\n",
      "Epoch 668: 0.12002076208591461, Accuracy: 0.9614999890327454\n",
      "Epoch 669: 0.1198611706495285, Accuracy: 0.961899995803833\n",
      "Epoch 670: 0.11970215290784836, Accuracy: 0.9617000222206116\n",
      "Epoch 671: 0.11954347789287567, Accuracy: 0.9620000123977661\n",
      "Epoch 672: 0.1193854957818985, Accuracy: 0.9617000222206116\n",
      "Epoch 673: 0.11922740936279297, Accuracy: 0.9620000123977661\n",
      "Epoch 674: 0.11907017230987549, Accuracy: 0.9617000222206116\n",
      "Epoch 675: 0.11891309916973114, Accuracy: 0.961899995803833\n",
      "Epoch 676: 0.11875662952661514, Accuracy: 0.9617000222206116\n",
      "Epoch 677: 0.1186002567410469, Accuracy: 0.9620000123977661\n",
      "Epoch 678: 0.11844463646411896, Accuracy: 0.9617999792098999\n",
      "Epoch 679: 0.1182892918586731, Accuracy: 0.9621000289916992\n",
      "Epoch 680: 0.11813431233167648, Accuracy: 0.961899995803833\n",
      "Epoch 681: 0.11797979474067688, Accuracy: 0.9620000123977661\n",
      "Epoch 682: 0.11782562732696533, Accuracy: 0.961899995803833\n",
      "Epoch 683: 0.11767170578241348, Accuracy: 0.9620000123977661\n",
      "Epoch 684: 0.11751813441514969, Accuracy: 0.9620000123977661\n",
      "Epoch 685: 0.11736446619033813, Accuracy: 0.961899995803833\n",
      "Epoch 686: 0.11721169203519821, Accuracy: 0.9621000289916992\n",
      "Epoch 687: 0.11705873161554337, Accuracy: 0.9621999859809875\n",
      "Epoch 688: 0.11690636724233627, Accuracy: 0.9621000289916992\n",
      "Epoch 689: 0.1167539581656456, Accuracy: 0.9621999859809875\n",
      "Epoch 690: 0.1166018545627594, Accuracy: 0.9621999859809875\n",
      "Epoch 691: 0.11645016819238663, Accuracy: 0.9623000025749207\n",
      "Epoch 692: 0.1162986159324646, Accuracy: 0.9623000025749207\n",
      "Epoch 693: 0.11614743620157242, Accuracy: 0.9623000025749207\n",
      "Epoch 694: 0.11599662154912949, Accuracy: 0.9621999859809875\n",
      "Epoch 695: 0.11584604531526566, Accuracy: 0.9624000191688538\n",
      "Epoch 696: 0.11569603532552719, Accuracy: 0.9623000025749207\n",
      "Epoch 697: 0.11554629355669022, Accuracy: 0.9624000191688538\n",
      "Epoch 698: 0.11539709568023682, Accuracy: 0.9623000025749207\n",
      "Epoch 699: 0.11524790525436401, Accuracy: 0.9624000191688538\n",
      "Epoch 700: 0.1150992214679718, Accuracy: 0.9621999859809875\n",
      "Epoch 701: 0.11495077610015869, Accuracy: 0.9624000191688538\n",
      "Epoch 702: 0.11480283737182617, Accuracy: 0.9621999859809875\n",
      "Epoch 703: 0.11465523391962051, Accuracy: 0.9624999761581421\n",
      "Epoch 704: 0.11450782418251038, Accuracy: 0.9624000191688538\n",
      "Epoch 705: 0.11436081677675247, Accuracy: 0.9627000093460083\n",
      "Epoch 706: 0.11421394348144531, Accuracy: 0.9624999761581421\n",
      "Epoch 707: 0.1140674501657486, Accuracy: 0.9627000093460083\n",
      "Epoch 708: 0.11392129957675934, Accuracy: 0.9627000093460083\n",
      "Epoch 709: 0.11377541720867157, Accuracy: 0.9627000093460083\n",
      "Epoch 710: 0.11362992227077484, Accuracy: 0.9627000093460083\n",
      "Epoch 711: 0.11348453164100647, Accuracy: 0.9628000259399414\n",
      "Epoch 712: 0.11333974450826645, Accuracy: 0.9627000093460083\n",
      "Epoch 713: 0.11319506168365479, Accuracy: 0.9628000259399414\n",
      "Epoch 714: 0.11305084079504013, Accuracy: 0.9627000093460083\n",
      "Epoch 715: 0.11290667206048965, Accuracy: 0.9628999829292297\n",
      "Epoch 716: 0.11276278644800186, Accuracy: 0.9629999995231628\n",
      "Epoch 717: 0.11261926591396332, Accuracy: 0.9628000259399414\n",
      "Epoch 718: 0.11247604340314865, Accuracy: 0.963100016117096\n",
      "Epoch 719: 0.11233318597078323, Accuracy: 0.9628000259399414\n",
      "Epoch 720: 0.11219056695699692, Accuracy: 0.9631999731063843\n",
      "Epoch 721: 0.11204849183559418, Accuracy: 0.9628999829292297\n",
      "Epoch 722: 0.11190656572580338, Accuracy: 0.9631999731063843\n",
      "Epoch 723: 0.11176507920026779, Accuracy: 0.9631999731063843\n",
      "Epoch 724: 0.1116238608956337, Accuracy: 0.9631999731063843\n",
      "Epoch 725: 0.11148323863744736, Accuracy: 0.9632999897003174\n",
      "Epoch 726: 0.11134278029203415, Accuracy: 0.9634000062942505\n",
      "Epoch 727: 0.11120259016752243, Accuracy: 0.9635000228881836\n",
      "Epoch 728: 0.11106261610984802, Accuracy: 0.9634000062942505\n",
      "Epoch 729: 0.11092285066843033, Accuracy: 0.9635999798774719\n",
      "Epoch 730: 0.11078358441591263, Accuracy: 0.9635000228881836\n",
      "Epoch 731: 0.11064448952674866, Accuracy: 0.9634000062942505\n",
      "Epoch 732: 0.11050558090209961, Accuracy: 0.9635999798774719\n",
      "Epoch 733: 0.11036679893732071, Accuracy: 0.9634000062942505\n",
      "Epoch 734: 0.11022857576608658, Accuracy: 0.963699996471405\n",
      "Epoch 735: 0.11009040474891663, Accuracy: 0.9635000228881836\n",
      "Epoch 736: 0.10995260626077652, Accuracy: 0.9639000296592712\n",
      "Epoch 737: 0.10981503129005432, Accuracy: 0.9635000228881836\n",
      "Epoch 738: 0.10967777669429779, Accuracy: 0.9639999866485596\n",
      "Epoch 739: 0.10954073071479797, Accuracy: 0.9635000228881836\n",
      "Epoch 740: 0.109404057264328, Accuracy: 0.9639999866485596\n",
      "Epoch 741: 0.10926751792430878, Accuracy: 0.963699996471405\n",
      "Epoch 742: 0.10913128405809402, Accuracy: 0.9639000296592712\n",
      "Epoch 743: 0.10899519175291061, Accuracy: 0.963699996471405\n",
      "Epoch 744: 0.10885971039533615, Accuracy: 0.9639000296592712\n",
      "Epoch 745: 0.10872424393892288, Accuracy: 0.963699996471405\n",
      "Epoch 746: 0.10858923196792603, Accuracy: 0.9639999866485596\n",
      "Epoch 747: 0.10845405608415604, Accuracy: 0.963699996471405\n",
      "Epoch 748: 0.10831931978464127, Accuracy: 0.9639999866485596\n",
      "Epoch 749: 0.10818493366241455, Accuracy: 0.9638000130653381\n",
      "Epoch 750: 0.10805099457502365, Accuracy: 0.9639999866485596\n",
      "Epoch 751: 0.10791733860969543, Accuracy: 0.9639999866485596\n",
      "Epoch 752: 0.10778401792049408, Accuracy: 0.9639999866485596\n",
      "Epoch 753: 0.10765103250741959, Accuracy: 0.9639999866485596\n",
      "Epoch 754: 0.10751854628324509, Accuracy: 0.9639999866485596\n",
      "Epoch 755: 0.10738595575094223, Accuracy: 0.9639999866485596\n",
      "Epoch 756: 0.10725405067205429, Accuracy: 0.9641000032424927\n",
      "Epoch 757: 0.10712207108736038, Accuracy: 0.9639999866485596\n",
      "Epoch 758: 0.10699057579040527, Accuracy: 0.9642000198364258\n",
      "Epoch 759: 0.10685910284519196, Accuracy: 0.9639999866485596\n",
      "Epoch 760: 0.10672806203365326, Accuracy: 0.9641000032424927\n",
      "Epoch 761: 0.10659722983837128, Accuracy: 0.9639999866485596\n",
      "Epoch 762: 0.10646659880876541, Accuracy: 0.9642000198364258\n",
      "Epoch 763: 0.10633645951747894, Accuracy: 0.9641000032424927\n",
      "Epoch 764: 0.10620656609535217, Accuracy: 0.9642999768257141\n",
      "Epoch 765: 0.10607721656560898, Accuracy: 0.9641000032424927\n",
      "Epoch 766: 0.10594787448644638, Accuracy: 0.9642999768257141\n",
      "Epoch 767: 0.1058187335729599, Accuracy: 0.9643999934196472\n",
      "Epoch 768: 0.10568983107805252, Accuracy: 0.9642999768257141\n",
      "Epoch 769: 0.10556109994649887, Accuracy: 0.9643999934196472\n",
      "Epoch 770: 0.10543239116668701, Accuracy: 0.9642999768257141\n",
      "Epoch 771: 0.10530366748571396, Accuracy: 0.9643999934196472\n",
      "Epoch 772: 0.10517535358667374, Accuracy: 0.9642999768257141\n",
      "Epoch 773: 0.10504703223705292, Accuracy: 0.9646000266075134\n",
      "Epoch 774: 0.1049191802740097, Accuracy: 0.9646000266075134\n",
      "Epoch 775: 0.1047915518283844, Accuracy: 0.9646000266075134\n",
      "Epoch 776: 0.10466410964727402, Accuracy: 0.9646000266075134\n",
      "Epoch 777: 0.10453732311725616, Accuracy: 0.9646000266075134\n",
      "Epoch 778: 0.10441062599420547, Accuracy: 0.9646999835968018\n",
      "Epoch 779: 0.10428463667631149, Accuracy: 0.9646000266075134\n",
      "Epoch 780: 0.10415838658809662, Accuracy: 0.9648000001907349\n",
      "Epoch 781: 0.10403288900852203, Accuracy: 0.9646999835968018\n",
      "Epoch 782: 0.1039067730307579, Accuracy: 0.964900016784668\n",
      "Epoch 783: 0.10378137230873108, Accuracy: 0.9648000001907349\n",
      "Epoch 784: 0.10365598648786545, Accuracy: 0.964900016784668\n",
      "Epoch 785: 0.10353124886751175, Accuracy: 0.9648000001907349\n",
      "Epoch 786: 0.10340629518032074, Accuracy: 0.964900016784668\n",
      "Epoch 787: 0.10328204184770584, Accuracy: 0.9649999737739563\n",
      "Epoch 788: 0.10315797477960587, Accuracy: 0.964900016784668\n",
      "Epoch 789: 0.10303396731615067, Accuracy: 0.9649999737739563\n",
      "Epoch 790: 0.10291021317243576, Accuracy: 0.964900016784668\n",
      "Epoch 791: 0.10278628021478653, Accuracy: 0.9649999737739563\n",
      "Epoch 792: 0.1026626005768776, Accuracy: 0.9649999737739563\n",
      "Epoch 793: 0.10253899544477463, Accuracy: 0.9649999737739563\n",
      "Epoch 794: 0.10241559892892838, Accuracy: 0.9649999737739563\n",
      "Epoch 795: 0.10229256004095078, Accuracy: 0.9648000001907349\n",
      "Epoch 796: 0.10216985642910004, Accuracy: 0.9649999737739563\n",
      "Epoch 797: 0.10204719752073288, Accuracy: 0.964900016784668\n",
      "Epoch 798: 0.10192537307739258, Accuracy: 0.9649999737739563\n",
      "Epoch 799: 0.10180376470088959, Accuracy: 0.964900016784668\n",
      "Epoch 800: 0.10168244689702988, Accuracy: 0.9649999737739563\n",
      "Epoch 801: 0.10156150162220001, Accuracy: 0.9648000001907349\n",
      "Epoch 802: 0.10144104063510895, Accuracy: 0.9650999903678894\n",
      "Epoch 803: 0.10132065415382385, Accuracy: 0.9648000001907349\n",
      "Epoch 804: 0.10120078921318054, Accuracy: 0.9650999903678894\n",
      "Epoch 805: 0.10108073800802231, Accuracy: 0.9648000001907349\n",
      "Epoch 806: 0.10096121579408646, Accuracy: 0.9650999903678894\n",
      "Epoch 807: 0.10084143280982971, Accuracy: 0.964900016784668\n",
      "Epoch 808: 0.1007222980260849, Accuracy: 0.9650999903678894\n",
      "Epoch 809: 0.1006033718585968, Accuracy: 0.964900016784668\n",
      "Epoch 810: 0.1004849374294281, Accuracy: 0.9652000069618225\n",
      "Epoch 811: 0.1003669872879982, Accuracy: 0.964900016784668\n",
      "Epoch 812: 0.10024856775999069, Accuracy: 0.9652000069618225\n",
      "Epoch 813: 0.1001305803656578, Accuracy: 0.964900016784668\n",
      "Epoch 814: 0.10001224279403687, Accuracy: 0.9652000069618225\n",
      "Epoch 815: 0.09989393502473831, Accuracy: 0.9649999737739563\n",
      "Epoch 816: 0.09977573901414871, Accuracy: 0.9652000069618225\n",
      "Epoch 817: 0.09965799748897552, Accuracy: 0.9649999737739563\n",
      "Epoch 818: 0.09954111278057098, Accuracy: 0.9652000069618225\n",
      "Epoch 819: 0.09942467510700226, Accuracy: 0.9649999737739563\n",
      "Epoch 820: 0.09930888563394547, Accuracy: 0.9652000069618225\n",
      "Epoch 821: 0.09919338673353195, Accuracy: 0.9649999737739563\n",
      "Epoch 822: 0.09907843172550201, Accuracy: 0.9652000069618225\n",
      "Epoch 823: 0.09896312654018402, Accuracy: 0.9649999737739563\n",
      "Epoch 824: 0.09884834289550781, Accuracy: 0.9652000069618225\n",
      "Epoch 825: 0.09873342514038086, Accuracy: 0.9650999903678894\n",
      "Epoch 826: 0.09861844033002853, Accuracy: 0.965399980545044\n",
      "Epoch 827: 0.09850352257490158, Accuracy: 0.9652000069618225\n",
      "Epoch 828: 0.09838913381099701, Accuracy: 0.9656000137329102\n",
      "Epoch 829: 0.09827430546283722, Accuracy: 0.9652000069618225\n",
      "Epoch 830: 0.09816040843725204, Accuracy: 0.9656000137329102\n",
      "Epoch 831: 0.09804657846689224, Accuracy: 0.9652000069618225\n",
      "Epoch 832: 0.09793278574943542, Accuracy: 0.9656000137329102\n",
      "Epoch 833: 0.09781993925571442, Accuracy: 0.9653000235557556\n",
      "Epoch 834: 0.09770645201206207, Accuracy: 0.9656999707221985\n",
      "Epoch 835: 0.09759410470724106, Accuracy: 0.9653000235557556\n",
      "Epoch 836: 0.09748052805662155, Accuracy: 0.9656999707221985\n",
      "Epoch 837: 0.09736883640289307, Accuracy: 0.965399980545044\n",
      "Epoch 838: 0.09725557267665863, Accuracy: 0.9657999873161316\n",
      "Epoch 839: 0.09714354574680328, Accuracy: 0.965399980545044\n",
      "Epoch 840: 0.09703035652637482, Accuracy: 0.9657999873161316\n",
      "Epoch 841: 0.09691882878541946, Accuracy: 0.965399980545044\n",
      "Epoch 842: 0.09680607169866562, Accuracy: 0.9659000039100647\n",
      "Epoch 843: 0.09669483453035355, Accuracy: 0.965499997138977\n",
      "Epoch 844: 0.09658289700746536, Accuracy: 0.9657999873161316\n",
      "Epoch 845: 0.0964716374874115, Accuracy: 0.965499997138977\n",
      "Epoch 846: 0.09636019915342331, Accuracy: 0.9659000039100647\n",
      "Epoch 847: 0.09624972939491272, Accuracy: 0.9656999707221985\n",
      "Epoch 848: 0.09613876789808273, Accuracy: 0.9660000205039978\n",
      "Epoch 849: 0.09602826088666916, Accuracy: 0.9656999707221985\n",
      "Epoch 850: 0.09591817855834961, Accuracy: 0.9660000205039978\n",
      "Epoch 851: 0.09580764174461365, Accuracy: 0.9656000137329102\n",
      "Epoch 852: 0.09569837898015976, Accuracy: 0.9660000205039978\n",
      "Epoch 853: 0.09558811038732529, Accuracy: 0.9656999707221985\n",
      "Epoch 854: 0.09547870606184006, Accuracy: 0.9660000205039978\n",
      "Epoch 855: 0.09536914527416229, Accuracy: 0.9657999873161316\n",
      "Epoch 856: 0.0952608659863472, Accuracy: 0.9660000205039978\n",
      "Epoch 857: 0.09515216201543808, Accuracy: 0.9657999873161316\n",
      "Epoch 858: 0.09504442662000656, Accuracy: 0.9660000205039978\n",
      "Epoch 859: 0.0949360653758049, Accuracy: 0.9659000039100647\n",
      "Epoch 860: 0.09482903778553009, Accuracy: 0.9661999940872192\n",
      "Epoch 861: 0.0947204977273941, Accuracy: 0.9659000039100647\n",
      "Epoch 862: 0.09461387246847153, Accuracy: 0.9661999940872192\n",
      "Epoch 863: 0.09450656920671463, Accuracy: 0.9659000039100647\n",
      "Epoch 864: 0.09440065920352936, Accuracy: 0.9661999940872192\n",
      "Epoch 865: 0.09429407864809036, Accuracy: 0.9659000039100647\n",
      "Epoch 866: 0.09418820589780807, Accuracy: 0.9663000106811523\n",
      "Epoch 867: 0.09408286958932877, Accuracy: 0.9659000039100647\n",
      "Epoch 868: 0.09397811442613602, Accuracy: 0.9664000272750854\n",
      "Epoch 869: 0.093873031437397, Accuracy: 0.9661999940872192\n",
      "Epoch 870: 0.09376832842826843, Accuracy: 0.9664999842643738\n",
      "Epoch 871: 0.09366276860237122, Accuracy: 0.9661999940872192\n",
      "Epoch 872: 0.09355934709310532, Accuracy: 0.9668999910354614\n",
      "Epoch 873: 0.09345358610153198, Accuracy: 0.9661999940872192\n",
      "Epoch 874: 0.0933505967259407, Accuracy: 0.9671000242233276\n",
      "Epoch 875: 0.09324558079242706, Accuracy: 0.9664000272750854\n",
      "Epoch 876: 0.0931428000330925, Accuracy: 0.9674000144004822\n",
      "Epoch 877: 0.09303668141365051, Accuracy: 0.9664000272750854\n",
      "Epoch 878: 0.092934250831604, Accuracy: 0.9674000144004822\n",
      "Epoch 879: 0.09282875806093216, Accuracy: 0.9664999842643738\n",
      "Epoch 880: 0.0927269235253334, Accuracy: 0.9674999713897705\n",
      "Epoch 881: 0.09262170642614365, Accuracy: 0.9664999842643738\n",
      "Epoch 882: 0.09252011030912399, Accuracy: 0.9674999713897705\n",
      "Epoch 883: 0.0924152284860611, Accuracy: 0.9664999842643738\n",
      "Epoch 884: 0.09231434762477875, Accuracy: 0.9674000144004822\n",
      "Epoch 885: 0.09220947325229645, Accuracy: 0.9664999842643738\n",
      "Epoch 886: 0.09210759401321411, Accuracy: 0.9674000144004822\n",
      "Epoch 887: 0.09200304001569748, Accuracy: 0.9664999842643738\n",
      "Epoch 888: 0.09190244972705841, Accuracy: 0.9674999713897705\n",
      "Epoch 889: 0.09179729223251343, Accuracy: 0.9670000076293945\n",
      "Epoch 890: 0.09169565886259079, Accuracy: 0.9674999713897705\n",
      "Epoch 891: 0.09158913046121597, Accuracy: 0.967199981212616\n",
      "Epoch 892: 0.091486856341362, Accuracy: 0.9675999879837036\n",
      "Epoch 893: 0.09138185530900955, Accuracy: 0.9672999978065491\n",
      "Epoch 894: 0.09128020703792572, Accuracy: 0.9675999879837036\n",
      "Epoch 895: 0.09117549657821655, Accuracy: 0.9672999978065491\n",
      "Epoch 896: 0.09107422828674316, Accuracy: 0.9675999879837036\n",
      "Epoch 897: 0.09096982330083847, Accuracy: 0.9674999713897705\n",
      "Epoch 898: 0.09086889773607254, Accuracy: 0.9675999879837036\n",
      "Epoch 899: 0.09076542407274246, Accuracy: 0.9674999713897705\n",
      "Epoch 900: 0.09066542237997055, Accuracy: 0.9675999879837036\n",
      "Epoch 901: 0.0905630812048912, Accuracy: 0.9674999713897705\n",
      "Epoch 902: 0.09046532958745956, Accuracy: 0.9675999879837036\n",
      "Epoch 903: 0.09036335349082947, Accuracy: 0.9674999713897705\n",
      "Epoch 904: 0.09026626497507095, Accuracy: 0.9678000211715698\n",
      "Epoch 905: 0.09016406536102295, Accuracy: 0.9674999713897705\n",
      "Epoch 906: 0.09006725251674652, Accuracy: 0.9678999781608582\n",
      "Epoch 907: 0.08996526151895523, Accuracy: 0.9674999713897705\n",
      "Epoch 908: 0.0898691788315773, Accuracy: 0.9678999781608582\n",
      "Epoch 909: 0.0897677093744278, Accuracy: 0.9674999713897705\n",
      "Epoch 910: 0.0896710678935051, Accuracy: 0.9678999781608582\n",
      "Epoch 911: 0.0895705297589302, Accuracy: 0.9675999879837036\n",
      "Epoch 912: 0.08947311341762543, Accuracy: 0.9679999947547913\n",
      "Epoch 913: 0.08937317132949829, Accuracy: 0.9678000211715698\n",
      "Epoch 914: 0.0892760157585144, Accuracy: 0.9679999947547913\n",
      "Epoch 915: 0.08917586505413055, Accuracy: 0.9678999781608582\n",
      "Epoch 916: 0.08907847851514816, Accuracy: 0.9681000113487244\n",
      "Epoch 917: 0.08897938579320908, Accuracy: 0.9678999781608582\n",
      "Epoch 918: 0.08888279646635056, Accuracy: 0.9682000279426575\n",
      "Epoch 919: 0.08878341317176819, Accuracy: 0.9678999781608582\n",
      "Epoch 920: 0.08868823945522308, Accuracy: 0.9682999849319458\n",
      "Epoch 921: 0.08858921378850937, Accuracy: 0.9679999947547913\n",
      "Epoch 922: 0.08849294483661652, Accuracy: 0.9682999849319458\n",
      "Epoch 923: 0.0883941799402237, Accuracy: 0.9679999947547913\n",
      "Epoch 924: 0.08829943090677261, Accuracy: 0.9682999849319458\n",
      "Epoch 925: 0.0882013589143753, Accuracy: 0.9679999947547913\n",
      "Epoch 926: 0.08810657262802124, Accuracy: 0.9682999849319458\n",
      "Epoch 927: 0.08800897002220154, Accuracy: 0.9679999947547913\n",
      "Epoch 928: 0.08791548013687134, Accuracy: 0.9684000015258789\n",
      "Epoch 929: 0.08781813830137253, Accuracy: 0.9679999947547913\n",
      "Epoch 930: 0.0877247303724289, Accuracy: 0.968500018119812\n",
      "Epoch 931: 0.0876270979642868, Accuracy: 0.9679999947547913\n",
      "Epoch 932: 0.08753352612257004, Accuracy: 0.968500018119812\n",
      "Epoch 933: 0.08743693679571152, Accuracy: 0.9679999947547913\n",
      "Epoch 934: 0.0873425155878067, Accuracy: 0.9685999751091003\n",
      "Epoch 935: 0.08724655956029892, Accuracy: 0.9679999947547913\n",
      "Epoch 936: 0.0871533751487732, Accuracy: 0.9688000082969666\n",
      "Epoch 937: 0.0870579332113266, Accuracy: 0.9679999947547913\n",
      "Epoch 938: 0.08696399629116058, Accuracy: 0.9688000082969666\n",
      "Epoch 939: 0.08686911314725876, Accuracy: 0.9681000113487244\n",
      "Epoch 940: 0.0867764949798584, Accuracy: 0.968999981880188\n",
      "Epoch 941: 0.08668191730976105, Accuracy: 0.9682000279426575\n",
      "Epoch 942: 0.08659037202596664, Accuracy: 0.968999981880188\n",
      "Epoch 943: 0.08649618178606033, Accuracy: 0.9682000279426575\n",
      "Epoch 944: 0.0864047035574913, Accuracy: 0.968999981880188\n",
      "Epoch 945: 0.08631017804145813, Accuracy: 0.9682000279426575\n",
      "Epoch 946: 0.08621825277805328, Accuracy: 0.968999981880188\n",
      "Epoch 947: 0.08612463623285294, Accuracy: 0.9682999849319458\n",
      "Epoch 948: 0.08603357523679733, Accuracy: 0.968999981880188\n",
      "Epoch 949: 0.08594077080488205, Accuracy: 0.968500018119812\n",
      "Epoch 950: 0.08584963530302048, Accuracy: 0.9690999984741211\n",
      "Epoch 951: 0.08575662970542908, Accuracy: 0.9686999917030334\n",
      "Epoch 952: 0.08566629141569138, Accuracy: 0.9690999984741211\n",
      "Epoch 953: 0.08557295054197311, Accuracy: 0.9686999917030334\n",
      "Epoch 954: 0.08548307418823242, Accuracy: 0.9692000150680542\n",
      "Epoch 955: 0.08539024740457535, Accuracy: 0.9688000082969666\n",
      "Epoch 956: 0.08530042320489883, Accuracy: 0.9692000150680542\n",
      "Epoch 957: 0.08520805090665817, Accuracy: 0.968999981880188\n",
      "Epoch 958: 0.0851203128695488, Accuracy: 0.9692000150680542\n",
      "Epoch 959: 0.08502887934446335, Accuracy: 0.9692000150680542\n",
      "Epoch 960: 0.08494193851947784, Accuracy: 0.9692000150680542\n",
      "Epoch 961: 0.08485051989555359, Accuracy: 0.9690999984741211\n",
      "Epoch 962: 0.08476351201534271, Accuracy: 0.9693999886512756\n",
      "Epoch 963: 0.08467304706573486, Accuracy: 0.9690999984741211\n",
      "Epoch 964: 0.08458603173494339, Accuracy: 0.9695000052452087\n",
      "Epoch 965: 0.08449569344520569, Accuracy: 0.9692000150680542\n",
      "Epoch 966: 0.08440949022769928, Accuracy: 0.9695000052452087\n",
      "Epoch 967: 0.08431971073150635, Accuracy: 0.9692000150680542\n",
      "Epoch 968: 0.0842345729470253, Accuracy: 0.9695000052452087\n",
      "Epoch 969: 0.08414578437805176, Accuracy: 0.9692000150680542\n",
      "Epoch 970: 0.08406195789575577, Accuracy: 0.9695000052452087\n",
      "Epoch 971: 0.08397344499826431, Accuracy: 0.9692000150680542\n",
      "Epoch 972: 0.08389125019311905, Accuracy: 0.9695000052452087\n",
      "Epoch 973: 0.08380240201950073, Accuracy: 0.9693999886512756\n",
      "Epoch 974: 0.08371903747320175, Accuracy: 0.9696000218391418\n",
      "Epoch 975: 0.08363030850887299, Accuracy: 0.9693999886512756\n",
      "Epoch 976: 0.08354777842760086, Accuracy: 0.9696000218391418\n",
      "Epoch 977: 0.08345983177423477, Accuracy: 0.9693999886512756\n",
      "Epoch 978: 0.08337874710559845, Accuracy: 0.9696000218391418\n",
      "Epoch 979: 0.0832914412021637, Accuracy: 0.9696000218391418\n",
      "Epoch 980: 0.08321025967597961, Accuracy: 0.9696000218391418\n",
      "Epoch 981: 0.08312015235424042, Accuracy: 0.9695000052452087\n",
      "Epoch 982: 0.08303838223218918, Accuracy: 0.9696000218391418\n",
      "Epoch 983: 0.08294855803251266, Accuracy: 0.9695000052452087\n",
      "Epoch 984: 0.0828675851225853, Accuracy: 0.9696000218391418\n",
      "Epoch 985: 0.08277751505374908, Accuracy: 0.9695000052452087\n",
      "Epoch 986: 0.08269575983285904, Accuracy: 0.9696000218391418\n",
      "Epoch 987: 0.082606740295887, Accuracy: 0.9695000052452087\n",
      "Epoch 988: 0.08252336084842682, Accuracy: 0.9696000218391418\n",
      "Epoch 989: 0.08243408054113388, Accuracy: 0.9695000052452087\n",
      "Epoch 990: 0.08235141634941101, Accuracy: 0.9696000218391418\n",
      "Epoch 991: 0.08226197957992554, Accuracy: 0.9695000052452087\n",
      "Epoch 992: 0.08218010514974594, Accuracy: 0.9696000218391418\n",
      "Epoch 993: 0.0820910707116127, Accuracy: 0.9696000218391418\n",
      "Epoch 994: 0.08200990408658981, Accuracy: 0.9696999788284302\n",
      "Epoch 995: 0.0819217637181282, Accuracy: 0.9696000218391418\n",
      "Epoch 996: 0.08184143155813217, Accuracy: 0.9696999788284302\n",
      "Epoch 997: 0.08175388723611832, Accuracy: 0.9696000218391418\n",
      "Epoch 998: 0.08167374134063721, Accuracy: 0.9696999788284302\n",
      "Epoch 999: 0.08158668875694275, Accuracy: 0.9696000218391418\n",
      "Epoch 1000: 0.08150739967823029, Accuracy: 0.9696999788284302\n",
      "n_in:  784\n",
      "n_out:  10\n",
      "Epoch 1: 2.6047489643096924, Accuracy: 0.09799999743700027\n",
      "Epoch 2: 2.721940279006958, Accuracy: 0.08940000087022781\n",
      "Epoch 3: 2.3067405223846436, Accuracy: 0.0908999964594841\n",
      "Epoch 4: 2.30497145652771, Accuracy: 0.09109999984502792\n",
      "Epoch 5: 2.3040037155151367, Accuracy: 0.09120000153779984\n",
      "Epoch 6: 2.3033523559570312, Accuracy: 0.09179999679327011\n",
      "Epoch 7: 2.302839994430542, Accuracy: 0.09179999679327011\n",
      "Epoch 8: 2.3023743629455566, Accuracy: 0.09220000356435776\n",
      "Epoch 9: 2.3018887042999268, Accuracy: 0.09189999848604202\n",
      "Epoch 10: 2.301318407058716, Accuracy: 0.0925000011920929\n",
      "Epoch 11: 2.3005685806274414, Accuracy: 0.09440000355243683\n",
      "Epoch 12: 2.2994909286499023, Accuracy: 0.0940999984741211\n",
      "Epoch 13: 2.2978010177612305, Accuracy: 0.09480000287294388\n",
      "Epoch 14: 2.2949421405792236, Accuracy: 0.09520000219345093\n",
      "Epoch 15: 2.289860963821411, Accuracy: 0.09619999676942825\n",
      "Epoch 16: 2.2807650566101074, Accuracy: 0.09489999711513519\n",
      "Epoch 17: 2.265516757965088, Accuracy: 0.09830000251531601\n",
      "Epoch 18: 2.2451012134552, Accuracy: 0.10010000318288803\n",
      "Epoch 19: 2.2236034870147705, Accuracy: 0.1054999977350235\n",
      "Epoch 20: 2.202540159225464, Accuracy: 0.15639999508857727\n",
      "Epoch 21: 2.1830482482910156, Accuracy: 0.21050000190734863\n",
      "Epoch 22: 2.1643784046173096, Accuracy: 0.2459000051021576\n",
      "Epoch 23: 2.1449365615844727, Accuracy: 0.27309998869895935\n",
      "Epoch 24: 2.1235997676849365, Accuracy: 0.2971000075340271\n",
      "Epoch 25: 2.0996227264404297, Accuracy: 0.3156000077724457\n",
      "Epoch 26: 2.072273015975952, Accuracy: 0.334199994802475\n",
      "Epoch 27: 2.040970802307129, Accuracy: 0.357699990272522\n",
      "Epoch 28: 2.005342721939087, Accuracy: 0.3865000009536743\n",
      "Epoch 29: 1.9648163318634033, Accuracy: 0.42320001125335693\n",
      "Epoch 30: 1.9187227487564087, Accuracy: 0.4544999897480011\n",
      "Epoch 31: 1.8664699792861938, Accuracy: 0.5072000026702881\n",
      "Epoch 32: 1.808049201965332, Accuracy: 0.5195000171661377\n",
      "Epoch 33: 1.744089961051941, Accuracy: 0.5623999834060669\n",
      "Epoch 34: 1.6794297695159912, Accuracy: 0.5360000133514404\n",
      "Epoch 35: 1.6277862787246704, Accuracy: 0.48240000009536743\n",
      "Epoch 36: 1.6621627807617188, Accuracy: 0.3377000093460083\n",
      "Epoch 37: 1.7150152921676636, Accuracy: 0.32330000400543213\n",
      "Epoch 38: 2.092318296432495, Accuracy: 0.4997999966144562\n",
      "Epoch 39: 1.6950573921203613, Accuracy: 0.49380001425743103\n",
      "Epoch 40: 1.3727705478668213, Accuracy: 0.6001999974250793\n",
      "Epoch 41: 1.3485087156295776, Accuracy: 0.5845000147819519\n",
      "Epoch 42: 1.4524255990982056, Accuracy: 0.6604999899864197\n",
      "Epoch 43: 1.3418867588043213, Accuracy: 0.6021999716758728\n",
      "Epoch 44: 1.269559383392334, Accuracy: 0.4140999913215637\n",
      "Epoch 45: 1.7158770561218262, Accuracy: 0.35899999737739563\n",
      "Epoch 46: 1.770612359046936, Accuracy: 0.7287999987602234\n",
      "Epoch 47: 1.3680287599563599, Accuracy: 0.7677000164985657\n",
      "Epoch 48: 0.9916819930076599, Accuracy: 0.7361999750137329\n",
      "Epoch 49: 0.9108511805534363, Accuracy: 0.7063000202178955\n",
      "Epoch 50: 0.944812536239624, Accuracy: 0.5659999847412109\n",
      "Epoch 51: 1.3397090435028076, Accuracy: 0.5611000061035156\n",
      "Epoch 52: 1.235284686088562, Accuracy: 0.6820999979972839\n",
      "Epoch 53: 1.0128192901611328, Accuracy: 0.7936999797821045\n",
      "Epoch 54: 0.7702938914299011, Accuracy: 0.7634000182151794\n",
      "Epoch 55: 0.7713401317596436, Accuracy: 0.6198999881744385\n",
      "Epoch 56: 1.0230854749679565, Accuracy: 0.5457000136375427\n",
      "Epoch 57: 1.4338321685791016, Accuracy: 0.6029999852180481\n",
      "Epoch 58: 1.1072001457214355, Accuracy: 0.7526000142097473\n",
      "Epoch 59: 0.8031972646713257, Accuracy: 0.839900016784668\n",
      "Epoch 60: 0.6680006980895996, Accuracy: 0.8281999826431274\n",
      "Epoch 61: 0.6349583864212036, Accuracy: 0.82669997215271\n",
      "Epoch 62: 0.6416601538658142, Accuracy: 0.7594000101089478\n",
      "Epoch 63: 0.7487040758132935, Accuracy: 0.717199981212616\n",
      "Epoch 64: 1.0007189512252808, Accuracy: 0.7125999927520752\n",
      "Epoch 65: 0.9225714206695557, Accuracy: 0.7842000126838684\n",
      "Epoch 66: 0.7467488050460815, Accuracy: 0.829200029373169\n",
      "Epoch 67: 0.6330289244651794, Accuracy: 0.8152999877929688\n",
      "Epoch 68: 0.6254393458366394, Accuracy: 0.8208000063896179\n",
      "Epoch 69: 0.6267901062965393, Accuracy: 0.7796000242233276\n",
      "Epoch 70: 0.6821022033691406, Accuracy: 0.7692000269889832\n",
      "Epoch 71: 0.7092172503471375, Accuracy: 0.7333999872207642\n",
      "Epoch 72: 0.7697106599807739, Accuracy: 0.7817000150680542\n",
      "Epoch 73: 0.6794381737709045, Accuracy: 0.8154000043869019\n",
      "Epoch 74: 0.5936201810836792, Accuracy: 0.8370000123977661\n",
      "Epoch 75: 0.5453171730041504, Accuracy: 0.8345999717712402\n",
      "Epoch 76: 0.5313929915428162, Accuracy: 0.8149999976158142\n",
      "Epoch 77: 0.5459986925125122, Accuracy: 0.7918000221252441\n",
      "Epoch 78: 0.6132373213768005, Accuracy: 0.7324000000953674\n",
      "Epoch 79: 0.7744280099868774, Accuracy: 0.6970000267028809\n",
      "Epoch 80: 0.8404675722122192, Accuracy: 0.7064999938011169\n",
      "Epoch 81: 0.8293929100036621, Accuracy: 0.8158000111579895\n",
      "Epoch 82: 0.6432215571403503, Accuracy: 0.8637999892234802\n",
      "Epoch 83: 0.50741046667099, Accuracy: 0.8708000183105469\n",
      "Epoch 84: 0.48294275999069214, Accuracy: 0.8690999746322632\n",
      "Epoch 85: 0.4757738709449768, Accuracy: 0.866599977016449\n",
      "Epoch 86: 0.48094576597213745, Accuracy: 0.8504999876022339\n",
      "Epoch 87: 0.5027252435684204, Accuracy: 0.8348000049591064\n",
      "Epoch 88: 0.5485931634902954, Accuracy: 0.7957000136375427\n",
      "Epoch 89: 0.6352689266204834, Accuracy: 0.7818999886512756\n",
      "Epoch 90: 0.6703318953514099, Accuracy: 0.7985000014305115\n",
      "Epoch 91: 0.6230283379554749, Accuracy: 0.8486999869346619\n",
      "Epoch 92: 0.5290066003799438, Accuracy: 0.8708999752998352\n",
      "Epoch 93: 0.46832406520843506, Accuracy: 0.8780999779701233\n",
      "Epoch 94: 0.4478550851345062, Accuracy: 0.8788999915122986\n",
      "Epoch 95: 0.4389618933200836, Accuracy: 0.8795999884605408\n",
      "Epoch 96: 0.4345424175262451, Accuracy: 0.8736000061035156\n",
      "Epoch 97: 0.43813368678092957, Accuracy: 0.8722000122070312\n",
      "Epoch 98: 0.4421066641807556, Accuracy: 0.8551999926567078\n",
      "Epoch 99: 0.4658786654472351, Accuracy: 0.8482999801635742\n",
      "Epoch 100: 0.4800177812576294, Accuracy: 0.816100001335144\n",
      "Epoch 101: 0.5339516401290894, Accuracy: 0.8237000107765198\n",
      "Epoch 102: 0.518096387386322, Accuracy: 0.8281000256538391\n",
      "Epoch 103: 0.5142454504966736, Accuracy: 0.8615999817848206\n",
      "Epoch 104: 0.4585215449333191, Accuracy: 0.8751999735832214\n",
      "Epoch 105: 0.43122628331184387, Accuracy: 0.885200023651123\n",
      "Epoch 106: 0.412014901638031, Accuracy: 0.8863000273704529\n",
      "Epoch 107: 0.40335556864738464, Accuracy: 0.8899000287055969\n",
      "Epoch 108: 0.3969708979129791, Accuracy: 0.8902999758720398\n",
      "Epoch 109: 0.39353638887405396, Accuracy: 0.8906000256538391\n",
      "Epoch 110: 0.391084760427475, Accuracy: 0.8913999795913696\n",
      "Epoch 111: 0.38992539048194885, Accuracy: 0.8902999758720398\n",
      "Epoch 112: 0.3901398479938507, Accuracy: 0.8903999924659729\n",
      "Epoch 113: 0.3907150328159332, Accuracy: 0.8881000280380249\n",
      "Epoch 114: 0.39440712332725525, Accuracy: 0.8859999775886536\n",
      "Epoch 115: 0.396001935005188, Accuracy: 0.8823999762535095\n",
      "Epoch 116: 0.4037613868713379, Accuracy: 0.8823000192642212\n",
      "Epoch 117: 0.40266284346580505, Accuracy: 0.8784999847412109\n",
      "Epoch 118: 0.4113876521587372, Accuracy: 0.8827000260353088\n",
      "Epoch 119: 0.4018358290195465, Accuracy: 0.8812999725341797\n",
      "Epoch 120: 0.40477418899536133, Accuracy: 0.8884000182151794\n",
      "Epoch 121: 0.389751136302948, Accuracy: 0.8895000219345093\n",
      "Epoch 122: 0.3878299593925476, Accuracy: 0.8944000005722046\n",
      "Epoch 123: 0.37573301792144775, Accuracy: 0.8944000005722046\n",
      "Epoch 124: 0.37344756722450256, Accuracy: 0.8981000185012817\n",
      "Epoch 125: 0.365665078163147, Accuracy: 0.8973000049591064\n",
      "Epoch 126: 0.36427435278892517, Accuracy: 0.9006999731063843\n",
      "Epoch 127: 0.3591492474079132, Accuracy: 0.8988999724388123\n",
      "Epoch 128: 0.35851284861564636, Accuracy: 0.9021000266075134\n",
      "Epoch 129: 0.35483333468437195, Accuracy: 0.8992000222206116\n",
      "Epoch 130: 0.3548487424850464, Accuracy: 0.902899980545044\n",
      "Epoch 131: 0.35199296474456787, Accuracy: 0.8995000123977661\n",
      "Epoch 132: 0.3526795208454132, Accuracy: 0.9020000100135803\n",
      "Epoch 133: 0.35037893056869507, Accuracy: 0.8992000222206116\n",
      "Epoch 134: 0.3518000841140747, Accuracy: 0.9017999768257141\n",
      "Epoch 135: 0.3499724268913269, Accuracy: 0.8999999761581421\n",
      "Epoch 136: 0.35220977663993835, Accuracy: 0.9017999768257141\n",
      "Epoch 137: 0.35081079602241516, Accuracy: 0.8999999761581421\n",
      "Epoch 138: 0.3537434935569763, Accuracy: 0.9007999897003174\n",
      "Epoch 139: 0.35272839665412903, Accuracy: 0.8988999724388123\n",
      "Epoch 140: 0.35596948862075806, Accuracy: 0.8996999859809875\n",
      "Epoch 141: 0.35516080260276794, Accuracy: 0.8988000154495239\n",
      "Epoch 142: 0.3578417897224426, Accuracy: 0.9007999897003174\n",
      "Epoch 143: 0.3568374216556549, Accuracy: 0.8996999859809875\n",
      "Epoch 144: 0.35793861746788025, Accuracy: 0.9003999829292297\n",
      "Epoch 145: 0.3561255633831024, Accuracy: 0.9007999897003174\n",
      "Epoch 146: 0.35501813888549805, Accuracy: 0.900600016117096\n",
      "Epoch 147: 0.351958304643631, Accuracy: 0.902400016784668\n",
      "Epoch 148: 0.34916025400161743, Accuracy: 0.9027000069618225\n",
      "Epoch 149: 0.3452811539173126, Accuracy: 0.9042999744415283\n",
      "Epoch 150: 0.34187543392181396, Accuracy: 0.9039000272750854\n",
      "Epoch 151: 0.3379673957824707, Accuracy: 0.9071000218391418\n",
      "Epoch 152: 0.33488425612449646, Accuracy: 0.9057999849319458\n",
      "Epoch 153: 0.3314686417579651, Accuracy: 0.90829998254776\n",
      "Epoch 154: 0.3290557861328125, Accuracy: 0.9078999757766724\n",
      "Epoch 155: 0.32621556520462036, Accuracy: 0.9089999794960022\n",
      "Epoch 156: 0.3244180381298065, Accuracy: 0.9078999757766724\n",
      "Epoch 157: 0.3221052587032318, Accuracy: 0.909600019454956\n",
      "Epoch 158: 0.32081884145736694, Accuracy: 0.9085999727249146\n",
      "Epoch 159: 0.318907767534256, Accuracy: 0.9097999930381775\n",
      "Epoch 160: 0.31799089908599854, Accuracy: 0.909500002861023\n",
      "Epoch 161: 0.3163903057575226, Accuracy: 0.9103999733924866\n",
      "Epoch 162: 0.31579193472862244, Accuracy: 0.9103999733924866\n",
      "Epoch 163: 0.31445378065109253, Accuracy: 0.9108999967575073\n",
      "Epoch 164: 0.3141205608844757, Accuracy: 0.9104999899864197\n",
      "Epoch 165: 0.3130168318748474, Accuracy: 0.911300003528595\n",
      "Epoch 166: 0.31293386220932007, Accuracy: 0.9103000164031982\n",
      "Epoch 167: 0.31205838918685913, Accuracy: 0.9125000238418579\n",
      "Epoch 168: 0.3121846616268158, Accuracy: 0.9099000096321106\n",
      "Epoch 169: 0.31154167652130127, Accuracy: 0.9121000170707703\n",
      "Epoch 170: 0.31179648637771606, Accuracy: 0.9093000292778015\n",
      "Epoch 171: 0.31134718656539917, Accuracy: 0.9117000102996826\n",
      "Epoch 172: 0.31158682703971863, Accuracy: 0.9088000059127808\n",
      "Epoch 173: 0.3112196624279022, Accuracy: 0.9118000268936157\n",
      "Epoch 174: 0.311195969581604, Accuracy: 0.9088000059127808\n",
      "Epoch 175: 0.3107224106788635, Accuracy: 0.9120000004768372\n",
      "Epoch 176: 0.3101732134819031, Accuracy: 0.9089000225067139\n",
      "Epoch 177: 0.3093976676464081, Accuracy: 0.9121999740600586\n",
      "Epoch 178: 0.3081918954849243, Accuracy: 0.9111999869346619\n",
      "Epoch 179: 0.3069775104522705, Accuracy: 0.9129999876022339\n",
      "Epoch 180: 0.3051929473876953, Accuracy: 0.9120000004768372\n",
      "Epoch 181: 0.30362245440483093, Accuracy: 0.9138000011444092\n",
      "Epoch 182: 0.30156248807907104, Accuracy: 0.9140999913215637\n",
      "Epoch 183: 0.2998407483100891, Accuracy: 0.9150000214576721\n",
      "Epoch 184: 0.29779645800590515, Accuracy: 0.9143000245094299\n",
      "Epoch 185: 0.29614001512527466, Accuracy: 0.9164999723434448\n",
      "Epoch 186: 0.29429832100868225, Accuracy: 0.9154000282287598\n",
      "Epoch 187: 0.29280510544776917, Accuracy: 0.9172999858856201\n",
      "Epoch 188: 0.2912074625492096, Accuracy: 0.9172999858856201\n",
      "Epoch 189: 0.28987768292427063, Accuracy: 0.9182000160217285\n",
      "Epoch 190: 0.28849777579307556, Accuracy: 0.9176999926567078\n",
      "Epoch 191: 0.28732946515083313, Accuracy: 0.9190000295639038\n",
      "Epoch 192: 0.28612515330314636, Accuracy: 0.9182999730110168\n",
      "Epoch 193: 0.285089373588562, Accuracy: 0.9200999736785889\n",
      "Epoch 194: 0.2840087115764618, Accuracy: 0.9186000227928162\n",
      "Epoch 195: 0.2830790877342224, Accuracy: 0.9205999970436096\n",
      "Epoch 196: 0.28210341930389404, Accuracy: 0.9190000295639038\n",
      "Epoch 197: 0.28125134110450745, Accuracy: 0.9208999872207642\n",
      "Epoch 198: 0.2803501486778259, Accuracy: 0.9200999736785889\n",
      "Epoch 199: 0.27955886721611023, Accuracy: 0.9207000136375427\n",
      "Epoch 200: 0.2787128686904907, Accuracy: 0.9205999970436096\n",
      "Epoch 201: 0.27797237038612366, Accuracy: 0.9211999773979187\n",
      "Epoch 202: 0.2771660387516022, Accuracy: 0.9211000204086304\n",
      "Epoch 203: 0.27646031975746155, Accuracy: 0.9214000105857849\n",
      "Epoch 204: 0.2756901681423187, Accuracy: 0.9218000173568726\n",
      "Epoch 205: 0.2750258147716522, Accuracy: 0.9215999841690063\n",
      "Epoch 206: 0.2742862403392792, Accuracy: 0.9218000173568726\n",
      "Epoch 207: 0.27365386486053467, Accuracy: 0.9218999743461609\n",
      "Epoch 208: 0.27293989062309265, Accuracy: 0.9222000241279602\n",
      "Epoch 209: 0.2723371684551239, Accuracy: 0.9222999811172485\n",
      "Epoch 210: 0.2716456353664398, Accuracy: 0.9223999977111816\n",
      "Epoch 211: 0.27106863260269165, Accuracy: 0.9232000112533569\n",
      "Epoch 212: 0.2703990042209625, Accuracy: 0.9229000210762024\n",
      "Epoch 213: 0.2698502242565155, Accuracy: 0.9235000014305115\n",
      "Epoch 214: 0.26919984817504883, Accuracy: 0.92330002784729\n",
      "Epoch 215: 0.2686815857887268, Accuracy: 0.9239000082015991\n",
      "Epoch 216: 0.26805219054222107, Accuracy: 0.9236000180244446\n",
      "Epoch 217: 0.26757121086120605, Accuracy: 0.9240000247955322\n",
      "Epoch 218: 0.26695892214775085, Accuracy: 0.923799991607666\n",
      "Epoch 219: 0.26651567220687866, Accuracy: 0.9240999817848206\n",
      "Epoch 220: 0.2659217417240143, Accuracy: 0.9240000247955322\n",
      "Epoch 221: 0.26550766825675964, Accuracy: 0.9240999817848206\n",
      "Epoch 222: 0.26492902636528015, Accuracy: 0.9243000149726868\n",
      "Epoch 223: 0.2645469605922699, Accuracy: 0.9243000149726868\n",
      "Epoch 224: 0.26397350430488586, Accuracy: 0.9247000217437744\n",
      "Epoch 225: 0.26361599564552307, Accuracy: 0.9248999953269958\n",
      "Epoch 226: 0.2630392014980316, Accuracy: 0.9246000051498413\n",
      "Epoch 227: 0.26270368695259094, Accuracy: 0.925000011920929\n",
      "Epoch 228: 0.2621125876903534, Accuracy: 0.9254000186920166\n",
      "Epoch 229: 0.2617921829223633, Accuracy: 0.925000011920929\n",
      "Epoch 230: 0.26118409633636475, Accuracy: 0.9258000254631042\n",
      "Epoch 231: 0.2608678340911865, Accuracy: 0.9251000285148621\n",
      "Epoch 232: 0.26022985577583313, Accuracy: 0.9259999990463257\n",
      "Epoch 233: 0.2599044740200043, Accuracy: 0.9247000217437744\n",
      "Epoch 234: 0.25923559069633484, Accuracy: 0.9262999892234802\n",
      "Epoch 235: 0.2588900625705719, Accuracy: 0.9254000186920166\n",
      "Epoch 236: 0.258188396692276, Accuracy: 0.9262999892234802\n",
      "Epoch 237: 0.2578221261501312, Accuracy: 0.925599992275238\n",
      "Epoch 238: 0.25707629323005676, Accuracy: 0.9262999892234802\n",
      "Epoch 239: 0.2566726803779602, Accuracy: 0.9258000254631042\n",
      "Epoch 240: 0.25588446855545044, Accuracy: 0.9266999959945679\n",
      "Epoch 241: 0.2554321885108948, Accuracy: 0.9261000156402588\n",
      "Epoch 242: 0.25461795926094055, Accuracy: 0.9269000291824341\n",
      "Epoch 243: 0.2541169226169586, Accuracy: 0.9269000291824341\n",
      "Epoch 244: 0.25327736139297485, Accuracy: 0.927299976348877\n",
      "Epoch 245: 0.25273364782333374, Accuracy: 0.9269999861717224\n",
      "Epoch 246: 0.2518767714500427, Accuracy: 0.9276999831199646\n",
      "Epoch 247: 0.25129663944244385, Accuracy: 0.9279000163078308\n",
      "Epoch 248: 0.2504490613937378, Accuracy: 0.9279000163078308\n",
      "Epoch 249: 0.24984712898731232, Accuracy: 0.9286999702453613\n",
      "Epoch 250: 0.24901500344276428, Accuracy: 0.9283999800682068\n",
      "Epoch 251: 0.24839910864830017, Accuracy: 0.9294999837875366\n",
      "Epoch 252: 0.24758446216583252, Accuracy: 0.9290000200271606\n",
      "Epoch 253: 0.24696588516235352, Accuracy: 0.9301999807357788\n",
      "Epoch 254: 0.24617698788642883, Accuracy: 0.9297000169754028\n",
      "Epoch 255: 0.2455577850341797, Accuracy: 0.9305999875068665\n",
      "Epoch 256: 0.24480053782463074, Accuracy: 0.9298999905586243\n",
      "Epoch 257: 0.24418288469314575, Accuracy: 0.9311000108718872\n",
      "Epoch 258: 0.24344708025455475, Accuracy: 0.9297000169754028\n",
      "Epoch 259: 0.24283868074417114, Accuracy: 0.9312999844551086\n",
      "Epoch 260: 0.24212540686130524, Accuracy: 0.9300000071525574\n",
      "Epoch 261: 0.2415306568145752, Accuracy: 0.9318000078201294\n",
      "Epoch 262: 0.24084070324897766, Accuracy: 0.9302999973297119\n",
      "Epoch 263: 0.24025586247444153, Accuracy: 0.9316999912261963\n",
      "Epoch 264: 0.23959071934223175, Accuracy: 0.9307000041007996\n",
      "Epoch 265: 0.2390137016773224, Accuracy: 0.9320999979972839\n",
      "Epoch 266: 0.23836715519428253, Accuracy: 0.9308000206947327\n",
      "Epoch 267: 0.2377990335226059, Accuracy: 0.9326000213623047\n",
      "Epoch 268: 0.23717498779296875, Accuracy: 0.9311000108718872\n",
      "Epoch 269: 0.236619234085083, Accuracy: 0.9327999949455261\n",
      "Epoch 270: 0.23601514101028442, Accuracy: 0.9312999844551086\n",
      "Epoch 271: 0.23547643423080444, Accuracy: 0.9330000281333923\n",
      "Epoch 272: 0.2348921149969101, Accuracy: 0.9314000010490417\n",
      "Epoch 273: 0.2343629002571106, Accuracy: 0.9332000017166138\n",
      "Epoch 274: 0.2337944656610489, Accuracy: 0.9319000244140625\n",
      "Epoch 275: 0.2332744151353836, Accuracy: 0.9333999752998352\n",
      "Epoch 276: 0.23272231221199036, Accuracy: 0.9325000047683716\n",
      "Epoch 277: 0.23221106827259064, Accuracy: 0.9337999820709229\n",
      "Epoch 278: 0.23167011141777039, Accuracy: 0.9327999949455261\n",
      "Epoch 279: 0.2311667799949646, Accuracy: 0.934499979019165\n",
      "Epoch 280: 0.2306341975927353, Accuracy: 0.9332000017166138\n",
      "Epoch 281: 0.23013964295387268, Accuracy: 0.9344000220298767\n",
      "Epoch 282: 0.2296151965856552, Accuracy: 0.9333999752998352\n",
      "Epoch 283: 0.22913019359111786, Accuracy: 0.9348999857902527\n",
      "Epoch 284: 0.22861605882644653, Accuracy: 0.9337000250816345\n",
      "Epoch 285: 0.22813250124454498, Accuracy: 0.9352999925613403\n",
      "Epoch 286: 0.22762951254844666, Accuracy: 0.9336000084877014\n",
      "Epoch 287: 0.22715362906455994, Accuracy: 0.9354000091552734\n",
      "Epoch 288: 0.22665618360042572, Accuracy: 0.933899998664856\n",
      "Epoch 289: 0.22618989646434784, Accuracy: 0.9355999827384949\n",
      "Epoch 290: 0.22570063173770905, Accuracy: 0.9341999888420105\n",
      "Epoch 291: 0.22523722052574158, Accuracy: 0.9359999895095825\n",
      "Epoch 292: 0.22474874556064606, Accuracy: 0.9341999888420105\n",
      "Epoch 293: 0.2242884784936905, Accuracy: 0.9362999796867371\n",
      "Epoch 294: 0.2238064557313919, Accuracy: 0.934499979019165\n",
      "Epoch 295: 0.22335098683834076, Accuracy: 0.9366999864578247\n",
      "Epoch 296: 0.22287334501743317, Accuracy: 0.9350000023841858\n",
      "Epoch 297: 0.22242185473442078, Accuracy: 0.9366999864578247\n",
      "Epoch 298: 0.22195173799991608, Accuracy: 0.9350000023841858\n",
      "Epoch 299: 0.221504807472229, Accuracy: 0.9370999932289124\n",
      "Epoch 300: 0.22103683650493622, Accuracy: 0.9354000091552734\n",
      "Epoch 301: 0.22059057652950287, Accuracy: 0.9373000264167786\n",
      "Epoch 302: 0.22012366354465485, Accuracy: 0.9358000159263611\n",
      "Epoch 303: 0.21968242526054382, Accuracy: 0.9375\n",
      "Epoch 304: 0.21921730041503906, Accuracy: 0.9361000061035156\n",
      "Epoch 305: 0.21878021955490112, Accuracy: 0.9373999834060669\n",
      "Epoch 306: 0.21832138299942017, Accuracy: 0.9363999962806702\n",
      "Epoch 307: 0.2178891897201538, Accuracy: 0.9376000165939331\n",
      "Epoch 308: 0.21743109822273254, Accuracy: 0.9366999864578247\n",
      "Epoch 309: 0.21700182557106018, Accuracy: 0.9379000067710876\n",
      "Epoch 310: 0.21654962003231049, Accuracy: 0.9369000196456909\n",
      "Epoch 311: 0.21612198650836945, Accuracy: 0.9380999803543091\n",
      "Epoch 312: 0.21567457914352417, Accuracy: 0.9373999834060669\n",
      "Epoch 313: 0.21525004506111145, Accuracy: 0.9383000135421753\n",
      "Epoch 314: 0.21480515599250793, Accuracy: 0.9379000067710876\n",
      "Epoch 315: 0.21438433229923248, Accuracy: 0.9387000203132629\n",
      "Epoch 316: 0.2139422595500946, Accuracy: 0.9383000135421753\n",
      "Epoch 317: 0.21352235972881317, Accuracy: 0.939300000667572\n",
      "Epoch 318: 0.21307958662509918, Accuracy: 0.9384999871253967\n",
      "Epoch 319: 0.21266232430934906, Accuracy: 0.9395999908447266\n",
      "Epoch 320: 0.2122192233800888, Accuracy: 0.9387000203132629\n",
      "Epoch 321: 0.21179886162281036, Accuracy: 0.9395999908447266\n",
      "Epoch 322: 0.21135902404785156, Accuracy: 0.9391000270843506\n",
      "Epoch 323: 0.2109408676624298, Accuracy: 0.9395999908447266\n",
      "Epoch 324: 0.21049733459949493, Accuracy: 0.9394999742507935\n",
      "Epoch 325: 0.2100813239812851, Accuracy: 0.9399999976158142\n",
      "Epoch 326: 0.2096404880285263, Accuracy: 0.9398000240325928\n",
      "Epoch 327: 0.209224134683609, Accuracy: 0.9401000142097473\n",
      "Epoch 328: 0.20878712832927704, Accuracy: 0.9401000142097473\n",
      "Epoch 329: 0.20837196707725525, Accuracy: 0.9401000142097473\n",
      "Epoch 330: 0.2079385370016098, Accuracy: 0.9401999711990356\n",
      "Epoch 331: 0.20752321183681488, Accuracy: 0.9402999877929688\n",
      "Epoch 332: 0.20709611475467682, Accuracy: 0.9405999779701233\n",
      "Epoch 333: 0.20668098330497742, Accuracy: 0.940500020980835\n",
      "Epoch 334: 0.20625293254852295, Accuracy: 0.9406999945640564\n",
      "Epoch 335: 0.20583543181419373, Accuracy: 0.9405999779701233\n",
      "Epoch 336: 0.20540867745876312, Accuracy: 0.9409000277519226\n",
      "Epoch 337: 0.204995796084404, Accuracy: 0.9409000277519226\n",
      "Epoch 338: 0.20457114279270172, Accuracy: 0.9412999749183655\n",
      "Epoch 339: 0.20416082441806793, Accuracy: 0.941100001335144\n",
      "Epoch 340: 0.2037346363067627, Accuracy: 0.9413999915122986\n",
      "Epoch 341: 0.20332540571689606, Accuracy: 0.9415000081062317\n",
      "Epoch 342: 0.20290040969848633, Accuracy: 0.9416000247001648\n",
      "Epoch 343: 0.20249530673027039, Accuracy: 0.9415000081062317\n",
      "Epoch 344: 0.20207686722278595, Accuracy: 0.9416999816894531\n",
      "Epoch 345: 0.2016749233007431, Accuracy: 0.9416000247001648\n",
      "Epoch 346: 0.20126095414161682, Accuracy: 0.9417999982833862\n",
      "Epoch 347: 0.20086179673671722, Accuracy: 0.9417999982833862\n",
      "Epoch 348: 0.20045116543769836, Accuracy: 0.9420999884605408\n",
      "Epoch 349: 0.2000531256198883, Accuracy: 0.9422000050544739\n",
      "Epoch 350: 0.19964423775672913, Accuracy: 0.942300021648407\n",
      "Epoch 351: 0.1992505043745041, Accuracy: 0.9420999884605408\n",
      "Epoch 352: 0.1988449990749359, Accuracy: 0.9426000118255615\n",
      "Epoch 353: 0.19845376908779144, Accuracy: 0.9424999952316284\n",
      "Epoch 354: 0.19805356860160828, Accuracy: 0.942799985408783\n",
      "Epoch 355: 0.1976671814918518, Accuracy: 0.9430000185966492\n",
      "Epoch 356: 0.1972721517086029, Accuracy: 0.9429000020027161\n",
      "Epoch 357: 0.1968897581100464, Accuracy: 0.9434999823570251\n",
      "Epoch 358: 0.196497842669487, Accuracy: 0.9434000253677368\n",
      "Epoch 359: 0.19611701369285583, Accuracy: 0.9437000155448914\n",
      "Epoch 360: 0.1957278698682785, Accuracy: 0.9435999989509583\n",
      "Epoch 361: 0.19534900784492493, Accuracy: 0.9438999891281128\n",
      "Epoch 362: 0.19496163725852966, Accuracy: 0.9438999891281128\n",
      "Epoch 363: 0.19458532333374023, Accuracy: 0.944100022315979\n",
      "Epoch 364: 0.19419845938682556, Accuracy: 0.9441999793052673\n",
      "Epoch 365: 0.19382578134536743, Accuracy: 0.9442999958992004\n",
      "Epoch 366: 0.19344063103199005, Accuracy: 0.944599986076355\n",
      "Epoch 367: 0.19306820631027222, Accuracy: 0.9442999958992004\n",
      "Epoch 368: 0.19268609583377838, Accuracy: 0.9448000192642212\n",
      "Epoch 369: 0.1923139989376068, Accuracy: 0.9442999958992004\n",
      "Epoch 370: 0.1919359564781189, Accuracy: 0.9452000260353088\n",
      "Epoch 371: 0.19156549870967865, Accuracy: 0.9444000124931335\n",
      "Epoch 372: 0.1911887228488922, Accuracy: 0.9455999732017517\n",
      "Epoch 373: 0.1908188760280609, Accuracy: 0.9445000290870667\n",
      "Epoch 374: 0.19044405221939087, Accuracy: 0.945900022983551\n",
      "Epoch 375: 0.19007804989814758, Accuracy: 0.9447000026702881\n",
      "Epoch 376: 0.1897084265947342, Accuracy: 0.9460999965667725\n",
      "Epoch 377: 0.18934644758701324, Accuracy: 0.9448999762535095\n",
      "Epoch 378: 0.18898038566112518, Accuracy: 0.9460999965667725\n",
      "Epoch 379: 0.18862424790859222, Accuracy: 0.9451000094413757\n",
      "Epoch 380: 0.1882624626159668, Accuracy: 0.9460999965667725\n",
      "Epoch 381: 0.18790684640407562, Accuracy: 0.9452999830245972\n",
      "Epoch 382: 0.18754784762859344, Accuracy: 0.9463000297546387\n",
      "Epoch 383: 0.187196284532547, Accuracy: 0.9452999830245972\n",
      "Epoch 384: 0.18683992326259613, Accuracy: 0.9463000297546387\n",
      "Epoch 385: 0.1864914894104004, Accuracy: 0.9452999830245972\n",
      "Epoch 386: 0.1861390918493271, Accuracy: 0.9465000033378601\n",
      "Epoch 387: 0.1857932060956955, Accuracy: 0.9456999897956848\n",
      "Epoch 388: 0.18544581532478333, Accuracy: 0.9465000033378601\n",
      "Epoch 389: 0.1851017326116562, Accuracy: 0.9455999732017517\n",
      "Epoch 390: 0.18475715816020966, Accuracy: 0.9466999769210815\n",
      "Epoch 391: 0.18441544473171234, Accuracy: 0.945900022983551\n",
      "Epoch 392: 0.18407288193702698, Accuracy: 0.9470999836921692\n",
      "Epoch 393: 0.1837335228919983, Accuracy: 0.9460999965667725\n",
      "Epoch 394: 0.18339477479457855, Accuracy: 0.9473999738693237\n",
      "Epoch 395: 0.1830567568540573, Accuracy: 0.9463000297546387\n",
      "Epoch 396: 0.1827203929424286, Accuracy: 0.9472000002861023\n",
      "Epoch 397: 0.18238449096679688, Accuracy: 0.9466000199317932\n",
      "Epoch 398: 0.18204987049102783, Accuracy: 0.9473000168800354\n",
      "Epoch 399: 0.18171843886375427, Accuracy: 0.9469000101089478\n",
      "Epoch 400: 0.18138648569583893, Accuracy: 0.9472000002861023\n",
      "Epoch 401: 0.18105702102184296, Accuracy: 0.9473000168800354\n",
      "Epoch 402: 0.18072789907455444, Accuracy: 0.9473000168800354\n",
      "Epoch 403: 0.18040096759796143, Accuracy: 0.9473000168800354\n",
      "Epoch 404: 0.18007434904575348, Accuracy: 0.9473999738693237\n",
      "Epoch 405: 0.17974868416786194, Accuracy: 0.9474999904632568\n",
      "Epoch 406: 0.1794241964817047, Accuracy: 0.9476000070571899\n",
      "Epoch 407: 0.1791001856327057, Accuracy: 0.947700023651123\n",
      "Epoch 408: 0.17877893149852753, Accuracy: 0.9476000070571899\n",
      "Epoch 409: 0.17845721542835236, Accuracy: 0.9480000138282776\n",
      "Epoch 410: 0.17813760042190552, Accuracy: 0.9477999806404114\n",
      "Epoch 411: 0.17781759798526764, Accuracy: 0.9480000138282776\n",
      "Epoch 412: 0.1774994432926178, Accuracy: 0.9480999708175659\n",
      "Epoch 413: 0.17718183994293213, Accuracy: 0.9480999708175659\n",
      "Epoch 414: 0.17686541378498077, Accuracy: 0.9484999775886536\n",
      "Epoch 415: 0.17655138671398163, Accuracy: 0.948199987411499\n",
      "Epoch 416: 0.17623713612556458, Accuracy: 0.9485999941825867\n",
      "Epoch 417: 0.17592410743236542, Accuracy: 0.9480999708175659\n",
      "Epoch 418: 0.17561355233192444, Accuracy: 0.9485999941825867\n",
      "Epoch 419: 0.17530253529548645, Accuracy: 0.9480000138282776\n",
      "Epoch 420: 0.17499254643917084, Accuracy: 0.9484000205993652\n",
      "Epoch 421: 0.17468377947807312, Accuracy: 0.948199987411499\n",
      "Epoch 422: 0.1743762493133545, Accuracy: 0.9484000205993652\n",
      "Epoch 423: 0.17406946420669556, Accuracy: 0.948199987411499\n",
      "Epoch 424: 0.17376387119293213, Accuracy: 0.9483000040054321\n",
      "Epoch 425: 0.17346011102199554, Accuracy: 0.9485999941825867\n",
      "Epoch 426: 0.17315661907196045, Accuracy: 0.9483000040054321\n",
      "Epoch 427: 0.1728547066450119, Accuracy: 0.9487000107765198\n",
      "Epoch 428: 0.17255306243896484, Accuracy: 0.9484999775886536\n",
      "Epoch 429: 0.17225316166877747, Accuracy: 0.9491000175476074\n",
      "Epoch 430: 0.17195314168930054, Accuracy: 0.9487000107765198\n",
      "Epoch 431: 0.1716560572385788, Accuracy: 0.9491000175476074\n",
      "Epoch 432: 0.1713586300611496, Accuracy: 0.9488000273704529\n",
      "Epoch 433: 0.17106372117996216, Accuracy: 0.9492999911308289\n",
      "Epoch 434: 0.17076827585697174, Accuracy: 0.9490000009536743\n",
      "Epoch 435: 0.1704745888710022, Accuracy: 0.9492999911308289\n",
      "Epoch 436: 0.17018093168735504, Accuracy: 0.9491999745368958\n",
      "Epoch 437: 0.1698894053697586, Accuracy: 0.949400007724762\n",
      "Epoch 438: 0.16959761083126068, Accuracy: 0.9492999911308289\n",
      "Epoch 439: 0.16930748522281647, Accuracy: 0.949400007724762\n",
      "Epoch 440: 0.16901859641075134, Accuracy: 0.9492999911308289\n",
      "Epoch 441: 0.16872933506965637, Accuracy: 0.9495000243186951\n",
      "Epoch 442: 0.16844165325164795, Accuracy: 0.9495000243186951\n",
      "Epoch 443: 0.16815342009067535, Accuracy: 0.949400007724762\n",
      "Epoch 444: 0.16786593198776245, Accuracy: 0.9495999813079834\n",
      "Epoch 445: 0.16758011281490326, Accuracy: 0.949400007724762\n",
      "Epoch 446: 0.16729344427585602, Accuracy: 0.9495999813079834\n",
      "Epoch 447: 0.16700853407382965, Accuracy: 0.9495000243186951\n",
      "Epoch 448: 0.1667231321334839, Accuracy: 0.9498000144958496\n",
      "Epoch 449: 0.16643886268138885, Accuracy: 0.9495999813079834\n",
      "Epoch 450: 0.16615517437458038, Accuracy: 0.9498999714851379\n",
      "Epoch 451: 0.165871724486351, Accuracy: 0.9496999979019165\n",
      "Epoch 452: 0.16559015214443207, Accuracy: 0.9498999714851379\n",
      "Epoch 453: 0.16530820727348328, Accuracy: 0.949999988079071\n",
      "Epoch 454: 0.1650291085243225, Accuracy: 0.9498999714851379\n",
      "Epoch 455: 0.16474944353103638, Accuracy: 0.9502000212669373\n",
      "Epoch 456: 0.16447192430496216, Accuracy: 0.949999988079071\n",
      "Epoch 457: 0.16419439017772675, Accuracy: 0.9502999782562256\n",
      "Epoch 458: 0.16391804814338684, Accuracy: 0.9501000046730042\n",
      "Epoch 459: 0.16364307701587677, Accuracy: 0.9505000114440918\n",
      "Epoch 460: 0.16336899995803833, Accuracy: 0.9502000212669373\n",
      "Epoch 461: 0.16309550404548645, Accuracy: 0.9506000280380249\n",
      "Epoch 462: 0.16282257437705994, Accuracy: 0.9502000212669373\n",
      "Epoch 463: 0.16255217790603638, Accuracy: 0.9509000182151794\n",
      "Epoch 464: 0.1622815579175949, Accuracy: 0.9502999782562256\n",
      "Epoch 465: 0.16201277077198029, Accuracy: 0.9509999752044678\n",
      "Epoch 466: 0.16174378991127014, Accuracy: 0.9503999948501587\n",
      "Epoch 467: 0.16147661209106445, Accuracy: 0.9513999819755554\n",
      "Epoch 468: 0.16120915114879608, Accuracy: 0.9505000114440918\n",
      "Epoch 469: 0.1609429568052292, Accuracy: 0.9513999819755554\n",
      "Epoch 470: 0.16067706048488617, Accuracy: 0.9506999850273132\n",
      "Epoch 471: 0.16041189432144165, Accuracy: 0.9513999819755554\n",
      "Epoch 472: 0.1601477563381195, Accuracy: 0.9508000016212463\n",
      "Epoch 473: 0.15988416969776154, Accuracy: 0.9514999985694885\n",
      "Epoch 474: 0.15962128341197968, Accuracy: 0.9509999752044678\n",
      "Epoch 475: 0.15935951471328735, Accuracy: 0.9514999985694885\n",
      "Epoch 476: 0.15909820795059204, Accuracy: 0.9510999917984009\n",
      "Epoch 477: 0.15883769094944, Accuracy: 0.95169997215271\n",
      "Epoch 478: 0.1585780382156372, Accuracy: 0.9513000249862671\n",
      "Epoch 479: 0.1583194136619568, Accuracy: 0.95169997215271\n",
      "Epoch 480: 0.1580614596605301, Accuracy: 0.9514999985694885\n",
      "Epoch 481: 0.15780413150787354, Accuracy: 0.95169997215271\n",
      "Epoch 482: 0.1575472503900528, Accuracy: 0.9516000151634216\n",
      "Epoch 483: 0.15729162096977234, Accuracy: 0.9519000053405762\n",
      "Epoch 484: 0.15703649818897247, Accuracy: 0.9517999887466431\n",
      "Epoch 485: 0.1567825824022293, Accuracy: 0.9520000219345093\n",
      "Epoch 486: 0.1565287560224533, Accuracy: 0.9519000053405762\n",
      "Epoch 487: 0.15627603232860565, Accuracy: 0.9520999789237976\n",
      "Epoch 488: 0.15602336823940277, Accuracy: 0.9519000053405762\n",
      "Epoch 489: 0.15577179193496704, Accuracy: 0.9521999955177307\n",
      "Epoch 490: 0.15552064776420593, Accuracy: 0.9519000053405762\n",
      "Epoch 491: 0.15527068078517914, Accuracy: 0.9521999955177307\n",
      "Epoch 492: 0.15502125024795532, Accuracy: 0.9520000219345093\n",
      "Epoch 493: 0.15477240085601807, Accuracy: 0.9523000121116638\n",
      "Epoch 494: 0.15452441573143005, Accuracy: 0.9520999789237976\n",
      "Epoch 495: 0.15427759289741516, Accuracy: 0.9524999856948853\n",
      "Epoch 496: 0.15403124690055847, Accuracy: 0.9523000121116638\n",
      "Epoch 497: 0.1537855565547943, Accuracy: 0.9526000022888184\n",
      "Epoch 498: 0.1535404920578003, Accuracy: 0.9524999856948853\n",
      "Epoch 499: 0.15329666435718536, Accuracy: 0.9531999826431274\n",
      "Epoch 500: 0.15305320918560028, Accuracy: 0.9528999924659729\n",
      "Epoch 501: 0.1528109908103943, Accuracy: 0.9534000158309937\n",
      "Epoch 502: 0.15256918966770172, Accuracy: 0.9531000256538391\n",
      "Epoch 503: 0.1523282527923584, Accuracy: 0.953499972820282\n",
      "Epoch 504: 0.15208768844604492, Accuracy: 0.9532999992370605\n",
      "Epoch 505: 0.1518479883670807, Accuracy: 0.9539999961853027\n",
      "Epoch 506: 0.15160925686359406, Accuracy: 0.953499972820282\n",
      "Epoch 507: 0.15137101709842682, Accuracy: 0.954200029373169\n",
      "Epoch 508: 0.1511334329843521, Accuracy: 0.953499972820282\n",
      "Epoch 509: 0.15089623630046844, Accuracy: 0.954200029373169\n",
      "Epoch 510: 0.15066000819206238, Accuracy: 0.953499972820282\n",
      "Epoch 511: 0.1504240185022354, Accuracy: 0.954200029373169\n",
      "Epoch 512: 0.15018907189369202, Accuracy: 0.9538000226020813\n",
      "Epoch 513: 0.1499548703432083, Accuracy: 0.9544000029563904\n",
      "Epoch 514: 0.14972130954265594, Accuracy: 0.9538999795913696\n",
      "Epoch 515: 0.14948831498622894, Accuracy: 0.9545000195503235\n",
      "Epoch 516: 0.14925654232501984, Accuracy: 0.9542999863624573\n",
      "Epoch 517: 0.14902529120445251, Accuracy: 0.9545000195503235\n",
      "Epoch 518: 0.14879466593265533, Accuracy: 0.9545000195503235\n",
      "Epoch 519: 0.14856474101543427, Accuracy: 0.9545999765396118\n",
      "Epoch 520: 0.14833520352840424, Accuracy: 0.9546999931335449\n",
      "Epoch 521: 0.14810633659362793, Accuracy: 0.9546999931335449\n",
      "Epoch 522: 0.14787812530994415, Accuracy: 0.9550999999046326\n",
      "Epoch 523: 0.14765086770057678, Accuracy: 0.954800009727478\n",
      "Epoch 524: 0.14742381870746613, Accuracy: 0.9550999999046326\n",
      "Epoch 525: 0.147197425365448, Accuracy: 0.9550999999046326\n",
      "Epoch 526: 0.14697177708148956, Accuracy: 0.9552000164985657\n",
      "Epoch 527: 0.14674663543701172, Accuracy: 0.9555000066757202\n",
      "Epoch 528: 0.14652223885059357, Accuracy: 0.955299973487854\n",
      "Epoch 529: 0.14629828929901123, Accuracy: 0.9556999802589417\n",
      "Epoch 530: 0.14607501029968262, Accuracy: 0.9555000066757202\n",
      "Epoch 531: 0.14585207402706146, Accuracy: 0.9556999802589417\n",
      "Epoch 532: 0.14563000202178955, Accuracy: 0.9557999968528748\n",
      "Epoch 533: 0.14540860056877136, Accuracy: 0.9559999704360962\n",
      "Epoch 534: 0.1451881229877472, Accuracy: 0.9557999968528748\n",
      "Epoch 535: 0.14496774971485138, Accuracy: 0.9560999870300293\n",
      "Epoch 536: 0.1447482705116272, Accuracy: 0.9559000134468079\n",
      "Epoch 537: 0.14452894032001495, Accuracy: 0.9560999870300293\n",
      "Epoch 538: 0.14430998265743256, Accuracy: 0.9559000134468079\n",
      "Epoch 539: 0.14409145712852478, Accuracy: 0.9562000036239624\n",
      "Epoch 540: 0.14387348294258118, Accuracy: 0.9559000134468079\n",
      "Epoch 541: 0.14365583658218384, Accuracy: 0.9562000036239624\n",
      "Epoch 542: 0.14343908429145813, Accuracy: 0.9559999704360962\n",
      "Epoch 543: 0.14322270452976227, Accuracy: 0.9562000036239624\n",
      "Epoch 544: 0.14300672709941864, Accuracy: 0.9559000134468079\n",
      "Epoch 545: 0.14279146492481232, Accuracy: 0.9563000202178955\n",
      "Epoch 546: 0.14257732033729553, Accuracy: 0.9559999704360962\n",
      "Epoch 547: 0.1423637866973877, Accuracy: 0.9563000202178955\n",
      "Epoch 548: 0.14215098321437836, Accuracy: 0.9563999772071838\n",
      "Epoch 549: 0.14193843305110931, Accuracy: 0.9563999772071838\n",
      "Epoch 550: 0.14172637462615967, Accuracy: 0.9564999938011169\n",
      "Epoch 551: 0.14151495695114136, Accuracy: 0.95660001039505\n",
      "Epoch 552: 0.1413041055202484, Accuracy: 0.9567000269889832\n",
      "Epoch 553: 0.14109356701374054, Accuracy: 0.9567000269889832\n",
      "Epoch 554: 0.1408834308385849, Accuracy: 0.9567999839782715\n",
      "Epoch 555: 0.14067389070987701, Accuracy: 0.9567999839782715\n",
      "Epoch 556: 0.1404651403427124, Accuracy: 0.957099974155426\n",
      "Epoch 557: 0.14025700092315674, Accuracy: 0.9570000171661377\n",
      "Epoch 558: 0.14004941284656525, Accuracy: 0.9571999907493591\n",
      "Epoch 559: 0.1398424357175827, Accuracy: 0.957099974155426\n",
      "Epoch 560: 0.13963590562343597, Accuracy: 0.9571999907493591\n",
      "Epoch 561: 0.13942977786064148, Accuracy: 0.9573000073432922\n",
      "Epoch 562: 0.13922421634197235, Accuracy: 0.957099974155426\n",
      "Epoch 563: 0.13901881873607635, Accuracy: 0.9574000239372253\n",
      "Epoch 564: 0.13881421089172363, Accuracy: 0.957099974155426\n",
      "Epoch 565: 0.13860996067523956, Accuracy: 0.9574999809265137\n",
      "Epoch 566: 0.13840638101100922, Accuracy: 0.9573000073432922\n",
      "Epoch 567: 0.13820293545722961, Accuracy: 0.9575999975204468\n",
      "Epoch 568: 0.13800032436847687, Accuracy: 0.9573000073432922\n",
      "Epoch 569: 0.13779804110527039, Accuracy: 0.9578999876976013\n",
      "Epoch 570: 0.13759660720825195, Accuracy: 0.9573000073432922\n",
      "Epoch 571: 0.13739562034606934, Accuracy: 0.9578999876976013\n",
      "Epoch 572: 0.13719531893730164, Accuracy: 0.9577000141143799\n",
      "Epoch 573: 0.13699547946453094, Accuracy: 0.9578999876976013\n",
      "Epoch 574: 0.13679607212543488, Accuracy: 0.9577000141143799\n",
      "Epoch 575: 0.136597141623497, Accuracy: 0.9580000042915344\n",
      "Epoch 576: 0.1363985687494278, Accuracy: 0.9577000141143799\n",
      "Epoch 577: 0.13620062172412872, Accuracy: 0.9580000042915344\n",
      "Epoch 578: 0.1360030621290207, Accuracy: 0.9580000042915344\n",
      "Epoch 579: 0.13580617308616638, Accuracy: 0.9581999778747559\n",
      "Epoch 580: 0.13560941815376282, Accuracy: 0.9581000208854675\n",
      "Epoch 581: 0.1354132890701294, Accuracy: 0.958299994468689\n",
      "Epoch 582: 0.13521745800971985, Accuracy: 0.9584000110626221\n",
      "Epoch 583: 0.1350223869085312, Accuracy: 0.9585999846458435\n",
      "Epoch 584: 0.13482779264450073, Accuracy: 0.9585000276565552\n",
      "Epoch 585: 0.1346336305141449, Accuracy: 0.9587000012397766\n",
      "Epoch 586: 0.13443982601165771, Accuracy: 0.9587000012397766\n",
      "Epoch 587: 0.13424639403820038, Accuracy: 0.958899974822998\n",
      "Epoch 588: 0.13405346870422363, Accuracy: 0.9587000012397766\n",
      "Epoch 589: 0.1338612139225006, Accuracy: 0.9589999914169312\n",
      "Epoch 590: 0.13366957008838654, Accuracy: 0.9587000012397766\n",
      "Epoch 591: 0.13347835838794708, Accuracy: 0.9591000080108643\n",
      "Epoch 592: 0.13328750431537628, Accuracy: 0.958899974822998\n",
      "Epoch 593: 0.1330970972776413, Accuracy: 0.9592000246047974\n",
      "Epoch 594: 0.13290724158287048, Accuracy: 0.9591000080108643\n",
      "Epoch 595: 0.13271787762641907, Accuracy: 0.9592999815940857\n",
      "Epoch 596: 0.1325291097164154, Accuracy: 0.9592999815940857\n",
      "Epoch 597: 0.13234087824821472, Accuracy: 0.9593999981880188\n",
      "Epoch 598: 0.13215303421020508, Accuracy: 0.9592999815940857\n",
      "Epoch 599: 0.1319655179977417, Accuracy: 0.9593999981880188\n",
      "Epoch 600: 0.13177864253520966, Accuracy: 0.9592999815940857\n",
      "Epoch 601: 0.1315920203924179, Accuracy: 0.9593999981880188\n",
      "Epoch 602: 0.13140571117401123, Accuracy: 0.9592999815940857\n",
      "Epoch 603: 0.13122011721134186, Accuracy: 0.9593999981880188\n",
      "Epoch 604: 0.13103483617305756, Accuracy: 0.9592999815940857\n",
      "Epoch 605: 0.1308499574661255, Accuracy: 0.9593999981880188\n",
      "Epoch 606: 0.13066543638706207, Accuracy: 0.9592999815940857\n",
      "Epoch 607: 0.13048142194747925, Accuracy: 0.9595000147819519\n",
      "Epoch 608: 0.13029786944389343, Accuracy: 0.9592999815940857\n",
      "Epoch 609: 0.13011454045772552, Accuracy: 0.9595000147819519\n",
      "Epoch 610: 0.12993161380290985, Accuracy: 0.9592999815940857\n",
      "Epoch 611: 0.1297493726015091, Accuracy: 0.9595000147819519\n",
      "Epoch 612: 0.12956762313842773, Accuracy: 0.9592999815940857\n",
      "Epoch 613: 0.129386305809021, Accuracy: 0.9595000147819519\n",
      "Epoch 614: 0.12920519709587097, Accuracy: 0.9593999981880188\n",
      "Epoch 615: 0.12902459502220154, Accuracy: 0.9595999717712402\n",
      "Epoch 616: 0.12884435057640076, Accuracy: 0.9595000147819519\n",
      "Epoch 617: 0.12866441905498505, Accuracy: 0.9598000049591064\n",
      "Epoch 618: 0.1284848153591156, Accuracy: 0.9595999717712402\n",
      "Epoch 619: 0.12830545008182526, Accuracy: 0.9598000049591064\n",
      "Epoch 620: 0.12812656164169312, Accuracy: 0.9595999717712402\n",
      "Epoch 621: 0.12794791162014008, Accuracy: 0.9599000215530396\n",
      "Epoch 622: 0.12776967883110046, Accuracy: 0.9596999883651733\n",
      "Epoch 623: 0.12759172916412354, Accuracy: 0.9599000215530396\n",
      "Epoch 624: 0.12741418182849884, Accuracy: 0.9599000215530396\n",
      "Epoch 625: 0.12723715603351593, Accuracy: 0.9599999785423279\n",
      "Epoch 626: 0.1270604282617569, Accuracy: 0.9599000215530396\n",
      "Epoch 627: 0.12688401341438293, Accuracy: 0.9602000117301941\n",
      "Epoch 628: 0.12670806050300598, Accuracy: 0.9599000215530396\n",
      "Epoch 629: 0.12653270363807678, Accuracy: 0.9602000117301941\n",
      "Epoch 630: 0.12635767459869385, Accuracy: 0.9599999785423279\n",
      "Epoch 631: 0.12618307769298553, Accuracy: 0.9602000117301941\n",
      "Epoch 632: 0.12600931525230408, Accuracy: 0.960099995136261\n",
      "Epoch 633: 0.12583591043949127, Accuracy: 0.9602000117301941\n",
      "Epoch 634: 0.12566322088241577, Accuracy: 0.9599999785423279\n",
      "Epoch 635: 0.1254907250404358, Accuracy: 0.9603000283241272\n",
      "Epoch 636: 0.12531869113445282, Accuracy: 0.9599999785423279\n",
      "Epoch 637: 0.1251470446586609, Accuracy: 0.9603999853134155\n",
      "Epoch 638: 0.12497592717409134, Accuracy: 0.9602000117301941\n",
      "Epoch 639: 0.12480513751506805, Accuracy: 0.9605000019073486\n",
      "Epoch 640: 0.1246349960565567, Accuracy: 0.9602000117301941\n",
      "Epoch 641: 0.12446507811546326, Accuracy: 0.9605000019073486\n",
      "Epoch 642: 0.12429579347372055, Accuracy: 0.9605000019073486\n",
      "Epoch 643: 0.12412658333778381, Accuracy: 0.9606000185012817\n",
      "Epoch 644: 0.12395787239074707, Accuracy: 0.9606000185012817\n",
      "Epoch 645: 0.12378939986228943, Accuracy: 0.9606999754905701\n",
      "Epoch 646: 0.12362141162157059, Accuracy: 0.9606999754905701\n",
      "Epoch 647: 0.12345359474420547, Accuracy: 0.9609000086784363\n",
      "Epoch 648: 0.12328631430864334, Accuracy: 0.9609000086784363\n",
      "Epoch 649: 0.12311934679746628, Accuracy: 0.9609000086784363\n",
      "Epoch 650: 0.12295286357402802, Accuracy: 0.9610000252723694\n",
      "Epoch 651: 0.12278702110052109, Accuracy: 0.9610000252723694\n",
      "Epoch 652: 0.12262154370546341, Accuracy: 0.9610999822616577\n",
      "Epoch 653: 0.12245628982782364, Accuracy: 0.9610999822616577\n",
      "Epoch 654: 0.12229162454605103, Accuracy: 0.9610999822616577\n",
      "Epoch 655: 0.1221272274851799, Accuracy: 0.9613000154495239\n",
      "Epoch 656: 0.12196330726146698, Accuracy: 0.9610999822616577\n",
      "Epoch 657: 0.121799536049366, Accuracy: 0.9613000154495239\n",
      "Epoch 658: 0.12163594365119934, Accuracy: 0.9610999822616577\n",
      "Epoch 659: 0.12147271633148193, Accuracy: 0.9613000154495239\n",
      "Epoch 660: 0.12131009995937347, Accuracy: 0.9611999988555908\n",
      "Epoch 661: 0.12114764004945755, Accuracy: 0.9613000154495239\n",
      "Epoch 662: 0.12098562717437744, Accuracy: 0.9613000154495239\n",
      "Epoch 663: 0.1208239495754242, Accuracy: 0.9613999724388123\n",
      "Epoch 664: 0.12066290527582169, Accuracy: 0.9613999724388123\n",
      "Epoch 665: 0.12050189077854156, Accuracy: 0.9613999724388123\n",
      "Epoch 666: 0.12034124881029129, Accuracy: 0.9614999890327454\n",
      "Epoch 667: 0.12018076330423355, Accuracy: 0.9617000222206116\n",
      "Epoch 668: 0.12002076208591461, Accuracy: 0.9614999890327454\n",
      "Epoch 669: 0.1198611706495285, Accuracy: 0.961899995803833\n",
      "Epoch 670: 0.11970215290784836, Accuracy: 0.9617000222206116\n",
      "Epoch 671: 0.11954347789287567, Accuracy: 0.9620000123977661\n",
      "Epoch 672: 0.1193854957818985, Accuracy: 0.9617000222206116\n",
      "Epoch 673: 0.11922740936279297, Accuracy: 0.9620000123977661\n",
      "Epoch 674: 0.11907017230987549, Accuracy: 0.9617000222206116\n",
      "Epoch 675: 0.11891309916973114, Accuracy: 0.961899995803833\n",
      "Epoch 676: 0.11875662952661514, Accuracy: 0.9617000222206116\n",
      "Epoch 677: 0.1186002567410469, Accuracy: 0.9620000123977661\n",
      "Epoch 678: 0.11844463646411896, Accuracy: 0.9617999792098999\n",
      "Epoch 679: 0.1182892918586731, Accuracy: 0.9621000289916992\n",
      "Epoch 680: 0.11813431233167648, Accuracy: 0.961899995803833\n",
      "Epoch 681: 0.11797979474067688, Accuracy: 0.9620000123977661\n",
      "Epoch 682: 0.11782562732696533, Accuracy: 0.961899995803833\n",
      "Epoch 683: 0.11767170578241348, Accuracy: 0.9620000123977661\n",
      "Epoch 684: 0.11751813441514969, Accuracy: 0.9620000123977661\n",
      "Epoch 685: 0.11736446619033813, Accuracy: 0.961899995803833\n",
      "Epoch 686: 0.11721169203519821, Accuracy: 0.9621000289916992\n",
      "Epoch 687: 0.11705873161554337, Accuracy: 0.9621999859809875\n",
      "Epoch 688: 0.11690636724233627, Accuracy: 0.9621000289916992\n",
      "Epoch 689: 0.1167539581656456, Accuracy: 0.9621999859809875\n",
      "Epoch 690: 0.1166018545627594, Accuracy: 0.9621999859809875\n",
      "Epoch 691: 0.11645016819238663, Accuracy: 0.9623000025749207\n",
      "Epoch 692: 0.1162986159324646, Accuracy: 0.9623000025749207\n",
      "Epoch 693: 0.11614743620157242, Accuracy: 0.9623000025749207\n",
      "Epoch 694: 0.11599662154912949, Accuracy: 0.9621999859809875\n",
      "Epoch 695: 0.11584604531526566, Accuracy: 0.9624000191688538\n",
      "Epoch 696: 0.11569603532552719, Accuracy: 0.9623000025749207\n",
      "Epoch 697: 0.11554629355669022, Accuracy: 0.9624000191688538\n",
      "Epoch 698: 0.11539709568023682, Accuracy: 0.9623000025749207\n",
      "Epoch 699: 0.11524790525436401, Accuracy: 0.9624000191688538\n",
      "Epoch 700: 0.1150992214679718, Accuracy: 0.9621999859809875\n",
      "Epoch 701: 0.11495077610015869, Accuracy: 0.9624000191688538\n",
      "Epoch 702: 0.11480283737182617, Accuracy: 0.9621999859809875\n",
      "Epoch 703: 0.11465523391962051, Accuracy: 0.9624999761581421\n",
      "Epoch 704: 0.11450782418251038, Accuracy: 0.9624000191688538\n",
      "Epoch 705: 0.11436081677675247, Accuracy: 0.9627000093460083\n",
      "Epoch 706: 0.11421394348144531, Accuracy: 0.9624999761581421\n",
      "Epoch 707: 0.1140674501657486, Accuracy: 0.9627000093460083\n",
      "Epoch 708: 0.11392129957675934, Accuracy: 0.9627000093460083\n",
      "Epoch 709: 0.11377541720867157, Accuracy: 0.9627000093460083\n",
      "Epoch 710: 0.11362992227077484, Accuracy: 0.9627000093460083\n",
      "Epoch 711: 0.11348453164100647, Accuracy: 0.9628000259399414\n",
      "Epoch 712: 0.11333974450826645, Accuracy: 0.9627000093460083\n",
      "Epoch 713: 0.11319506168365479, Accuracy: 0.9628000259399414\n",
      "Epoch 714: 0.11305084079504013, Accuracy: 0.9627000093460083\n",
      "Epoch 715: 0.11290667206048965, Accuracy: 0.9628999829292297\n",
      "Epoch 716: 0.11276278644800186, Accuracy: 0.9629999995231628\n",
      "Epoch 717: 0.11261926591396332, Accuracy: 0.9628000259399414\n",
      "Epoch 718: 0.11247604340314865, Accuracy: 0.963100016117096\n",
      "Epoch 719: 0.11233318597078323, Accuracy: 0.9628000259399414\n",
      "Epoch 720: 0.11219056695699692, Accuracy: 0.9631999731063843\n",
      "Epoch 721: 0.11204849183559418, Accuracy: 0.9628999829292297\n",
      "Epoch 722: 0.11190656572580338, Accuracy: 0.9631999731063843\n",
      "Epoch 723: 0.11176507920026779, Accuracy: 0.9631999731063843\n",
      "Epoch 724: 0.1116238608956337, Accuracy: 0.9631999731063843\n",
      "Epoch 725: 0.11148323863744736, Accuracy: 0.9632999897003174\n",
      "Epoch 726: 0.11134278029203415, Accuracy: 0.9634000062942505\n",
      "Epoch 727: 0.11120259016752243, Accuracy: 0.9635000228881836\n",
      "Epoch 728: 0.11106261610984802, Accuracy: 0.9634000062942505\n",
      "Epoch 729: 0.11092285066843033, Accuracy: 0.9635999798774719\n",
      "Epoch 730: 0.11078358441591263, Accuracy: 0.9635000228881836\n",
      "Epoch 731: 0.11064448952674866, Accuracy: 0.9634000062942505\n",
      "Epoch 732: 0.11050558090209961, Accuracy: 0.9635999798774719\n",
      "Epoch 733: 0.11036679893732071, Accuracy: 0.9634000062942505\n",
      "Epoch 734: 0.11022857576608658, Accuracy: 0.963699996471405\n",
      "Epoch 735: 0.11009040474891663, Accuracy: 0.9635000228881836\n",
      "Epoch 736: 0.10995260626077652, Accuracy: 0.9639000296592712\n",
      "Epoch 737: 0.10981503129005432, Accuracy: 0.9635000228881836\n",
      "Epoch 738: 0.10967777669429779, Accuracy: 0.9639999866485596\n",
      "Epoch 739: 0.10954073071479797, Accuracy: 0.9635000228881836\n",
      "Epoch 740: 0.109404057264328, Accuracy: 0.9639999866485596\n",
      "Epoch 741: 0.10926751792430878, Accuracy: 0.963699996471405\n",
      "Epoch 742: 0.10913128405809402, Accuracy: 0.9639000296592712\n",
      "Epoch 743: 0.10899519175291061, Accuracy: 0.963699996471405\n",
      "Epoch 744: 0.10885971039533615, Accuracy: 0.9639000296592712\n",
      "Epoch 745: 0.10872424393892288, Accuracy: 0.963699996471405\n",
      "Epoch 746: 0.10858923196792603, Accuracy: 0.9639999866485596\n",
      "Epoch 747: 0.10845405608415604, Accuracy: 0.963699996471405\n",
      "Epoch 748: 0.10831931978464127, Accuracy: 0.9639999866485596\n",
      "Epoch 749: 0.10818493366241455, Accuracy: 0.9638000130653381\n",
      "Epoch 750: 0.10805099457502365, Accuracy: 0.9639999866485596\n",
      "Epoch 751: 0.10791733860969543, Accuracy: 0.9639999866485596\n",
      "Epoch 752: 0.10778401792049408, Accuracy: 0.9639999866485596\n",
      "Epoch 753: 0.10765103250741959, Accuracy: 0.9639999866485596\n",
      "Epoch 754: 0.10751854628324509, Accuracy: 0.9639999866485596\n",
      "Epoch 755: 0.10738595575094223, Accuracy: 0.9639999866485596\n",
      "Epoch 756: 0.10725405067205429, Accuracy: 0.9641000032424927\n",
      "Epoch 757: 0.10712207108736038, Accuracy: 0.9639999866485596\n",
      "Epoch 758: 0.10699057579040527, Accuracy: 0.9642000198364258\n",
      "Epoch 759: 0.10685910284519196, Accuracy: 0.9639999866485596\n",
      "Epoch 760: 0.10672806203365326, Accuracy: 0.9641000032424927\n",
      "Epoch 761: 0.10659722983837128, Accuracy: 0.9639999866485596\n",
      "Epoch 762: 0.10646659880876541, Accuracy: 0.9642000198364258\n",
      "Epoch 763: 0.10633645951747894, Accuracy: 0.9641000032424927\n",
      "Epoch 764: 0.10620656609535217, Accuracy: 0.9642999768257141\n",
      "Epoch 765: 0.10607721656560898, Accuracy: 0.9641000032424927\n",
      "Epoch 766: 0.10594787448644638, Accuracy: 0.9642999768257141\n",
      "Epoch 767: 0.1058187335729599, Accuracy: 0.9643999934196472\n",
      "Epoch 768: 0.10568983107805252, Accuracy: 0.9642999768257141\n",
      "Epoch 769: 0.10556109994649887, Accuracy: 0.9643999934196472\n",
      "Epoch 770: 0.10543239116668701, Accuracy: 0.9642999768257141\n",
      "Epoch 771: 0.10530366748571396, Accuracy: 0.9643999934196472\n",
      "Epoch 772: 0.10517535358667374, Accuracy: 0.9642999768257141\n",
      "Epoch 773: 0.10504703223705292, Accuracy: 0.9646000266075134\n",
      "Epoch 774: 0.1049191802740097, Accuracy: 0.9646000266075134\n",
      "Epoch 775: 0.1047915518283844, Accuracy: 0.9646000266075134\n",
      "Epoch 776: 0.10466410964727402, Accuracy: 0.9646000266075134\n",
      "Epoch 777: 0.10453732311725616, Accuracy: 0.9646000266075134\n",
      "Epoch 778: 0.10441062599420547, Accuracy: 0.9646999835968018\n",
      "Epoch 779: 0.10428463667631149, Accuracy: 0.9646000266075134\n",
      "Epoch 780: 0.10415838658809662, Accuracy: 0.9648000001907349\n",
      "Epoch 781: 0.10403288900852203, Accuracy: 0.9646999835968018\n",
      "Epoch 782: 0.1039067730307579, Accuracy: 0.964900016784668\n",
      "Epoch 783: 0.10378137230873108, Accuracy: 0.9648000001907349\n",
      "Epoch 784: 0.10365598648786545, Accuracy: 0.964900016784668\n",
      "Epoch 785: 0.10353124886751175, Accuracy: 0.9648000001907349\n",
      "Epoch 786: 0.10340629518032074, Accuracy: 0.964900016784668\n",
      "Epoch 787: 0.10328204184770584, Accuracy: 0.9649999737739563\n",
      "Epoch 788: 0.10315797477960587, Accuracy: 0.964900016784668\n",
      "Epoch 789: 0.10303396731615067, Accuracy: 0.9649999737739563\n",
      "Epoch 790: 0.10291021317243576, Accuracy: 0.964900016784668\n",
      "Epoch 791: 0.10278628021478653, Accuracy: 0.9649999737739563\n",
      "Epoch 792: 0.1026626005768776, Accuracy: 0.9649999737739563\n",
      "Epoch 793: 0.10253899544477463, Accuracy: 0.9649999737739563\n",
      "Epoch 794: 0.10241559892892838, Accuracy: 0.9649999737739563\n",
      "Epoch 795: 0.10229256004095078, Accuracy: 0.9648000001907349\n",
      "Epoch 796: 0.10216985642910004, Accuracy: 0.9649999737739563\n",
      "Epoch 797: 0.10204719752073288, Accuracy: 0.964900016784668\n",
      "Epoch 798: 0.10192537307739258, Accuracy: 0.9649999737739563\n",
      "Epoch 799: 0.10180376470088959, Accuracy: 0.964900016784668\n",
      "Epoch 800: 0.10168244689702988, Accuracy: 0.9649999737739563\n",
      "Epoch 801: 0.10156150162220001, Accuracy: 0.9648000001907349\n",
      "Epoch 802: 0.10144104063510895, Accuracy: 0.9650999903678894\n",
      "Epoch 803: 0.10132065415382385, Accuracy: 0.9648000001907349\n",
      "Epoch 804: 0.10120078921318054, Accuracy: 0.9650999903678894\n",
      "Epoch 805: 0.10108073800802231, Accuracy: 0.9648000001907349\n",
      "Epoch 806: 0.10096121579408646, Accuracy: 0.9650999903678894\n",
      "Epoch 807: 0.10084143280982971, Accuracy: 0.964900016784668\n",
      "Epoch 808: 0.1007222980260849, Accuracy: 0.9650999903678894\n",
      "Epoch 809: 0.1006033718585968, Accuracy: 0.964900016784668\n",
      "Epoch 810: 0.1004849374294281, Accuracy: 0.9652000069618225\n",
      "Epoch 811: 0.1003669872879982, Accuracy: 0.964900016784668\n",
      "Epoch 812: 0.10024856775999069, Accuracy: 0.9652000069618225\n",
      "Epoch 813: 0.1001305803656578, Accuracy: 0.964900016784668\n",
      "Epoch 814: 0.10001224279403687, Accuracy: 0.9652000069618225\n",
      "Epoch 815: 0.09989393502473831, Accuracy: 0.9649999737739563\n",
      "Epoch 816: 0.09977573901414871, Accuracy: 0.9652000069618225\n",
      "Epoch 817: 0.09965799748897552, Accuracy: 0.9649999737739563\n",
      "Epoch 818: 0.09954111278057098, Accuracy: 0.9652000069618225\n",
      "Epoch 819: 0.09942467510700226, Accuracy: 0.9649999737739563\n",
      "Epoch 820: 0.09930888563394547, Accuracy: 0.9652000069618225\n",
      "Epoch 821: 0.09919338673353195, Accuracy: 0.9649999737739563\n",
      "Epoch 822: 0.09907843172550201, Accuracy: 0.9652000069618225\n",
      "Epoch 823: 0.09896312654018402, Accuracy: 0.9649999737739563\n",
      "Epoch 824: 0.09884834289550781, Accuracy: 0.9652000069618225\n",
      "Epoch 825: 0.09873342514038086, Accuracy: 0.9650999903678894\n",
      "Epoch 826: 0.09861844033002853, Accuracy: 0.965399980545044\n",
      "Epoch 827: 0.09850352257490158, Accuracy: 0.9652000069618225\n",
      "Epoch 828: 0.09838913381099701, Accuracy: 0.9656000137329102\n",
      "Epoch 829: 0.09827430546283722, Accuracy: 0.9652000069618225\n",
      "Epoch 830: 0.09816040843725204, Accuracy: 0.9656000137329102\n",
      "Epoch 831: 0.09804657846689224, Accuracy: 0.9652000069618225\n",
      "Epoch 832: 0.09793278574943542, Accuracy: 0.9656000137329102\n",
      "Epoch 833: 0.09781993925571442, Accuracy: 0.9653000235557556\n",
      "Epoch 834: 0.09770645201206207, Accuracy: 0.9656999707221985\n",
      "Epoch 835: 0.09759410470724106, Accuracy: 0.9653000235557556\n",
      "Epoch 836: 0.09748052805662155, Accuracy: 0.9656999707221985\n",
      "Epoch 837: 0.09736883640289307, Accuracy: 0.965399980545044\n",
      "Epoch 838: 0.09725557267665863, Accuracy: 0.9657999873161316\n",
      "Epoch 839: 0.09714354574680328, Accuracy: 0.965399980545044\n",
      "Epoch 840: 0.09703035652637482, Accuracy: 0.9657999873161316\n",
      "Epoch 841: 0.09691882878541946, Accuracy: 0.965399980545044\n",
      "Epoch 842: 0.09680607169866562, Accuracy: 0.9659000039100647\n",
      "Epoch 843: 0.09669483453035355, Accuracy: 0.965499997138977\n",
      "Epoch 844: 0.09658289700746536, Accuracy: 0.9657999873161316\n",
      "Epoch 845: 0.0964716374874115, Accuracy: 0.965499997138977\n",
      "Epoch 846: 0.09636019915342331, Accuracy: 0.9659000039100647\n",
      "Epoch 847: 0.09624972939491272, Accuracy: 0.9656999707221985\n",
      "Epoch 848: 0.09613876789808273, Accuracy: 0.9660000205039978\n",
      "Epoch 849: 0.09602826088666916, Accuracy: 0.9656999707221985\n",
      "Epoch 850: 0.09591817855834961, Accuracy: 0.9660000205039978\n",
      "Epoch 851: 0.09580764174461365, Accuracy: 0.9656000137329102\n",
      "Epoch 852: 0.09569837898015976, Accuracy: 0.9660000205039978\n",
      "Epoch 853: 0.09558811038732529, Accuracy: 0.9656999707221985\n",
      "Epoch 854: 0.09547870606184006, Accuracy: 0.9660000205039978\n",
      "Epoch 855: 0.09536914527416229, Accuracy: 0.9657999873161316\n",
      "Epoch 856: 0.0952608659863472, Accuracy: 0.9660000205039978\n",
      "Epoch 857: 0.09515216201543808, Accuracy: 0.9657999873161316\n",
      "Epoch 858: 0.09504442662000656, Accuracy: 0.9660000205039978\n",
      "Epoch 859: 0.0949360653758049, Accuracy: 0.9659000039100647\n",
      "Epoch 860: 0.09482903778553009, Accuracy: 0.9661999940872192\n",
      "Epoch 861: 0.0947204977273941, Accuracy: 0.9659000039100647\n",
      "Epoch 862: 0.09461387246847153, Accuracy: 0.9661999940872192\n",
      "Epoch 863: 0.09450656920671463, Accuracy: 0.9659000039100647\n",
      "Epoch 864: 0.09440065920352936, Accuracy: 0.9661999940872192\n",
      "Epoch 865: 0.09429407864809036, Accuracy: 0.9659000039100647\n",
      "Epoch 866: 0.09418820589780807, Accuracy: 0.9663000106811523\n",
      "Epoch 867: 0.09408286958932877, Accuracy: 0.9659000039100647\n",
      "Epoch 868: 0.09397811442613602, Accuracy: 0.9664000272750854\n",
      "Epoch 869: 0.093873031437397, Accuracy: 0.9661999940872192\n",
      "Epoch 870: 0.09376832842826843, Accuracy: 0.9664999842643738\n",
      "Epoch 871: 0.09366276860237122, Accuracy: 0.9661999940872192\n",
      "Epoch 872: 0.09355934709310532, Accuracy: 0.9668999910354614\n",
      "Epoch 873: 0.09345358610153198, Accuracy: 0.9661999940872192\n",
      "Epoch 874: 0.0933505967259407, Accuracy: 0.9671000242233276\n",
      "Epoch 875: 0.09324558079242706, Accuracy: 0.9664000272750854\n",
      "Epoch 876: 0.0931428000330925, Accuracy: 0.9674000144004822\n",
      "Epoch 877: 0.09303668141365051, Accuracy: 0.9664000272750854\n",
      "Epoch 878: 0.092934250831604, Accuracy: 0.9674000144004822\n",
      "Epoch 879: 0.09282875806093216, Accuracy: 0.9664999842643738\n",
      "Epoch 880: 0.0927269235253334, Accuracy: 0.9674999713897705\n",
      "Epoch 881: 0.09262170642614365, Accuracy: 0.9664999842643738\n",
      "Epoch 882: 0.09252011030912399, Accuracy: 0.9674999713897705\n",
      "Epoch 883: 0.0924152284860611, Accuracy: 0.9664999842643738\n",
      "Epoch 884: 0.09231434762477875, Accuracy: 0.9674000144004822\n",
      "Epoch 885: 0.09220947325229645, Accuracy: 0.9664999842643738\n",
      "Epoch 886: 0.09210759401321411, Accuracy: 0.9674000144004822\n",
      "Epoch 887: 0.09200304001569748, Accuracy: 0.9664999842643738\n",
      "Epoch 888: 0.09190244972705841, Accuracy: 0.9674999713897705\n",
      "Epoch 889: 0.09179729223251343, Accuracy: 0.9670000076293945\n",
      "Epoch 890: 0.09169565886259079, Accuracy: 0.9674999713897705\n",
      "Epoch 891: 0.09158913046121597, Accuracy: 0.967199981212616\n",
      "Epoch 892: 0.091486856341362, Accuracy: 0.9675999879837036\n",
      "Epoch 893: 0.09138185530900955, Accuracy: 0.9672999978065491\n",
      "Epoch 894: 0.09128020703792572, Accuracy: 0.9675999879837036\n",
      "Epoch 895: 0.09117549657821655, Accuracy: 0.9672999978065491\n",
      "Epoch 896: 0.09107422828674316, Accuracy: 0.9675999879837036\n",
      "Epoch 897: 0.09096982330083847, Accuracy: 0.9674999713897705\n",
      "Epoch 898: 0.09086889773607254, Accuracy: 0.9675999879837036\n",
      "Epoch 899: 0.09076542407274246, Accuracy: 0.9674999713897705\n",
      "Epoch 900: 0.09066542237997055, Accuracy: 0.9675999879837036\n",
      "Epoch 901: 0.0905630812048912, Accuracy: 0.9674999713897705\n",
      "Epoch 902: 0.09046532958745956, Accuracy: 0.9675999879837036\n",
      "Epoch 903: 0.09036335349082947, Accuracy: 0.9674999713897705\n",
      "Epoch 904: 0.09026626497507095, Accuracy: 0.9678000211715698\n",
      "Epoch 905: 0.09016406536102295, Accuracy: 0.9674999713897705\n",
      "Epoch 906: 0.09006725251674652, Accuracy: 0.9678999781608582\n",
      "Epoch 907: 0.08996526151895523, Accuracy: 0.9674999713897705\n",
      "Epoch 908: 0.0898691788315773, Accuracy: 0.9678999781608582\n",
      "Epoch 909: 0.0897677093744278, Accuracy: 0.9674999713897705\n",
      "Epoch 910: 0.0896710678935051, Accuracy: 0.9678999781608582\n",
      "Epoch 911: 0.0895705297589302, Accuracy: 0.9675999879837036\n",
      "Epoch 912: 0.08947311341762543, Accuracy: 0.9679999947547913\n",
      "Epoch 913: 0.08937317132949829, Accuracy: 0.9678000211715698\n",
      "Epoch 914: 0.0892760157585144, Accuracy: 0.9679999947547913\n",
      "Epoch 915: 0.08917586505413055, Accuracy: 0.9678999781608582\n",
      "Epoch 916: 0.08907847851514816, Accuracy: 0.9681000113487244\n",
      "Epoch 917: 0.08897938579320908, Accuracy: 0.9678999781608582\n",
      "Epoch 918: 0.08888279646635056, Accuracy: 0.9682000279426575\n",
      "Epoch 919: 0.08878341317176819, Accuracy: 0.9678999781608582\n",
      "Epoch 920: 0.08868823945522308, Accuracy: 0.9682999849319458\n",
      "Epoch 921: 0.08858921378850937, Accuracy: 0.9679999947547913\n",
      "Epoch 922: 0.08849294483661652, Accuracy: 0.9682999849319458\n",
      "Epoch 923: 0.0883941799402237, Accuracy: 0.9679999947547913\n",
      "Epoch 924: 0.08829943090677261, Accuracy: 0.9682999849319458\n",
      "Epoch 925: 0.0882013589143753, Accuracy: 0.9679999947547913\n",
      "Epoch 926: 0.08810657262802124, Accuracy: 0.9682999849319458\n",
      "Epoch 927: 0.08800897002220154, Accuracy: 0.9679999947547913\n",
      "Epoch 928: 0.08791548013687134, Accuracy: 0.9684000015258789\n",
      "Epoch 929: 0.08781813830137253, Accuracy: 0.9679999947547913\n",
      "Epoch 930: 0.0877247303724289, Accuracy: 0.968500018119812\n",
      "Epoch 931: 0.0876270979642868, Accuracy: 0.9679999947547913\n",
      "Epoch 932: 0.08753352612257004, Accuracy: 0.968500018119812\n",
      "Epoch 933: 0.08743693679571152, Accuracy: 0.9679999947547913\n",
      "Epoch 934: 0.0873425155878067, Accuracy: 0.9685999751091003\n",
      "Epoch 935: 0.08724655956029892, Accuracy: 0.9679999947547913\n",
      "Epoch 936: 0.0871533751487732, Accuracy: 0.9688000082969666\n",
      "Epoch 937: 0.0870579332113266, Accuracy: 0.9679999947547913\n",
      "Epoch 938: 0.08696399629116058, Accuracy: 0.9688000082969666\n",
      "Epoch 939: 0.08686911314725876, Accuracy: 0.9681000113487244\n",
      "Epoch 940: 0.0867764949798584, Accuracy: 0.968999981880188\n",
      "Epoch 941: 0.08668191730976105, Accuracy: 0.9682000279426575\n",
      "Epoch 942: 0.08659037202596664, Accuracy: 0.968999981880188\n",
      "Epoch 943: 0.08649618178606033, Accuracy: 0.9682000279426575\n",
      "Epoch 944: 0.0864047035574913, Accuracy: 0.968999981880188\n",
      "Epoch 945: 0.08631017804145813, Accuracy: 0.9682000279426575\n",
      "Epoch 946: 0.08621825277805328, Accuracy: 0.968999981880188\n",
      "Epoch 947: 0.08612463623285294, Accuracy: 0.9682999849319458\n",
      "Epoch 948: 0.08603357523679733, Accuracy: 0.968999981880188\n",
      "Epoch 949: 0.08594077080488205, Accuracy: 0.968500018119812\n",
      "Epoch 950: 0.08584963530302048, Accuracy: 0.9690999984741211\n",
      "Epoch 951: 0.08575662970542908, Accuracy: 0.9686999917030334\n",
      "Epoch 952: 0.08566629141569138, Accuracy: 0.9690999984741211\n",
      "Epoch 953: 0.08557295054197311, Accuracy: 0.9686999917030334\n",
      "Epoch 954: 0.08548307418823242, Accuracy: 0.9692000150680542\n",
      "Epoch 955: 0.08539024740457535, Accuracy: 0.9688000082969666\n",
      "Epoch 956: 0.08530042320489883, Accuracy: 0.9692000150680542\n",
      "Epoch 957: 0.08520805090665817, Accuracy: 0.968999981880188\n",
      "Epoch 958: 0.0851203128695488, Accuracy: 0.9692000150680542\n",
      "Epoch 959: 0.08502887934446335, Accuracy: 0.9692000150680542\n",
      "Epoch 960: 0.08494193851947784, Accuracy: 0.9692000150680542\n",
      "Epoch 961: 0.08485051989555359, Accuracy: 0.9690999984741211\n",
      "Epoch 962: 0.08476351201534271, Accuracy: 0.9693999886512756\n",
      "Epoch 963: 0.08467304706573486, Accuracy: 0.9690999984741211\n",
      "Epoch 964: 0.08458603173494339, Accuracy: 0.9695000052452087\n",
      "Epoch 965: 0.08449569344520569, Accuracy: 0.9692000150680542\n",
      "Epoch 966: 0.08440949022769928, Accuracy: 0.9695000052452087\n",
      "Epoch 967: 0.08431971073150635, Accuracy: 0.9692000150680542\n",
      "Epoch 968: 0.0842345729470253, Accuracy: 0.9695000052452087\n",
      "Epoch 969: 0.08414578437805176, Accuracy: 0.9692000150680542\n",
      "Epoch 970: 0.08406195789575577, Accuracy: 0.9695000052452087\n",
      "Epoch 971: 0.08397344499826431, Accuracy: 0.9692000150680542\n",
      "Epoch 972: 0.08389125019311905, Accuracy: 0.9695000052452087\n",
      "Epoch 973: 0.08380240201950073, Accuracy: 0.9693999886512756\n",
      "Epoch 974: 0.08371903747320175, Accuracy: 0.9696000218391418\n",
      "Epoch 975: 0.08363030850887299, Accuracy: 0.9693999886512756\n",
      "Epoch 976: 0.08354777842760086, Accuracy: 0.9696000218391418\n",
      "Epoch 977: 0.08345983177423477, Accuracy: 0.9693999886512756\n",
      "Epoch 978: 0.08337874710559845, Accuracy: 0.9696000218391418\n",
      "Epoch 979: 0.0832914412021637, Accuracy: 0.9696000218391418\n",
      "Epoch 980: 0.08321025967597961, Accuracy: 0.9696000218391418\n",
      "Epoch 981: 0.08312015235424042, Accuracy: 0.9695000052452087\n",
      "Epoch 982: 0.08303838223218918, Accuracy: 0.9696000218391418\n",
      "Epoch 983: 0.08294855803251266, Accuracy: 0.9695000052452087\n",
      "Epoch 984: 0.0828675851225853, Accuracy: 0.9696000218391418\n",
      "Epoch 985: 0.08277751505374908, Accuracy: 0.9695000052452087\n",
      "Epoch 986: 0.08269575983285904, Accuracy: 0.9696000218391418\n",
      "Epoch 987: 0.082606740295887, Accuracy: 0.9695000052452087\n",
      "Epoch 988: 0.08252336084842682, Accuracy: 0.9696000218391418\n",
      "Epoch 989: 0.08243408054113388, Accuracy: 0.9695000052452087\n",
      "Epoch 990: 0.08235141634941101, Accuracy: 0.9696000218391418\n",
      "Epoch 991: 0.08226197957992554, Accuracy: 0.9695000052452087\n",
      "Epoch 992: 0.08218010514974594, Accuracy: 0.9696000218391418\n",
      "Epoch 993: 0.0820910707116127, Accuracy: 0.9696000218391418\n",
      "Epoch 994: 0.08200990408658981, Accuracy: 0.9696999788284302\n",
      "Epoch 995: 0.0819217637181282, Accuracy: 0.9696000218391418\n",
      "Epoch 996: 0.08184143155813217, Accuracy: 0.9696999788284302\n",
      "Epoch 997: 0.08175388723611832, Accuracy: 0.9696000218391418\n",
      "Epoch 998: 0.08167374134063721, Accuracy: 0.9696999788284302\n",
      "Epoch 999: 0.08158668875694275, Accuracy: 0.9696000218391418\n",
      "Epoch 1000: 0.08150739967823029, Accuracy: 0.9696999788284302\n",
      "n_in:  784\n",
      "n_out:  10\n",
      "Epoch 1: 2.6047489643096924, Accuracy: 0.09799999743700027\n",
      "Epoch 2: 2.721940279006958, Accuracy: 0.08940000087022781\n",
      "Epoch 3: 2.3067405223846436, Accuracy: 0.0908999964594841\n",
      "Epoch 4: 2.30497145652771, Accuracy: 0.09109999984502792\n",
      "Epoch 5: 2.3040037155151367, Accuracy: 0.09120000153779984\n",
      "Epoch 6: 2.3033523559570312, Accuracy: 0.09179999679327011\n",
      "Epoch 7: 2.302839994430542, Accuracy: 0.09179999679327011\n",
      "Epoch 8: 2.3023743629455566, Accuracy: 0.09220000356435776\n",
      "Epoch 9: 2.3018887042999268, Accuracy: 0.09189999848604202\n",
      "Epoch 10: 2.301318407058716, Accuracy: 0.0925000011920929\n",
      "Epoch 11: 2.3005685806274414, Accuracy: 0.09440000355243683\n",
      "Epoch 12: 2.2994909286499023, Accuracy: 0.0940999984741211\n",
      "Epoch 13: 2.2978010177612305, Accuracy: 0.09480000287294388\n",
      "Epoch 14: 2.2949421405792236, Accuracy: 0.09520000219345093\n",
      "Epoch 15: 2.289860963821411, Accuracy: 0.09619999676942825\n",
      "Epoch 16: 2.2807650566101074, Accuracy: 0.09489999711513519\n",
      "Epoch 17: 2.265516757965088, Accuracy: 0.09830000251531601\n",
      "Epoch 18: 2.2451012134552, Accuracy: 0.10010000318288803\n",
      "Epoch 19: 2.2236034870147705, Accuracy: 0.1054999977350235\n",
      "Epoch 20: 2.202540159225464, Accuracy: 0.15639999508857727\n",
      "Epoch 21: 2.1830482482910156, Accuracy: 0.21050000190734863\n",
      "Epoch 22: 2.1643784046173096, Accuracy: 0.2459000051021576\n",
      "Epoch 23: 2.1449365615844727, Accuracy: 0.27309998869895935\n",
      "Epoch 24: 2.1235997676849365, Accuracy: 0.2971000075340271\n",
      "Epoch 25: 2.0996227264404297, Accuracy: 0.3156000077724457\n",
      "Epoch 26: 2.072273015975952, Accuracy: 0.334199994802475\n",
      "Epoch 27: 2.040970802307129, Accuracy: 0.357699990272522\n",
      "Epoch 28: 2.005342721939087, Accuracy: 0.3865000009536743\n",
      "Epoch 29: 1.9648163318634033, Accuracy: 0.42320001125335693\n",
      "Epoch 30: 1.9187227487564087, Accuracy: 0.4544999897480011\n",
      "Epoch 31: 1.8664699792861938, Accuracy: 0.5072000026702881\n",
      "Epoch 32: 1.808049201965332, Accuracy: 0.5195000171661377\n",
      "Epoch 33: 1.744089961051941, Accuracy: 0.5623999834060669\n",
      "Epoch 34: 1.6794297695159912, Accuracy: 0.5360000133514404\n",
      "Epoch 35: 1.6277862787246704, Accuracy: 0.48240000009536743\n",
      "Epoch 36: 1.6621627807617188, Accuracy: 0.3377000093460083\n",
      "Epoch 37: 1.7150152921676636, Accuracy: 0.32330000400543213\n",
      "Epoch 38: 2.092318296432495, Accuracy: 0.4997999966144562\n",
      "Epoch 39: 1.6950573921203613, Accuracy: 0.49380001425743103\n",
      "Epoch 40: 1.3727705478668213, Accuracy: 0.6001999974250793\n",
      "Epoch 41: 1.3485087156295776, Accuracy: 0.5845000147819519\n",
      "Epoch 42: 1.4524255990982056, Accuracy: 0.6604999899864197\n",
      "Epoch 43: 1.3418867588043213, Accuracy: 0.6021999716758728\n",
      "Epoch 44: 1.269559383392334, Accuracy: 0.4140999913215637\n",
      "Epoch 45: 1.7158770561218262, Accuracy: 0.35899999737739563\n",
      "Epoch 46: 1.770612359046936, Accuracy: 0.7287999987602234\n",
      "Epoch 47: 1.3680287599563599, Accuracy: 0.7677000164985657\n",
      "Epoch 48: 0.9916819930076599, Accuracy: 0.7361999750137329\n",
      "Epoch 49: 0.9108511805534363, Accuracy: 0.7063000202178955\n",
      "Epoch 50: 0.944812536239624, Accuracy: 0.5659999847412109\n",
      "Epoch 51: 1.3397090435028076, Accuracy: 0.5611000061035156\n",
      "Epoch 52: 1.235284686088562, Accuracy: 0.6820999979972839\n",
      "Epoch 53: 1.0128192901611328, Accuracy: 0.7936999797821045\n",
      "Epoch 54: 0.7702938914299011, Accuracy: 0.7634000182151794\n",
      "Epoch 55: 0.7713401317596436, Accuracy: 0.6198999881744385\n",
      "Epoch 56: 1.0230854749679565, Accuracy: 0.5457000136375427\n",
      "Epoch 57: 1.4338321685791016, Accuracy: 0.6029999852180481\n",
      "Epoch 58: 1.1072001457214355, Accuracy: 0.7526000142097473\n",
      "Epoch 59: 0.8031972646713257, Accuracy: 0.839900016784668\n",
      "Epoch 60: 0.6680006980895996, Accuracy: 0.8281999826431274\n",
      "Epoch 61: 0.6349583864212036, Accuracy: 0.82669997215271\n",
      "Epoch 62: 0.6416601538658142, Accuracy: 0.7594000101089478\n",
      "Epoch 63: 0.7487040758132935, Accuracy: 0.717199981212616\n",
      "Epoch 64: 1.0007189512252808, Accuracy: 0.7125999927520752\n",
      "Epoch 65: 0.9225714206695557, Accuracy: 0.7842000126838684\n",
      "Epoch 66: 0.7467488050460815, Accuracy: 0.829200029373169\n",
      "Epoch 67: 0.6330289244651794, Accuracy: 0.8152999877929688\n",
      "Epoch 68: 0.6254393458366394, Accuracy: 0.8208000063896179\n",
      "Epoch 69: 0.6267901062965393, Accuracy: 0.7796000242233276\n",
      "Epoch 70: 0.6821022033691406, Accuracy: 0.7692000269889832\n",
      "Epoch 71: 0.7092172503471375, Accuracy: 0.7333999872207642\n",
      "Epoch 72: 0.7697106599807739, Accuracy: 0.7817000150680542\n",
      "Epoch 73: 0.6794381737709045, Accuracy: 0.8154000043869019\n",
      "Epoch 74: 0.5936201810836792, Accuracy: 0.8370000123977661\n",
      "Epoch 75: 0.5453171730041504, Accuracy: 0.8345999717712402\n",
      "Epoch 76: 0.5313929915428162, Accuracy: 0.8149999976158142\n",
      "Epoch 77: 0.5459986925125122, Accuracy: 0.7918000221252441\n",
      "Epoch 78: 0.6132373213768005, Accuracy: 0.7324000000953674\n",
      "Epoch 79: 0.7744280099868774, Accuracy: 0.6970000267028809\n",
      "Epoch 80: 0.8404675722122192, Accuracy: 0.7064999938011169\n",
      "Epoch 81: 0.8293929100036621, Accuracy: 0.8158000111579895\n",
      "Epoch 82: 0.6432215571403503, Accuracy: 0.8637999892234802\n",
      "Epoch 83: 0.50741046667099, Accuracy: 0.8708000183105469\n",
      "Epoch 84: 0.48294275999069214, Accuracy: 0.8690999746322632\n",
      "Epoch 85: 0.4757738709449768, Accuracy: 0.866599977016449\n",
      "Epoch 86: 0.48094576597213745, Accuracy: 0.8504999876022339\n",
      "Epoch 87: 0.5027252435684204, Accuracy: 0.8348000049591064\n",
      "Epoch 88: 0.5485931634902954, Accuracy: 0.7957000136375427\n",
      "Epoch 89: 0.6352689266204834, Accuracy: 0.7818999886512756\n",
      "Epoch 90: 0.6703318953514099, Accuracy: 0.7985000014305115\n",
      "Epoch 91: 0.6230283379554749, Accuracy: 0.8486999869346619\n",
      "Epoch 92: 0.5290066003799438, Accuracy: 0.8708999752998352\n",
      "Epoch 93: 0.46832406520843506, Accuracy: 0.8780999779701233\n",
      "Epoch 94: 0.4478550851345062, Accuracy: 0.8788999915122986\n",
      "Epoch 95: 0.4389618933200836, Accuracy: 0.8795999884605408\n",
      "Epoch 96: 0.4345424175262451, Accuracy: 0.8736000061035156\n",
      "Epoch 97: 0.43813368678092957, Accuracy: 0.8722000122070312\n",
      "Epoch 98: 0.4421066641807556, Accuracy: 0.8551999926567078\n",
      "Epoch 99: 0.4658786654472351, Accuracy: 0.8482999801635742\n",
      "Epoch 100: 0.4800177812576294, Accuracy: 0.816100001335144\n",
      "Epoch 101: 0.5339516401290894, Accuracy: 0.8237000107765198\n",
      "Epoch 102: 0.518096387386322, Accuracy: 0.8281000256538391\n",
      "Epoch 103: 0.5142454504966736, Accuracy: 0.8615999817848206\n",
      "Epoch 104: 0.4585215449333191, Accuracy: 0.8751999735832214\n",
      "Epoch 105: 0.43122628331184387, Accuracy: 0.885200023651123\n",
      "Epoch 106: 0.412014901638031, Accuracy: 0.8863000273704529\n",
      "Epoch 107: 0.40335556864738464, Accuracy: 0.8899000287055969\n",
      "Epoch 108: 0.3969708979129791, Accuracy: 0.8902999758720398\n",
      "Epoch 109: 0.39353638887405396, Accuracy: 0.8906000256538391\n",
      "Epoch 110: 0.391084760427475, Accuracy: 0.8913999795913696\n",
      "Epoch 111: 0.38992539048194885, Accuracy: 0.8902999758720398\n",
      "Epoch 112: 0.3901398479938507, Accuracy: 0.8903999924659729\n",
      "Epoch 113: 0.3907150328159332, Accuracy: 0.8881000280380249\n",
      "Epoch 114: 0.39440712332725525, Accuracy: 0.8859999775886536\n",
      "Epoch 115: 0.396001935005188, Accuracy: 0.8823999762535095\n",
      "Epoch 116: 0.4037613868713379, Accuracy: 0.8823000192642212\n",
      "Epoch 117: 0.40266284346580505, Accuracy: 0.8784999847412109\n",
      "Epoch 118: 0.4113876521587372, Accuracy: 0.8827000260353088\n",
      "Epoch 119: 0.4018358290195465, Accuracy: 0.8812999725341797\n",
      "Epoch 120: 0.40477418899536133, Accuracy: 0.8884000182151794\n",
      "Epoch 121: 0.389751136302948, Accuracy: 0.8895000219345093\n",
      "Epoch 122: 0.3878299593925476, Accuracy: 0.8944000005722046\n",
      "Epoch 123: 0.37573301792144775, Accuracy: 0.8944000005722046\n",
      "Epoch 124: 0.37344756722450256, Accuracy: 0.8981000185012817\n",
      "Epoch 125: 0.365665078163147, Accuracy: 0.8973000049591064\n",
      "Epoch 126: 0.36427435278892517, Accuracy: 0.9006999731063843\n",
      "Epoch 127: 0.3591492474079132, Accuracy: 0.8988999724388123\n",
      "Epoch 128: 0.35851284861564636, Accuracy: 0.9021000266075134\n",
      "Epoch 129: 0.35483333468437195, Accuracy: 0.8992000222206116\n",
      "Epoch 130: 0.3548487424850464, Accuracy: 0.902899980545044\n",
      "Epoch 131: 0.35199296474456787, Accuracy: 0.8995000123977661\n",
      "Epoch 132: 0.3526795208454132, Accuracy: 0.9020000100135803\n",
      "Epoch 133: 0.35037893056869507, Accuracy: 0.8992000222206116\n",
      "Epoch 134: 0.3518000841140747, Accuracy: 0.9017999768257141\n",
      "Epoch 135: 0.3499724268913269, Accuracy: 0.8999999761581421\n",
      "Epoch 136: 0.35220977663993835, Accuracy: 0.9017999768257141\n",
      "Epoch 137: 0.35081079602241516, Accuracy: 0.8999999761581421\n",
      "Epoch 138: 0.3537434935569763, Accuracy: 0.9007999897003174\n",
      "Epoch 139: 0.35272839665412903, Accuracy: 0.8988999724388123\n",
      "Epoch 140: 0.35596948862075806, Accuracy: 0.8996999859809875\n",
      "Epoch 141: 0.35516080260276794, Accuracy: 0.8988000154495239\n",
      "Epoch 142: 0.3578417897224426, Accuracy: 0.9007999897003174\n",
      "Epoch 143: 0.3568374216556549, Accuracy: 0.8996999859809875\n",
      "Epoch 144: 0.35793861746788025, Accuracy: 0.9003999829292297\n",
      "Epoch 145: 0.3561255633831024, Accuracy: 0.9007999897003174\n",
      "Epoch 146: 0.35501813888549805, Accuracy: 0.900600016117096\n",
      "Epoch 147: 0.351958304643631, Accuracy: 0.902400016784668\n",
      "Epoch 148: 0.34916025400161743, Accuracy: 0.9027000069618225\n",
      "Epoch 149: 0.3452811539173126, Accuracy: 0.9042999744415283\n",
      "Epoch 150: 0.34187543392181396, Accuracy: 0.9039000272750854\n",
      "Epoch 151: 0.3379673957824707, Accuracy: 0.9071000218391418\n",
      "Epoch 152: 0.33488425612449646, Accuracy: 0.9057999849319458\n",
      "Epoch 153: 0.3314686417579651, Accuracy: 0.90829998254776\n",
      "Epoch 154: 0.3290557861328125, Accuracy: 0.9078999757766724\n",
      "Epoch 155: 0.32621556520462036, Accuracy: 0.9089999794960022\n",
      "Epoch 156: 0.3244180381298065, Accuracy: 0.9078999757766724\n",
      "Epoch 157: 0.3221052587032318, Accuracy: 0.909600019454956\n",
      "Epoch 158: 0.32081884145736694, Accuracy: 0.9085999727249146\n",
      "Epoch 159: 0.318907767534256, Accuracy: 0.9097999930381775\n",
      "Epoch 160: 0.31799089908599854, Accuracy: 0.909500002861023\n",
      "Epoch 161: 0.3163903057575226, Accuracy: 0.9103999733924866\n",
      "Epoch 162: 0.31579193472862244, Accuracy: 0.9103999733924866\n",
      "Epoch 163: 0.31445378065109253, Accuracy: 0.9108999967575073\n",
      "Epoch 164: 0.3141205608844757, Accuracy: 0.9104999899864197\n",
      "Epoch 165: 0.3130168318748474, Accuracy: 0.911300003528595\n",
      "Epoch 166: 0.31293386220932007, Accuracy: 0.9103000164031982\n",
      "Epoch 167: 0.31205838918685913, Accuracy: 0.9125000238418579\n",
      "Epoch 168: 0.3121846616268158, Accuracy: 0.9099000096321106\n",
      "Epoch 169: 0.31154167652130127, Accuracy: 0.9121000170707703\n",
      "Epoch 170: 0.31179648637771606, Accuracy: 0.9093000292778015\n",
      "Epoch 171: 0.31134718656539917, Accuracy: 0.9117000102996826\n",
      "Epoch 172: 0.31158682703971863, Accuracy: 0.9088000059127808\n",
      "Epoch 173: 0.3112196624279022, Accuracy: 0.9118000268936157\n",
      "Epoch 174: 0.311195969581604, Accuracy: 0.9088000059127808\n",
      "Epoch 175: 0.3107224106788635, Accuracy: 0.9120000004768372\n",
      "Epoch 176: 0.3101732134819031, Accuracy: 0.9089000225067139\n",
      "Epoch 177: 0.3093976676464081, Accuracy: 0.9121999740600586\n",
      "Epoch 178: 0.3081918954849243, Accuracy: 0.9111999869346619\n",
      "Epoch 179: 0.3069775104522705, Accuracy: 0.9129999876022339\n",
      "Epoch 180: 0.3051929473876953, Accuracy: 0.9120000004768372\n",
      "Epoch 181: 0.30362245440483093, Accuracy: 0.9138000011444092\n",
      "Epoch 182: 0.30156248807907104, Accuracy: 0.9140999913215637\n",
      "Epoch 183: 0.2998407483100891, Accuracy: 0.9150000214576721\n",
      "Epoch 184: 0.29779645800590515, Accuracy: 0.9143000245094299\n",
      "Epoch 185: 0.29614001512527466, Accuracy: 0.9164999723434448\n",
      "Epoch 186: 0.29429832100868225, Accuracy: 0.9154000282287598\n",
      "Epoch 187: 0.29280510544776917, Accuracy: 0.9172999858856201\n",
      "Epoch 188: 0.2912074625492096, Accuracy: 0.9172999858856201\n",
      "Epoch 189: 0.28987768292427063, Accuracy: 0.9182000160217285\n",
      "Epoch 190: 0.28849777579307556, Accuracy: 0.9176999926567078\n",
      "Epoch 191: 0.28732946515083313, Accuracy: 0.9190000295639038\n",
      "Epoch 192: 0.28612515330314636, Accuracy: 0.9182999730110168\n",
      "Epoch 193: 0.285089373588562, Accuracy: 0.9200999736785889\n",
      "Epoch 194: 0.2840087115764618, Accuracy: 0.9186000227928162\n",
      "Epoch 195: 0.2830790877342224, Accuracy: 0.9205999970436096\n",
      "Epoch 196: 0.28210341930389404, Accuracy: 0.9190000295639038\n",
      "Epoch 197: 0.28125134110450745, Accuracy: 0.9208999872207642\n",
      "Epoch 198: 0.2803501486778259, Accuracy: 0.9200999736785889\n",
      "Epoch 199: 0.27955886721611023, Accuracy: 0.9207000136375427\n",
      "Epoch 200: 0.2787128686904907, Accuracy: 0.9205999970436096\n",
      "Epoch 201: 0.27797237038612366, Accuracy: 0.9211999773979187\n",
      "Epoch 202: 0.2771660387516022, Accuracy: 0.9211000204086304\n",
      "Epoch 203: 0.27646031975746155, Accuracy: 0.9214000105857849\n",
      "Epoch 204: 0.2756901681423187, Accuracy: 0.9218000173568726\n",
      "Epoch 205: 0.2750258147716522, Accuracy: 0.9215999841690063\n",
      "Epoch 206: 0.2742862403392792, Accuracy: 0.9218000173568726\n",
      "Epoch 207: 0.27365386486053467, Accuracy: 0.9218999743461609\n",
      "Epoch 208: 0.27293989062309265, Accuracy: 0.9222000241279602\n",
      "Epoch 209: 0.2723371684551239, Accuracy: 0.9222999811172485\n",
      "Epoch 210: 0.2716456353664398, Accuracy: 0.9223999977111816\n",
      "Epoch 211: 0.27106863260269165, Accuracy: 0.9232000112533569\n",
      "Epoch 212: 0.2703990042209625, Accuracy: 0.9229000210762024\n",
      "Epoch 213: 0.2698502242565155, Accuracy: 0.9235000014305115\n",
      "Epoch 214: 0.26919984817504883, Accuracy: 0.92330002784729\n",
      "Epoch 215: 0.2686815857887268, Accuracy: 0.9239000082015991\n",
      "Epoch 216: 0.26805219054222107, Accuracy: 0.9236000180244446\n",
      "Epoch 217: 0.26757121086120605, Accuracy: 0.9240000247955322\n",
      "Epoch 218: 0.26695892214775085, Accuracy: 0.923799991607666\n",
      "Epoch 219: 0.26651567220687866, Accuracy: 0.9240999817848206\n",
      "Epoch 220: 0.2659217417240143, Accuracy: 0.9240000247955322\n",
      "Epoch 221: 0.26550766825675964, Accuracy: 0.9240999817848206\n",
      "Epoch 222: 0.26492902636528015, Accuracy: 0.9243000149726868\n",
      "Epoch 223: 0.2645469605922699, Accuracy: 0.9243000149726868\n",
      "Epoch 224: 0.26397350430488586, Accuracy: 0.9247000217437744\n",
      "Epoch 225: 0.26361599564552307, Accuracy: 0.9248999953269958\n",
      "Epoch 226: 0.2630392014980316, Accuracy: 0.9246000051498413\n",
      "Epoch 227: 0.26270368695259094, Accuracy: 0.925000011920929\n",
      "Epoch 228: 0.2621125876903534, Accuracy: 0.9254000186920166\n",
      "Epoch 229: 0.2617921829223633, Accuracy: 0.925000011920929\n",
      "Epoch 230: 0.26118409633636475, Accuracy: 0.9258000254631042\n",
      "Epoch 231: 0.2608678340911865, Accuracy: 0.9251000285148621\n",
      "Epoch 232: 0.26022985577583313, Accuracy: 0.9259999990463257\n",
      "Epoch 233: 0.2599044740200043, Accuracy: 0.9247000217437744\n",
      "Epoch 234: 0.25923559069633484, Accuracy: 0.9262999892234802\n",
      "Epoch 235: 0.2588900625705719, Accuracy: 0.9254000186920166\n",
      "Epoch 236: 0.258188396692276, Accuracy: 0.9262999892234802\n",
      "Epoch 237: 0.2578221261501312, Accuracy: 0.925599992275238\n",
      "Epoch 238: 0.25707629323005676, Accuracy: 0.9262999892234802\n",
      "Epoch 239: 0.2566726803779602, Accuracy: 0.9258000254631042\n",
      "Epoch 240: 0.25588446855545044, Accuracy: 0.9266999959945679\n",
      "Epoch 241: 0.2554321885108948, Accuracy: 0.9261000156402588\n",
      "Epoch 242: 0.25461795926094055, Accuracy: 0.9269000291824341\n",
      "Epoch 243: 0.2541169226169586, Accuracy: 0.9269000291824341\n",
      "Epoch 244: 0.25327736139297485, Accuracy: 0.927299976348877\n",
      "Epoch 245: 0.25273364782333374, Accuracy: 0.9269999861717224\n",
      "Epoch 246: 0.2518767714500427, Accuracy: 0.9276999831199646\n",
      "Epoch 247: 0.25129663944244385, Accuracy: 0.9279000163078308\n",
      "Epoch 248: 0.2504490613937378, Accuracy: 0.9279000163078308\n",
      "Epoch 249: 0.24984712898731232, Accuracy: 0.9286999702453613\n",
      "Epoch 250: 0.24901500344276428, Accuracy: 0.9283999800682068\n",
      "Epoch 251: 0.24839910864830017, Accuracy: 0.9294999837875366\n",
      "Epoch 252: 0.24758446216583252, Accuracy: 0.9290000200271606\n",
      "Epoch 253: 0.24696588516235352, Accuracy: 0.9301999807357788\n",
      "Epoch 254: 0.24617698788642883, Accuracy: 0.9297000169754028\n",
      "Epoch 255: 0.2455577850341797, Accuracy: 0.9305999875068665\n",
      "Epoch 256: 0.24480053782463074, Accuracy: 0.9298999905586243\n",
      "Epoch 257: 0.24418288469314575, Accuracy: 0.9311000108718872\n",
      "Epoch 258: 0.24344708025455475, Accuracy: 0.9297000169754028\n",
      "Epoch 259: 0.24283868074417114, Accuracy: 0.9312999844551086\n",
      "Epoch 260: 0.24212540686130524, Accuracy: 0.9300000071525574\n",
      "Epoch 261: 0.2415306568145752, Accuracy: 0.9318000078201294\n",
      "Epoch 262: 0.24084070324897766, Accuracy: 0.9302999973297119\n",
      "Epoch 263: 0.24025586247444153, Accuracy: 0.9316999912261963\n",
      "Epoch 264: 0.23959071934223175, Accuracy: 0.9307000041007996\n",
      "Epoch 265: 0.2390137016773224, Accuracy: 0.9320999979972839\n",
      "Epoch 266: 0.23836715519428253, Accuracy: 0.9308000206947327\n",
      "Epoch 267: 0.2377990335226059, Accuracy: 0.9326000213623047\n",
      "Epoch 268: 0.23717498779296875, Accuracy: 0.9311000108718872\n",
      "Epoch 269: 0.236619234085083, Accuracy: 0.9327999949455261\n",
      "Epoch 270: 0.23601514101028442, Accuracy: 0.9312999844551086\n",
      "Epoch 271: 0.23547643423080444, Accuracy: 0.9330000281333923\n",
      "Epoch 272: 0.2348921149969101, Accuracy: 0.9314000010490417\n",
      "Epoch 273: 0.2343629002571106, Accuracy: 0.9332000017166138\n",
      "Epoch 274: 0.2337944656610489, Accuracy: 0.9319000244140625\n",
      "Epoch 275: 0.2332744151353836, Accuracy: 0.9333999752998352\n",
      "Epoch 276: 0.23272231221199036, Accuracy: 0.9325000047683716\n",
      "Epoch 277: 0.23221106827259064, Accuracy: 0.9337999820709229\n",
      "Epoch 278: 0.23167011141777039, Accuracy: 0.9327999949455261\n",
      "Epoch 279: 0.2311667799949646, Accuracy: 0.934499979019165\n",
      "Epoch 280: 0.2306341975927353, Accuracy: 0.9332000017166138\n",
      "Epoch 281: 0.23013964295387268, Accuracy: 0.9344000220298767\n",
      "Epoch 282: 0.2296151965856552, Accuracy: 0.9333999752998352\n",
      "Epoch 283: 0.22913019359111786, Accuracy: 0.9348999857902527\n",
      "Epoch 284: 0.22861605882644653, Accuracy: 0.9337000250816345\n",
      "Epoch 285: 0.22813250124454498, Accuracy: 0.9352999925613403\n",
      "Epoch 286: 0.22762951254844666, Accuracy: 0.9336000084877014\n",
      "Epoch 287: 0.22715362906455994, Accuracy: 0.9354000091552734\n",
      "Epoch 288: 0.22665618360042572, Accuracy: 0.933899998664856\n",
      "Epoch 289: 0.22618989646434784, Accuracy: 0.9355999827384949\n",
      "Epoch 290: 0.22570063173770905, Accuracy: 0.9341999888420105\n",
      "Epoch 291: 0.22523722052574158, Accuracy: 0.9359999895095825\n",
      "Epoch 292: 0.22474874556064606, Accuracy: 0.9341999888420105\n",
      "Epoch 293: 0.2242884784936905, Accuracy: 0.9362999796867371\n",
      "Epoch 294: 0.2238064557313919, Accuracy: 0.934499979019165\n",
      "Epoch 295: 0.22335098683834076, Accuracy: 0.9366999864578247\n",
      "Epoch 296: 0.22287334501743317, Accuracy: 0.9350000023841858\n",
      "Epoch 297: 0.22242185473442078, Accuracy: 0.9366999864578247\n",
      "Epoch 298: 0.22195173799991608, Accuracy: 0.9350000023841858\n",
      "Epoch 299: 0.221504807472229, Accuracy: 0.9370999932289124\n",
      "Epoch 300: 0.22103683650493622, Accuracy: 0.9354000091552734\n",
      "Epoch 301: 0.22059057652950287, Accuracy: 0.9373000264167786\n",
      "Epoch 302: 0.22012366354465485, Accuracy: 0.9358000159263611\n",
      "Epoch 303: 0.21968242526054382, Accuracy: 0.9375\n",
      "Epoch 304: 0.21921730041503906, Accuracy: 0.9361000061035156\n",
      "Epoch 305: 0.21878021955490112, Accuracy: 0.9373999834060669\n",
      "Epoch 306: 0.21832138299942017, Accuracy: 0.9363999962806702\n",
      "Epoch 307: 0.2178891897201538, Accuracy: 0.9376000165939331\n",
      "Epoch 308: 0.21743109822273254, Accuracy: 0.9366999864578247\n",
      "Epoch 309: 0.21700182557106018, Accuracy: 0.9379000067710876\n",
      "Epoch 310: 0.21654962003231049, Accuracy: 0.9369000196456909\n",
      "Epoch 311: 0.21612198650836945, Accuracy: 0.9380999803543091\n",
      "Epoch 312: 0.21567457914352417, Accuracy: 0.9373999834060669\n",
      "Epoch 313: 0.21525004506111145, Accuracy: 0.9383000135421753\n",
      "Epoch 314: 0.21480515599250793, Accuracy: 0.9379000067710876\n",
      "Epoch 315: 0.21438433229923248, Accuracy: 0.9387000203132629\n",
      "Epoch 316: 0.2139422595500946, Accuracy: 0.9383000135421753\n",
      "Epoch 317: 0.21352235972881317, Accuracy: 0.939300000667572\n",
      "Epoch 318: 0.21307958662509918, Accuracy: 0.9384999871253967\n",
      "Epoch 319: 0.21266232430934906, Accuracy: 0.9395999908447266\n",
      "Epoch 320: 0.2122192233800888, Accuracy: 0.9387000203132629\n",
      "Epoch 321: 0.21179886162281036, Accuracy: 0.9395999908447266\n",
      "Epoch 322: 0.21135902404785156, Accuracy: 0.9391000270843506\n",
      "Epoch 323: 0.2109408676624298, Accuracy: 0.9395999908447266\n",
      "Epoch 324: 0.21049733459949493, Accuracy: 0.9394999742507935\n",
      "Epoch 325: 0.2100813239812851, Accuracy: 0.9399999976158142\n",
      "Epoch 326: 0.2096404880285263, Accuracy: 0.9398000240325928\n",
      "Epoch 327: 0.209224134683609, Accuracy: 0.9401000142097473\n",
      "Epoch 328: 0.20878712832927704, Accuracy: 0.9401000142097473\n",
      "Epoch 329: 0.20837196707725525, Accuracy: 0.9401000142097473\n",
      "Epoch 330: 0.2079385370016098, Accuracy: 0.9401999711990356\n",
      "Epoch 331: 0.20752321183681488, Accuracy: 0.9402999877929688\n",
      "Epoch 332: 0.20709611475467682, Accuracy: 0.9405999779701233\n",
      "Epoch 333: 0.20668098330497742, Accuracy: 0.940500020980835\n",
      "Epoch 334: 0.20625293254852295, Accuracy: 0.9406999945640564\n",
      "Epoch 335: 0.20583543181419373, Accuracy: 0.9405999779701233\n",
      "Epoch 336: 0.20540867745876312, Accuracy: 0.9409000277519226\n",
      "Epoch 337: 0.204995796084404, Accuracy: 0.9409000277519226\n",
      "Epoch 338: 0.20457114279270172, Accuracy: 0.9412999749183655\n",
      "Epoch 339: 0.20416082441806793, Accuracy: 0.941100001335144\n",
      "Epoch 340: 0.2037346363067627, Accuracy: 0.9413999915122986\n",
      "Epoch 341: 0.20332540571689606, Accuracy: 0.9415000081062317\n",
      "Epoch 342: 0.20290040969848633, Accuracy: 0.9416000247001648\n",
      "Epoch 343: 0.20249530673027039, Accuracy: 0.9415000081062317\n",
      "Epoch 344: 0.20207686722278595, Accuracy: 0.9416999816894531\n",
      "Epoch 345: 0.2016749233007431, Accuracy: 0.9416000247001648\n",
      "Epoch 346: 0.20126095414161682, Accuracy: 0.9417999982833862\n",
      "Epoch 347: 0.20086179673671722, Accuracy: 0.9417999982833862\n",
      "Epoch 348: 0.20045116543769836, Accuracy: 0.9420999884605408\n",
      "Epoch 349: 0.2000531256198883, Accuracy: 0.9422000050544739\n",
      "Epoch 350: 0.19964423775672913, Accuracy: 0.942300021648407\n",
      "Epoch 351: 0.1992505043745041, Accuracy: 0.9420999884605408\n",
      "Epoch 352: 0.1988449990749359, Accuracy: 0.9426000118255615\n",
      "Epoch 353: 0.19845376908779144, Accuracy: 0.9424999952316284\n",
      "Epoch 354: 0.19805356860160828, Accuracy: 0.942799985408783\n",
      "Epoch 355: 0.1976671814918518, Accuracy: 0.9430000185966492\n",
      "Epoch 356: 0.1972721517086029, Accuracy: 0.9429000020027161\n",
      "Epoch 357: 0.1968897581100464, Accuracy: 0.9434999823570251\n",
      "Epoch 358: 0.196497842669487, Accuracy: 0.9434000253677368\n",
      "Epoch 359: 0.19611701369285583, Accuracy: 0.9437000155448914\n",
      "Epoch 360: 0.1957278698682785, Accuracy: 0.9435999989509583\n",
      "Epoch 361: 0.19534900784492493, Accuracy: 0.9438999891281128\n",
      "Epoch 362: 0.19496163725852966, Accuracy: 0.9438999891281128\n",
      "Epoch 363: 0.19458532333374023, Accuracy: 0.944100022315979\n",
      "Epoch 364: 0.19419845938682556, Accuracy: 0.9441999793052673\n",
      "Epoch 365: 0.19382578134536743, Accuracy: 0.9442999958992004\n",
      "Epoch 366: 0.19344063103199005, Accuracy: 0.944599986076355\n",
      "Epoch 367: 0.19306820631027222, Accuracy: 0.9442999958992004\n",
      "Epoch 368: 0.19268609583377838, Accuracy: 0.9448000192642212\n",
      "Epoch 369: 0.1923139989376068, Accuracy: 0.9442999958992004\n",
      "Epoch 370: 0.1919359564781189, Accuracy: 0.9452000260353088\n",
      "Epoch 371: 0.19156549870967865, Accuracy: 0.9444000124931335\n",
      "Epoch 372: 0.1911887228488922, Accuracy: 0.9455999732017517\n",
      "Epoch 373: 0.1908188760280609, Accuracy: 0.9445000290870667\n",
      "Epoch 374: 0.19044405221939087, Accuracy: 0.945900022983551\n",
      "Epoch 375: 0.19007804989814758, Accuracy: 0.9447000026702881\n",
      "Epoch 376: 0.1897084265947342, Accuracy: 0.9460999965667725\n",
      "Epoch 377: 0.18934644758701324, Accuracy: 0.9448999762535095\n",
      "Epoch 378: 0.18898038566112518, Accuracy: 0.9460999965667725\n",
      "Epoch 379: 0.18862424790859222, Accuracy: 0.9451000094413757\n",
      "Epoch 380: 0.1882624626159668, Accuracy: 0.9460999965667725\n",
      "Epoch 381: 0.18790684640407562, Accuracy: 0.9452999830245972\n",
      "Epoch 382: 0.18754784762859344, Accuracy: 0.9463000297546387\n",
      "Epoch 383: 0.187196284532547, Accuracy: 0.9452999830245972\n",
      "Epoch 384: 0.18683992326259613, Accuracy: 0.9463000297546387\n",
      "Epoch 385: 0.1864914894104004, Accuracy: 0.9452999830245972\n",
      "Epoch 386: 0.1861390918493271, Accuracy: 0.9465000033378601\n",
      "Epoch 387: 0.1857932060956955, Accuracy: 0.9456999897956848\n",
      "Epoch 388: 0.18544581532478333, Accuracy: 0.9465000033378601\n",
      "Epoch 389: 0.1851017326116562, Accuracy: 0.9455999732017517\n",
      "Epoch 390: 0.18475715816020966, Accuracy: 0.9466999769210815\n",
      "Epoch 391: 0.18441544473171234, Accuracy: 0.945900022983551\n",
      "Epoch 392: 0.18407288193702698, Accuracy: 0.9470999836921692\n",
      "Epoch 393: 0.1837335228919983, Accuracy: 0.9460999965667725\n",
      "Epoch 394: 0.18339477479457855, Accuracy: 0.9473999738693237\n",
      "Epoch 395: 0.1830567568540573, Accuracy: 0.9463000297546387\n",
      "Epoch 396: 0.1827203929424286, Accuracy: 0.9472000002861023\n",
      "Epoch 397: 0.18238449096679688, Accuracy: 0.9466000199317932\n",
      "Epoch 398: 0.18204987049102783, Accuracy: 0.9473000168800354\n",
      "Epoch 399: 0.18171843886375427, Accuracy: 0.9469000101089478\n",
      "Epoch 400: 0.18138648569583893, Accuracy: 0.9472000002861023\n",
      "Epoch 401: 0.18105702102184296, Accuracy: 0.9473000168800354\n",
      "Epoch 402: 0.18072789907455444, Accuracy: 0.9473000168800354\n",
      "Epoch 403: 0.18040096759796143, Accuracy: 0.9473000168800354\n",
      "Epoch 404: 0.18007434904575348, Accuracy: 0.9473999738693237\n",
      "Epoch 405: 0.17974868416786194, Accuracy: 0.9474999904632568\n",
      "Epoch 406: 0.1794241964817047, Accuracy: 0.9476000070571899\n",
      "Epoch 407: 0.1791001856327057, Accuracy: 0.947700023651123\n",
      "Epoch 408: 0.17877893149852753, Accuracy: 0.9476000070571899\n",
      "Epoch 409: 0.17845721542835236, Accuracy: 0.9480000138282776\n",
      "Epoch 410: 0.17813760042190552, Accuracy: 0.9477999806404114\n",
      "Epoch 411: 0.17781759798526764, Accuracy: 0.9480000138282776\n",
      "Epoch 412: 0.1774994432926178, Accuracy: 0.9480999708175659\n",
      "Epoch 413: 0.17718183994293213, Accuracy: 0.9480999708175659\n",
      "Epoch 414: 0.17686541378498077, Accuracy: 0.9484999775886536\n",
      "Epoch 415: 0.17655138671398163, Accuracy: 0.948199987411499\n",
      "Epoch 416: 0.17623713612556458, Accuracy: 0.9485999941825867\n",
      "Epoch 417: 0.17592410743236542, Accuracy: 0.9480999708175659\n",
      "Epoch 418: 0.17561355233192444, Accuracy: 0.9485999941825867\n",
      "Epoch 419: 0.17530253529548645, Accuracy: 0.9480000138282776\n",
      "Epoch 420: 0.17499254643917084, Accuracy: 0.9484000205993652\n",
      "Epoch 421: 0.17468377947807312, Accuracy: 0.948199987411499\n",
      "Epoch 422: 0.1743762493133545, Accuracy: 0.9484000205993652\n",
      "Epoch 423: 0.17406946420669556, Accuracy: 0.948199987411499\n",
      "Epoch 424: 0.17376387119293213, Accuracy: 0.9483000040054321\n",
      "Epoch 425: 0.17346011102199554, Accuracy: 0.9485999941825867\n",
      "Epoch 426: 0.17315661907196045, Accuracy: 0.9483000040054321\n",
      "Epoch 427: 0.1728547066450119, Accuracy: 0.9487000107765198\n",
      "Epoch 428: 0.17255306243896484, Accuracy: 0.9484999775886536\n",
      "Epoch 429: 0.17225316166877747, Accuracy: 0.9491000175476074\n",
      "Epoch 430: 0.17195314168930054, Accuracy: 0.9487000107765198\n",
      "Epoch 431: 0.1716560572385788, Accuracy: 0.9491000175476074\n",
      "Epoch 432: 0.1713586300611496, Accuracy: 0.9488000273704529\n",
      "Epoch 433: 0.17106372117996216, Accuracy: 0.9492999911308289\n",
      "Epoch 434: 0.17076827585697174, Accuracy: 0.9490000009536743\n",
      "Epoch 435: 0.1704745888710022, Accuracy: 0.9492999911308289\n",
      "Epoch 436: 0.17018093168735504, Accuracy: 0.9491999745368958\n",
      "Epoch 437: 0.1698894053697586, Accuracy: 0.949400007724762\n",
      "Epoch 438: 0.16959761083126068, Accuracy: 0.9492999911308289\n",
      "Epoch 439: 0.16930748522281647, Accuracy: 0.949400007724762\n",
      "Epoch 440: 0.16901859641075134, Accuracy: 0.9492999911308289\n",
      "Epoch 441: 0.16872933506965637, Accuracy: 0.9495000243186951\n",
      "Epoch 442: 0.16844165325164795, Accuracy: 0.9495000243186951\n",
      "Epoch 443: 0.16815342009067535, Accuracy: 0.949400007724762\n",
      "Epoch 444: 0.16786593198776245, Accuracy: 0.9495999813079834\n",
      "Epoch 445: 0.16758011281490326, Accuracy: 0.949400007724762\n",
      "Epoch 446: 0.16729344427585602, Accuracy: 0.9495999813079834\n",
      "Epoch 447: 0.16700853407382965, Accuracy: 0.9495000243186951\n",
      "Epoch 448: 0.1667231321334839, Accuracy: 0.9498000144958496\n",
      "Epoch 449: 0.16643886268138885, Accuracy: 0.9495999813079834\n",
      "Epoch 450: 0.16615517437458038, Accuracy: 0.9498999714851379\n",
      "Epoch 451: 0.165871724486351, Accuracy: 0.9496999979019165\n",
      "Epoch 452: 0.16559015214443207, Accuracy: 0.9498999714851379\n",
      "Epoch 453: 0.16530820727348328, Accuracy: 0.949999988079071\n",
      "Epoch 454: 0.1650291085243225, Accuracy: 0.9498999714851379\n",
      "Epoch 455: 0.16474944353103638, Accuracy: 0.9502000212669373\n",
      "Epoch 456: 0.16447192430496216, Accuracy: 0.949999988079071\n",
      "Epoch 457: 0.16419439017772675, Accuracy: 0.9502999782562256\n",
      "Epoch 458: 0.16391804814338684, Accuracy: 0.9501000046730042\n",
      "Epoch 459: 0.16364307701587677, Accuracy: 0.9505000114440918\n",
      "Epoch 460: 0.16336899995803833, Accuracy: 0.9502000212669373\n",
      "Epoch 461: 0.16309550404548645, Accuracy: 0.9506000280380249\n",
      "Epoch 462: 0.16282257437705994, Accuracy: 0.9502000212669373\n",
      "Epoch 463: 0.16255217790603638, Accuracy: 0.9509000182151794\n",
      "Epoch 464: 0.1622815579175949, Accuracy: 0.9502999782562256\n",
      "Epoch 465: 0.16201277077198029, Accuracy: 0.9509999752044678\n",
      "Epoch 466: 0.16174378991127014, Accuracy: 0.9503999948501587\n",
      "Epoch 467: 0.16147661209106445, Accuracy: 0.9513999819755554\n",
      "Epoch 468: 0.16120915114879608, Accuracy: 0.9505000114440918\n",
      "Epoch 469: 0.1609429568052292, Accuracy: 0.9513999819755554\n",
      "Epoch 470: 0.16067706048488617, Accuracy: 0.9506999850273132\n",
      "Epoch 471: 0.16041189432144165, Accuracy: 0.9513999819755554\n",
      "Epoch 472: 0.1601477563381195, Accuracy: 0.9508000016212463\n",
      "Epoch 473: 0.15988416969776154, Accuracy: 0.9514999985694885\n",
      "Epoch 474: 0.15962128341197968, Accuracy: 0.9509999752044678\n",
      "Epoch 475: 0.15935951471328735, Accuracy: 0.9514999985694885\n",
      "Epoch 476: 0.15909820795059204, Accuracy: 0.9510999917984009\n",
      "Epoch 477: 0.15883769094944, Accuracy: 0.95169997215271\n",
      "Epoch 478: 0.1585780382156372, Accuracy: 0.9513000249862671\n",
      "Epoch 479: 0.1583194136619568, Accuracy: 0.95169997215271\n",
      "Epoch 480: 0.1580614596605301, Accuracy: 0.9514999985694885\n",
      "Epoch 481: 0.15780413150787354, Accuracy: 0.95169997215271\n",
      "Epoch 482: 0.1575472503900528, Accuracy: 0.9516000151634216\n",
      "Epoch 483: 0.15729162096977234, Accuracy: 0.9519000053405762\n",
      "Epoch 484: 0.15703649818897247, Accuracy: 0.9517999887466431\n",
      "Epoch 485: 0.1567825824022293, Accuracy: 0.9520000219345093\n",
      "Epoch 486: 0.1565287560224533, Accuracy: 0.9519000053405762\n",
      "Epoch 487: 0.15627603232860565, Accuracy: 0.9520999789237976\n",
      "Epoch 488: 0.15602336823940277, Accuracy: 0.9519000053405762\n",
      "Epoch 489: 0.15577179193496704, Accuracy: 0.9521999955177307\n",
      "Epoch 490: 0.15552064776420593, Accuracy: 0.9519000053405762\n",
      "Epoch 491: 0.15527068078517914, Accuracy: 0.9521999955177307\n",
      "Epoch 492: 0.15502125024795532, Accuracy: 0.9520000219345093\n",
      "Epoch 493: 0.15477240085601807, Accuracy: 0.9523000121116638\n",
      "Epoch 494: 0.15452441573143005, Accuracy: 0.9520999789237976\n",
      "Epoch 495: 0.15427759289741516, Accuracy: 0.9524999856948853\n",
      "Epoch 496: 0.15403124690055847, Accuracy: 0.9523000121116638\n",
      "Epoch 497: 0.1537855565547943, Accuracy: 0.9526000022888184\n",
      "Epoch 498: 0.1535404920578003, Accuracy: 0.9524999856948853\n",
      "Epoch 499: 0.15329666435718536, Accuracy: 0.9531999826431274\n",
      "Epoch 500: 0.15305320918560028, Accuracy: 0.9528999924659729\n",
      "Epoch 501: 0.1528109908103943, Accuracy: 0.9534000158309937\n",
      "Epoch 502: 0.15256918966770172, Accuracy: 0.9531000256538391\n",
      "Epoch 503: 0.1523282527923584, Accuracy: 0.953499972820282\n",
      "Epoch 504: 0.15208768844604492, Accuracy: 0.9532999992370605\n",
      "Epoch 505: 0.1518479883670807, Accuracy: 0.9539999961853027\n",
      "Epoch 506: 0.15160925686359406, Accuracy: 0.953499972820282\n",
      "Epoch 507: 0.15137101709842682, Accuracy: 0.954200029373169\n",
      "Epoch 508: 0.1511334329843521, Accuracy: 0.953499972820282\n",
      "Epoch 509: 0.15089623630046844, Accuracy: 0.954200029373169\n",
      "Epoch 510: 0.15066000819206238, Accuracy: 0.953499972820282\n",
      "Epoch 511: 0.1504240185022354, Accuracy: 0.954200029373169\n",
      "Epoch 512: 0.15018907189369202, Accuracy: 0.9538000226020813\n",
      "Epoch 513: 0.1499548703432083, Accuracy: 0.9544000029563904\n",
      "Epoch 514: 0.14972130954265594, Accuracy: 0.9538999795913696\n",
      "Epoch 515: 0.14948831498622894, Accuracy: 0.9545000195503235\n",
      "Epoch 516: 0.14925654232501984, Accuracy: 0.9542999863624573\n",
      "Epoch 517: 0.14902529120445251, Accuracy: 0.9545000195503235\n",
      "Epoch 518: 0.14879466593265533, Accuracy: 0.9545000195503235\n",
      "Epoch 519: 0.14856474101543427, Accuracy: 0.9545999765396118\n",
      "Epoch 520: 0.14833520352840424, Accuracy: 0.9546999931335449\n",
      "Epoch 521: 0.14810633659362793, Accuracy: 0.9546999931335449\n",
      "Epoch 522: 0.14787812530994415, Accuracy: 0.9550999999046326\n",
      "Epoch 523: 0.14765086770057678, Accuracy: 0.954800009727478\n",
      "Epoch 524: 0.14742381870746613, Accuracy: 0.9550999999046326\n",
      "Epoch 525: 0.147197425365448, Accuracy: 0.9550999999046326\n",
      "Epoch 526: 0.14697177708148956, Accuracy: 0.9552000164985657\n",
      "Epoch 527: 0.14674663543701172, Accuracy: 0.9555000066757202\n",
      "Epoch 528: 0.14652223885059357, Accuracy: 0.955299973487854\n",
      "Epoch 529: 0.14629828929901123, Accuracy: 0.9556999802589417\n",
      "Epoch 530: 0.14607501029968262, Accuracy: 0.9555000066757202\n",
      "Epoch 531: 0.14585207402706146, Accuracy: 0.9556999802589417\n",
      "Epoch 532: 0.14563000202178955, Accuracy: 0.9557999968528748\n",
      "Epoch 533: 0.14540860056877136, Accuracy: 0.9559999704360962\n",
      "Epoch 534: 0.1451881229877472, Accuracy: 0.9557999968528748\n",
      "Epoch 535: 0.14496774971485138, Accuracy: 0.9560999870300293\n",
      "Epoch 536: 0.1447482705116272, Accuracy: 0.9559000134468079\n",
      "Epoch 537: 0.14452894032001495, Accuracy: 0.9560999870300293\n",
      "Epoch 538: 0.14430998265743256, Accuracy: 0.9559000134468079\n",
      "Epoch 539: 0.14409145712852478, Accuracy: 0.9562000036239624\n",
      "Epoch 540: 0.14387348294258118, Accuracy: 0.9559000134468079\n",
      "Epoch 541: 0.14365583658218384, Accuracy: 0.9562000036239624\n",
      "Epoch 542: 0.14343908429145813, Accuracy: 0.9559999704360962\n",
      "Epoch 543: 0.14322270452976227, Accuracy: 0.9562000036239624\n",
      "Epoch 544: 0.14300672709941864, Accuracy: 0.9559000134468079\n",
      "Epoch 545: 0.14279146492481232, Accuracy: 0.9563000202178955\n",
      "Epoch 546: 0.14257732033729553, Accuracy: 0.9559999704360962\n",
      "Epoch 547: 0.1423637866973877, Accuracy: 0.9563000202178955\n",
      "Epoch 548: 0.14215098321437836, Accuracy: 0.9563999772071838\n",
      "Epoch 549: 0.14193843305110931, Accuracy: 0.9563999772071838\n",
      "Epoch 550: 0.14172637462615967, Accuracy: 0.9564999938011169\n",
      "Epoch 551: 0.14151495695114136, Accuracy: 0.95660001039505\n",
      "Epoch 552: 0.1413041055202484, Accuracy: 0.9567000269889832\n",
      "Epoch 553: 0.14109356701374054, Accuracy: 0.9567000269889832\n",
      "Epoch 554: 0.1408834308385849, Accuracy: 0.9567999839782715\n",
      "Epoch 555: 0.14067389070987701, Accuracy: 0.9567999839782715\n",
      "Epoch 556: 0.1404651403427124, Accuracy: 0.957099974155426\n",
      "Epoch 557: 0.14025700092315674, Accuracy: 0.9570000171661377\n",
      "Epoch 558: 0.14004941284656525, Accuracy: 0.9571999907493591\n",
      "Epoch 559: 0.1398424357175827, Accuracy: 0.957099974155426\n",
      "Epoch 560: 0.13963590562343597, Accuracy: 0.9571999907493591\n",
      "Epoch 561: 0.13942977786064148, Accuracy: 0.9573000073432922\n",
      "Epoch 562: 0.13922421634197235, Accuracy: 0.957099974155426\n",
      "Epoch 563: 0.13901881873607635, Accuracy: 0.9574000239372253\n",
      "Epoch 564: 0.13881421089172363, Accuracy: 0.957099974155426\n",
      "Epoch 565: 0.13860996067523956, Accuracy: 0.9574999809265137\n",
      "Epoch 566: 0.13840638101100922, Accuracy: 0.9573000073432922\n",
      "Epoch 567: 0.13820293545722961, Accuracy: 0.9575999975204468\n",
      "Epoch 568: 0.13800032436847687, Accuracy: 0.9573000073432922\n",
      "Epoch 569: 0.13779804110527039, Accuracy: 0.9578999876976013\n",
      "Epoch 570: 0.13759660720825195, Accuracy: 0.9573000073432922\n",
      "Epoch 571: 0.13739562034606934, Accuracy: 0.9578999876976013\n",
      "Epoch 572: 0.13719531893730164, Accuracy: 0.9577000141143799\n",
      "Epoch 573: 0.13699547946453094, Accuracy: 0.9578999876976013\n",
      "Epoch 574: 0.13679607212543488, Accuracy: 0.9577000141143799\n",
      "Epoch 575: 0.136597141623497, Accuracy: 0.9580000042915344\n",
      "Epoch 576: 0.1363985687494278, Accuracy: 0.9577000141143799\n",
      "Epoch 577: 0.13620062172412872, Accuracy: 0.9580000042915344\n",
      "Epoch 578: 0.1360030621290207, Accuracy: 0.9580000042915344\n",
      "Epoch 579: 0.13580617308616638, Accuracy: 0.9581999778747559\n",
      "Epoch 580: 0.13560941815376282, Accuracy: 0.9581000208854675\n",
      "Epoch 581: 0.1354132890701294, Accuracy: 0.958299994468689\n",
      "Epoch 582: 0.13521745800971985, Accuracy: 0.9584000110626221\n",
      "Epoch 583: 0.1350223869085312, Accuracy: 0.9585999846458435\n",
      "Epoch 584: 0.13482779264450073, Accuracy: 0.9585000276565552\n",
      "Epoch 585: 0.1346336305141449, Accuracy: 0.9587000012397766\n",
      "Epoch 586: 0.13443982601165771, Accuracy: 0.9587000012397766\n",
      "Epoch 587: 0.13424639403820038, Accuracy: 0.958899974822998\n",
      "Epoch 588: 0.13405346870422363, Accuracy: 0.9587000012397766\n",
      "Epoch 589: 0.1338612139225006, Accuracy: 0.9589999914169312\n",
      "Epoch 590: 0.13366957008838654, Accuracy: 0.9587000012397766\n",
      "Epoch 591: 0.13347835838794708, Accuracy: 0.9591000080108643\n",
      "Epoch 592: 0.13328750431537628, Accuracy: 0.958899974822998\n",
      "Epoch 593: 0.1330970972776413, Accuracy: 0.9592000246047974\n",
      "Epoch 594: 0.13290724158287048, Accuracy: 0.9591000080108643\n",
      "Epoch 595: 0.13271787762641907, Accuracy: 0.9592999815940857\n",
      "Epoch 596: 0.1325291097164154, Accuracy: 0.9592999815940857\n",
      "Epoch 597: 0.13234087824821472, Accuracy: 0.9593999981880188\n",
      "Epoch 598: 0.13215303421020508, Accuracy: 0.9592999815940857\n",
      "Epoch 599: 0.1319655179977417, Accuracy: 0.9593999981880188\n",
      "Epoch 600: 0.13177864253520966, Accuracy: 0.9592999815940857\n",
      "Epoch 601: 0.1315920203924179, Accuracy: 0.9593999981880188\n",
      "Epoch 602: 0.13140571117401123, Accuracy: 0.9592999815940857\n",
      "Epoch 603: 0.13122011721134186, Accuracy: 0.9593999981880188\n",
      "Epoch 604: 0.13103483617305756, Accuracy: 0.9592999815940857\n",
      "Epoch 605: 0.1308499574661255, Accuracy: 0.9593999981880188\n",
      "Epoch 606: 0.13066543638706207, Accuracy: 0.9592999815940857\n",
      "Epoch 607: 0.13048142194747925, Accuracy: 0.9595000147819519\n",
      "Epoch 608: 0.13029786944389343, Accuracy: 0.9592999815940857\n",
      "Epoch 609: 0.13011454045772552, Accuracy: 0.9595000147819519\n",
      "Epoch 610: 0.12993161380290985, Accuracy: 0.9592999815940857\n",
      "Epoch 611: 0.1297493726015091, Accuracy: 0.9595000147819519\n",
      "Epoch 612: 0.12956762313842773, Accuracy: 0.9592999815940857\n",
      "Epoch 613: 0.129386305809021, Accuracy: 0.9595000147819519\n",
      "Epoch 614: 0.12920519709587097, Accuracy: 0.9593999981880188\n",
      "Epoch 615: 0.12902459502220154, Accuracy: 0.9595999717712402\n",
      "Epoch 616: 0.12884435057640076, Accuracy: 0.9595000147819519\n",
      "Epoch 617: 0.12866441905498505, Accuracy: 0.9598000049591064\n",
      "Epoch 618: 0.1284848153591156, Accuracy: 0.9595999717712402\n",
      "Epoch 619: 0.12830545008182526, Accuracy: 0.9598000049591064\n",
      "Epoch 620: 0.12812656164169312, Accuracy: 0.9595999717712402\n",
      "Epoch 621: 0.12794791162014008, Accuracy: 0.9599000215530396\n",
      "Epoch 622: 0.12776967883110046, Accuracy: 0.9596999883651733\n",
      "Epoch 623: 0.12759172916412354, Accuracy: 0.9599000215530396\n",
      "Epoch 624: 0.12741418182849884, Accuracy: 0.9599000215530396\n",
      "Epoch 625: 0.12723715603351593, Accuracy: 0.9599999785423279\n",
      "Epoch 626: 0.1270604282617569, Accuracy: 0.9599000215530396\n",
      "Epoch 627: 0.12688401341438293, Accuracy: 0.9602000117301941\n",
      "Epoch 628: 0.12670806050300598, Accuracy: 0.9599000215530396\n",
      "Epoch 629: 0.12653270363807678, Accuracy: 0.9602000117301941\n",
      "Epoch 630: 0.12635767459869385, Accuracy: 0.9599999785423279\n",
      "Epoch 631: 0.12618307769298553, Accuracy: 0.9602000117301941\n",
      "Epoch 632: 0.12600931525230408, Accuracy: 0.960099995136261\n",
      "Epoch 633: 0.12583591043949127, Accuracy: 0.9602000117301941\n",
      "Epoch 634: 0.12566322088241577, Accuracy: 0.9599999785423279\n",
      "Epoch 635: 0.1254907250404358, Accuracy: 0.9603000283241272\n",
      "Epoch 636: 0.12531869113445282, Accuracy: 0.9599999785423279\n",
      "Epoch 637: 0.1251470446586609, Accuracy: 0.9603999853134155\n",
      "Epoch 638: 0.12497592717409134, Accuracy: 0.9602000117301941\n",
      "Epoch 639: 0.12480513751506805, Accuracy: 0.9605000019073486\n",
      "Epoch 640: 0.1246349960565567, Accuracy: 0.9602000117301941\n",
      "Epoch 641: 0.12446507811546326, Accuracy: 0.9605000019073486\n",
      "Epoch 642: 0.12429579347372055, Accuracy: 0.9605000019073486\n",
      "Epoch 643: 0.12412658333778381, Accuracy: 0.9606000185012817\n",
      "Epoch 644: 0.12395787239074707, Accuracy: 0.9606000185012817\n",
      "Epoch 645: 0.12378939986228943, Accuracy: 0.9606999754905701\n",
      "Epoch 646: 0.12362141162157059, Accuracy: 0.9606999754905701\n",
      "Epoch 647: 0.12345359474420547, Accuracy: 0.9609000086784363\n",
      "Epoch 648: 0.12328631430864334, Accuracy: 0.9609000086784363\n",
      "Epoch 649: 0.12311934679746628, Accuracy: 0.9609000086784363\n",
      "Epoch 650: 0.12295286357402802, Accuracy: 0.9610000252723694\n",
      "Epoch 651: 0.12278702110052109, Accuracy: 0.9610000252723694\n",
      "Epoch 652: 0.12262154370546341, Accuracy: 0.9610999822616577\n",
      "Epoch 653: 0.12245628982782364, Accuracy: 0.9610999822616577\n",
      "Epoch 654: 0.12229162454605103, Accuracy: 0.9610999822616577\n",
      "Epoch 655: 0.1221272274851799, Accuracy: 0.9613000154495239\n",
      "Epoch 656: 0.12196330726146698, Accuracy: 0.9610999822616577\n",
      "Epoch 657: 0.121799536049366, Accuracy: 0.9613000154495239\n",
      "Epoch 658: 0.12163594365119934, Accuracy: 0.9610999822616577\n",
      "Epoch 659: 0.12147271633148193, Accuracy: 0.9613000154495239\n",
      "Epoch 660: 0.12131009995937347, Accuracy: 0.9611999988555908\n",
      "Epoch 661: 0.12114764004945755, Accuracy: 0.9613000154495239\n",
      "Epoch 662: 0.12098562717437744, Accuracy: 0.9613000154495239\n",
      "Epoch 663: 0.1208239495754242, Accuracy: 0.9613999724388123\n",
      "Epoch 664: 0.12066290527582169, Accuracy: 0.9613999724388123\n",
      "Epoch 665: 0.12050189077854156, Accuracy: 0.9613999724388123\n",
      "Epoch 666: 0.12034124881029129, Accuracy: 0.9614999890327454\n",
      "Epoch 667: 0.12018076330423355, Accuracy: 0.9617000222206116\n",
      "Epoch 668: 0.12002076208591461, Accuracy: 0.9614999890327454\n",
      "Epoch 669: 0.1198611706495285, Accuracy: 0.961899995803833\n",
      "Epoch 670: 0.11970215290784836, Accuracy: 0.9617000222206116\n",
      "Epoch 671: 0.11954347789287567, Accuracy: 0.9620000123977661\n",
      "Epoch 672: 0.1193854957818985, Accuracy: 0.9617000222206116\n",
      "Epoch 673: 0.11922740936279297, Accuracy: 0.9620000123977661\n",
      "Epoch 674: 0.11907017230987549, Accuracy: 0.9617000222206116\n",
      "Epoch 675: 0.11891309916973114, Accuracy: 0.961899995803833\n",
      "Epoch 676: 0.11875662952661514, Accuracy: 0.9617000222206116\n",
      "Epoch 677: 0.1186002567410469, Accuracy: 0.9620000123977661\n",
      "Epoch 678: 0.11844463646411896, Accuracy: 0.9617999792098999\n",
      "Epoch 679: 0.1182892918586731, Accuracy: 0.9621000289916992\n",
      "Epoch 680: 0.11813431233167648, Accuracy: 0.961899995803833\n",
      "Epoch 681: 0.11797979474067688, Accuracy: 0.9620000123977661\n",
      "Epoch 682: 0.11782562732696533, Accuracy: 0.961899995803833\n",
      "Epoch 683: 0.11767170578241348, Accuracy: 0.9620000123977661\n",
      "Epoch 684: 0.11751813441514969, Accuracy: 0.9620000123977661\n",
      "Epoch 685: 0.11736446619033813, Accuracy: 0.961899995803833\n",
      "Epoch 686: 0.11721169203519821, Accuracy: 0.9621000289916992\n",
      "Epoch 687: 0.11705873161554337, Accuracy: 0.9621999859809875\n",
      "Epoch 688: 0.11690636724233627, Accuracy: 0.9621000289916992\n",
      "Epoch 689: 0.1167539581656456, Accuracy: 0.9621999859809875\n",
      "Epoch 690: 0.1166018545627594, Accuracy: 0.9621999859809875\n",
      "Epoch 691: 0.11645016819238663, Accuracy: 0.9623000025749207\n",
      "Epoch 692: 0.1162986159324646, Accuracy: 0.9623000025749207\n",
      "Epoch 693: 0.11614743620157242, Accuracy: 0.9623000025749207\n",
      "Epoch 694: 0.11599662154912949, Accuracy: 0.9621999859809875\n",
      "Epoch 695: 0.11584604531526566, Accuracy: 0.9624000191688538\n",
      "Epoch 696: 0.11569603532552719, Accuracy: 0.9623000025749207\n",
      "Epoch 697: 0.11554629355669022, Accuracy: 0.9624000191688538\n",
      "Epoch 698: 0.11539709568023682, Accuracy: 0.9623000025749207\n",
      "Epoch 699: 0.11524790525436401, Accuracy: 0.9624000191688538\n",
      "Epoch 700: 0.1150992214679718, Accuracy: 0.9621999859809875\n",
      "Epoch 701: 0.11495077610015869, Accuracy: 0.9624000191688538\n",
      "Epoch 702: 0.11480283737182617, Accuracy: 0.9621999859809875\n",
      "Epoch 703: 0.11465523391962051, Accuracy: 0.9624999761581421\n",
      "Epoch 704: 0.11450782418251038, Accuracy: 0.9624000191688538\n",
      "Epoch 705: 0.11436081677675247, Accuracy: 0.9627000093460083\n",
      "Epoch 706: 0.11421394348144531, Accuracy: 0.9624999761581421\n",
      "Epoch 707: 0.1140674501657486, Accuracy: 0.9627000093460083\n",
      "Epoch 708: 0.11392129957675934, Accuracy: 0.9627000093460083\n",
      "Epoch 709: 0.11377541720867157, Accuracy: 0.9627000093460083\n",
      "Epoch 710: 0.11362992227077484, Accuracy: 0.9627000093460083\n",
      "Epoch 711: 0.11348453164100647, Accuracy: 0.9628000259399414\n",
      "Epoch 712: 0.11333974450826645, Accuracy: 0.9627000093460083\n",
      "Epoch 713: 0.11319506168365479, Accuracy: 0.9628000259399414\n",
      "Epoch 714: 0.11305084079504013, Accuracy: 0.9627000093460083\n",
      "Epoch 715: 0.11290667206048965, Accuracy: 0.9628999829292297\n",
      "Epoch 716: 0.11276278644800186, Accuracy: 0.9629999995231628\n",
      "Epoch 717: 0.11261926591396332, Accuracy: 0.9628000259399414\n",
      "Epoch 718: 0.11247604340314865, Accuracy: 0.963100016117096\n",
      "Epoch 719: 0.11233318597078323, Accuracy: 0.9628000259399414\n",
      "Epoch 720: 0.11219056695699692, Accuracy: 0.9631999731063843\n",
      "Epoch 721: 0.11204849183559418, Accuracy: 0.9628999829292297\n",
      "Epoch 722: 0.11190656572580338, Accuracy: 0.9631999731063843\n",
      "Epoch 723: 0.11176507920026779, Accuracy: 0.9631999731063843\n",
      "Epoch 724: 0.1116238608956337, Accuracy: 0.9631999731063843\n",
      "Epoch 725: 0.11148323863744736, Accuracy: 0.9632999897003174\n",
      "Epoch 726: 0.11134278029203415, Accuracy: 0.9634000062942505\n",
      "Epoch 727: 0.11120259016752243, Accuracy: 0.9635000228881836\n",
      "Epoch 728: 0.11106261610984802, Accuracy: 0.9634000062942505\n",
      "Epoch 729: 0.11092285066843033, Accuracy: 0.9635999798774719\n",
      "Epoch 730: 0.11078358441591263, Accuracy: 0.9635000228881836\n",
      "Epoch 731: 0.11064448952674866, Accuracy: 0.9634000062942505\n",
      "Epoch 732: 0.11050558090209961, Accuracy: 0.9635999798774719\n",
      "Epoch 733: 0.11036679893732071, Accuracy: 0.9634000062942505\n",
      "Epoch 734: 0.11022857576608658, Accuracy: 0.963699996471405\n",
      "Epoch 735: 0.11009040474891663, Accuracy: 0.9635000228881836\n",
      "Epoch 736: 0.10995260626077652, Accuracy: 0.9639000296592712\n",
      "Epoch 737: 0.10981503129005432, Accuracy: 0.9635000228881836\n",
      "Epoch 738: 0.10967777669429779, Accuracy: 0.9639999866485596\n",
      "Epoch 739: 0.10954073071479797, Accuracy: 0.9635000228881836\n",
      "Epoch 740: 0.109404057264328, Accuracy: 0.9639999866485596\n",
      "Epoch 741: 0.10926751792430878, Accuracy: 0.963699996471405\n",
      "Epoch 742: 0.10913128405809402, Accuracy: 0.9639000296592712\n",
      "Epoch 743: 0.10899519175291061, Accuracy: 0.963699996471405\n",
      "Epoch 744: 0.10885971039533615, Accuracy: 0.9639000296592712\n",
      "Epoch 745: 0.10872424393892288, Accuracy: 0.963699996471405\n",
      "Epoch 746: 0.10858923196792603, Accuracy: 0.9639999866485596\n",
      "Epoch 747: 0.10845405608415604, Accuracy: 0.963699996471405\n",
      "Epoch 748: 0.10831931978464127, Accuracy: 0.9639999866485596\n",
      "Epoch 749: 0.10818493366241455, Accuracy: 0.9638000130653381\n",
      "Epoch 750: 0.10805099457502365, Accuracy: 0.9639999866485596\n",
      "Epoch 751: 0.10791733860969543, Accuracy: 0.9639999866485596\n",
      "Epoch 752: 0.10778401792049408, Accuracy: 0.9639999866485596\n",
      "Epoch 753: 0.10765103250741959, Accuracy: 0.9639999866485596\n",
      "Epoch 754: 0.10751854628324509, Accuracy: 0.9639999866485596\n",
      "Epoch 755: 0.10738595575094223, Accuracy: 0.9639999866485596\n",
      "Epoch 756: 0.10725405067205429, Accuracy: 0.9641000032424927\n",
      "Epoch 757: 0.10712207108736038, Accuracy: 0.9639999866485596\n",
      "Epoch 758: 0.10699057579040527, Accuracy: 0.9642000198364258\n",
      "Epoch 759: 0.10685910284519196, Accuracy: 0.9639999866485596\n",
      "Epoch 760: 0.10672806203365326, Accuracy: 0.9641000032424927\n",
      "Epoch 761: 0.10659722983837128, Accuracy: 0.9639999866485596\n",
      "Epoch 762: 0.10646659880876541, Accuracy: 0.9642000198364258\n",
      "Epoch 763: 0.10633645951747894, Accuracy: 0.9641000032424927\n",
      "Epoch 764: 0.10620656609535217, Accuracy: 0.9642999768257141\n",
      "Epoch 765: 0.10607721656560898, Accuracy: 0.9641000032424927\n",
      "Epoch 766: 0.10594787448644638, Accuracy: 0.9642999768257141\n",
      "Epoch 767: 0.1058187335729599, Accuracy: 0.9643999934196472\n",
      "Epoch 768: 0.10568983107805252, Accuracy: 0.9642999768257141\n",
      "Epoch 769: 0.10556109994649887, Accuracy: 0.9643999934196472\n",
      "Epoch 770: 0.10543239116668701, Accuracy: 0.9642999768257141\n",
      "Epoch 771: 0.10530366748571396, Accuracy: 0.9643999934196472\n",
      "Epoch 772: 0.10517535358667374, Accuracy: 0.9642999768257141\n",
      "Epoch 773: 0.10504703223705292, Accuracy: 0.9646000266075134\n",
      "Epoch 774: 0.1049191802740097, Accuracy: 0.9646000266075134\n",
      "Epoch 775: 0.1047915518283844, Accuracy: 0.9646000266075134\n",
      "Epoch 776: 0.10466410964727402, Accuracy: 0.9646000266075134\n",
      "Epoch 777: 0.10453732311725616, Accuracy: 0.9646000266075134\n",
      "Epoch 778: 0.10441062599420547, Accuracy: 0.9646999835968018\n",
      "Epoch 779: 0.10428463667631149, Accuracy: 0.9646000266075134\n",
      "Epoch 780: 0.10415838658809662, Accuracy: 0.9648000001907349\n",
      "Epoch 781: 0.10403288900852203, Accuracy: 0.9646999835968018\n",
      "Epoch 782: 0.1039067730307579, Accuracy: 0.964900016784668\n",
      "Epoch 783: 0.10378137230873108, Accuracy: 0.9648000001907349\n",
      "Epoch 784: 0.10365598648786545, Accuracy: 0.964900016784668\n",
      "Epoch 785: 0.10353124886751175, Accuracy: 0.9648000001907349\n",
      "Epoch 786: 0.10340629518032074, Accuracy: 0.964900016784668\n",
      "Epoch 787: 0.10328204184770584, Accuracy: 0.9649999737739563\n",
      "Epoch 788: 0.10315797477960587, Accuracy: 0.964900016784668\n",
      "Epoch 789: 0.10303396731615067, Accuracy: 0.9649999737739563\n",
      "Epoch 790: 0.10291021317243576, Accuracy: 0.964900016784668\n",
      "Epoch 791: 0.10278628021478653, Accuracy: 0.9649999737739563\n",
      "Epoch 792: 0.1026626005768776, Accuracy: 0.9649999737739563\n",
      "Epoch 793: 0.10253899544477463, Accuracy: 0.9649999737739563\n",
      "Epoch 794: 0.10241559892892838, Accuracy: 0.9649999737739563\n",
      "Epoch 795: 0.10229256004095078, Accuracy: 0.9648000001907349\n",
      "Epoch 796: 0.10216985642910004, Accuracy: 0.9649999737739563\n",
      "Epoch 797: 0.10204719752073288, Accuracy: 0.964900016784668\n",
      "Epoch 798: 0.10192537307739258, Accuracy: 0.9649999737739563\n",
      "Epoch 799: 0.10180376470088959, Accuracy: 0.964900016784668\n",
      "Epoch 800: 0.10168244689702988, Accuracy: 0.9649999737739563\n",
      "Epoch 801: 0.10156150162220001, Accuracy: 0.9648000001907349\n",
      "Epoch 802: 0.10144104063510895, Accuracy: 0.9650999903678894\n",
      "Epoch 803: 0.10132065415382385, Accuracy: 0.9648000001907349\n",
      "Epoch 804: 0.10120078921318054, Accuracy: 0.9650999903678894\n",
      "Epoch 805: 0.10108073800802231, Accuracy: 0.9648000001907349\n",
      "Epoch 806: 0.10096121579408646, Accuracy: 0.9650999903678894\n",
      "Epoch 807: 0.10084143280982971, Accuracy: 0.964900016784668\n",
      "Epoch 808: 0.1007222980260849, Accuracy: 0.9650999903678894\n",
      "Epoch 809: 0.1006033718585968, Accuracy: 0.964900016784668\n",
      "Epoch 810: 0.1004849374294281, Accuracy: 0.9652000069618225\n",
      "Epoch 811: 0.1003669872879982, Accuracy: 0.964900016784668\n",
      "Epoch 812: 0.10024856775999069, Accuracy: 0.9652000069618225\n",
      "Epoch 813: 0.1001305803656578, Accuracy: 0.964900016784668\n",
      "Epoch 814: 0.10001224279403687, Accuracy: 0.9652000069618225\n",
      "Epoch 815: 0.09989393502473831, Accuracy: 0.9649999737739563\n",
      "Epoch 816: 0.09977573901414871, Accuracy: 0.9652000069618225\n",
      "Epoch 817: 0.09965799748897552, Accuracy: 0.9649999737739563\n",
      "Epoch 818: 0.09954111278057098, Accuracy: 0.9652000069618225\n",
      "Epoch 819: 0.09942467510700226, Accuracy: 0.9649999737739563\n",
      "Epoch 820: 0.09930888563394547, Accuracy: 0.9652000069618225\n",
      "Epoch 821: 0.09919338673353195, Accuracy: 0.9649999737739563\n",
      "Epoch 822: 0.09907843172550201, Accuracy: 0.9652000069618225\n",
      "Epoch 823: 0.09896312654018402, Accuracy: 0.9649999737739563\n",
      "Epoch 824: 0.09884834289550781, Accuracy: 0.9652000069618225\n",
      "Epoch 825: 0.09873342514038086, Accuracy: 0.9650999903678894\n",
      "Epoch 826: 0.09861844033002853, Accuracy: 0.965399980545044\n",
      "Epoch 827: 0.09850352257490158, Accuracy: 0.9652000069618225\n",
      "Epoch 828: 0.09838913381099701, Accuracy: 0.9656000137329102\n",
      "Epoch 829: 0.09827430546283722, Accuracy: 0.9652000069618225\n",
      "Epoch 830: 0.09816040843725204, Accuracy: 0.9656000137329102\n",
      "Epoch 831: 0.09804657846689224, Accuracy: 0.9652000069618225\n",
      "Epoch 832: 0.09793278574943542, Accuracy: 0.9656000137329102\n",
      "Epoch 833: 0.09781993925571442, Accuracy: 0.9653000235557556\n",
      "Epoch 834: 0.09770645201206207, Accuracy: 0.9656999707221985\n",
      "Epoch 835: 0.09759410470724106, Accuracy: 0.9653000235557556\n",
      "Epoch 836: 0.09748052805662155, Accuracy: 0.9656999707221985\n",
      "Epoch 837: 0.09736883640289307, Accuracy: 0.965399980545044\n",
      "Epoch 838: 0.09725557267665863, Accuracy: 0.9657999873161316\n",
      "Epoch 839: 0.09714354574680328, Accuracy: 0.965399980545044\n",
      "Epoch 840: 0.09703035652637482, Accuracy: 0.9657999873161316\n",
      "Epoch 841: 0.09691882878541946, Accuracy: 0.965399980545044\n",
      "Epoch 842: 0.09680607169866562, Accuracy: 0.9659000039100647\n",
      "Epoch 843: 0.09669483453035355, Accuracy: 0.965499997138977\n",
      "Epoch 844: 0.09658289700746536, Accuracy: 0.9657999873161316\n",
      "Epoch 845: 0.0964716374874115, Accuracy: 0.965499997138977\n",
      "Epoch 846: 0.09636019915342331, Accuracy: 0.9659000039100647\n",
      "Epoch 847: 0.09624972939491272, Accuracy: 0.9656999707221985\n",
      "Epoch 848: 0.09613876789808273, Accuracy: 0.9660000205039978\n",
      "Epoch 849: 0.09602826088666916, Accuracy: 0.9656999707221985\n",
      "Epoch 850: 0.09591817855834961, Accuracy: 0.9660000205039978\n",
      "Epoch 851: 0.09580764174461365, Accuracy: 0.9656000137329102\n",
      "Epoch 852: 0.09569837898015976, Accuracy: 0.9660000205039978\n",
      "Epoch 853: 0.09558811038732529, Accuracy: 0.9656999707221985\n",
      "Epoch 854: 0.09547870606184006, Accuracy: 0.9660000205039978\n",
      "Epoch 855: 0.09536914527416229, Accuracy: 0.9657999873161316\n",
      "Epoch 856: 0.0952608659863472, Accuracy: 0.9660000205039978\n",
      "Epoch 857: 0.09515216201543808, Accuracy: 0.9657999873161316\n",
      "Epoch 858: 0.09504442662000656, Accuracy: 0.9660000205039978\n",
      "Epoch 859: 0.0949360653758049, Accuracy: 0.9659000039100647\n",
      "Epoch 860: 0.09482903778553009, Accuracy: 0.9661999940872192\n",
      "Epoch 861: 0.0947204977273941, Accuracy: 0.9659000039100647\n",
      "Epoch 862: 0.09461387246847153, Accuracy: 0.9661999940872192\n",
      "Epoch 863: 0.09450656920671463, Accuracy: 0.9659000039100647\n",
      "Epoch 864: 0.09440065920352936, Accuracy: 0.9661999940872192\n",
      "Epoch 865: 0.09429407864809036, Accuracy: 0.9659000039100647\n",
      "Epoch 866: 0.09418820589780807, Accuracy: 0.9663000106811523\n",
      "Epoch 867: 0.09408286958932877, Accuracy: 0.9659000039100647\n",
      "Epoch 868: 0.09397811442613602, Accuracy: 0.9664000272750854\n",
      "Epoch 869: 0.093873031437397, Accuracy: 0.9661999940872192\n",
      "Epoch 870: 0.09376832842826843, Accuracy: 0.9664999842643738\n",
      "Epoch 871: 0.09366276860237122, Accuracy: 0.9661999940872192\n",
      "Epoch 872: 0.09355934709310532, Accuracy: 0.9668999910354614\n",
      "Epoch 873: 0.09345358610153198, Accuracy: 0.9661999940872192\n",
      "Epoch 874: 0.0933505967259407, Accuracy: 0.9671000242233276\n",
      "Epoch 875: 0.09324558079242706, Accuracy: 0.9664000272750854\n",
      "Epoch 876: 0.0931428000330925, Accuracy: 0.9674000144004822\n",
      "Epoch 877: 0.09303668141365051, Accuracy: 0.9664000272750854\n",
      "Epoch 878: 0.092934250831604, Accuracy: 0.9674000144004822\n",
      "Epoch 879: 0.09282875806093216, Accuracy: 0.9664999842643738\n",
      "Epoch 880: 0.0927269235253334, Accuracy: 0.9674999713897705\n",
      "Epoch 881: 0.09262170642614365, Accuracy: 0.9664999842643738\n",
      "Epoch 882: 0.09252011030912399, Accuracy: 0.9674999713897705\n",
      "Epoch 883: 0.0924152284860611, Accuracy: 0.9664999842643738\n",
      "Epoch 884: 0.09231434762477875, Accuracy: 0.9674000144004822\n",
      "Epoch 885: 0.09220947325229645, Accuracy: 0.9664999842643738\n",
      "Epoch 886: 0.09210759401321411, Accuracy: 0.9674000144004822\n",
      "Epoch 887: 0.09200304001569748, Accuracy: 0.9664999842643738\n",
      "Epoch 888: 0.09190244972705841, Accuracy: 0.9674999713897705\n",
      "Epoch 889: 0.09179729223251343, Accuracy: 0.9670000076293945\n",
      "Epoch 890: 0.09169565886259079, Accuracy: 0.9674999713897705\n",
      "Epoch 891: 0.09158913046121597, Accuracy: 0.967199981212616\n",
      "Epoch 892: 0.091486856341362, Accuracy: 0.9675999879837036\n",
      "Epoch 893: 0.09138185530900955, Accuracy: 0.9672999978065491\n",
      "Epoch 894: 0.09128020703792572, Accuracy: 0.9675999879837036\n",
      "Epoch 895: 0.09117549657821655, Accuracy: 0.9672999978065491\n",
      "Epoch 896: 0.09107422828674316, Accuracy: 0.9675999879837036\n",
      "Epoch 897: 0.09096982330083847, Accuracy: 0.9674999713897705\n",
      "Epoch 898: 0.09086889773607254, Accuracy: 0.9675999879837036\n",
      "Epoch 899: 0.09076542407274246, Accuracy: 0.9674999713897705\n",
      "Epoch 900: 0.09066542237997055, Accuracy: 0.9675999879837036\n",
      "Epoch 901: 0.0905630812048912, Accuracy: 0.9674999713897705\n",
      "Epoch 902: 0.09046532958745956, Accuracy: 0.9675999879837036\n",
      "Epoch 903: 0.09036335349082947, Accuracy: 0.9674999713897705\n",
      "Epoch 904: 0.09026626497507095, Accuracy: 0.9678000211715698\n",
      "Epoch 905: 0.09016406536102295, Accuracy: 0.9674999713897705\n",
      "Epoch 906: 0.09006725251674652, Accuracy: 0.9678999781608582\n",
      "Epoch 907: 0.08996526151895523, Accuracy: 0.9674999713897705\n",
      "Epoch 908: 0.0898691788315773, Accuracy: 0.9678999781608582\n",
      "Epoch 909: 0.0897677093744278, Accuracy: 0.9674999713897705\n",
      "Epoch 910: 0.0896710678935051, Accuracy: 0.9678999781608582\n",
      "Epoch 911: 0.0895705297589302, Accuracy: 0.9675999879837036\n",
      "Epoch 912: 0.08947311341762543, Accuracy: 0.9679999947547913\n",
      "Epoch 913: 0.08937317132949829, Accuracy: 0.9678000211715698\n",
      "Epoch 914: 0.0892760157585144, Accuracy: 0.9679999947547913\n",
      "Epoch 915: 0.08917586505413055, Accuracy: 0.9678999781608582\n",
      "Epoch 916: 0.08907847851514816, Accuracy: 0.9681000113487244\n",
      "Epoch 917: 0.08897938579320908, Accuracy: 0.9678999781608582\n",
      "Epoch 918: 0.08888279646635056, Accuracy: 0.9682000279426575\n",
      "Epoch 919: 0.08878341317176819, Accuracy: 0.9678999781608582\n",
      "Epoch 920: 0.08868823945522308, Accuracy: 0.9682999849319458\n",
      "Epoch 921: 0.08858921378850937, Accuracy: 0.9679999947547913\n",
      "Epoch 922: 0.08849294483661652, Accuracy: 0.9682999849319458\n",
      "Epoch 923: 0.0883941799402237, Accuracy: 0.9679999947547913\n",
      "Epoch 924: 0.08829943090677261, Accuracy: 0.9682999849319458\n",
      "Epoch 925: 0.0882013589143753, Accuracy: 0.9679999947547913\n",
      "Epoch 926: 0.08810657262802124, Accuracy: 0.9682999849319458\n",
      "Epoch 927: 0.08800897002220154, Accuracy: 0.9679999947547913\n",
      "Epoch 928: 0.08791548013687134, Accuracy: 0.9684000015258789\n",
      "Epoch 929: 0.08781813830137253, Accuracy: 0.9679999947547913\n",
      "Epoch 930: 0.0877247303724289, Accuracy: 0.968500018119812\n",
      "Epoch 931: 0.0876270979642868, Accuracy: 0.9679999947547913\n",
      "Epoch 932: 0.08753352612257004, Accuracy: 0.968500018119812\n",
      "Epoch 933: 0.08743693679571152, Accuracy: 0.9679999947547913\n",
      "Epoch 934: 0.0873425155878067, Accuracy: 0.9685999751091003\n",
      "Epoch 935: 0.08724655956029892, Accuracy: 0.9679999947547913\n",
      "Epoch 936: 0.0871533751487732, Accuracy: 0.9688000082969666\n",
      "Epoch 937: 0.0870579332113266, Accuracy: 0.9679999947547913\n",
      "Epoch 938: 0.08696399629116058, Accuracy: 0.9688000082969666\n",
      "Epoch 939: 0.08686911314725876, Accuracy: 0.9681000113487244\n",
      "Epoch 940: 0.0867764949798584, Accuracy: 0.968999981880188\n",
      "Epoch 941: 0.08668191730976105, Accuracy: 0.9682000279426575\n",
      "Epoch 942: 0.08659037202596664, Accuracy: 0.968999981880188\n",
      "Epoch 943: 0.08649618178606033, Accuracy: 0.9682000279426575\n",
      "Epoch 944: 0.0864047035574913, Accuracy: 0.968999981880188\n",
      "Epoch 945: 0.08631017804145813, Accuracy: 0.9682000279426575\n",
      "Epoch 946: 0.08621825277805328, Accuracy: 0.968999981880188\n",
      "Epoch 947: 0.08612463623285294, Accuracy: 0.9682999849319458\n",
      "Epoch 948: 0.08603357523679733, Accuracy: 0.968999981880188\n",
      "Epoch 949: 0.08594077080488205, Accuracy: 0.968500018119812\n",
      "Epoch 950: 0.08584963530302048, Accuracy: 0.9690999984741211\n",
      "Epoch 951: 0.08575662970542908, Accuracy: 0.9686999917030334\n",
      "Epoch 952: 0.08566629141569138, Accuracy: 0.9690999984741211\n",
      "Epoch 953: 0.08557295054197311, Accuracy: 0.9686999917030334\n",
      "Epoch 954: 0.08548307418823242, Accuracy: 0.9692000150680542\n",
      "Epoch 955: 0.08539024740457535, Accuracy: 0.9688000082969666\n",
      "Epoch 956: 0.08530042320489883, Accuracy: 0.9692000150680542\n",
      "Epoch 957: 0.08520805090665817, Accuracy: 0.968999981880188\n",
      "Epoch 958: 0.0851203128695488, Accuracy: 0.9692000150680542\n",
      "Epoch 959: 0.08502887934446335, Accuracy: 0.9692000150680542\n",
      "Epoch 960: 0.08494193851947784, Accuracy: 0.9692000150680542\n",
      "Epoch 961: 0.08485051989555359, Accuracy: 0.9690999984741211\n",
      "Epoch 962: 0.08476351201534271, Accuracy: 0.9693999886512756\n",
      "Epoch 963: 0.08467304706573486, Accuracy: 0.9690999984741211\n",
      "Epoch 964: 0.08458603173494339, Accuracy: 0.9695000052452087\n",
      "Epoch 965: 0.08449569344520569, Accuracy: 0.9692000150680542\n",
      "Epoch 966: 0.08440949022769928, Accuracy: 0.9695000052452087\n",
      "Epoch 967: 0.08431971073150635, Accuracy: 0.9692000150680542\n",
      "Epoch 968: 0.0842345729470253, Accuracy: 0.9695000052452087\n",
      "Epoch 969: 0.08414578437805176, Accuracy: 0.9692000150680542\n",
      "Epoch 970: 0.08406195789575577, Accuracy: 0.9695000052452087\n",
      "Epoch 971: 0.08397344499826431, Accuracy: 0.9692000150680542\n",
      "Epoch 972: 0.08389125019311905, Accuracy: 0.9695000052452087\n",
      "Epoch 973: 0.08380240201950073, Accuracy: 0.9693999886512756\n",
      "Epoch 974: 0.08371903747320175, Accuracy: 0.9696000218391418\n",
      "Epoch 975: 0.08363030850887299, Accuracy: 0.9693999886512756\n",
      "Epoch 976: 0.08354777842760086, Accuracy: 0.9696000218391418\n",
      "Epoch 977: 0.08345983177423477, Accuracy: 0.9693999886512756\n",
      "Epoch 978: 0.08337874710559845, Accuracy: 0.9696000218391418\n",
      "Epoch 979: 0.0832914412021637, Accuracy: 0.9696000218391418\n",
      "Epoch 980: 0.08321025967597961, Accuracy: 0.9696000218391418\n",
      "Epoch 981: 0.08312015235424042, Accuracy: 0.9695000052452087\n",
      "Epoch 982: 0.08303838223218918, Accuracy: 0.9696000218391418\n",
      "Epoch 983: 0.08294855803251266, Accuracy: 0.9695000052452087\n",
      "Epoch 984: 0.0828675851225853, Accuracy: 0.9696000218391418\n",
      "Epoch 985: 0.08277751505374908, Accuracy: 0.9695000052452087\n",
      "Epoch 986: 0.08269575983285904, Accuracy: 0.9696000218391418\n",
      "Epoch 987: 0.082606740295887, Accuracy: 0.9695000052452087\n",
      "Epoch 988: 0.08252336084842682, Accuracy: 0.9696000218391418\n",
      "Epoch 989: 0.08243408054113388, Accuracy: 0.9695000052452087\n",
      "Epoch 990: 0.08235141634941101, Accuracy: 0.9696000218391418\n",
      "Epoch 991: 0.08226197957992554, Accuracy: 0.9695000052452087\n",
      "Epoch 992: 0.08218010514974594, Accuracy: 0.9696000218391418\n",
      "Epoch 993: 0.0820910707116127, Accuracy: 0.9696000218391418\n",
      "Epoch 994: 0.08200990408658981, Accuracy: 0.9696999788284302\n",
      "Epoch 995: 0.0819217637181282, Accuracy: 0.9696000218391418\n",
      "Epoch 996: 0.08184143155813217, Accuracy: 0.9696999788284302\n",
      "Epoch 997: 0.08175388723611832, Accuracy: 0.9696000218391418\n",
      "Epoch 998: 0.08167374134063721, Accuracy: 0.9696999788284302\n",
      "Epoch 999: 0.08158668875694275, Accuracy: 0.9696000218391418\n",
      "Epoch 1000: 0.08150739967823029, Accuracy: 0.9696999788284302\n",
      "n_in:  784\n",
      "n_out:  10\n",
      "Epoch 1: 2.6047489643096924, Accuracy: 0.09799999743700027\n",
      "Epoch 2: 2.721940279006958, Accuracy: 0.08940000087022781\n",
      "Epoch 3: 2.3067405223846436, Accuracy: 0.0908999964594841\n",
      "Epoch 4: 2.30497145652771, Accuracy: 0.09109999984502792\n",
      "Epoch 5: 2.3040037155151367, Accuracy: 0.09120000153779984\n",
      "Epoch 6: 2.3033523559570312, Accuracy: 0.09179999679327011\n",
      "Epoch 7: 2.302839994430542, Accuracy: 0.09179999679327011\n",
      "Epoch 8: 2.3023743629455566, Accuracy: 0.09220000356435776\n",
      "Epoch 9: 2.3018887042999268, Accuracy: 0.09189999848604202\n",
      "Epoch 10: 2.301318407058716, Accuracy: 0.0925000011920929\n",
      "Epoch 11: 2.3005685806274414, Accuracy: 0.09440000355243683\n",
      "Epoch 12: 2.2994909286499023, Accuracy: 0.0940999984741211\n",
      "Epoch 13: 2.2978010177612305, Accuracy: 0.09480000287294388\n",
      "Epoch 14: 2.2949421405792236, Accuracy: 0.09520000219345093\n",
      "Epoch 15: 2.289860963821411, Accuracy: 0.09619999676942825\n",
      "Epoch 16: 2.2807650566101074, Accuracy: 0.09489999711513519\n",
      "Epoch 17: 2.265516757965088, Accuracy: 0.09830000251531601\n",
      "Epoch 18: 2.2451012134552, Accuracy: 0.10010000318288803\n",
      "Epoch 19: 2.2236034870147705, Accuracy: 0.1054999977350235\n",
      "Epoch 20: 2.202540159225464, Accuracy: 0.15639999508857727\n",
      "Epoch 21: 2.1830482482910156, Accuracy: 0.21050000190734863\n",
      "Epoch 22: 2.1643784046173096, Accuracy: 0.2459000051021576\n",
      "Epoch 23: 2.1449365615844727, Accuracy: 0.27309998869895935\n",
      "Epoch 24: 2.1235997676849365, Accuracy: 0.2971000075340271\n",
      "Epoch 25: 2.0996227264404297, Accuracy: 0.3156000077724457\n",
      "Epoch 26: 2.072273015975952, Accuracy: 0.334199994802475\n",
      "Epoch 27: 2.040970802307129, Accuracy: 0.357699990272522\n",
      "Epoch 28: 2.005342721939087, Accuracy: 0.3865000009536743\n",
      "Epoch 29: 1.9648163318634033, Accuracy: 0.42320001125335693\n",
      "Epoch 30: 1.9187227487564087, Accuracy: 0.4544999897480011\n",
      "Epoch 31: 1.8664699792861938, Accuracy: 0.5072000026702881\n",
      "Epoch 32: 1.808049201965332, Accuracy: 0.5195000171661377\n",
      "Epoch 33: 1.744089961051941, Accuracy: 0.5623999834060669\n",
      "Epoch 34: 1.6794297695159912, Accuracy: 0.5360000133514404\n",
      "Epoch 35: 1.6277862787246704, Accuracy: 0.48240000009536743\n",
      "Epoch 36: 1.6621627807617188, Accuracy: 0.3377000093460083\n",
      "Epoch 37: 1.7150152921676636, Accuracy: 0.32330000400543213\n",
      "Epoch 38: 2.092318296432495, Accuracy: 0.4997999966144562\n",
      "Epoch 39: 1.6950573921203613, Accuracy: 0.49380001425743103\n",
      "Epoch 40: 1.3727705478668213, Accuracy: 0.6001999974250793\n",
      "Epoch 41: 1.3485087156295776, Accuracy: 0.5845000147819519\n",
      "Epoch 42: 1.4524255990982056, Accuracy: 0.6604999899864197\n",
      "Epoch 43: 1.3418867588043213, Accuracy: 0.6021999716758728\n",
      "Epoch 44: 1.269559383392334, Accuracy: 0.4140999913215637\n",
      "Epoch 45: 1.7158770561218262, Accuracy: 0.35899999737739563\n",
      "Epoch 46: 1.770612359046936, Accuracy: 0.7287999987602234\n",
      "Epoch 47: 1.3680287599563599, Accuracy: 0.7677000164985657\n",
      "Epoch 48: 0.9916819930076599, Accuracy: 0.7361999750137329\n",
      "Epoch 49: 0.9108511805534363, Accuracy: 0.7063000202178955\n",
      "Epoch 50: 0.944812536239624, Accuracy: 0.5659999847412109\n",
      "Epoch 51: 1.3397090435028076, Accuracy: 0.5611000061035156\n",
      "Epoch 52: 1.235284686088562, Accuracy: 0.6820999979972839\n",
      "Epoch 53: 1.0128192901611328, Accuracy: 0.7936999797821045\n",
      "Epoch 54: 0.7702938914299011, Accuracy: 0.7634000182151794\n",
      "Epoch 55: 0.7713401317596436, Accuracy: 0.6198999881744385\n",
      "Epoch 56: 1.0230854749679565, Accuracy: 0.5457000136375427\n",
      "Epoch 57: 1.4338321685791016, Accuracy: 0.6029999852180481\n",
      "Epoch 58: 1.1072001457214355, Accuracy: 0.7526000142097473\n",
      "Epoch 59: 0.8031972646713257, Accuracy: 0.839900016784668\n",
      "Epoch 60: 0.6680006980895996, Accuracy: 0.8281999826431274\n",
      "Epoch 61: 0.6349583864212036, Accuracy: 0.82669997215271\n",
      "Epoch 62: 0.6416601538658142, Accuracy: 0.7594000101089478\n",
      "Epoch 63: 0.7487040758132935, Accuracy: 0.717199981212616\n",
      "Epoch 64: 1.0007189512252808, Accuracy: 0.7125999927520752\n",
      "Epoch 65: 0.9225714206695557, Accuracy: 0.7842000126838684\n",
      "Epoch 66: 0.7467488050460815, Accuracy: 0.829200029373169\n",
      "Epoch 67: 0.6330289244651794, Accuracy: 0.8152999877929688\n",
      "Epoch 68: 0.6254393458366394, Accuracy: 0.8208000063896179\n",
      "Epoch 69: 0.6267901062965393, Accuracy: 0.7796000242233276\n",
      "Epoch 70: 0.6821022033691406, Accuracy: 0.7692000269889832\n",
      "Epoch 71: 0.7092172503471375, Accuracy: 0.7333999872207642\n",
      "Epoch 72: 0.7697106599807739, Accuracy: 0.7817000150680542\n",
      "Epoch 73: 0.6794381737709045, Accuracy: 0.8154000043869019\n",
      "Epoch 74: 0.5936201810836792, Accuracy: 0.8370000123977661\n",
      "Epoch 75: 0.5453171730041504, Accuracy: 0.8345999717712402\n",
      "Epoch 76: 0.5313929915428162, Accuracy: 0.8149999976158142\n",
      "Epoch 77: 0.5459986925125122, Accuracy: 0.7918000221252441\n",
      "Epoch 78: 0.6132373213768005, Accuracy: 0.7324000000953674\n",
      "Epoch 79: 0.7744280099868774, Accuracy: 0.6970000267028809\n",
      "Epoch 80: 0.8404675722122192, Accuracy: 0.7064999938011169\n",
      "Epoch 81: 0.8293929100036621, Accuracy: 0.8158000111579895\n",
      "Epoch 82: 0.6432215571403503, Accuracy: 0.8637999892234802\n",
      "Epoch 83: 0.50741046667099, Accuracy: 0.8708000183105469\n",
      "Epoch 84: 0.48294275999069214, Accuracy: 0.8690999746322632\n",
      "Epoch 85: 0.4757738709449768, Accuracy: 0.866599977016449\n",
      "Epoch 86: 0.48094576597213745, Accuracy: 0.8504999876022339\n",
      "Epoch 87: 0.5027252435684204, Accuracy: 0.8348000049591064\n",
      "Epoch 88: 0.5485931634902954, Accuracy: 0.7957000136375427\n",
      "Epoch 89: 0.6352689266204834, Accuracy: 0.7818999886512756\n",
      "Epoch 90: 0.6703318953514099, Accuracy: 0.7985000014305115\n",
      "Epoch 91: 0.6230283379554749, Accuracy: 0.8486999869346619\n",
      "Epoch 92: 0.5290066003799438, Accuracy: 0.8708999752998352\n",
      "Epoch 93: 0.46832406520843506, Accuracy: 0.8780999779701233\n",
      "Epoch 94: 0.4478550851345062, Accuracy: 0.8788999915122986\n",
      "Epoch 95: 0.4389618933200836, Accuracy: 0.8795999884605408\n",
      "Epoch 96: 0.4345424175262451, Accuracy: 0.8736000061035156\n",
      "Epoch 97: 0.43813368678092957, Accuracy: 0.8722000122070312\n",
      "Epoch 98: 0.4421066641807556, Accuracy: 0.8551999926567078\n",
      "Epoch 99: 0.4658786654472351, Accuracy: 0.8482999801635742\n",
      "Epoch 100: 0.4800177812576294, Accuracy: 0.816100001335144\n",
      "Epoch 101: 0.5339516401290894, Accuracy: 0.8237000107765198\n",
      "Epoch 102: 0.518096387386322, Accuracy: 0.8281000256538391\n",
      "Epoch 103: 0.5142454504966736, Accuracy: 0.8615999817848206\n",
      "Epoch 104: 0.4585215449333191, Accuracy: 0.8751999735832214\n",
      "Epoch 105: 0.43122628331184387, Accuracy: 0.885200023651123\n",
      "Epoch 106: 0.412014901638031, Accuracy: 0.8863000273704529\n",
      "Epoch 107: 0.40335556864738464, Accuracy: 0.8899000287055969\n",
      "Epoch 108: 0.3969708979129791, Accuracy: 0.8902999758720398\n",
      "Epoch 109: 0.39353638887405396, Accuracy: 0.8906000256538391\n",
      "Epoch 110: 0.391084760427475, Accuracy: 0.8913999795913696\n",
      "Epoch 111: 0.38992539048194885, Accuracy: 0.8902999758720398\n",
      "Epoch 112: 0.3901398479938507, Accuracy: 0.8903999924659729\n",
      "Epoch 113: 0.3907150328159332, Accuracy: 0.8881000280380249\n",
      "Epoch 114: 0.39440712332725525, Accuracy: 0.8859999775886536\n",
      "Epoch 115: 0.396001935005188, Accuracy: 0.8823999762535095\n",
      "Epoch 116: 0.4037613868713379, Accuracy: 0.8823000192642212\n",
      "Epoch 117: 0.40266284346580505, Accuracy: 0.8784999847412109\n",
      "Epoch 118: 0.4113876521587372, Accuracy: 0.8827000260353088\n",
      "Epoch 119: 0.4018358290195465, Accuracy: 0.8812999725341797\n",
      "Epoch 120: 0.40477418899536133, Accuracy: 0.8884000182151794\n",
      "Epoch 121: 0.389751136302948, Accuracy: 0.8895000219345093\n",
      "Epoch 122: 0.3878299593925476, Accuracy: 0.8944000005722046\n",
      "Epoch 123: 0.37573301792144775, Accuracy: 0.8944000005722046\n",
      "Epoch 124: 0.37344756722450256, Accuracy: 0.8981000185012817\n",
      "Epoch 125: 0.365665078163147, Accuracy: 0.8973000049591064\n",
      "Epoch 126: 0.36427435278892517, Accuracy: 0.9006999731063843\n",
      "Epoch 127: 0.3591492474079132, Accuracy: 0.8988999724388123\n",
      "Epoch 128: 0.35851284861564636, Accuracy: 0.9021000266075134\n",
      "Epoch 129: 0.35483333468437195, Accuracy: 0.8992000222206116\n",
      "Epoch 130: 0.3548487424850464, Accuracy: 0.902899980545044\n",
      "Epoch 131: 0.35199296474456787, Accuracy: 0.8995000123977661\n",
      "Epoch 132: 0.3526795208454132, Accuracy: 0.9020000100135803\n",
      "Epoch 133: 0.35037893056869507, Accuracy: 0.8992000222206116\n",
      "Epoch 134: 0.3518000841140747, Accuracy: 0.9017999768257141\n",
      "Epoch 135: 0.3499724268913269, Accuracy: 0.8999999761581421\n",
      "Epoch 136: 0.35220977663993835, Accuracy: 0.9017999768257141\n",
      "Epoch 137: 0.35081079602241516, Accuracy: 0.8999999761581421\n",
      "Epoch 138: 0.3537434935569763, Accuracy: 0.9007999897003174\n",
      "Epoch 139: 0.35272839665412903, Accuracy: 0.8988999724388123\n",
      "Epoch 140: 0.35596948862075806, Accuracy: 0.8996999859809875\n",
      "Epoch 141: 0.35516080260276794, Accuracy: 0.8988000154495239\n",
      "Epoch 142: 0.3578417897224426, Accuracy: 0.9007999897003174\n",
      "Epoch 143: 0.3568374216556549, Accuracy: 0.8996999859809875\n",
      "Epoch 144: 0.35793861746788025, Accuracy: 0.9003999829292297\n",
      "Epoch 145: 0.3561255633831024, Accuracy: 0.9007999897003174\n",
      "Epoch 146: 0.35501813888549805, Accuracy: 0.900600016117096\n",
      "Epoch 147: 0.351958304643631, Accuracy: 0.902400016784668\n",
      "Epoch 148: 0.34916025400161743, Accuracy: 0.9027000069618225\n",
      "Epoch 149: 0.3452811539173126, Accuracy: 0.9042999744415283\n",
      "Epoch 150: 0.34187543392181396, Accuracy: 0.9039000272750854\n",
      "Epoch 151: 0.3379673957824707, Accuracy: 0.9071000218391418\n",
      "Epoch 152: 0.33488425612449646, Accuracy: 0.9057999849319458\n",
      "Epoch 153: 0.3314686417579651, Accuracy: 0.90829998254776\n",
      "Epoch 154: 0.3290557861328125, Accuracy: 0.9078999757766724\n",
      "Epoch 155: 0.32621556520462036, Accuracy: 0.9089999794960022\n",
      "Epoch 156: 0.3244180381298065, Accuracy: 0.9078999757766724\n",
      "Epoch 157: 0.3221052587032318, Accuracy: 0.909600019454956\n",
      "Epoch 158: 0.32081884145736694, Accuracy: 0.9085999727249146\n",
      "Epoch 159: 0.318907767534256, Accuracy: 0.9097999930381775\n",
      "Epoch 160: 0.31799089908599854, Accuracy: 0.909500002861023\n",
      "Epoch 161: 0.3163903057575226, Accuracy: 0.9103999733924866\n",
      "Epoch 162: 0.31579193472862244, Accuracy: 0.9103999733924866\n",
      "Epoch 163: 0.31445378065109253, Accuracy: 0.9108999967575073\n",
      "Epoch 164: 0.3141205608844757, Accuracy: 0.9104999899864197\n",
      "Epoch 165: 0.3130168318748474, Accuracy: 0.911300003528595\n",
      "Epoch 166: 0.31293386220932007, Accuracy: 0.9103000164031982\n",
      "Epoch 167: 0.31205838918685913, Accuracy: 0.9125000238418579\n",
      "Epoch 168: 0.3121846616268158, Accuracy: 0.9099000096321106\n",
      "Epoch 169: 0.31154167652130127, Accuracy: 0.9121000170707703\n",
      "Epoch 170: 0.31179648637771606, Accuracy: 0.9093000292778015\n",
      "Epoch 171: 0.31134718656539917, Accuracy: 0.9117000102996826\n",
      "Epoch 172: 0.31158682703971863, Accuracy: 0.9088000059127808\n",
      "Epoch 173: 0.3112196624279022, Accuracy: 0.9118000268936157\n",
      "Epoch 174: 0.311195969581604, Accuracy: 0.9088000059127808\n",
      "Epoch 175: 0.3107224106788635, Accuracy: 0.9120000004768372\n",
      "Epoch 176: 0.3101732134819031, Accuracy: 0.9089000225067139\n",
      "Epoch 177: 0.3093976676464081, Accuracy: 0.9121999740600586\n",
      "Epoch 178: 0.3081918954849243, Accuracy: 0.9111999869346619\n",
      "Epoch 179: 0.3069775104522705, Accuracy: 0.9129999876022339\n",
      "Epoch 180: 0.3051929473876953, Accuracy: 0.9120000004768372\n",
      "Epoch 181: 0.30362245440483093, Accuracy: 0.9138000011444092\n",
      "Epoch 182: 0.30156248807907104, Accuracy: 0.9140999913215637\n",
      "Epoch 183: 0.2998407483100891, Accuracy: 0.9150000214576721\n",
      "Epoch 184: 0.29779645800590515, Accuracy: 0.9143000245094299\n",
      "Epoch 185: 0.29614001512527466, Accuracy: 0.9164999723434448\n",
      "Epoch 186: 0.29429832100868225, Accuracy: 0.9154000282287598\n",
      "Epoch 187: 0.29280510544776917, Accuracy: 0.9172999858856201\n",
      "Epoch 188: 0.2912074625492096, Accuracy: 0.9172999858856201\n",
      "Epoch 189: 0.28987768292427063, Accuracy: 0.9182000160217285\n",
      "Epoch 190: 0.28849777579307556, Accuracy: 0.9176999926567078\n",
      "Epoch 191: 0.28732946515083313, Accuracy: 0.9190000295639038\n",
      "Epoch 192: 0.28612515330314636, Accuracy: 0.9182999730110168\n",
      "Epoch 193: 0.285089373588562, Accuracy: 0.9200999736785889\n",
      "Epoch 194: 0.2840087115764618, Accuracy: 0.9186000227928162\n",
      "Epoch 195: 0.2830790877342224, Accuracy: 0.9205999970436096\n",
      "Epoch 196: 0.28210341930389404, Accuracy: 0.9190000295639038\n",
      "Epoch 197: 0.28125134110450745, Accuracy: 0.9208999872207642\n",
      "Epoch 198: 0.2803501486778259, Accuracy: 0.9200999736785889\n",
      "Epoch 199: 0.27955886721611023, Accuracy: 0.9207000136375427\n",
      "Epoch 200: 0.2787128686904907, Accuracy: 0.9205999970436096\n",
      "Epoch 201: 0.27797237038612366, Accuracy: 0.9211999773979187\n",
      "Epoch 202: 0.2771660387516022, Accuracy: 0.9211000204086304\n",
      "Epoch 203: 0.27646031975746155, Accuracy: 0.9214000105857849\n",
      "Epoch 204: 0.2756901681423187, Accuracy: 0.9218000173568726\n",
      "Epoch 205: 0.2750258147716522, Accuracy: 0.9215999841690063\n",
      "Epoch 206: 0.2742862403392792, Accuracy: 0.9218000173568726\n",
      "Epoch 207: 0.27365386486053467, Accuracy: 0.9218999743461609\n",
      "Epoch 208: 0.27293989062309265, Accuracy: 0.9222000241279602\n",
      "Epoch 209: 0.2723371684551239, Accuracy: 0.9222999811172485\n",
      "Epoch 210: 0.2716456353664398, Accuracy: 0.9223999977111816\n",
      "Epoch 211: 0.27106863260269165, Accuracy: 0.9232000112533569\n",
      "Epoch 212: 0.2703990042209625, Accuracy: 0.9229000210762024\n",
      "Epoch 213: 0.2698502242565155, Accuracy: 0.9235000014305115\n",
      "Epoch 214: 0.26919984817504883, Accuracy: 0.92330002784729\n",
      "Epoch 215: 0.2686815857887268, Accuracy: 0.9239000082015991\n",
      "Epoch 216: 0.26805219054222107, Accuracy: 0.9236000180244446\n",
      "Epoch 217: 0.26757121086120605, Accuracy: 0.9240000247955322\n",
      "Epoch 218: 0.26695892214775085, Accuracy: 0.923799991607666\n",
      "Epoch 219: 0.26651567220687866, Accuracy: 0.9240999817848206\n",
      "Epoch 220: 0.2659217417240143, Accuracy: 0.9240000247955322\n",
      "Epoch 221: 0.26550766825675964, Accuracy: 0.9240999817848206\n",
      "Epoch 222: 0.26492902636528015, Accuracy: 0.9243000149726868\n",
      "Epoch 223: 0.2645469605922699, Accuracy: 0.9243000149726868\n",
      "Epoch 224: 0.26397350430488586, Accuracy: 0.9247000217437744\n",
      "Epoch 225: 0.26361599564552307, Accuracy: 0.9248999953269958\n",
      "Epoch 226: 0.2630392014980316, Accuracy: 0.9246000051498413\n",
      "Epoch 227: 0.26270368695259094, Accuracy: 0.925000011920929\n",
      "Epoch 228: 0.2621125876903534, Accuracy: 0.9254000186920166\n",
      "Epoch 229: 0.2617921829223633, Accuracy: 0.925000011920929\n",
      "Epoch 230: 0.26118409633636475, Accuracy: 0.9258000254631042\n",
      "Epoch 231: 0.2608678340911865, Accuracy: 0.9251000285148621\n",
      "Epoch 232: 0.26022985577583313, Accuracy: 0.9259999990463257\n",
      "Epoch 233: 0.2599044740200043, Accuracy: 0.9247000217437744\n",
      "Epoch 234: 0.25923559069633484, Accuracy: 0.9262999892234802\n",
      "Epoch 235: 0.2588900625705719, Accuracy: 0.9254000186920166\n",
      "Epoch 236: 0.258188396692276, Accuracy: 0.9262999892234802\n",
      "Epoch 237: 0.2578221261501312, Accuracy: 0.925599992275238\n",
      "Epoch 238: 0.25707629323005676, Accuracy: 0.9262999892234802\n",
      "Epoch 239: 0.2566726803779602, Accuracy: 0.9258000254631042\n",
      "Epoch 240: 0.25588446855545044, Accuracy: 0.9266999959945679\n",
      "Epoch 241: 0.2554321885108948, Accuracy: 0.9261000156402588\n",
      "Epoch 242: 0.25461795926094055, Accuracy: 0.9269000291824341\n",
      "Epoch 243: 0.2541169226169586, Accuracy: 0.9269000291824341\n",
      "Epoch 244: 0.25327736139297485, Accuracy: 0.927299976348877\n",
      "Epoch 245: 0.25273364782333374, Accuracy: 0.9269999861717224\n",
      "Epoch 246: 0.2518767714500427, Accuracy: 0.9276999831199646\n",
      "Epoch 247: 0.25129663944244385, Accuracy: 0.9279000163078308\n",
      "Epoch 248: 0.2504490613937378, Accuracy: 0.9279000163078308\n",
      "Epoch 249: 0.24984712898731232, Accuracy: 0.9286999702453613\n",
      "Epoch 250: 0.24901500344276428, Accuracy: 0.9283999800682068\n",
      "Epoch 251: 0.24839910864830017, Accuracy: 0.9294999837875366\n",
      "Epoch 252: 0.24758446216583252, Accuracy: 0.9290000200271606\n",
      "Epoch 253: 0.24696588516235352, Accuracy: 0.9301999807357788\n",
      "Epoch 254: 0.24617698788642883, Accuracy: 0.9297000169754028\n",
      "Epoch 255: 0.2455577850341797, Accuracy: 0.9305999875068665\n",
      "Epoch 256: 0.24480053782463074, Accuracy: 0.9298999905586243\n",
      "Epoch 257: 0.24418288469314575, Accuracy: 0.9311000108718872\n",
      "Epoch 258: 0.24344708025455475, Accuracy: 0.9297000169754028\n",
      "Epoch 259: 0.24283868074417114, Accuracy: 0.9312999844551086\n",
      "Epoch 260: 0.24212540686130524, Accuracy: 0.9300000071525574\n",
      "Epoch 261: 0.2415306568145752, Accuracy: 0.9318000078201294\n",
      "Epoch 262: 0.24084070324897766, Accuracy: 0.9302999973297119\n",
      "Epoch 263: 0.24025586247444153, Accuracy: 0.9316999912261963\n",
      "Epoch 264: 0.23959071934223175, Accuracy: 0.9307000041007996\n",
      "Epoch 265: 0.2390137016773224, Accuracy: 0.9320999979972839\n",
      "Epoch 266: 0.23836715519428253, Accuracy: 0.9308000206947327\n",
      "Epoch 267: 0.2377990335226059, Accuracy: 0.9326000213623047\n",
      "Epoch 268: 0.23717498779296875, Accuracy: 0.9311000108718872\n",
      "Epoch 269: 0.236619234085083, Accuracy: 0.9327999949455261\n",
      "Epoch 270: 0.23601514101028442, Accuracy: 0.9312999844551086\n",
      "Epoch 271: 0.23547643423080444, Accuracy: 0.9330000281333923\n",
      "Epoch 272: 0.2348921149969101, Accuracy: 0.9314000010490417\n",
      "Epoch 273: 0.2343629002571106, Accuracy: 0.9332000017166138\n",
      "Epoch 274: 0.2337944656610489, Accuracy: 0.9319000244140625\n",
      "Epoch 275: 0.2332744151353836, Accuracy: 0.9333999752998352\n",
      "Epoch 276: 0.23272231221199036, Accuracy: 0.9325000047683716\n",
      "Epoch 277: 0.23221106827259064, Accuracy: 0.9337999820709229\n",
      "Epoch 278: 0.23167011141777039, Accuracy: 0.9327999949455261\n",
      "Epoch 279: 0.2311667799949646, Accuracy: 0.934499979019165\n",
      "Epoch 280: 0.2306341975927353, Accuracy: 0.9332000017166138\n",
      "Epoch 281: 0.23013964295387268, Accuracy: 0.9344000220298767\n",
      "Epoch 282: 0.2296151965856552, Accuracy: 0.9333999752998352\n",
      "Epoch 283: 0.22913019359111786, Accuracy: 0.9348999857902527\n",
      "Epoch 284: 0.22861605882644653, Accuracy: 0.9337000250816345\n",
      "Epoch 285: 0.22813250124454498, Accuracy: 0.9352999925613403\n",
      "Epoch 286: 0.22762951254844666, Accuracy: 0.9336000084877014\n",
      "Epoch 287: 0.22715362906455994, Accuracy: 0.9354000091552734\n",
      "Epoch 288: 0.22665618360042572, Accuracy: 0.933899998664856\n",
      "Epoch 289: 0.22618989646434784, Accuracy: 0.9355999827384949\n",
      "Epoch 290: 0.22570063173770905, Accuracy: 0.9341999888420105\n",
      "Epoch 291: 0.22523722052574158, Accuracy: 0.9359999895095825\n",
      "Epoch 292: 0.22474874556064606, Accuracy: 0.9341999888420105\n",
      "Epoch 293: 0.2242884784936905, Accuracy: 0.9362999796867371\n",
      "Epoch 294: 0.2238064557313919, Accuracy: 0.934499979019165\n",
      "Epoch 295: 0.22335098683834076, Accuracy: 0.9366999864578247\n",
      "Epoch 296: 0.22287334501743317, Accuracy: 0.9350000023841858\n",
      "Epoch 297: 0.22242185473442078, Accuracy: 0.9366999864578247\n",
      "Epoch 298: 0.22195173799991608, Accuracy: 0.9350000023841858\n",
      "Epoch 299: 0.221504807472229, Accuracy: 0.9370999932289124\n",
      "Epoch 300: 0.22103683650493622, Accuracy: 0.9354000091552734\n",
      "Epoch 301: 0.22059057652950287, Accuracy: 0.9373000264167786\n",
      "Epoch 302: 0.22012366354465485, Accuracy: 0.9358000159263611\n",
      "Epoch 303: 0.21968242526054382, Accuracy: 0.9375\n",
      "Epoch 304: 0.21921730041503906, Accuracy: 0.9361000061035156\n",
      "Epoch 305: 0.21878021955490112, Accuracy: 0.9373999834060669\n",
      "Epoch 306: 0.21832138299942017, Accuracy: 0.9363999962806702\n",
      "Epoch 307: 0.2178891897201538, Accuracy: 0.9376000165939331\n",
      "Epoch 308: 0.21743109822273254, Accuracy: 0.9366999864578247\n",
      "Epoch 309: 0.21700182557106018, Accuracy: 0.9379000067710876\n",
      "Epoch 310: 0.21654962003231049, Accuracy: 0.9369000196456909\n",
      "Epoch 311: 0.21612198650836945, Accuracy: 0.9380999803543091\n",
      "Epoch 312: 0.21567457914352417, Accuracy: 0.9373999834060669\n",
      "Epoch 313: 0.21525004506111145, Accuracy: 0.9383000135421753\n",
      "Epoch 314: 0.21480515599250793, Accuracy: 0.9379000067710876\n",
      "Epoch 315: 0.21438433229923248, Accuracy: 0.9387000203132629\n",
      "Epoch 316: 0.2139422595500946, Accuracy: 0.9383000135421753\n",
      "Epoch 317: 0.21352235972881317, Accuracy: 0.939300000667572\n",
      "Epoch 318: 0.21307958662509918, Accuracy: 0.9384999871253967\n",
      "Epoch 319: 0.21266232430934906, Accuracy: 0.9395999908447266\n",
      "Epoch 320: 0.2122192233800888, Accuracy: 0.9387000203132629\n",
      "Epoch 321: 0.21179886162281036, Accuracy: 0.9395999908447266\n",
      "Epoch 322: 0.21135902404785156, Accuracy: 0.9391000270843506\n",
      "Epoch 323: 0.2109408676624298, Accuracy: 0.9395999908447266\n",
      "Epoch 324: 0.21049733459949493, Accuracy: 0.9394999742507935\n",
      "Epoch 325: 0.2100813239812851, Accuracy: 0.9399999976158142\n",
      "Epoch 326: 0.2096404880285263, Accuracy: 0.9398000240325928\n",
      "Epoch 327: 0.209224134683609, Accuracy: 0.9401000142097473\n",
      "Epoch 328: 0.20878712832927704, Accuracy: 0.9401000142097473\n",
      "Epoch 329: 0.20837196707725525, Accuracy: 0.9401000142097473\n",
      "Epoch 330: 0.2079385370016098, Accuracy: 0.9401999711990356\n",
      "Epoch 331: 0.20752321183681488, Accuracy: 0.9402999877929688\n",
      "Epoch 332: 0.20709611475467682, Accuracy: 0.9405999779701233\n",
      "Epoch 333: 0.20668098330497742, Accuracy: 0.940500020980835\n",
      "Epoch 334: 0.20625293254852295, Accuracy: 0.9406999945640564\n",
      "Epoch 335: 0.20583543181419373, Accuracy: 0.9405999779701233\n",
      "Epoch 336: 0.20540867745876312, Accuracy: 0.9409000277519226\n",
      "Epoch 337: 0.204995796084404, Accuracy: 0.9409000277519226\n",
      "Epoch 338: 0.20457114279270172, Accuracy: 0.9412999749183655\n",
      "Epoch 339: 0.20416082441806793, Accuracy: 0.941100001335144\n",
      "Epoch 340: 0.2037346363067627, Accuracy: 0.9413999915122986\n",
      "Epoch 341: 0.20332540571689606, Accuracy: 0.9415000081062317\n",
      "Epoch 342: 0.20290040969848633, Accuracy: 0.9416000247001648\n",
      "Epoch 343: 0.20249530673027039, Accuracy: 0.9415000081062317\n",
      "Epoch 344: 0.20207686722278595, Accuracy: 0.9416999816894531\n",
      "Epoch 345: 0.2016749233007431, Accuracy: 0.9416000247001648\n",
      "Epoch 346: 0.20126095414161682, Accuracy: 0.9417999982833862\n",
      "Epoch 347: 0.20086179673671722, Accuracy: 0.9417999982833862\n",
      "Epoch 348: 0.20045116543769836, Accuracy: 0.9420999884605408\n",
      "Epoch 349: 0.2000531256198883, Accuracy: 0.9422000050544739\n",
      "Epoch 350: 0.19964423775672913, Accuracy: 0.942300021648407\n",
      "Epoch 351: 0.1992505043745041, Accuracy: 0.9420999884605408\n",
      "Epoch 352: 0.1988449990749359, Accuracy: 0.9426000118255615\n",
      "Epoch 353: 0.19845376908779144, Accuracy: 0.9424999952316284\n",
      "Epoch 354: 0.19805356860160828, Accuracy: 0.942799985408783\n",
      "Epoch 355: 0.1976671814918518, Accuracy: 0.9430000185966492\n",
      "Epoch 356: 0.1972721517086029, Accuracy: 0.9429000020027161\n",
      "Epoch 357: 0.1968897581100464, Accuracy: 0.9434999823570251\n",
      "Epoch 358: 0.196497842669487, Accuracy: 0.9434000253677368\n",
      "Epoch 359: 0.19611701369285583, Accuracy: 0.9437000155448914\n",
      "Epoch 360: 0.1957278698682785, Accuracy: 0.9435999989509583\n",
      "Epoch 361: 0.19534900784492493, Accuracy: 0.9438999891281128\n",
      "Epoch 362: 0.19496163725852966, Accuracy: 0.9438999891281128\n",
      "Epoch 363: 0.19458532333374023, Accuracy: 0.944100022315979\n",
      "Epoch 364: 0.19419845938682556, Accuracy: 0.9441999793052673\n",
      "Epoch 365: 0.19382578134536743, Accuracy: 0.9442999958992004\n",
      "Epoch 366: 0.19344063103199005, Accuracy: 0.944599986076355\n",
      "Epoch 367: 0.19306820631027222, Accuracy: 0.9442999958992004\n",
      "Epoch 368: 0.19268609583377838, Accuracy: 0.9448000192642212\n",
      "Epoch 369: 0.1923139989376068, Accuracy: 0.9442999958992004\n",
      "Epoch 370: 0.1919359564781189, Accuracy: 0.9452000260353088\n",
      "Epoch 371: 0.19156549870967865, Accuracy: 0.9444000124931335\n",
      "Epoch 372: 0.1911887228488922, Accuracy: 0.9455999732017517\n",
      "Epoch 373: 0.1908188760280609, Accuracy: 0.9445000290870667\n",
      "Epoch 374: 0.19044405221939087, Accuracy: 0.945900022983551\n",
      "Epoch 375: 0.19007804989814758, Accuracy: 0.9447000026702881\n",
      "Epoch 376: 0.1897084265947342, Accuracy: 0.9460999965667725\n",
      "Epoch 377: 0.18934644758701324, Accuracy: 0.9448999762535095\n",
      "Epoch 378: 0.18898038566112518, Accuracy: 0.9460999965667725\n",
      "Epoch 379: 0.18862424790859222, Accuracy: 0.9451000094413757\n",
      "Epoch 380: 0.1882624626159668, Accuracy: 0.9460999965667725\n",
      "Epoch 381: 0.18790684640407562, Accuracy: 0.9452999830245972\n",
      "Epoch 382: 0.18754784762859344, Accuracy: 0.9463000297546387\n",
      "Epoch 383: 0.187196284532547, Accuracy: 0.9452999830245972\n",
      "Epoch 384: 0.18683992326259613, Accuracy: 0.9463000297546387\n",
      "Epoch 385: 0.1864914894104004, Accuracy: 0.9452999830245972\n",
      "Epoch 386: 0.1861390918493271, Accuracy: 0.9465000033378601\n",
      "Epoch 387: 0.1857932060956955, Accuracy: 0.9456999897956848\n",
      "Epoch 388: 0.18544581532478333, Accuracy: 0.9465000033378601\n",
      "Epoch 389: 0.1851017326116562, Accuracy: 0.9455999732017517\n",
      "Epoch 390: 0.18475715816020966, Accuracy: 0.9466999769210815\n",
      "Epoch 391: 0.18441544473171234, Accuracy: 0.945900022983551\n",
      "Epoch 392: 0.18407288193702698, Accuracy: 0.9470999836921692\n",
      "Epoch 393: 0.1837335228919983, Accuracy: 0.9460999965667725\n",
      "Epoch 394: 0.18339477479457855, Accuracy: 0.9473999738693237\n",
      "Epoch 395: 0.1830567568540573, Accuracy: 0.9463000297546387\n",
      "Epoch 396: 0.1827203929424286, Accuracy: 0.9472000002861023\n",
      "Epoch 397: 0.18238449096679688, Accuracy: 0.9466000199317932\n",
      "Epoch 398: 0.18204987049102783, Accuracy: 0.9473000168800354\n",
      "Epoch 399: 0.18171843886375427, Accuracy: 0.9469000101089478\n",
      "Epoch 400: 0.18138648569583893, Accuracy: 0.9472000002861023\n",
      "Epoch 401: 0.18105702102184296, Accuracy: 0.9473000168800354\n",
      "Epoch 402: 0.18072789907455444, Accuracy: 0.9473000168800354\n",
      "Epoch 403: 0.18040096759796143, Accuracy: 0.9473000168800354\n",
      "Epoch 404: 0.18007434904575348, Accuracy: 0.9473999738693237\n",
      "Epoch 405: 0.17974868416786194, Accuracy: 0.9474999904632568\n",
      "Epoch 406: 0.1794241964817047, Accuracy: 0.9476000070571899\n",
      "Epoch 407: 0.1791001856327057, Accuracy: 0.947700023651123\n",
      "Epoch 408: 0.17877893149852753, Accuracy: 0.9476000070571899\n",
      "Epoch 409: 0.17845721542835236, Accuracy: 0.9480000138282776\n",
      "Epoch 410: 0.17813760042190552, Accuracy: 0.9477999806404114\n",
      "Epoch 411: 0.17781759798526764, Accuracy: 0.9480000138282776\n",
      "Epoch 412: 0.1774994432926178, Accuracy: 0.9480999708175659\n",
      "Epoch 413: 0.17718183994293213, Accuracy: 0.9480999708175659\n",
      "Epoch 414: 0.17686541378498077, Accuracy: 0.9484999775886536\n",
      "Epoch 415: 0.17655138671398163, Accuracy: 0.948199987411499\n",
      "Epoch 416: 0.17623713612556458, Accuracy: 0.9485999941825867\n",
      "Epoch 417: 0.17592410743236542, Accuracy: 0.9480999708175659\n",
      "Epoch 418: 0.17561355233192444, Accuracy: 0.9485999941825867\n",
      "Epoch 419: 0.17530253529548645, Accuracy: 0.9480000138282776\n",
      "Epoch 420: 0.17499254643917084, Accuracy: 0.9484000205993652\n",
      "Epoch 421: 0.17468377947807312, Accuracy: 0.948199987411499\n",
      "Epoch 422: 0.1743762493133545, Accuracy: 0.9484000205993652\n",
      "Epoch 423: 0.17406946420669556, Accuracy: 0.948199987411499\n",
      "Epoch 424: 0.17376387119293213, Accuracy: 0.9483000040054321\n",
      "Epoch 425: 0.17346011102199554, Accuracy: 0.9485999941825867\n",
      "Epoch 426: 0.17315661907196045, Accuracy: 0.9483000040054321\n",
      "Epoch 427: 0.1728547066450119, Accuracy: 0.9487000107765198\n",
      "Epoch 428: 0.17255306243896484, Accuracy: 0.9484999775886536\n",
      "Epoch 429: 0.17225316166877747, Accuracy: 0.9491000175476074\n",
      "Epoch 430: 0.17195314168930054, Accuracy: 0.9487000107765198\n",
      "Epoch 431: 0.1716560572385788, Accuracy: 0.9491000175476074\n",
      "Epoch 432: 0.1713586300611496, Accuracy: 0.9488000273704529\n",
      "Epoch 433: 0.17106372117996216, Accuracy: 0.9492999911308289\n",
      "Epoch 434: 0.17076827585697174, Accuracy: 0.9490000009536743\n",
      "Epoch 435: 0.1704745888710022, Accuracy: 0.9492999911308289\n",
      "Epoch 436: 0.17018093168735504, Accuracy: 0.9491999745368958\n",
      "Epoch 437: 0.1698894053697586, Accuracy: 0.949400007724762\n",
      "Epoch 438: 0.16959761083126068, Accuracy: 0.9492999911308289\n",
      "Epoch 439: 0.16930748522281647, Accuracy: 0.949400007724762\n",
      "Epoch 440: 0.16901859641075134, Accuracy: 0.9492999911308289\n",
      "Epoch 441: 0.16872933506965637, Accuracy: 0.9495000243186951\n",
      "Epoch 442: 0.16844165325164795, Accuracy: 0.9495000243186951\n",
      "Epoch 443: 0.16815342009067535, Accuracy: 0.949400007724762\n",
      "Epoch 444: 0.16786593198776245, Accuracy: 0.9495999813079834\n",
      "Epoch 445: 0.16758011281490326, Accuracy: 0.949400007724762\n",
      "Epoch 446: 0.16729344427585602, Accuracy: 0.9495999813079834\n",
      "Epoch 447: 0.16700853407382965, Accuracy: 0.9495000243186951\n",
      "Epoch 448: 0.1667231321334839, Accuracy: 0.9498000144958496\n",
      "Epoch 449: 0.16643886268138885, Accuracy: 0.9495999813079834\n",
      "Epoch 450: 0.16615517437458038, Accuracy: 0.9498999714851379\n",
      "Epoch 451: 0.165871724486351, Accuracy: 0.9496999979019165\n",
      "Epoch 452: 0.16559015214443207, Accuracy: 0.9498999714851379\n",
      "Epoch 453: 0.16530820727348328, Accuracy: 0.949999988079071\n",
      "Epoch 454: 0.1650291085243225, Accuracy: 0.9498999714851379\n",
      "Epoch 455: 0.16474944353103638, Accuracy: 0.9502000212669373\n",
      "Epoch 456: 0.16447192430496216, Accuracy: 0.949999988079071\n",
      "Epoch 457: 0.16419439017772675, Accuracy: 0.9502999782562256\n",
      "Epoch 458: 0.16391804814338684, Accuracy: 0.9501000046730042\n",
      "Epoch 459: 0.16364307701587677, Accuracy: 0.9505000114440918\n",
      "Epoch 460: 0.16336899995803833, Accuracy: 0.9502000212669373\n",
      "Epoch 461: 0.16309550404548645, Accuracy: 0.9506000280380249\n",
      "Epoch 462: 0.16282257437705994, Accuracy: 0.9502000212669373\n",
      "Epoch 463: 0.16255217790603638, Accuracy: 0.9509000182151794\n",
      "Epoch 464: 0.1622815579175949, Accuracy: 0.9502999782562256\n",
      "Epoch 465: 0.16201277077198029, Accuracy: 0.9509999752044678\n",
      "Epoch 466: 0.16174378991127014, Accuracy: 0.9503999948501587\n",
      "Epoch 467: 0.16147661209106445, Accuracy: 0.9513999819755554\n",
      "Epoch 468: 0.16120915114879608, Accuracy: 0.9505000114440918\n",
      "Epoch 469: 0.1609429568052292, Accuracy: 0.9513999819755554\n",
      "Epoch 470: 0.16067706048488617, Accuracy: 0.9506999850273132\n",
      "Epoch 471: 0.16041189432144165, Accuracy: 0.9513999819755554\n",
      "Epoch 472: 0.1601477563381195, Accuracy: 0.9508000016212463\n",
      "Epoch 473: 0.15988416969776154, Accuracy: 0.9514999985694885\n",
      "Epoch 474: 0.15962128341197968, Accuracy: 0.9509999752044678\n",
      "Epoch 475: 0.15935951471328735, Accuracy: 0.9514999985694885\n",
      "Epoch 476: 0.15909820795059204, Accuracy: 0.9510999917984009\n",
      "Epoch 477: 0.15883769094944, Accuracy: 0.95169997215271\n",
      "Epoch 478: 0.1585780382156372, Accuracy: 0.9513000249862671\n",
      "Epoch 479: 0.1583194136619568, Accuracy: 0.95169997215271\n",
      "Epoch 480: 0.1580614596605301, Accuracy: 0.9514999985694885\n",
      "Epoch 481: 0.15780413150787354, Accuracy: 0.95169997215271\n",
      "Epoch 482: 0.1575472503900528, Accuracy: 0.9516000151634216\n",
      "Epoch 483: 0.15729162096977234, Accuracy: 0.9519000053405762\n",
      "Epoch 484: 0.15703649818897247, Accuracy: 0.9517999887466431\n",
      "Epoch 485: 0.1567825824022293, Accuracy: 0.9520000219345093\n",
      "Epoch 486: 0.1565287560224533, Accuracy: 0.9519000053405762\n",
      "Epoch 487: 0.15627603232860565, Accuracy: 0.9520999789237976\n",
      "Epoch 488: 0.15602336823940277, Accuracy: 0.9519000053405762\n",
      "Epoch 489: 0.15577179193496704, Accuracy: 0.9521999955177307\n",
      "Epoch 490: 0.15552064776420593, Accuracy: 0.9519000053405762\n",
      "Epoch 491: 0.15527068078517914, Accuracy: 0.9521999955177307\n",
      "Epoch 492: 0.15502125024795532, Accuracy: 0.9520000219345093\n",
      "Epoch 493: 0.15477240085601807, Accuracy: 0.9523000121116638\n",
      "Epoch 494: 0.15452441573143005, Accuracy: 0.9520999789237976\n",
      "Epoch 495: 0.15427759289741516, Accuracy: 0.9524999856948853\n",
      "Epoch 496: 0.15403124690055847, Accuracy: 0.9523000121116638\n",
      "Epoch 497: 0.1537855565547943, Accuracy: 0.9526000022888184\n",
      "Epoch 498: 0.1535404920578003, Accuracy: 0.9524999856948853\n",
      "Epoch 499: 0.15329666435718536, Accuracy: 0.9531999826431274\n",
      "Epoch 500: 0.15305320918560028, Accuracy: 0.9528999924659729\n",
      "Epoch 501: 0.1528109908103943, Accuracy: 0.9534000158309937\n",
      "Epoch 502: 0.15256918966770172, Accuracy: 0.9531000256538391\n",
      "Epoch 503: 0.1523282527923584, Accuracy: 0.953499972820282\n",
      "Epoch 504: 0.15208768844604492, Accuracy: 0.9532999992370605\n",
      "Epoch 505: 0.1518479883670807, Accuracy: 0.9539999961853027\n",
      "Epoch 506: 0.15160925686359406, Accuracy: 0.953499972820282\n",
      "Epoch 507: 0.15137101709842682, Accuracy: 0.954200029373169\n",
      "Epoch 508: 0.1511334329843521, Accuracy: 0.953499972820282\n",
      "Epoch 509: 0.15089623630046844, Accuracy: 0.954200029373169\n",
      "Epoch 510: 0.15066000819206238, Accuracy: 0.953499972820282\n",
      "Epoch 511: 0.1504240185022354, Accuracy: 0.954200029373169\n",
      "Epoch 512: 0.15018907189369202, Accuracy: 0.9538000226020813\n",
      "Epoch 513: 0.1499548703432083, Accuracy: 0.9544000029563904\n",
      "Epoch 514: 0.14972130954265594, Accuracy: 0.9538999795913696\n",
      "Epoch 515: 0.14948831498622894, Accuracy: 0.9545000195503235\n",
      "Epoch 516: 0.14925654232501984, Accuracy: 0.9542999863624573\n",
      "Epoch 517: 0.14902529120445251, Accuracy: 0.9545000195503235\n",
      "Epoch 518: 0.14879466593265533, Accuracy: 0.9545000195503235\n",
      "Epoch 519: 0.14856474101543427, Accuracy: 0.9545999765396118\n",
      "Epoch 520: 0.14833520352840424, Accuracy: 0.9546999931335449\n",
      "Epoch 521: 0.14810633659362793, Accuracy: 0.9546999931335449\n",
      "Epoch 522: 0.14787812530994415, Accuracy: 0.9550999999046326\n",
      "Epoch 523: 0.14765086770057678, Accuracy: 0.954800009727478\n",
      "Epoch 524: 0.14742381870746613, Accuracy: 0.9550999999046326\n",
      "Epoch 525: 0.147197425365448, Accuracy: 0.9550999999046326\n",
      "Epoch 526: 0.14697177708148956, Accuracy: 0.9552000164985657\n",
      "Epoch 527: 0.14674663543701172, Accuracy: 0.9555000066757202\n",
      "Epoch 528: 0.14652223885059357, Accuracy: 0.955299973487854\n",
      "Epoch 529: 0.14629828929901123, Accuracy: 0.9556999802589417\n",
      "Epoch 530: 0.14607501029968262, Accuracy: 0.9555000066757202\n",
      "Epoch 531: 0.14585207402706146, Accuracy: 0.9556999802589417\n",
      "Epoch 532: 0.14563000202178955, Accuracy: 0.9557999968528748\n",
      "Epoch 533: 0.14540860056877136, Accuracy: 0.9559999704360962\n",
      "Epoch 534: 0.1451881229877472, Accuracy: 0.9557999968528748\n",
      "Epoch 535: 0.14496774971485138, Accuracy: 0.9560999870300293\n",
      "Epoch 536: 0.1447482705116272, Accuracy: 0.9559000134468079\n",
      "Epoch 537: 0.14452894032001495, Accuracy: 0.9560999870300293\n",
      "Epoch 538: 0.14430998265743256, Accuracy: 0.9559000134468079\n",
      "Epoch 539: 0.14409145712852478, Accuracy: 0.9562000036239624\n",
      "Epoch 540: 0.14387348294258118, Accuracy: 0.9559000134468079\n",
      "Epoch 541: 0.14365583658218384, Accuracy: 0.9562000036239624\n",
      "Epoch 542: 0.14343908429145813, Accuracy: 0.9559999704360962\n",
      "Epoch 543: 0.14322270452976227, Accuracy: 0.9562000036239624\n",
      "Epoch 544: 0.14300672709941864, Accuracy: 0.9559000134468079\n",
      "Epoch 545: 0.14279146492481232, Accuracy: 0.9563000202178955\n",
      "Epoch 546: 0.14257732033729553, Accuracy: 0.9559999704360962\n",
      "Epoch 547: 0.1423637866973877, Accuracy: 0.9563000202178955\n",
      "Epoch 548: 0.14215098321437836, Accuracy: 0.9563999772071838\n",
      "Epoch 549: 0.14193843305110931, Accuracy: 0.9563999772071838\n",
      "Epoch 550: 0.14172637462615967, Accuracy: 0.9564999938011169\n",
      "Epoch 551: 0.14151495695114136, Accuracy: 0.95660001039505\n",
      "Epoch 552: 0.1413041055202484, Accuracy: 0.9567000269889832\n",
      "Epoch 553: 0.14109356701374054, Accuracy: 0.9567000269889832\n",
      "Epoch 554: 0.1408834308385849, Accuracy: 0.9567999839782715\n",
      "Epoch 555: 0.14067389070987701, Accuracy: 0.9567999839782715\n",
      "Epoch 556: 0.1404651403427124, Accuracy: 0.957099974155426\n",
      "Epoch 557: 0.14025700092315674, Accuracy: 0.9570000171661377\n",
      "Epoch 558: 0.14004941284656525, Accuracy: 0.9571999907493591\n",
      "Epoch 559: 0.1398424357175827, Accuracy: 0.957099974155426\n",
      "Epoch 560: 0.13963590562343597, Accuracy: 0.9571999907493591\n",
      "Epoch 561: 0.13942977786064148, Accuracy: 0.9573000073432922\n",
      "Epoch 562: 0.13922421634197235, Accuracy: 0.957099974155426\n",
      "Epoch 563: 0.13901881873607635, Accuracy: 0.9574000239372253\n",
      "Epoch 564: 0.13881421089172363, Accuracy: 0.957099974155426\n",
      "Epoch 565: 0.13860996067523956, Accuracy: 0.9574999809265137\n",
      "Epoch 566: 0.13840638101100922, Accuracy: 0.9573000073432922\n",
      "Epoch 567: 0.13820293545722961, Accuracy: 0.9575999975204468\n",
      "Epoch 568: 0.13800032436847687, Accuracy: 0.9573000073432922\n",
      "Epoch 569: 0.13779804110527039, Accuracy: 0.9578999876976013\n",
      "Epoch 570: 0.13759660720825195, Accuracy: 0.9573000073432922\n",
      "Epoch 571: 0.13739562034606934, Accuracy: 0.9578999876976013\n",
      "Epoch 572: 0.13719531893730164, Accuracy: 0.9577000141143799\n",
      "Epoch 573: 0.13699547946453094, Accuracy: 0.9578999876976013\n",
      "Epoch 574: 0.13679607212543488, Accuracy: 0.9577000141143799\n",
      "Epoch 575: 0.136597141623497, Accuracy: 0.9580000042915344\n",
      "Epoch 576: 0.1363985687494278, Accuracy: 0.9577000141143799\n",
      "Epoch 577: 0.13620062172412872, Accuracy: 0.9580000042915344\n",
      "Epoch 578: 0.1360030621290207, Accuracy: 0.9580000042915344\n",
      "Epoch 579: 0.13580617308616638, Accuracy: 0.9581999778747559\n",
      "Epoch 580: 0.13560941815376282, Accuracy: 0.9581000208854675\n",
      "Epoch 581: 0.1354132890701294, Accuracy: 0.958299994468689\n",
      "Epoch 582: 0.13521745800971985, Accuracy: 0.9584000110626221\n",
      "Epoch 583: 0.1350223869085312, Accuracy: 0.9585999846458435\n",
      "Epoch 584: 0.13482779264450073, Accuracy: 0.9585000276565552\n",
      "Epoch 585: 0.1346336305141449, Accuracy: 0.9587000012397766\n",
      "Epoch 586: 0.13443982601165771, Accuracy: 0.9587000012397766\n",
      "Epoch 587: 0.13424639403820038, Accuracy: 0.958899974822998\n",
      "Epoch 588: 0.13405346870422363, Accuracy: 0.9587000012397766\n",
      "Epoch 589: 0.1338612139225006, Accuracy: 0.9589999914169312\n",
      "Epoch 590: 0.13366957008838654, Accuracy: 0.9587000012397766\n",
      "Epoch 591: 0.13347835838794708, Accuracy: 0.9591000080108643\n",
      "Epoch 592: 0.13328750431537628, Accuracy: 0.958899974822998\n",
      "Epoch 593: 0.1330970972776413, Accuracy: 0.9592000246047974\n",
      "Epoch 594: 0.13290724158287048, Accuracy: 0.9591000080108643\n",
      "Epoch 595: 0.13271787762641907, Accuracy: 0.9592999815940857\n",
      "Epoch 596: 0.1325291097164154, Accuracy: 0.9592999815940857\n",
      "Epoch 597: 0.13234087824821472, Accuracy: 0.9593999981880188\n",
      "Epoch 598: 0.13215303421020508, Accuracy: 0.9592999815940857\n",
      "Epoch 599: 0.1319655179977417, Accuracy: 0.9593999981880188\n",
      "Epoch 600: 0.13177864253520966, Accuracy: 0.9592999815940857\n",
      "Epoch 601: 0.1315920203924179, Accuracy: 0.9593999981880188\n",
      "Epoch 602: 0.13140571117401123, Accuracy: 0.9592999815940857\n",
      "Epoch 603: 0.13122011721134186, Accuracy: 0.9593999981880188\n",
      "Epoch 604: 0.13103483617305756, Accuracy: 0.9592999815940857\n",
      "Epoch 605: 0.1308499574661255, Accuracy: 0.9593999981880188\n",
      "Epoch 606: 0.13066543638706207, Accuracy: 0.9592999815940857\n",
      "Epoch 607: 0.13048142194747925, Accuracy: 0.9595000147819519\n",
      "Epoch 608: 0.13029786944389343, Accuracy: 0.9592999815940857\n",
      "Epoch 609: 0.13011454045772552, Accuracy: 0.9595000147819519\n",
      "Epoch 610: 0.12993161380290985, Accuracy: 0.9592999815940857\n",
      "Epoch 611: 0.1297493726015091, Accuracy: 0.9595000147819519\n",
      "Epoch 612: 0.12956762313842773, Accuracy: 0.9592999815940857\n",
      "Epoch 613: 0.129386305809021, Accuracy: 0.9595000147819519\n",
      "Epoch 614: 0.12920519709587097, Accuracy: 0.9593999981880188\n",
      "Epoch 615: 0.12902459502220154, Accuracy: 0.9595999717712402\n",
      "Epoch 616: 0.12884435057640076, Accuracy: 0.9595000147819519\n",
      "Epoch 617: 0.12866441905498505, Accuracy: 0.9598000049591064\n",
      "Epoch 618: 0.1284848153591156, Accuracy: 0.9595999717712402\n",
      "Epoch 619: 0.12830545008182526, Accuracy: 0.9598000049591064\n",
      "Epoch 620: 0.12812656164169312, Accuracy: 0.9595999717712402\n",
      "Epoch 621: 0.12794791162014008, Accuracy: 0.9599000215530396\n",
      "Epoch 622: 0.12776967883110046, Accuracy: 0.9596999883651733\n",
      "Epoch 623: 0.12759172916412354, Accuracy: 0.9599000215530396\n",
      "Epoch 624: 0.12741418182849884, Accuracy: 0.9599000215530396\n",
      "Epoch 625: 0.12723715603351593, Accuracy: 0.9599999785423279\n",
      "Epoch 626: 0.1270604282617569, Accuracy: 0.9599000215530396\n",
      "Epoch 627: 0.12688401341438293, Accuracy: 0.9602000117301941\n",
      "Epoch 628: 0.12670806050300598, Accuracy: 0.9599000215530396\n",
      "Epoch 629: 0.12653270363807678, Accuracy: 0.9602000117301941\n",
      "Epoch 630: 0.12635767459869385, Accuracy: 0.9599999785423279\n",
      "Epoch 631: 0.12618307769298553, Accuracy: 0.9602000117301941\n",
      "Epoch 632: 0.12600931525230408, Accuracy: 0.960099995136261\n",
      "Epoch 633: 0.12583591043949127, Accuracy: 0.9602000117301941\n",
      "Epoch 634: 0.12566322088241577, Accuracy: 0.9599999785423279\n",
      "Epoch 635: 0.1254907250404358, Accuracy: 0.9603000283241272\n",
      "Epoch 636: 0.12531869113445282, Accuracy: 0.9599999785423279\n",
      "Epoch 637: 0.1251470446586609, Accuracy: 0.9603999853134155\n",
      "Epoch 638: 0.12497592717409134, Accuracy: 0.9602000117301941\n",
      "Epoch 639: 0.12480513751506805, Accuracy: 0.9605000019073486\n",
      "Epoch 640: 0.1246349960565567, Accuracy: 0.9602000117301941\n",
      "Epoch 641: 0.12446507811546326, Accuracy: 0.9605000019073486\n",
      "Epoch 642: 0.12429579347372055, Accuracy: 0.9605000019073486\n",
      "Epoch 643: 0.12412658333778381, Accuracy: 0.9606000185012817\n",
      "Epoch 644: 0.12395787239074707, Accuracy: 0.9606000185012817\n",
      "Epoch 645: 0.12378939986228943, Accuracy: 0.9606999754905701\n",
      "Epoch 646: 0.12362141162157059, Accuracy: 0.9606999754905701\n",
      "Epoch 647: 0.12345359474420547, Accuracy: 0.9609000086784363\n",
      "Epoch 648: 0.12328631430864334, Accuracy: 0.9609000086784363\n",
      "Epoch 649: 0.12311934679746628, Accuracy: 0.9609000086784363\n",
      "Epoch 650: 0.12295286357402802, Accuracy: 0.9610000252723694\n",
      "Epoch 651: 0.12278702110052109, Accuracy: 0.9610000252723694\n",
      "Epoch 652: 0.12262154370546341, Accuracy: 0.9610999822616577\n",
      "Epoch 653: 0.12245628982782364, Accuracy: 0.9610999822616577\n",
      "Epoch 654: 0.12229162454605103, Accuracy: 0.9610999822616577\n",
      "Epoch 655: 0.1221272274851799, Accuracy: 0.9613000154495239\n",
      "Epoch 656: 0.12196330726146698, Accuracy: 0.9610999822616577\n",
      "Epoch 657: 0.121799536049366, Accuracy: 0.9613000154495239\n",
      "Epoch 658: 0.12163594365119934, Accuracy: 0.9610999822616577\n",
      "Epoch 659: 0.12147271633148193, Accuracy: 0.9613000154495239\n",
      "Epoch 660: 0.12131009995937347, Accuracy: 0.9611999988555908\n",
      "Epoch 661: 0.12114764004945755, Accuracy: 0.9613000154495239\n",
      "Epoch 662: 0.12098562717437744, Accuracy: 0.9613000154495239\n",
      "Epoch 663: 0.1208239495754242, Accuracy: 0.9613999724388123\n",
      "Epoch 664: 0.12066290527582169, Accuracy: 0.9613999724388123\n",
      "Epoch 665: 0.12050189077854156, Accuracy: 0.9613999724388123\n",
      "Epoch 666: 0.12034124881029129, Accuracy: 0.9614999890327454\n",
      "Epoch 667: 0.12018076330423355, Accuracy: 0.9617000222206116\n",
      "Epoch 668: 0.12002076208591461, Accuracy: 0.9614999890327454\n",
      "Epoch 669: 0.1198611706495285, Accuracy: 0.961899995803833\n",
      "Epoch 670: 0.11970215290784836, Accuracy: 0.9617000222206116\n",
      "Epoch 671: 0.11954347789287567, Accuracy: 0.9620000123977661\n",
      "Epoch 672: 0.1193854957818985, Accuracy: 0.9617000222206116\n",
      "Epoch 673: 0.11922740936279297, Accuracy: 0.9620000123977661\n",
      "Epoch 674: 0.11907017230987549, Accuracy: 0.9617000222206116\n",
      "Epoch 675: 0.11891309916973114, Accuracy: 0.961899995803833\n",
      "Epoch 676: 0.11875662952661514, Accuracy: 0.9617000222206116\n",
      "Epoch 677: 0.1186002567410469, Accuracy: 0.9620000123977661\n",
      "Epoch 678: 0.11844463646411896, Accuracy: 0.9617999792098999\n",
      "Epoch 679: 0.1182892918586731, Accuracy: 0.9621000289916992\n",
      "Epoch 680: 0.11813431233167648, Accuracy: 0.961899995803833\n",
      "Epoch 681: 0.11797979474067688, Accuracy: 0.9620000123977661\n",
      "Epoch 682: 0.11782562732696533, Accuracy: 0.961899995803833\n",
      "Epoch 683: 0.11767170578241348, Accuracy: 0.9620000123977661\n",
      "Epoch 684: 0.11751813441514969, Accuracy: 0.9620000123977661\n",
      "Epoch 685: 0.11736446619033813, Accuracy: 0.961899995803833\n",
      "Epoch 686: 0.11721169203519821, Accuracy: 0.9621000289916992\n",
      "Epoch 687: 0.11705873161554337, Accuracy: 0.9621999859809875\n",
      "Epoch 688: 0.11690636724233627, Accuracy: 0.9621000289916992\n",
      "Epoch 689: 0.1167539581656456, Accuracy: 0.9621999859809875\n",
      "Epoch 690: 0.1166018545627594, Accuracy: 0.9621999859809875\n",
      "Epoch 691: 0.11645016819238663, Accuracy: 0.9623000025749207\n",
      "Epoch 692: 0.1162986159324646, Accuracy: 0.9623000025749207\n",
      "Epoch 693: 0.11614743620157242, Accuracy: 0.9623000025749207\n",
      "Epoch 694: 0.11599662154912949, Accuracy: 0.9621999859809875\n",
      "Epoch 695: 0.11584604531526566, Accuracy: 0.9624000191688538\n",
      "Epoch 696: 0.11569603532552719, Accuracy: 0.9623000025749207\n",
      "Epoch 697: 0.11554629355669022, Accuracy: 0.9624000191688538\n",
      "Epoch 698: 0.11539709568023682, Accuracy: 0.9623000025749207\n",
      "Epoch 699: 0.11524790525436401, Accuracy: 0.9624000191688538\n",
      "Epoch 700: 0.1150992214679718, Accuracy: 0.9621999859809875\n",
      "Epoch 701: 0.11495077610015869, Accuracy: 0.9624000191688538\n",
      "Epoch 702: 0.11480283737182617, Accuracy: 0.9621999859809875\n",
      "Epoch 703: 0.11465523391962051, Accuracy: 0.9624999761581421\n",
      "Epoch 704: 0.11450782418251038, Accuracy: 0.9624000191688538\n",
      "Epoch 705: 0.11436081677675247, Accuracy: 0.9627000093460083\n",
      "Epoch 706: 0.11421394348144531, Accuracy: 0.9624999761581421\n",
      "Epoch 707: 0.1140674501657486, Accuracy: 0.9627000093460083\n",
      "Epoch 708: 0.11392129957675934, Accuracy: 0.9627000093460083\n",
      "Epoch 709: 0.11377541720867157, Accuracy: 0.9627000093460083\n",
      "Epoch 710: 0.11362992227077484, Accuracy: 0.9627000093460083\n",
      "Epoch 711: 0.11348453164100647, Accuracy: 0.9628000259399414\n",
      "Epoch 712: 0.11333974450826645, Accuracy: 0.9627000093460083\n",
      "Epoch 713: 0.11319506168365479, Accuracy: 0.9628000259399414\n",
      "Epoch 714: 0.11305084079504013, Accuracy: 0.9627000093460083\n",
      "Epoch 715: 0.11290667206048965, Accuracy: 0.9628999829292297\n",
      "Epoch 716: 0.11276278644800186, Accuracy: 0.9629999995231628\n",
      "Epoch 717: 0.11261926591396332, Accuracy: 0.9628000259399414\n",
      "Epoch 718: 0.11247604340314865, Accuracy: 0.963100016117096\n",
      "Epoch 719: 0.11233318597078323, Accuracy: 0.9628000259399414\n",
      "Epoch 720: 0.11219056695699692, Accuracy: 0.9631999731063843\n",
      "Epoch 721: 0.11204849183559418, Accuracy: 0.9628999829292297\n",
      "Epoch 722: 0.11190656572580338, Accuracy: 0.9631999731063843\n",
      "Epoch 723: 0.11176507920026779, Accuracy: 0.9631999731063843\n",
      "Epoch 724: 0.1116238608956337, Accuracy: 0.9631999731063843\n",
      "Epoch 725: 0.11148323863744736, Accuracy: 0.9632999897003174\n",
      "Epoch 726: 0.11134278029203415, Accuracy: 0.9634000062942505\n",
      "Epoch 727: 0.11120259016752243, Accuracy: 0.9635000228881836\n",
      "Epoch 728: 0.11106261610984802, Accuracy: 0.9634000062942505\n",
      "Epoch 729: 0.11092285066843033, Accuracy: 0.9635999798774719\n",
      "Epoch 730: 0.11078358441591263, Accuracy: 0.9635000228881836\n",
      "Epoch 731: 0.11064448952674866, Accuracy: 0.9634000062942505\n",
      "Epoch 732: 0.11050558090209961, Accuracy: 0.9635999798774719\n",
      "Epoch 733: 0.11036679893732071, Accuracy: 0.9634000062942505\n",
      "Epoch 734: 0.11022857576608658, Accuracy: 0.963699996471405\n",
      "Epoch 735: 0.11009040474891663, Accuracy: 0.9635000228881836\n",
      "Epoch 736: 0.10995260626077652, Accuracy: 0.9639000296592712\n",
      "Epoch 737: 0.10981503129005432, Accuracy: 0.9635000228881836\n",
      "Epoch 738: 0.10967777669429779, Accuracy: 0.9639999866485596\n",
      "Epoch 739: 0.10954073071479797, Accuracy: 0.9635000228881836\n",
      "Epoch 740: 0.109404057264328, Accuracy: 0.9639999866485596\n",
      "Epoch 741: 0.10926751792430878, Accuracy: 0.963699996471405\n",
      "Epoch 742: 0.10913128405809402, Accuracy: 0.9639000296592712\n",
      "Epoch 743: 0.10899519175291061, Accuracy: 0.963699996471405\n",
      "Epoch 744: 0.10885971039533615, Accuracy: 0.9639000296592712\n",
      "Epoch 745: 0.10872424393892288, Accuracy: 0.963699996471405\n",
      "Epoch 746: 0.10858923196792603, Accuracy: 0.9639999866485596\n",
      "Epoch 747: 0.10845405608415604, Accuracy: 0.963699996471405\n",
      "Epoch 748: 0.10831931978464127, Accuracy: 0.9639999866485596\n",
      "Epoch 749: 0.10818493366241455, Accuracy: 0.9638000130653381\n",
      "Epoch 750: 0.10805099457502365, Accuracy: 0.9639999866485596\n",
      "Epoch 751: 0.10791733860969543, Accuracy: 0.9639999866485596\n",
      "Epoch 752: 0.10778401792049408, Accuracy: 0.9639999866485596\n",
      "Epoch 753: 0.10765103250741959, Accuracy: 0.9639999866485596\n",
      "Epoch 754: 0.10751854628324509, Accuracy: 0.9639999866485596\n",
      "Epoch 755: 0.10738595575094223, Accuracy: 0.9639999866485596\n",
      "Epoch 756: 0.10725405067205429, Accuracy: 0.9641000032424927\n",
      "Epoch 757: 0.10712207108736038, Accuracy: 0.9639999866485596\n",
      "Epoch 758: 0.10699057579040527, Accuracy: 0.9642000198364258\n",
      "Epoch 759: 0.10685910284519196, Accuracy: 0.9639999866485596\n",
      "Epoch 760: 0.10672806203365326, Accuracy: 0.9641000032424927\n",
      "Epoch 761: 0.10659722983837128, Accuracy: 0.9639999866485596\n",
      "Epoch 762: 0.10646659880876541, Accuracy: 0.9642000198364258\n",
      "Epoch 763: 0.10633645951747894, Accuracy: 0.9641000032424927\n",
      "Epoch 764: 0.10620656609535217, Accuracy: 0.9642999768257141\n",
      "Epoch 765: 0.10607721656560898, Accuracy: 0.9641000032424927\n",
      "Epoch 766: 0.10594787448644638, Accuracy: 0.9642999768257141\n",
      "Epoch 767: 0.1058187335729599, Accuracy: 0.9643999934196472\n",
      "Epoch 768: 0.10568983107805252, Accuracy: 0.9642999768257141\n",
      "Epoch 769: 0.10556109994649887, Accuracy: 0.9643999934196472\n",
      "Epoch 770: 0.10543239116668701, Accuracy: 0.9642999768257141\n",
      "Epoch 771: 0.10530366748571396, Accuracy: 0.9643999934196472\n",
      "Epoch 772: 0.10517535358667374, Accuracy: 0.9642999768257141\n",
      "Epoch 773: 0.10504703223705292, Accuracy: 0.9646000266075134\n",
      "Epoch 774: 0.1049191802740097, Accuracy: 0.9646000266075134\n",
      "Epoch 775: 0.1047915518283844, Accuracy: 0.9646000266075134\n",
      "Epoch 776: 0.10466410964727402, Accuracy: 0.9646000266075134\n",
      "Epoch 777: 0.10453732311725616, Accuracy: 0.9646000266075134\n",
      "Epoch 778: 0.10441062599420547, Accuracy: 0.9646999835968018\n",
      "Epoch 779: 0.10428463667631149, Accuracy: 0.9646000266075134\n",
      "Epoch 780: 0.10415838658809662, Accuracy: 0.9648000001907349\n",
      "Epoch 781: 0.10403288900852203, Accuracy: 0.9646999835968018\n",
      "Epoch 782: 0.1039067730307579, Accuracy: 0.964900016784668\n",
      "Epoch 783: 0.10378137230873108, Accuracy: 0.9648000001907349\n",
      "Epoch 784: 0.10365598648786545, Accuracy: 0.964900016784668\n",
      "Epoch 785: 0.10353124886751175, Accuracy: 0.9648000001907349\n",
      "Epoch 786: 0.10340629518032074, Accuracy: 0.964900016784668\n",
      "Epoch 787: 0.10328204184770584, Accuracy: 0.9649999737739563\n",
      "Epoch 788: 0.10315797477960587, Accuracy: 0.964900016784668\n",
      "Epoch 789: 0.10303396731615067, Accuracy: 0.9649999737739563\n",
      "Epoch 790: 0.10291021317243576, Accuracy: 0.964900016784668\n",
      "Epoch 791: 0.10278628021478653, Accuracy: 0.9649999737739563\n",
      "Epoch 792: 0.1026626005768776, Accuracy: 0.9649999737739563\n",
      "Epoch 793: 0.10253899544477463, Accuracy: 0.9649999737739563\n",
      "Epoch 794: 0.10241559892892838, Accuracy: 0.9649999737739563\n",
      "Epoch 795: 0.10229256004095078, Accuracy: 0.9648000001907349\n",
      "Epoch 796: 0.10216985642910004, Accuracy: 0.9649999737739563\n",
      "Epoch 797: 0.10204719752073288, Accuracy: 0.964900016784668\n",
      "Epoch 798: 0.10192537307739258, Accuracy: 0.9649999737739563\n",
      "Epoch 799: 0.10180376470088959, Accuracy: 0.964900016784668\n",
      "Epoch 800: 0.10168244689702988, Accuracy: 0.9649999737739563\n",
      "Epoch 801: 0.10156150162220001, Accuracy: 0.9648000001907349\n",
      "Epoch 802: 0.10144104063510895, Accuracy: 0.9650999903678894\n",
      "Epoch 803: 0.10132065415382385, Accuracy: 0.9648000001907349\n",
      "Epoch 804: 0.10120078921318054, Accuracy: 0.9650999903678894\n",
      "Epoch 805: 0.10108073800802231, Accuracy: 0.9648000001907349\n",
      "Epoch 806: 0.10096121579408646, Accuracy: 0.9650999903678894\n",
      "Epoch 807: 0.10084143280982971, Accuracy: 0.964900016784668\n",
      "Epoch 808: 0.1007222980260849, Accuracy: 0.9650999903678894\n",
      "Epoch 809: 0.1006033718585968, Accuracy: 0.964900016784668\n",
      "Epoch 810: 0.1004849374294281, Accuracy: 0.9652000069618225\n",
      "Epoch 811: 0.1003669872879982, Accuracy: 0.964900016784668\n",
      "Epoch 812: 0.10024856775999069, Accuracy: 0.9652000069618225\n",
      "Epoch 813: 0.1001305803656578, Accuracy: 0.964900016784668\n",
      "Epoch 814: 0.10001224279403687, Accuracy: 0.9652000069618225\n",
      "Epoch 815: 0.09989393502473831, Accuracy: 0.9649999737739563\n",
      "Epoch 816: 0.09977573901414871, Accuracy: 0.9652000069618225\n",
      "Epoch 817: 0.09965799748897552, Accuracy: 0.9649999737739563\n",
      "Epoch 818: 0.09954111278057098, Accuracy: 0.9652000069618225\n",
      "Epoch 819: 0.09942467510700226, Accuracy: 0.9649999737739563\n",
      "Epoch 820: 0.09930888563394547, Accuracy: 0.9652000069618225\n",
      "Epoch 821: 0.09919338673353195, Accuracy: 0.9649999737739563\n",
      "Epoch 822: 0.09907843172550201, Accuracy: 0.9652000069618225\n",
      "Epoch 823: 0.09896312654018402, Accuracy: 0.9649999737739563\n",
      "Epoch 824: 0.09884834289550781, Accuracy: 0.9652000069618225\n",
      "Epoch 825: 0.09873342514038086, Accuracy: 0.9650999903678894\n",
      "Epoch 826: 0.09861844033002853, Accuracy: 0.965399980545044\n",
      "Epoch 827: 0.09850352257490158, Accuracy: 0.9652000069618225\n",
      "Epoch 828: 0.09838913381099701, Accuracy: 0.9656000137329102\n",
      "Epoch 829: 0.09827430546283722, Accuracy: 0.9652000069618225\n",
      "Epoch 830: 0.09816040843725204, Accuracy: 0.9656000137329102\n",
      "Epoch 831: 0.09804657846689224, Accuracy: 0.9652000069618225\n",
      "Epoch 832: 0.09793278574943542, Accuracy: 0.9656000137329102\n",
      "Epoch 833: 0.09781993925571442, Accuracy: 0.9653000235557556\n",
      "Epoch 834: 0.09770645201206207, Accuracy: 0.9656999707221985\n",
      "Epoch 835: 0.09759410470724106, Accuracy: 0.9653000235557556\n",
      "Epoch 836: 0.09748052805662155, Accuracy: 0.9656999707221985\n",
      "Epoch 837: 0.09736883640289307, Accuracy: 0.965399980545044\n",
      "Epoch 838: 0.09725557267665863, Accuracy: 0.9657999873161316\n",
      "Epoch 839: 0.09714354574680328, Accuracy: 0.965399980545044\n",
      "Epoch 840: 0.09703035652637482, Accuracy: 0.9657999873161316\n",
      "Epoch 841: 0.09691882878541946, Accuracy: 0.965399980545044\n",
      "Epoch 842: 0.09680607169866562, Accuracy: 0.9659000039100647\n",
      "Epoch 843: 0.09669483453035355, Accuracy: 0.965499997138977\n",
      "Epoch 844: 0.09658289700746536, Accuracy: 0.9657999873161316\n",
      "Epoch 845: 0.0964716374874115, Accuracy: 0.965499997138977\n",
      "Epoch 846: 0.09636019915342331, Accuracy: 0.9659000039100647\n",
      "Epoch 847: 0.09624972939491272, Accuracy: 0.9656999707221985\n",
      "Epoch 848: 0.09613876789808273, Accuracy: 0.9660000205039978\n",
      "Epoch 849: 0.09602826088666916, Accuracy: 0.9656999707221985\n",
      "Epoch 850: 0.09591817855834961, Accuracy: 0.9660000205039978\n",
      "Epoch 851: 0.09580764174461365, Accuracy: 0.9656000137329102\n",
      "Epoch 852: 0.09569837898015976, Accuracy: 0.9660000205039978\n",
      "Epoch 853: 0.09558811038732529, Accuracy: 0.9656999707221985\n",
      "Epoch 854: 0.09547870606184006, Accuracy: 0.9660000205039978\n",
      "Epoch 855: 0.09536914527416229, Accuracy: 0.9657999873161316\n",
      "Epoch 856: 0.0952608659863472, Accuracy: 0.9660000205039978\n",
      "Epoch 857: 0.09515216201543808, Accuracy: 0.9657999873161316\n",
      "Epoch 858: 0.09504442662000656, Accuracy: 0.9660000205039978\n",
      "Epoch 859: 0.0949360653758049, Accuracy: 0.9659000039100647\n",
      "Epoch 860: 0.09482903778553009, Accuracy: 0.9661999940872192\n",
      "Epoch 861: 0.0947204977273941, Accuracy: 0.9659000039100647\n",
      "Epoch 862: 0.09461387246847153, Accuracy: 0.9661999940872192\n",
      "Epoch 863: 0.09450656920671463, Accuracy: 0.9659000039100647\n",
      "Epoch 864: 0.09440065920352936, Accuracy: 0.9661999940872192\n",
      "Epoch 865: 0.09429407864809036, Accuracy: 0.9659000039100647\n",
      "Epoch 866: 0.09418820589780807, Accuracy: 0.9663000106811523\n",
      "Epoch 867: 0.09408286958932877, Accuracy: 0.9659000039100647\n",
      "Epoch 868: 0.09397811442613602, Accuracy: 0.9664000272750854\n",
      "Epoch 869: 0.093873031437397, Accuracy: 0.9661999940872192\n",
      "Epoch 870: 0.09376832842826843, Accuracy: 0.9664999842643738\n",
      "Epoch 871: 0.09366276860237122, Accuracy: 0.9661999940872192\n",
      "Epoch 872: 0.09355934709310532, Accuracy: 0.9668999910354614\n",
      "Epoch 873: 0.09345358610153198, Accuracy: 0.9661999940872192\n",
      "Epoch 874: 0.0933505967259407, Accuracy: 0.9671000242233276\n",
      "Epoch 875: 0.09324558079242706, Accuracy: 0.9664000272750854\n",
      "Epoch 876: 0.0931428000330925, Accuracy: 0.9674000144004822\n",
      "Epoch 877: 0.09303668141365051, Accuracy: 0.9664000272750854\n",
      "Epoch 878: 0.092934250831604, Accuracy: 0.9674000144004822\n",
      "Epoch 879: 0.09282875806093216, Accuracy: 0.9664999842643738\n",
      "Epoch 880: 0.0927269235253334, Accuracy: 0.9674999713897705\n",
      "Epoch 881: 0.09262170642614365, Accuracy: 0.9664999842643738\n",
      "Epoch 882: 0.09252011030912399, Accuracy: 0.9674999713897705\n",
      "Epoch 883: 0.0924152284860611, Accuracy: 0.9664999842643738\n",
      "Epoch 884: 0.09231434762477875, Accuracy: 0.9674000144004822\n",
      "Epoch 885: 0.09220947325229645, Accuracy: 0.9664999842643738\n",
      "Epoch 886: 0.09210759401321411, Accuracy: 0.9674000144004822\n",
      "Epoch 887: 0.09200304001569748, Accuracy: 0.9664999842643738\n",
      "Epoch 888: 0.09190244972705841, Accuracy: 0.9674999713897705\n",
      "Epoch 889: 0.09179729223251343, Accuracy: 0.9670000076293945\n",
      "Epoch 890: 0.09169565886259079, Accuracy: 0.9674999713897705\n",
      "Epoch 891: 0.09158913046121597, Accuracy: 0.967199981212616\n",
      "Epoch 892: 0.091486856341362, Accuracy: 0.9675999879837036\n",
      "Epoch 893: 0.09138185530900955, Accuracy: 0.9672999978065491\n",
      "Epoch 894: 0.09128020703792572, Accuracy: 0.9675999879837036\n",
      "Epoch 895: 0.09117549657821655, Accuracy: 0.9672999978065491\n",
      "Epoch 896: 0.09107422828674316, Accuracy: 0.9675999879837036\n",
      "Epoch 897: 0.09096982330083847, Accuracy: 0.9674999713897705\n",
      "Epoch 898: 0.09086889773607254, Accuracy: 0.9675999879837036\n",
      "Epoch 899: 0.09076542407274246, Accuracy: 0.9674999713897705\n",
      "Epoch 900: 0.09066542237997055, Accuracy: 0.9675999879837036\n",
      "Epoch 901: 0.0905630812048912, Accuracy: 0.9674999713897705\n",
      "Epoch 902: 0.09046532958745956, Accuracy: 0.9675999879837036\n",
      "Epoch 903: 0.09036335349082947, Accuracy: 0.9674999713897705\n",
      "Epoch 904: 0.09026626497507095, Accuracy: 0.9678000211715698\n",
      "Epoch 905: 0.09016406536102295, Accuracy: 0.9674999713897705\n",
      "Epoch 906: 0.09006725251674652, Accuracy: 0.9678999781608582\n",
      "Epoch 907: 0.08996526151895523, Accuracy: 0.9674999713897705\n",
      "Epoch 908: 0.0898691788315773, Accuracy: 0.9678999781608582\n",
      "Epoch 909: 0.0897677093744278, Accuracy: 0.9674999713897705\n",
      "Epoch 910: 0.0896710678935051, Accuracy: 0.9678999781608582\n",
      "Epoch 911: 0.0895705297589302, Accuracy: 0.9675999879837036\n",
      "Epoch 912: 0.08947311341762543, Accuracy: 0.9679999947547913\n",
      "Epoch 913: 0.08937317132949829, Accuracy: 0.9678000211715698\n",
      "Epoch 914: 0.0892760157585144, Accuracy: 0.9679999947547913\n",
      "Epoch 915: 0.08917586505413055, Accuracy: 0.9678999781608582\n",
      "Epoch 916: 0.08907847851514816, Accuracy: 0.9681000113487244\n",
      "Epoch 917: 0.08897938579320908, Accuracy: 0.9678999781608582\n",
      "Epoch 918: 0.08888279646635056, Accuracy: 0.9682000279426575\n",
      "Epoch 919: 0.08878341317176819, Accuracy: 0.9678999781608582\n",
      "Epoch 920: 0.08868823945522308, Accuracy: 0.9682999849319458\n",
      "Epoch 921: 0.08858921378850937, Accuracy: 0.9679999947547913\n",
      "Epoch 922: 0.08849294483661652, Accuracy: 0.9682999849319458\n",
      "Epoch 923: 0.0883941799402237, Accuracy: 0.9679999947547913\n",
      "Epoch 924: 0.08829943090677261, Accuracy: 0.9682999849319458\n",
      "Epoch 925: 0.0882013589143753, Accuracy: 0.9679999947547913\n",
      "Epoch 926: 0.08810657262802124, Accuracy: 0.9682999849319458\n",
      "Epoch 927: 0.08800897002220154, Accuracy: 0.9679999947547913\n",
      "Epoch 928: 0.08791548013687134, Accuracy: 0.9684000015258789\n",
      "Epoch 929: 0.08781813830137253, Accuracy: 0.9679999947547913\n",
      "Epoch 930: 0.0877247303724289, Accuracy: 0.968500018119812\n",
      "Epoch 931: 0.0876270979642868, Accuracy: 0.9679999947547913\n",
      "Epoch 932: 0.08753352612257004, Accuracy: 0.968500018119812\n",
      "Epoch 933: 0.08743693679571152, Accuracy: 0.9679999947547913\n",
      "Epoch 934: 0.0873425155878067, Accuracy: 0.9685999751091003\n",
      "Epoch 935: 0.08724655956029892, Accuracy: 0.9679999947547913\n",
      "Epoch 936: 0.0871533751487732, Accuracy: 0.9688000082969666\n",
      "Epoch 937: 0.0870579332113266, Accuracy: 0.9679999947547913\n",
      "Epoch 938: 0.08696399629116058, Accuracy: 0.9688000082969666\n",
      "Epoch 939: 0.08686911314725876, Accuracy: 0.9681000113487244\n",
      "Epoch 940: 0.0867764949798584, Accuracy: 0.968999981880188\n",
      "Epoch 941: 0.08668191730976105, Accuracy: 0.9682000279426575\n",
      "Epoch 942: 0.08659037202596664, Accuracy: 0.968999981880188\n",
      "Epoch 943: 0.08649618178606033, Accuracy: 0.9682000279426575\n",
      "Epoch 944: 0.0864047035574913, Accuracy: 0.968999981880188\n",
      "Epoch 945: 0.08631017804145813, Accuracy: 0.9682000279426575\n",
      "Epoch 946: 0.08621825277805328, Accuracy: 0.968999981880188\n",
      "Epoch 947: 0.08612463623285294, Accuracy: 0.9682999849319458\n",
      "Epoch 948: 0.08603357523679733, Accuracy: 0.968999981880188\n",
      "Epoch 949: 0.08594077080488205, Accuracy: 0.968500018119812\n",
      "Epoch 950: 0.08584963530302048, Accuracy: 0.9690999984741211\n",
      "Epoch 951: 0.08575662970542908, Accuracy: 0.9686999917030334\n",
      "Epoch 952: 0.08566629141569138, Accuracy: 0.9690999984741211\n",
      "Epoch 953: 0.08557295054197311, Accuracy: 0.9686999917030334\n",
      "Epoch 954: 0.08548307418823242, Accuracy: 0.9692000150680542\n",
      "Epoch 955: 0.08539024740457535, Accuracy: 0.9688000082969666\n",
      "Epoch 956: 0.08530042320489883, Accuracy: 0.9692000150680542\n",
      "Epoch 957: 0.08520805090665817, Accuracy: 0.968999981880188\n",
      "Epoch 958: 0.0851203128695488, Accuracy: 0.9692000150680542\n",
      "Epoch 959: 0.08502887934446335, Accuracy: 0.9692000150680542\n",
      "Epoch 960: 0.08494193851947784, Accuracy: 0.9692000150680542\n",
      "Epoch 961: 0.08485051989555359, Accuracy: 0.9690999984741211\n",
      "Epoch 962: 0.08476351201534271, Accuracy: 0.9693999886512756\n",
      "Epoch 963: 0.08467304706573486, Accuracy: 0.9690999984741211\n",
      "Epoch 964: 0.08458603173494339, Accuracy: 0.9695000052452087\n",
      "Epoch 965: 0.08449569344520569, Accuracy: 0.9692000150680542\n",
      "Epoch 966: 0.08440949022769928, Accuracy: 0.9695000052452087\n",
      "Epoch 967: 0.08431971073150635, Accuracy: 0.9692000150680542\n",
      "Epoch 968: 0.0842345729470253, Accuracy: 0.9695000052452087\n",
      "Epoch 969: 0.08414578437805176, Accuracy: 0.9692000150680542\n",
      "Epoch 970: 0.08406195789575577, Accuracy: 0.9695000052452087\n",
      "Epoch 971: 0.08397344499826431, Accuracy: 0.9692000150680542\n",
      "Epoch 972: 0.08389125019311905, Accuracy: 0.9695000052452087\n",
      "Epoch 973: 0.08380240201950073, Accuracy: 0.9693999886512756\n",
      "Epoch 974: 0.08371903747320175, Accuracy: 0.9696000218391418\n",
      "Epoch 975: 0.08363030850887299, Accuracy: 0.9693999886512756\n",
      "Epoch 976: 0.08354777842760086, Accuracy: 0.9696000218391418\n",
      "Epoch 977: 0.08345983177423477, Accuracy: 0.9693999886512756\n",
      "Epoch 978: 0.08337874710559845, Accuracy: 0.9696000218391418\n",
      "Epoch 979: 0.0832914412021637, Accuracy: 0.9696000218391418\n",
      "Epoch 980: 0.08321025967597961, Accuracy: 0.9696000218391418\n",
      "Epoch 981: 0.08312015235424042, Accuracy: 0.9695000052452087\n",
      "Epoch 982: 0.08303838223218918, Accuracy: 0.9696000218391418\n",
      "Epoch 983: 0.08294855803251266, Accuracy: 0.9695000052452087\n",
      "Epoch 984: 0.0828675851225853, Accuracy: 0.9696000218391418\n",
      "Epoch 985: 0.08277751505374908, Accuracy: 0.9695000052452087\n",
      "Epoch 986: 0.08269575983285904, Accuracy: 0.9696000218391418\n",
      "Epoch 987: 0.082606740295887, Accuracy: 0.9695000052452087\n",
      "Epoch 988: 0.08252336084842682, Accuracy: 0.9696000218391418\n",
      "Epoch 989: 0.08243408054113388, Accuracy: 0.9695000052452087\n",
      "Epoch 990: 0.08235141634941101, Accuracy: 0.9696000218391418\n",
      "Epoch 991: 0.08226197957992554, Accuracy: 0.9695000052452087\n",
      "Epoch 992: 0.08218010514974594, Accuracy: 0.9696000218391418\n",
      "Epoch 993: 0.0820910707116127, Accuracy: 0.9696000218391418\n",
      "Epoch 994: 0.08200990408658981, Accuracy: 0.9696999788284302\n",
      "Epoch 995: 0.0819217637181282, Accuracy: 0.9696000218391418\n",
      "Epoch 996: 0.08184143155813217, Accuracy: 0.9696999788284302\n",
      "Epoch 997: 0.08175388723611832, Accuracy: 0.9696000218391418\n",
      "Epoch 998: 0.08167374134063721, Accuracy: 0.9696999788284302\n",
      "Epoch 999: 0.08158668875694275, Accuracy: 0.9696000218391418\n",
      "Epoch 1000: 0.08150739967823029, Accuracy: 0.9696999788284302\n"
     ]
    }
   ],
   "source": [
    "def ensemble():\n",
    "    trained_coeffs = train_deep_net(epochs, lr=lr, trn_indep=trn_indep, trn_dep=trn_dep)\n",
    "    return calc_preds(trained_coeffs, tst_indep)\n",
    "\n",
    "learns = [ensemble() for _ in range(5)]\n",
    "ens_preds = torch.stack(learns).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageId,Label\n",
      "1,2\n",
      "2,0\n",
      "3,9\n",
      "4,9\n",
      "5,3\n",
      "6,7\n",
      "7,0\n",
      "8,3\n",
      "9,0\n"
     ]
    }
   ],
   "source": [
    "tst_df['ImageId'] = range(1, len(tst_df) + 1)\n",
    "tst_df['Label'] = torch.argmax(ens_preds, dim=1)\n",
    "sub_df = tst_df[['ImageId','Label']]\n",
    "sub_df.to_csv('ens_sub.csv', index=False)\n",
    "\n",
    "!head ens_sub.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
